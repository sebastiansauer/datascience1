# Regularisierte Modelle




```{r global-knitr-options, include=FALSE}
  knitr::opts_chunk$set(
  fig.pos = 'H',
  fig.asp = 0.618,
  fig.align='center',
  fig.width = 5,
  out.width = "100%",
  fig.cap = "", 
  dpi = 300,
  # tidy = TRUE,
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  fig.show = "hold")
```




## Lernsteuerung

```{r chapter-start-sections, echo = FALSE, results = "asis"}
source("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/R-Code/render-course-sections.R")

source("funs/chapter-start-sections.R")
#chapter_start_sections(title = "Regularisierung")
```








## Vorbereitung


In diesem Kapitel werden folgende R-Pakete benötigt:

```{r echo = TRUE}
library(tidymodels)
library(tictoc)  # Zeitmessung
```




## Was ist Regularisierung?


Regularisieren verweist auf "regulär"; 
laut [Duden]() bedeutet das Wort so viel wie "den Regeln, Bestimmungen, 
Vorschriften entsprechend; vorschriftsmäßig, ordnungsgemäß, richtig" oder "üblich".

Im Englischen spricht man auch von "penalized models", "bestrafte Modell" und von "shrinkage",
von "Schrumpfung" im Zusammenhang mit dieer Art von Modellen.

Regularisierung ist ein Metalalgorithmus, also ein Verfahren, was als zweiter Schritt "auf" verschiedene 
Modelle angewendet werden kann - zumeist aber auf lineare Modelle, worauf 
wir uns im Folgenden konzentrieren.

Das Ziel von Regularisierung ist es, Overfitting zu vermeiden,
in dem die Komplexität eines Modells reduziert wird.
Der Effekt von Regularisierung ist, 
dass die Varianz der Modelle verringert wird und damit das Overfitting.
Der Preis ist, dass der Bias erhöht wird,
aber oft geht die Rechnung auf, dass der Gewinn größer ist als der Verlust.

Im Kontext von linearen Modellen bedeutet das,
dass die Koeffizienten ($\beta$s) im Betrag verringert werden durch Regularisierung,
also in Richtung Null "geschrumpft" werden.

Dem liegt die Idee zugrunde,
dass extreme Werte in den Koeffizienten vermutlich nicht "echt", sondern durch Rauschen
fälschlich vorgegaukelt werden.

Die bekanntesten Vertreter dieser Modellart sind *Ridge Regression*, $L2$, das *Lasso*, $L1$, sowie *Elastic Net*.


## Ähnliche Verfahren

 Ein ähnliches
Ziel wie der Regulaisierung liegt dem Pruning zugrunde, 
dem nachträglichen Beschneiden von Entscheidungsbäumen.
In beiden Fällen wird die Komplexität des Modells verringert,
und damit die Varianz auf Kosten eines möglichen Anstiegs der Verzerrung (Bias)
des Modells. Unterm Strich hofft man, dass der Gewinn die Kosten übersteigt
und somit der Fit im Test-Sample besser wird.



Eine Andere Art der Regularisierung wird durch die Verwendung von Bayes-Modellen erreicht:
Setzt man einen konservativen Prior, etwa mit Mittelwert Null und kleiner Streuung,
so werden die Posteriori-Koeffizienten gegen Null hin geschrumpft werden.

Mit Mehrebenen-Modellen (Multi Level Models) lässt sich ein ähnlicher Effekt erreichen.






## Normale Regression (OLS)



Man kann sich fragen, warum sollte man an der normalen Least-Square-Regression 
(OLS: Ordinary Least Square) weiter herumbasteln wollen,
schließlich garantiert das Gauss-Markov-Theorem, dass eine lineare Regression
den besten linearen unverzerrten Schätzwert (BLUE, best linear unbiased estimator) stellt,
vorausgesetzt die Voraussetzungen der Regression sind erfüllt.

Ja, die Schätzwerte (Vorhersagen) der Regression sind BLUE, schätzen also den wahren
Wert korrekt und maximal präzise. Das gilt (natürlich) nur, wenn die Voraussetzungen der Regression erfüllt
sind, also vor allem, dass die Beziehung auch linear-additiv ist.



Zur Erinnerung, mit OLS minimiert man  man den quadrierten Fehler, $RSS$, Residual Sum of Square:


$$RSS = \sum_{i=1}^n \left(y_i - \beta_0 - \sum_{j=1}^p \beta_j x_{ij} \right)$$

Abb. \@ref(fig:ols) visualisiert die Optimierung mit OLS [Quelle](https://www.crumplab.com/rstatsforpsych/regression.html).
An [gleicher Stelle](https://www.crumplab.com/rstatsforpsych/regression.html) findet sich
eine gute Darstellung zu den (mathematischen) Grundlagen der OLS-Regression.

```{r ols, fig.cap = "Visualisierung der Minimierung der RSS durch OLS", out.width = "70%"}
knitr::include_graphics("https://www.crumplab.com/rstatsforpsych/imgs/regression_squares.gif")
```


Übrigens nennt man Funktionen, die man minimiert mit Hilfe von Methoden des maschinellen Lernens 
mit dem Ziel die optimalen Koeffizienten (wie $\beta$s) zu finden, auch *Loss Functions* (Kostenfunktion).

Das Problem der Regression ist, dass die schöne Eigenschaft BLUE nur im *Train-Sample*, *nicht* (notwendig)
im Test-Sample gilt.




## Ridge Regression, L2


Ridge Regression ist sehr ähnlich zum OLS-Algorithmus,
nur das ein "Strafterm aufgebrummt" wird, der $RSS$ erhöht.


Der Gesamtterm, der optimiert wird, $L_{l2}$ (Loss L2) ist also
die Summe aus RSS und dem Strafterm:


$$L_{L2} = RSS + \text{Strafterm}$$

Der Strafterm ist so aufgebaut,
dass (im Absolutbetrag) größere Koeffizienten mehr zum Fehler beitragen,
also eine Funktion der (quadrierten) Summe der Absolutwerte der Koeffizienten:


$$\text{Strafterm} = \lambda \sum_{j=1}^p \beta_j^2$$


Dabei ist $\lambda$ (lambda) ein Tuningparameter, 
der bestimmt, wie stark die Bestrafung ausfällt. Den Wert von $\lambda$ lassen wir durch
Tuning bestimmen, wobei $\lambda \in \mathbb{R}^+\setminus\{0\}$. 
Es gilt: Je größer lambda, desto stärker die Schrumpfung der Koeffizienten gegen Null,
da der gesamte zu minimierende Term, $L_{L2}$ entsprechend durch lambda vergrößert wird.

‚

<!-- ## Aufgaben und Vertiefung -->




```{r render-outline-vertiefung-aufgaben, results = "asis", echo = FALSE, message = FALSE, eval = FALSE}
source("https://raw.githubusercontent.com/sebastiansauer/Lehre/main/R-Code/render-course-sections.R")

render_section(course_dates_file,
                 content_file,
                 i = NULL,
                 title = "Regularisierung",
                 name = "Aufgaben",
                 header_level = 1)


render_section(course_dates_file,
               content_file,
               i = NULL, 
               title = "Regularisierung",
               name = "Vertiefung",
               header_level = 1)
```
