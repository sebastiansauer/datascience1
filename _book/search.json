[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "",
    "text": "1 Zu diesem Buch\nQuelle: ImageFlip"
  },
  {
    "objectID": "index.html#was-rÃ¤t-meister-yoda",
    "href": "index.html#was-rÃ¤t-meister-yoda",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "\n1.1 Was rÃ¤t Meister Yoda?",
    "text": "1.1 Was rÃ¤t Meister Yoda?\nMeister Yoda rÃ¤t: Lesen Sie die Hinweise (AbbildungÂ 1.1).\n\n\nAbbildungÂ 1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\n\nQuelle: made at imageflip"
  },
  {
    "objectID": "index.html#selbstÃ¤ndige-vorbereitung-vor-kursbeginn",
    "href": "index.html#selbstÃ¤ndige-vorbereitung-vor-kursbeginn",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "\n1.2 SelbstÃ¤ndige Vorbereitung vor Kursbeginn",
    "text": "1.2 SelbstÃ¤ndige Vorbereitung vor Kursbeginn\nDie folgenden Inhalte werden in diesem Buch/Kurs vorausgesetzt. Falls Ihnen der Stoff nicht gelÃ¤ufig ist, sollten Sie sich selbstÃ¤ndig damit vertraut machen.\n\nGrundlagen der Statistik wie im Kurs Statistik1 vermittelt\nEinfÃ¼hrung in die Inferenzstatistik wie im Kurs Bayes:Start! vermittelt"
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "\n1.3 Zitation",
    "text": "1.3 Zitation\nNutzen Sie folgende DOI, um dieses Buch zu zitieren: \nHier ist die Zitation im Bibtex-Format:\n@online{sauer_grundlagen_2023,\n    title = {Grundlagen der Prognosemodellierung},\n    rights = {{MIT}},\n    url = {https://ds1-prognosemodellierung.netlify.app/},\n    type = {Kursbuch},\n    author = {Sauer, Sebastian},\n    date = {2023-08-24},\n}"
  },
  {
    "objectID": "index.html#quellcode",
    "href": "index.html#quellcode",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "\n1.4 Quellcode",
    "text": "1.4 Quellcode\nDer Quellcode liegt Ã¶ffentlich zugÃ¤nglich in diesem Github-Repositorium."
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°",
    "section": "\n1.5 Technische Details",
    "text": "1.5 Technische Details\n\nDiese Version des Buches wurde erstellt am: 2023-08-24 16:07:44\nDie URL zu diesem Buch lautet https://sebastiansauer.github.io/datascience1/ und ist bei GitHub Pages gehostet.\nDen Quellcode finden Sie in diesem Github-Repo.\nSie haben Feedback, Fehlerhinweise oder WÃ¼nsche zur Weiterentwicklung? Am besten stellen Sie hier einen Issue ein.\nDieses Projekt steht unter der MIT-Lizenz.\nDieses Buch wurde in RStudio mit Hilfe von bookdown geschrieben.\nDiese Version des Buches wurde mit der R-Version R version 4.2.1 (2022-06-23) und den folgenden technischen Spezifikationen erstellt:\n\n\n## â”€ Session info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23)\n##  os       macOS Big Sur ... 10.16\n##  system   x86_64, darwin17.0\n##  ui       X11\n##  language (EN)\n##  collate  en_US.UTF-8\n##  ctype    en_US.UTF-8\n##  tz       Europe/Berlin\n##  date     2023-05-03\n##  pandoc   2.19.2 @ /Applications/RStudio.app/Contents/Resources/app/quarto/bin/tools/ (via rmarkdown)\n## \n## â”€ Packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n##  package     * version date (UTC) lib source\n##  cli           3.6.1   2023-03-23 [1] CRAN (R 4.2.0)\n##  colorout    * 1.2-2   2022-06-13 [1] local\n##  digest        0.6.31  2022-12-11 [1] CRAN (R 4.2.0)\n##  evaluate      0.20    2023-01-17 [1] CRAN (R 4.2.0)\n##  fastmap       1.1.1   2023-02-24 [1] CRAN (R 4.2.0)\n##  htmltools     0.5.5   2023-03-23 [1] CRAN (R 4.2.0)\n##  htmlwidgets   1.6.2   2023-03-17 [1] CRAN (R 4.2.0)\n##  jsonlite      1.8.4   2022-12-06 [1] CRAN (R 4.2.0)\n##  knitr         1.42    2023-01-25 [1] CRAN (R 4.2.0)\n##  rlang         1.1.0   2023-03-14 [1] CRAN (R 4.2.0)\n##  rmarkdown     2.21    2023-03-26 [1] CRAN (R 4.2.0)\n##  rstudioapi    0.14    2022-08-22 [1] CRAN (R 4.2.0)\n##  sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.2.0)\n##  xfun          0.38    2023-03-24 [1] CRAN (R 4.2.0)\n##  yaml          2.3.7   2023-01-23 [1] CRAN (R 4.2.0)\n## \n##  [1] /Users/sebastiansaueruser/Rlibs\n##  [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n## \n## â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
  },
  {
    "objectID": "010-Hinweise.html#ihr-lernerfolg",
    "href": "010-Hinweise.html#ihr-lernerfolg",
    "title": "Lernhilfen",
    "section": "\n2.1 Ihr Lernerfolg",
    "text": "2.1 Ihr Lernerfolg\n\n2.1.1 Was Sie hier lernen und wozu das gut ist\nAlle Welt spricht von Big Data, aber ohne die Analyse sind die groÃŸen Daten nur groÃŸes Rauschen. Was letztlich interessiert, sind die Erkenntnisse, die Einblicke, nicht die Daten an sich. Dabei ist es egal, ob die Daten groÃŸ oder klein sind. NatÃ¼rlich erlauben die heutigen Datenmengen im Verbund mit leistungsfÃ¤higen Rechnern und neuen Analysemethoden ein VerstÃ¤ndnis, das vor Kurzem noch nicht mÃ¶glich war. Und wir stehen erst am Anfang dieser Entwicklung. Vielleicht handelt es sich bei diesem Feld um eines der dynamischsten Fachgebiete der heutigen Zeit. Sie sind dabei: Sie lernen einiges Handwerkszeugs des â€œDatenwissenschaftlersâ€. Wir konzentrieren uns auf das vielleicht bekannteste Teilgebiet: Ereignisse vorhersagen auf Basis von hoch strukturierten Daten und geeigneter Algorithmen und Verfahren. Nach diesem Kurs sollten Sie in der Lage sein, typisches Gebabbel des Fachgebiet mit LÃ¤ssigkeit mitzumachen. Ach ja, und mit einigem Erfolg Vorhersagemodelle entwickeln.\n\n2.1.2 Lernziele\n\n\n\n\n\n\nWichtig\n\n\n\nKurz gesagt: Sie lernen die Grundlagen von Data Science.\\(\\square\\)\n\n\nNach diesem Kurs sollten Sie\n\ngrundlegende Konzepte des statistischen Lernens verstehen und mit R anwenden kÃ¶nnen\ngÃ¤ngige Prognose-Algorithmen kennen, in GrundzÃ¼gen verstehen und mit R anwenden kÃ¶nnen\ndie GÃ¼te und Grenze von Prognosemodellen einschÃ¤tzen kÃ¶nnen\n\n2.1.3 Ãœberblick\nAbb. AbbildungÂ 2.1 gibt einen Ãœberblick Ã¼ber den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Grundlagen]\n      direction TB\n      E[R] --- Um[Statistisches&lt;br&gt;Lernen]\n      Um --- tm[tidymodels]\n    end\n    subgraph M[Lernalgorithmen]\n      direction TB\n      M1[Regression] --- Vis[Baeume]\n      Vis --- U[Regularisierung]\n      U --- G[...]\n    end\n    subgraph N[Anwendung]\n      direction TB\n      D[Fallstudien]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\nAbbildungÂ 2.1: Ein â€˜Fahrplanâ€™ als â€˜Big Pictureâ€™ dieses Buches\n\n\n\n\n2.1.4 Modulzeitplan\n\n\n\n\n\n\n\n\n\n\n\n\n\nNr\n      Thema\n      Datum\n      Kommentar\n    \n\n\n1\nStatistisches Lernen\n13.3. - 19.3.\nLehrbeginn ist am Mi., 15.3.23\n\n\n2\nStatistisches Lernen\n20.3. - 26.3.\nNA\n\n\n3\nR, zweiter Blick\n27.3. - 2.4.\nNA\n\n\n4\nR, zweiter Blick\n3.4. - 9.4\nKarwoche (kein Unterricht am Do. und Fr.)\n\n\n5\ntidymodels\n10.4. - 16.4.\nOsterwoche (kein Unterricht am Mo. und Di.)\n\n\n6\nknn\n17.4. - 23.4.\nNA\n\n\n7\nResampling und Tuning\n24.4. - 30.4.\nNA\n\n\n8\nLogistische Regression\n1.5. - 7.5.\nMaifeiertag (kein Unterricht am Mo.)\n\n\n9\nEntscheidungsbÃ¤ume\n8.5. - 14.5.\nNA\n\n\n10\nBaumbasierte Modelle\n15.5. - 21.5.\nNA\n\n\n11\n-\n22.5. - 28.5.\nBlockwocke - kein regulÃ¤rer Unterricht\n\n\n12\nRegularisierung\n29.6. - 4.6.\nPfingstwoche (kein Unterricht am Mo. und Di.)\n\n\n13\nRegularisierung\n5.6. - 11.6.\nFronleichnam (kein Unterricht am Do. und Fr.)\n\n\n14\nFallstudien bei Kaggle\n12.6. - 18.6.\nNA\n\n\n15\nDimensionsreduktion\n19.6. - 25.6.\nNA\n\n\n16\nDer rote Faden\n26.6. - 2.7.\nLetzter Lehrtag ist Fr., 30.6.\n\n\n\n\n\n\n\n2.1.5 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, mÃ¶glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse"
  },
  {
    "objectID": "010-Hinweise.html#lernhilfen",
    "href": "010-Hinweise.html#lernhilfen",
    "title": "Lernhilfen",
    "section": "\n2.2 Lernhilfen",
    "text": "2.2 Lernhilfen\n\n2.2.1 PDF-Version\nUm eine PDF-Version eines Kapitels zu erhalten, kÃ¶nnen Sie im Browser die Druckfunktion nutzen (Strg-P). WÃ¤hlen Sie dort â€œPDFâ€ als Ziel.\n\n2.2.2 Videos\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buchs. Besonders diese Playlist passt zu den Inhalten dieses Buchs.\n\n2.2.3 Software\nInstallieren Sie R und seine Freunde. FÃ¼r die Bayes-Inferenz brauchen Sie1 zusÃ¤tzliche Software, was leider etwas Zusatzaufwand erfordert. Lesen Sie hier die Hinweise dazu. Installieren Sie die folgende R-Pakete2:\n\ntidyverse\neasystats\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n2.2.4 Online-UnterstÃ¼tzung\nDieser Kurs kann in PrÃ¤senz und Online angeboten werden. Wenn Sie die Wahl haben, empfehle ich die Teilnahme in PrÃ¤senz, da der Lernerfolg hÃ¶her ist. Online ist es meist schwieriger, sich zu konzentrieren. Aber auch online ist es mÃ¶glich, den Stoff gut zu lernen, s. AbbildungÂ 2.2.\n\n\nAbbildungÂ 2.2: We believe in you! Image Credit: Allison Horst\n\nBitte beachten Sie, dass bei einer Teilnahme in PrÃ¤senz eine aktive Mitarbeit erwartet wird. Hingegen ist bei einer Online-Teilnahme keine/kaum aktive Mitarbeit mÃ¶glich.\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen wÃ¤hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\n\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von ArbeitsbeitrÃ¤gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\nNutzen Sie das vom Dozenten bereitgestelle Forum, um Fragen zu stellen und Fragen zu beantworten.\n\n2.2.5 Lerntipps\n\n\n\n\n\n\nHinweis\n\n\n\nStetige Mitarbeit - auch und gerade auÃŸerhalb des Unterrichts - ist der SchlÃ¼ssel zum PrÃ¼fungserfolg.\n\n\n\n\nLerngruppe: Treten Sie einer Lerngruppe bei.\n\nTutorium: Besuchen Sie ein Tutorium, falls eines angeboten wird.\n\nVor- und Nachbereitung: Bereiten Sie den Unterricht vor und nach.\n\nSelbsttest: Testen Sie sich mit Flashcards (Karteikarten mit Vor- und RÃ¼ckseite). Wenn Sie alle Aufgaben dieses Kurses aus dem FF beherrschen, sollte die PrÃ¼fung kein Problem sein.\n\nÃœbungen: Bearbeiten Sie alle Ãœbungsaufgaben gewissenhaft.\nPortal Datenwerk: Gehen Sie die Aufgaben auf dem Portal Datenwerk durch (soweit relevant).\n\nFallstudien: Schauen Sie sich meine Fallstudiensammlungen an: https://sebastiansauer-academic.netlify.app/courseware/casestudies/\n\nLehrkraft ansprechen: Sprechen Sie die Lehrkraft an, wenn Sie Fragen haben. Haben Sie keine Scheu! Bitte lesen Sie aber vorab die Hinweise, um Redundanz zu vermeiden.\n\n2.2.6 Selbstlernkontrolle\nFÃ¼r jedes Kapitel sind (am Kapitelende) Aufgaben eingestellt, jeweils mit LÃ¶sung. Ein Teil dieser Aufgaben hat eine kurze, eindeutige LÃ¶sung (z.B. â€œ42â€ oder â€œAntwort Câ€); ein (kleiner) Teil der Aufgaben verlangen komplexere Antworten (z.B. â€œWelche Arten von Prioris gibt es bei stan_glm()?). Nutzen Sie die Fragen mit eindeutiger, kurzer LÃ¶sung um sich selber zu prÃ¼fen. Nutzen Sie die Fragen mit komplexerer, lÃ¤ngerer LÃ¶sung, um ein Themengebiet tiefer zu erarbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nFortwÃ¤hrendes Feedback zu Ihrem Lernfortschritt ist wichtig, damit Sie Ihre LernbemÃ¼hungen steuern kÃ¶nnen. Bearbeiten Sie daher die bereitgestellten Arbeiten ernsthaft.\n\n\n\n2.2.7 Lernen lernen\nHier sind einige Quellen (Literatur), die Ihnen helfen sollen, das Lernen (noch besser) zu lernen:\n\nEssentielle Tipps fÃ¼r Bachelor-Studierende der Psychologie\nKonzentriert arbeiten: Regeln fÃ¼r eine Welt voller Ablenkungen\nWie man ein Buch liest\nErsti-Hilfe: 112 Tipps fÃ¼r StudienanfÃ¤nger - erfolgreich studieren ab der ersten Vorlesung\nVon der KÃ¼rze des Lebens\nBlog â€œStudienscheissâ€"
  },
  {
    "objectID": "010-Hinweise.html#literatur",
    "href": "010-Hinweise.html#literatur",
    "title": "Lernhilfen",
    "section": "\n2.3 Literatur",
    "text": "2.3 Literatur\nZentrale Kursliteratur fÃ¼r die theoretischen Konzepte ist Rhys (2020). Bitte prÃ¼fen Sie, ob das Buch in einer Bibliothek verfÃ¼gbar ist. Die praktische Umsetzung in R basiert auf Silge und Kuhn (2022) (dem â€œTidymodels-Konzeptâ€); das Buch ist frei online verfÃ¼gbar.\nEine gute ErgÃ¤nzung ist das Lehrbuch von Timbers, Campbell, und Lee (2022), welches grundlegende Data-Science-Konzepte erlÃ¤utert und mit tidymodels umsetzt.\nJames u.Â a. (2021) haben ein weithin renommiertes und sehr bekanntes Buch verfasst. Es ist allerdings etwas anspruchsvoller aus Rhys (2020), daher steht es nicht im Fokus dieses Kurses, aber einige Schwenker zu Inhalten von James u.Â a. (2021) gibt es. Schauen Sie mal rein, das Buch ist gut!\nIn einigen Punkten ist weiterhin Sauer (2019) hilfreich; das Buch ist Ã¼ber SpringerLink in Ihrer Hochschul-Bibliothek verfÃ¼gbar. Eine gute ErgÃ¤nzung ist das â€œLab-Buchâ€ von Hvitfeldt (2022). In dem Buch wird das Lehrbuch James u.Â a. (2021) in Tidymodels-Konzepte Ã¼bersetzt; durchaus nett!"
  },
  {
    "objectID": "010-Hinweise.html#faq",
    "href": "010-Hinweise.html#faq",
    "title": "Lernhilfen",
    "section": "\n2.4 FAQ",
    "text": "2.4 FAQ\n\n\nFolien\n\nFrage: Gibt es ein Folienskript?\nAntwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zugÃ¤ngliche Literatur gibt, dort gibt es ein Skript.\n\n\n\nEnglisch\n\nIst die Literatur auf Englisch?\nJa. Allerdings ist die Literatur gut zugÃ¤nglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca in Wissenschaft und Wirtschaft. Ein solides VerstÃ¤ndnis englischer (geschriebener) Sprache ist fÃ¼r eine gute Ausbildung unerlÃ¤sslich. Zu dem sollte die Kursliteratur fachlich passende und gute BÃ¼cher umfassen; oft sind das englische Titel.\n\n\n\nAnstrengend\n\nIst der Kurs sehr anstrengend, aufwÃ¤ndig?\nDer Kurs hat ein mittleres Anspruchsniveau.\n\n\n\nMathe\n\nMuss man ein Mathe-Crack sein, um eine gute Note zu erreichen?\nNein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur an, sie werden wenig Mathe darin finden.\n\n\n\nPrÃ¼fungsliteratur\n\nWelche Literatur ist prÃ¼fungsrelevant?\nPrÃ¼fungsrelevant im engeren Sinne ist das Skript sowie alles, was im Unterricht behandelt wurde.\n\n\n\nPrÃ¼fung\n\nWie sieht die PrÃ¼fung aus?\nDie PrÃ¼fung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, in der reines Wissen abgefragt wird.\n\n\n\nNur R?\n\nWird nur R in dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig.\nIn der Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. In einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit eingerÃ¤umt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen.\n\n\n\n\n\n\n\nHvitfeldt, Emil. 2022. ISLR tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, und Melissa Lee. 2022. Data science: an introduction. First edition. Statistics. Boca Raton: CRC Press."
  },
  {
    "objectID": "010-Hinweise.html#footnotes",
    "href": "010-Hinweise.html#footnotes",
    "title": "Lernhilfen",
    "section": "",
    "text": "nicht gleich zu Beginn, aber nach 2-3 Wochenâ†©ï¸\nfalls Sie die Pakete schon installiert haben, kÃ¶nnten Sie mal in RStudio auf â€œupdate.packagesâ€ klickenâ†©ï¸"
  },
  {
    "objectID": "030-Pruefung.html#Ã¼berblick",
    "href": "030-Pruefung.html#Ã¼berblick",
    "title": "3Â  PrÃ¼fung",
    "section": "3.1 Ãœberblick",
    "text": "3.1 Ãœberblick\nDie PrÃ¼fungsleistung besteht aus einer Hauptleistung und einer Bonusleistung.\n\n3.1.1 Bonusleistung\n\nBei der PrÃ¼fungsleistung der Bonusleistung handelt es sich um ein FachggesprÃ¤ch.\nIm Rahmen des FachgesprÃ¤chs stellt die Lehrkraft fachliche Fragen und Sie beantworten diese.\nDie Fragen speisen sich aus dem kompletten (prÃ¼fungsrelevanten) Stoffes des Moduls.\nDer prÃ¼fungsrelevante Stoff besteht aus den Inhalten des Skriptes sowie allem, was auÃŸerdem im Unterricht besprochen wurde.\nDie Dauer dieser PrÃ¼fungsleistung betrÃ¤gt ca. 10 Minuten.\nDie Bewertung erfolgt anhand der EinschÃ¤tzung â€œbestandenâ€ oder â€œnicht bestandenâ€.\nEine bestandene Bonusleistung verbessert die Gesamtnote um 0,3 Notenstufen.\nEs sind keine Hilfsmittel erlaubt.\nDie PrÃ¼fung kann nur in PrÃ¤senz erbracht werden, nicht online. Grund dafÃ¼r ist die Vergleichbarkeit der PrÃ¼fungsbedingungen und dass der korrekte (Nicht-)Gebrauch von (unerlaubten) Hilfsmitteln online schwer kontrolliert werden kann.\nWeitere Hinweise finden Sie in der PrÃ¼fungsordnung.\n\n\n3.1.2 Hauptleistung\nDie Hauptleistung besteht aus einer Projektarbeit in Form eines Prognosewettbewerbs.\n\nGegenstand dieser PrÃ¼fungsform ist eine Projektarbeit in Form eines Prognosewettbewerbs.\n\n\n3.1.3 tl;dr: Zusammenfassung\nVorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. Wenn Sie den DAX-Stand von morgen genau vorhersagen kÃ¶nnen, rufen Sie mich bitte sofort an. Genau das ist Ihre Aufgabe in dieser PrÃ¼fungsleistung: Sie sollen Werte vorhersagen.\nEtwas konkreter: Stellen Sie sich ein paar Studentis vor. Von allen wissen Sie, wie lange die Person fÃ¼r die Statistikklausur gelernt hat. AuÃŸerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. Und Sie wissen die Note jeder Person in der Statistikklausur. Auf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die PrÃ¼fung in Statistik schreiben muss will: â€œSag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?â€. Mit Hilfe Ihrer Analyse kÃ¶nnen Sie diese Frage (und andere) beantworten. NatÃ¼rlich kÃ¶nnten Sie es sich leicht machen und antworten: â€œMei, der Notendurchschnitt war beim letzten Mal 2.7. Also ist 2.7 kein ganz doofer Tipp fÃ¼r deine Note.â€ Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, wenn man es geschickt anstellt. Da hilft Ihnen die Statistik (doch, wirklich).\nKurz gesagt gehen Sie so vor: Importieren Sie die Daten in R, starten Sie die nÃ¶tigen R-Pakete und schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. Dann nehmen Sie die vielversprechendsten PrÃ¤diktoren in ein Regressionsmodell und schauen sich an, wie gut die Vorhersage ist. Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. Je genauer Ihre Vorhersage, desto besser ist Ihr PrÃ¼fungsergebnis.\n\n\n3.1.4 Vorhersage\nNeben der erklÃ¤renden, rÃ¼ckwÃ¤rtsgerichteten Modellierung spielt insbesondere in der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle: Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. fÃ¼r neue Kunden auf Basis von soziodemographischen Daten den Kundenwert â€“ mÃ¶glichst genau â€“ zu prognostizieren. Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden, d.h. inklusive des fÃ¼r diese Kunden bekannten Kundenwertes.\nIhnen werden zwei Teildatenmengen zur VerfÃ¼gung gestellt: Zum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet.\n\nBei den Trainingsdaten (Train-Sample) liegen sowohl die erklÃ¤renden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor. Auf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) geschÃ¤tzt. Es ist also die Variable \\(y\\) vorherzusagen.\nDieses geschÃ¤tzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(x_0\\), fÃ¼r die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({x}_0)\\) berechnet. Der unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.\n\nLiegt zu einem noch spÃ¤teren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, so kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden, d.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden.\nIn der praktischen Anwendung kÃ¶nnen zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben):\n\ndie Trainingsphase, d.h., die Phase fÃ¼r die sowohl erklÃ¤rende (\\(x\\)) als auch die erklÃ¤rte Variable (\\(y\\)) bekannt sind. Hier wird das Modell geschÃ¤tzt (gelernt): \\(\\hat{f}(x)\\). DafÃ¼r wird der Trainingsdatensatz genutzt.\nIn der folgenden Anwendungsphase sind nur die erklÃ¤renden Variablen (\\(x_0\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.\nEvt. gibt es spÃ¤ter noch die Evaluierungsphase, fÃ¼r die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, so dass die VorhersagegÃ¼te des Modells Ã¼berprÃ¼ft werden kann.\n\nIm Computer kann man dieses Anwendungsszenario simulieren: man teilt die Datenmenge zufÃ¤llig in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((x,y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((x_0)\\)) auf: Die Modellierung erfolgt auf den Trainingsdaten. Das Modell wird angewendet auf die Testdaten (Anwendungsdaten). Da man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden.\n\n\n3.1.5 Hauptziel: Genaue Prognose\nIhre Aufgabe ist: Spielen Sie den Data-Scientist! Konstruieren Sie ein Modell auf Basis der Trainingsdaten \\((x,y\\)) und sagen Sie fÃ¼r die Testdaten (\\(x_0\\)) die Zielvariable mÃ¶glichst genau voraus (\\(\\hat{y}_0\\)).\nIhr(e) Dozent*in kennt den Wert der Zielvariable (\\(y_0\\)). Sie nicht.\nVon zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser, das weniger Vorhersagefehler aufweist (im Test-Datensatz), also genauer vorhersagt. Kurz gesagt: Genauer ist besser.\n\n\n\n\n\n3.1.6 PrÃ¼fungsmaterial\nEs werden Ihnen im Rahmen der PrÃ¼fung drei (Text-)Dateien bereitgestellt:\n\nTrainings-Datensatz\nTest-Datensatz\nData Dictionary\n\nBeachten Sie, dass der Zugriff zum PrÃ¼fungsmaterial eingeschrÃ¤nkt sein kann (z.B. nur wÃ¤hrend der PrÃ¼fungszeit, nur nach BestÃ¤tigung der Kenntnis der PrÃ¼fungsbedingungen, nur fÃ¼r angemeldete Studentis).\nWelche Variable vorherzusagen ist (die AV), steht im Data Dictionary.\nDie Materialien (oder Hinweise zum Bezugsort) finden Sie im entsprechenden Moodlekurs.\n\n\n3.1.7 Einzureichende Dateien\n\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, qmd-, Rmd-Notebook oder Rmd-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.qmd.\n\n\n\n3.1.8 Zum Aufbau Ihrer Prognosedatei im CSV-Format\n\nDie CSV-Datei muss aus genau zwei Spalten mit exakt folgenden Spaltennamen bestehen:\n\n\nid: Den ID-Wert jedes vorhergesagten Wertes\npred: Der vorhergesagte Wert.\n\n\nSofern nicht anderweitig definiert, entspricht die ID einer Beobachtung ihrer Zeilennummer (in der Reihenfolge, wie sie in der vom PrÃ¼fer ausgegebenen Datei vorliegt). Die erste Beobachtung (im Test-Sample) bekommt die ID 1, die zweite Beobachtung die ID 2, etc. Die ID ist als Zahl (reell oder ganzzahlig) zu formatieren.\nDie CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).\nDie eingereichte CSV-Datei muss genau die Anzahl an Zeilen aufweisen, die der ZeilenlÃ¤nge im Test-Datensatz entspricht.\nPrÃ¼fen Sie, dass Ihre CSV-Datei sich problemlos lesen lÃ¤sst. Falls keine (funktionstÃ¼chtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die PrÃ¼fung nicht bestanden. Tipp: Ã–ffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vernÃ¼nftig aussieht. Achtung: Ã–ffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, der CSV-Dateien verfÃ¤lschen kann auch ohne dass man die Datei speichert.\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, Rmd-, qmd- oder Rmd-Notebook-Datei)\n\nReichen Sie keine weiteren Dateien ein.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichten Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd.\nUmlaute in ihren Dateinamen sind durch ASCII-Zeichen zu ersetzen (also SÃ¼ÃŸ wird Suess etc.).\n\n\n\n3.1.9 Gliederung Ihrer Analyse\nIhr Analysedokument stellt alle Ihre Schritte vor, die Sie im Rahmen der Bearbeitung der PrÃ¼fungsaufgabe unternommen haben, zumindest was die Analyse der Daten betrifft.\nDas Dokument mischt drei Textarten: R-Syntax, R-Ausgaben sowie Prosa (d.h. Ihre ErklÃ¤rung zu Ihrer Analyse). Alle drei Aspekte sind gleichermaÃŸen wichtig fÃ¼r diese Analyse.\nWenn Sie das Dokument als R-Markdown-Datei (qmd- oder Rmd-Datei) anlegen, mÃ¼ssen Sie R-Code in einem â€œR-Chunkâ€ auszeichnen. Prosa wird in Rmd-Datei als Standard gesehen, sie brauchen ihn nicht extra auszuzeichnen (fÃ¼r R-Notebook-Dateien gilt das Gleiche). In R-Skript-Dateien ist es umgekehrt: Sie mÃ¼ssen R-Code nicht extra auszeichnen, da in R-Skripten R als â€œStandard-Textâ€ gesehen wird. Hingegen mÃ¼ssen Sie Prosa als Kommentar einfÃ¼gen. Es bleibt Ihnen Ã¼berlassen, fÃ¼r welche Variante (R-, Rmd- oder R-Notebook) Sie sich entscheiden. Keine Option wird als besser oder schlechter gewertet (vermutlich ist Rmd fÃ¼r Sie am einfachsten).\nSie kÃ¶nnen Ihr Analysedokument z.B. so gliedern:\n\nForschungsfrage und Hintergrund (Beschreiben Sie kurz, worum es geht)\nVorbereitung (Pakete laden, Daten importieren, etc.)\nExplorative Datenanalyse (Untersuchen Sie den Datensatz nach AuffÃ¤lligkeiten, die Sie dann beim Modellieren nutzen)\nModelle (z.B. via lm(av ~ uv))\nVorhersagen (Vorhersage der Test-Daten anhand des besten Vorhersagemodells und Einreichen)\n\nDie Gliederung ist kein Muss; andere Gliederung sind auch mÃ¶glich. Entscheidend ist die fachliche Angemessenheit.\n\n3.1.9.1 Abschnitt Forschungsfrage und Hintergrund\nIn diesem Abschnitt passiert noch keine Statistik bzw. keine Analyse. Stattdessen stellen Sie in â€œnormaler Spracheâ€, also ohne intensiven Gebrauch vom (statistischem) Fachvokabular dar, was Ziel und was Hintergrund der Analyse ist. Sie kÃ¶nnen als Ziel bzw. Hintergrund den formalen Aspekt der PrÃ¼fung anfÃ¼hren, wichtiger sind aber inhaltliche bzw. fachliche Ãœberlegungen: Worum geht es in der Analyse? Warum ist die Frage wichtig? Was wird untersucht? Anhand welcher Methodik wird die Frage untersucht?\nEine viertel bis halbe Seite sollte fÃ¼r diesen Abschnitt reichen.\n\n\n3.1.9.2 Vorbereitung\nIn diesem Abschnitt Ihres Analysedokuments fÃ¼hren Sie die technische Vorbereitung durch. Das betrifft vor allem das Importieren der Daten und das Starten aller R-Pakete, die in der Analyse verwendet werden.\nZum Importieren der Daten gehen Sie bitte so vor: Legen Sie fÃ¼r diese Analyse ein Projekt in Rstudio an. Speichern Sie in diesem Ordner (auf der Wurzelebene, nicht in Unterverzeichnissen) die zu analyiserenden Daten. Ã„ndern Sie nicht den Dateinamen der Daten. Importieren Sie die Daten z.B. auf folgende Weise: d_train &lt;- read_csv(\"d_train.csv) bzw. d_test &lt;- read_csv(\"d_test.csv\"). Auf diese Weise ist die Reproduzierbarkeit Ihrer Analyse sichergestellt.\n\n\n3.1.9.3 Explorative Datenanalyse\nDie explorative Datenanalyse (EDA) meint sowohl die deskriptive Statistik als auch die Datenvisualisierung. Typische Schritte sind: das Bearbeiten (oder Entfernen) von Extremwerten und fehlenden Werten, die Untersuchung von Verteilungsformen oder das Suchen nach Mustern (Korrelationen, Gruppenunterschieden). Ein nÃ¼tzliches Ergebnis ist z.B. zu erkennen, welche Variablen sich als PrÃ¤diktoren eignen (fÃ¼r den nÃ¤chsten Abschnitt der Modellierung). Ziel ist, dass Sie den folgenden Schritt vorbereiten, also Schritte unternehmen, damit Sie die AV mÃ¶glichst gut vorhersagen kÃ¶nnen.\n\n\n3.1.9.4 Modellierung\nIn diesem Schritt berechnen Sie Prognosemodelle. Das sind oft lineare Modelle, also etwa lm(av ~ uv). Es empfiehlt sich, mehrere Modelle zu berechnen und zu schauen, welches dieser Kandidaten am besten ist. Die GÃ¼te eines Prognosemodells bemisst sich letztlich nur an der PrÃ¤zision der Vorhersage neuer Daten, also des Test-Datensatzes. Wie gut Ihre Vorhersagen also wirklich sind, erfahren Sie erst mit der Notenbekanntgabe. Allerdings kÃ¶nnen Sie die Trainingsdaten nutzen, um die GÃ¼te Ihrer Modelle abzuschÃ¤tzen.\n\n\n3.1.9.5 Vorhersagen\nSchlieÃŸlich entscheiden Sie sich fÃ¼r einen Modellkandidaten. Diesen Modellkandidaten nehmen Sie her, um die (Ihnen unbekannten) Werte der AV (Zielvariablen) vorherzusagen. Diese Vorhersagen - zusammen mit der ID fÃ¼r jede Vorhersagen - speichern Sie als (regulÃ¤re) CSV-Datei ab und reichen Sie als Ihre PrÃ¼fungsleistung ein, zusammen mit Ihrer Analysedatei.\n\n\n\n3.1.10 Tipps\n\n3.1.10.1 Tipps fÃ¼r eine gute Prognose\n\nSchauen Sie in die Literatur.\nEvtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von AusreiÃŸern) helfen.\nÃœberlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierfÃ¼r gibt es Algorithmen und R-Funktionen.\nVermeiden Sie Ãœber-Anpassung (Overfitting).\nVermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgefÃ¼llt.\nArbeiten Sie die bereitgestellten Fallstudien durch. Wenn Sie mehr tun mÃ¶chten, finden Sie im Internet eine FÃ¼lle von weiteren Fallstudien.\n\n\n\n3.1.10.2 Tipps zur Datenverarbeitung\n\nEin â€œdeutschesâ€ Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets kÃ¶nnen dies allerdings.\n\n\n\n3.1.10.3 Tipps zum Aufbau des Analyseskripts\n\nZu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.\n\n\n\n\n\n3.1.11 Bewertung\n\n3.1.11.1 Kriterien\n\nEs gibt drei Bewertungskriterien:\n\nFormalia: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Ãœbersichtlichkeit der Analyse.\nMethode: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.\nInhalt: VorhersagegÃ¼te.\n\nDas zentrale Bewertungskriterium ist Inhalt; die Ã¼brigen beiden Kriterien flieÃŸen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein.\nDie Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.\nEs werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.\nEs werden keine Hinweise vergeben, stattdessen gibt es einen Ãœberblick an typischen Fehlern.\nEs wird i.d.R. keine MusterlÃ¶sung verÃ¶ffentlicht, um nachfolgende Kohorten nicht zu bevorteilen bzw. die aktuelle Kohorte nicht zu benachteiligen.\n\n\n\n3.1.11.2 Kennzahl der ModellgÃ¼te\nDie GÃ¼te der Vorhersage wird anhand des RMSE bemessen.\n\n\n\n\n3.1.11.3 Notenstufen\nZur VorhersagegÃ¼te: Die VorhersagegÃ¼te eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\).\nIhre Bewertung erfolgt entsprechend Ihrer VorhersagegÃ¼te, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als \\(2,0\\)!\n\n\n3.1.11.4 Bewertungsprozess\nDer Gutachter legt im Nachgang der PrÃ¼fung alle Teilnehmis ihre jeweilige Wert der Kennzahl der ModellgÃ¼te offen. AuÃŸerdem werden die vorherzusagenden Daten verÃ¶ffentlicht sowie die Grenzwerte fÃ¼r jede Notenstufe. Auf dieser Basis ist es allen Teilnehmis mÃ¶glich, die Korrektheit Ihrer Note selbstÃ¤ndig zu Ã¼berprÃ¼fen.\n\n\n3.1.11.5 Einsichtnahme\nIn der Regel gibt es keine â€œEinsichtnahmeâ€. Der Grund ist einfach: Sie bekommen mit der Note den Wert Ihrer ModellgÃ¼te mitgeteilt. DarÃ¼ber hinaus wird (zumeist) keine Bewertung durchgefÃ¼hrt. In diesem Fall gibt es also neben der ModellgÃ¼te keine weiteren Korrekturhinweise und damit nichts, was eingesehen werden kÃ¶nnte.\nBeachten Sie, dass Sie den vom PrÃ¼fer angegebenen Wert Ihrer ModellgÃ¼te selber nachrechnen kÃ¶nnen - das ist besser als eine Einsichtnahme.\nWenn Sie der Meinung sind, dass Ihre Arbeit doch eigentlich besser sein mÃ¼sste, als es Ihre Note widerspiegelt, kann ein Blick in die Liste der â€œLieblingsfehlerâ€ nÃ¼tzen. Vielleicht finden Sie auf jener Liste auch einen (oder mehrere Fehler), die Sie auch in Ihrer eigenen Analyse finden.\n\n\n\n3.1.12 Freie Wahl in der Methodik\nSie haben freie Wahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie kÃ¶nnen aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen. (Die freie Wahl gilt nicht fÃ¼r die Formalia und Randbedingungen; auch nicht fÃ¼r die zu verwendende Software und Programmiersprachen.)\nEine EinfÃ¼hrung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling with R.2. Die BÃ¼cher beinhalten jeweils Beispiele und Anwendung mit R.\nAuch ist es Ihnen Ã¼berlassen, welche Variablen Sie zur Modellierung heranziehen â€“ und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, AusreiÃŸer bereinigen o.Ã„.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchfÃ¼hren, auch auf den Testdaten (Anwendungsdaten) durchzufÃ¼hren.\nHinweise zur Modellwahl usw. gibt es auch in erwÃ¤hnter Literatur, aber auch in vielen BÃ¼chern zum Thema Data-Science.\nAlles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent sein.\nIm Ãœbrigen lautet die Aufgabe: Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine schÃ¶ne Antwort, trifft die Wirklichkeit aber leider nicht immer. Eine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangslÃ¤ufig eine gute Vorhersage (Test-Set).\n\n\n3.1.13 Formalia\n\nEs sind nur Einzelarbeiten zulÃ¤ssig.\nIn der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in bereitgestellten Datensatz genutzt werden.\nAlle Analyseschritte bzw. alle VerÃ¤nderungen an den Daten mÃ¼ssen im (eingereichten) Analyseskript nachvollziehbar aufgefÃ¼hrt sein. Das Analyseskript ist als R-Skript, qmd-Datei, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie kÃ¶nnen die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).\nDas Analyseskript muss grundsÃ¤tzlich funktionstÃ¼chtig fÃ¼r den PrÃ¼fer sein: Alle Befehle mÃ¼ssen ohne Fehlermeldung durchlaufen. Ausnahmen: a) Installation fehlender Pakete, b) Daten sollen aus der Wurzelebene des Projektordners importiert werden..\nEs dÃ¼rfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzulÃ¤ssig.\nNichtbeachtung der fÃ¼r dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug fÃ¼hren.\nDer Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.\nEs muss keine Literatur zitiert werden.\nEin ausgedrucktes Exemplar muss nicht abgegeben werden.\nWÃ¤hrend der PrÃ¼fungsphase werden keine inhaltlichen Fragen (â€œwie macht man nochmal eine Log-Transformation?â€) und keine technischen Fragen (â€œwie installiert man nochmal ein R-Paket?â€) beantwortet.\n\n\n\n3.1.14 Ich brauche Hilfe!\n\n3.1.14.1 Wo finde ich Beispiele und Vorlagen?\nIm Rahmen des Unterrichts wurden mehrere Fallstudien erarbeitet bzw. bereitgestellt, diese dienen Ihnen als ideale Vorlage.\nEine Beispiel-Modellierung finden Sie in der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd. Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen kÃ¶nnen, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt.\nIm Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen kÃ¶nnen.\n\n\n3.1.14.2 ProbeprÃ¼fung fÃ¼r den Prognosewettbewerb\nJa, hier. In diesem Ordner liegen die Dokumente, die Sie fÃ¼r die echte PrÃ¼fung auch bekommen:\n\nTrain-Datensatz\nTest-Datensatz\nHinweise zur vorherzusagenden Variablen\n\n\n\n3.1.14.3 Materialsammlung\nIn diesem Ordner finden Sie eine Materialsammlung zum Prognosewettbewerb.\n\n\n3.1.14.4 Videos\nDiese Playlist beinhaltet Videos, die die Rahmenbedingungen der PrÃ¼fungsleistung vorstellt.\n\n\n\n3.1.15 Plagiatskontrolle\nDie eingereichten Arbeiten kÃ¶nnen automatisiert auf Plagiate Ã¼berprÃ¼ft werden. Gibt es substanzielle Ãœberschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungenÃ¼gend bewertet oder es folgt eine Abwertung der Note."
  },
  {
    "objectID": "030-Pruefung.html#footnotes",
    "href": "030-Pruefung.html#footnotes",
    "title": "3Â  PrÃ¼fung",
    "section": "",
    "text": "https://link.springer.com/book/10.1007/978-3-658-21587-3â†©ï¸\nhttps://www.tmwr.org/â†©ï¸"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#lernsteuerung",
    "href": "040-Statistisches-Lernen.html#lernsteuerung",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Vorbereitung\n\nLesen Sie die Hinweise zum Modul.\nInstallieren (oder Updaten) Sie die fÃ¼r dieses Modul angegeben Software. Lesen Sie die Literatur.\n\n4.1.2 Lernziele\n\nSie kÃ¶nnen erlÃ¤utern, was man unter statistischem Lernen versteht. Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann. Sie kennen verschiedenen Arten von statistischem Lernen und kÃ¶nnen Algorithmen zu diesen Arten zuordnen.\n\n4.1.3 Literatur\n\nRhys, Kap. 1\nevtl. Sauer, Kap. 15\n\n4.1.4 Hinweise\n\nBitte beachten Sie die Hinweise zum PrÃ¤senzunterricht und der Streamingoption.\nBitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) lÃ¤uft.\n\n4.1.5 R-Pakete\nBenÃ¶tigte R-Pakete fÃ¼r dieses Kapitel:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-data-science",
    "href": "040-Statistisches-Lernen.html#was-ist-data-science",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.2 Was ist Data Science?",
    "text": "4.2 Was ist Data Science?\nEs gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, und Horton (2017) definieren Data Science wie folgt (S. 4):\n\n\n\n\n\n\nHinweis\n\n\n\nThe science of extracting meaningful information from data.\\(\\square\\)\n\n\nAuf der anderen Seite entgegen viele Statistiker: â€œHey, das machen wir doch schon immer!â€.\nEine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (â€œDomÃ¤neâ€), die sozusagen den EmpfÃ¤nger bzw. die Kunden oder den Rahmen stellt. Dieser â€œDreiklangâ€ ist in folgendem Venn-Diagramm dargestellt."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "href": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.3 Was ist Machine Learning?",
    "text": "4.3 Was ist Machine Learning?\n\nDefinition 4.1 Maschinelles Lernen (ML), oft auch (synonym) als statistisches Lernen (statistical learning) bezeichnet, ist ein Teilgebiet der kÃ¼nstlichen Intelligenz (KI; artificial intelligence, AI) (Rhys 2020). ML wird auch als data-based bezeichnet in Abgrenzung von rule-based, was auch als â€œklassische KIâ€ bezeichnet wird, vgl. AbbildungÂ 4.1.\n\n\n\n\n\nflowchart LR\n  subgraph KI[KÃ¼nstliche Intelligenz KI]\n    rb[rule based]\n    db[data based]\n  end   \n\n\nAbbildungÂ 4.1: KI und Maschinelles Lernen\n\n\n\nIn beiden FÃ¤llen finden Algorithmen Verwendung.\n\nDefinition 4.2 (Algorithmus) Algorithmen sind nichts anderes als genaue Schritt-fÃ¼r-Schritt-Anleitungen, um etwas zu erledigen.\\(\\square\\)\n\n\nBeispiel 4.1 Ein Kochrezept ist ein klassisches Beispiel fÃ¼r einen Algorithmus.\\(\\square\\)\n\nHier findet sich ein Beispiel fÃ¼r einen einfachen Additionsalgorithmus.\nEs gibt viele ML-Algorithmen, vgl. AbbildungÂ 4.2.\n\n\n\n\nflowchart LR\n  subgraph KI[KI]\n    subgraph ML[ML]\n      A[Regression]\n      B[Neuronale Netze]\n      C[weitere]\n    end\n  end\n\n\nAbbildungÂ 4.2: ML-Matroschka\n\n\n\n\n4.3.1 Rule-based\nKlassische (Ã¤ltere) KI implementiert Regeln â€œhartverdrahtetâ€ in ein Computersystem. Nutzer fÃ¼ttern Daten in dieses System. Das System leitet dann daraus Antworten ab.\nRegeln kann man prototypisch mit Wenn-Dann-Abfragen darstellen:\n\nlernzeit &lt;- c(0, 10, 10, 20)\nschlauer_nebensitzer &lt;- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] &gt; 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}\n## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\n\nSicherlich kÃ¶nnte man das schlauer programmieren, vielleicht so:\n\nd &lt;- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %&gt;% \n  mutate(bestanden = ifelse(lernzeit &gt; 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))\n\n\n\n  \n\n\n\n\n4.3.2 Data-based\nML hat zum Ziel, Regeln aus den Daten zu lernen. Man fÃ¼ttert Daten und Antworten in das System, das System gibt Regeln zurÃ¼ck.\nJames u.Â a. (2021) definieren ML so: Nehmen wir an, wir haben die abhÃ¤ngige Variable \\(Y\\) und \\(p\\) PrÃ¤diktoren, \\(X_1,X_2, \\ldots, X_p\\). Weiter nehmen wir an, die Beziehung zwischen \\(Y\\) und \\(X = (X_1, X_2, \\ldots, X_p)\\) kann durch eine Funktion \\(f\\) beschrieben werden. Das kann man so darstellen:\n\\[Y = f(X) + \\epsilon\\]\nML kann man auffassen als eine Menge an Verfahren, um \\(f\\) zu schÃ¤tzen.\nEin Beispiel ist in Abb. AbbildungÂ 4.3 gezeigt (James u.Â a. 2021).\n\n\nAbbildungÂ 4.3: Vorhersage des Einkommens durch Ausbildungsjahre\n\nNatÃ¼rlich kann \\(X\\) mehr als eine Variable beinhalten, vgl. AbbildungÂ 4.4) (James u.Â a. 2021).\n\n\nAbbildungÂ 4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren\n\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gefÃ¼ttert und liefern Antworten. ML-Systeme werden mit Daten und Antworten gefÃ¼ttert und liefern Regeln zurÃ¼ck, s. AbbildungÂ 4.5.\n\n\n\n\nflowchart LR\n  subgraph rb[rule-based]\n  D[Daten] --&gt;A[Antworten]\n  R[Regeln] --&gt;A\n  end\n  subgraph db[data-based]\n  D2[Daten] --&gt; R2[Regeln]\n  A2[Antworten] --&gt; R2\n  end\n\n\nAbbildungÂ 4.5: Vergleich von klassischer KI (rule-based) und ML (data-based)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "href": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.4 Modell vs.Â Algorithmus",
    "text": "4.4 Modell vs.Â Algorithmus\n\n4.4.1 Modell\nEin Modell, s. Abb. AbbildungÂ 4.6) (Spurzem 2017)!\n\n\nAbbildungÂ 4.6: Ein Modell-Auto\n\nWie man sieht, ist ein Modell eine vereinfachte ReprÃ¤sentation eines Gegenstands.\nDer Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. AbbildungÂ 4.7).\n\n\nAbbildungÂ 4.7: Gegenstand und Modell\n\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln, die aus den Daten gelernt wurden.\n\n4.4.2 Beispiel fÃ¼r einen ML-Algorithmus\nUnter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren, anhand dessen die Beziehung zwischen \\(X\\) und \\(Y\\) â€œgelerntâ€ wird. Bei Rhys (2020) (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:\nBeispiel eines Regressionsalgorithmus\n\nSetze Gerade in die Daten mit \\(b_0 = \\hat{y}, b_1 = 0\\)\n\nBerechne \\(MSS = \\sum (y_i - \\hat{y_i})^2\\)\n\nâ€œDreheâ€ die Gerade ein bisschen, d.h. erhÃ¶he \\(b_1^{neu} = b_1^{alt} + 0.1\\)\n\nWiederhole 2-3 solange, bis \\(MSS &lt; \\text{Zielwert}\\)\n\n\nDiesen Algorithmus kann man â€œvon Handâ€ z.B. mit dieser App durchspielen."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#taxonomie",
    "href": "040-Statistisches-Lernen.html#taxonomie",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.5 Taxonomie",
    "text": "4.5 Taxonomie\nMethoden des maschinellen Lernens lassen sich verschiedentlich gliedern. Eine typische Gliederung unterscheidet in supervidierte (geleitete) und nicht-supervidierte (ungeleitete) Algorithmen, s. Abb. AbbildungÂ 4.8).\n\n\n\n\nflowchart LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --&gt; SL\n  ML --&gt; NSL\n  SL --&gt; Re\n  SL --&gt; Class\n  NSL --&gt; DimRed\n  NSL --&gt; Clust\n\n\n\nAbbildungÂ 4.8: Taxonomie der Arten des maschinellen Lernens\n\n\n\n\n4.5.1 Geleitetes Lernen\nDie zwei Phasen des geleiteten Lernens sind in Abb. AbbildungÂ 4.9) dargestellt.\n\n\n\n\nflowchart TD\n  subgraph A[Lernphase]\n    B[Daten mit Antwort] --&gt; C[Geleiteter Algorithmus]\n    C --&gt; D[Modell]\n  end\n  subgraph E[Vorhersagephase]\n    H[Neue Daten ohne Antwort] --&gt; F[Modell]\n    F --&gt; G[Antworten]\n  end\n  A--&gt;E\n\n\nAbbildungÂ 4.9: Geleitetes Lernen geschieht in zwei Phasen\n\n\n\n\n4.5.1.1 Regression: Numerische Vorhersage\n\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n\n\n\n\nDie ModellgÃ¼te eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden GÃ¼tekoeffizienten gemessen:\n\nMean Squared Error (Mittlerer Quadratfehler):\n\n\\[MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\]\n\nMean Absolute Error (Mittlerer Absolutfehler):\n\n\\[MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|\\]\n\nWir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzuschÃ¤tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.\n\n\n4.5.1.2 Klassifikation: Nominale Vorhersage\n\n\nBei einer Klassifikation wird nicht eine Zahl, sondern eine Klasse vorhergesagt\n\nDie ModellgÃ¼te eines numerischen Vorhersagemodells wird oft mit folgendem GÃ¼tekoeffizienten gemessen:\n\nMittlerer Klassifikationfehler \\(e\\):\n\n\\[e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) \\]\nDabei ist \\(I\\) eine Indikatorfunktion, die 1 zurÃ¼ckliefert, wenn tatsÃ¤chlicher Wert und vorhergesagter Wert identisch sind.\n\n4.5.2 Ungeleitetes Lernen\nDie zwei Phasen des ungeleiteten Lernens sind in AbbildungÂ 4.10 dargestellt.\n\n\n\n\nflowchart LR\n  subgraph X[Lernphase]\n    A[Daten ohne Antwort] --&gt; B[Ungeleiteter Algorithmus]\n    B --&gt; C[Modell]\n  end\n  subgraph D[Vorhersagephase]\n    E[Neue Daten, ohne Antwort] --&gt; C2[Modell]\n    C2 --&gt; F[Zuordnung zu den Regeln des Modells]\n  end  \n  X---&gt;D\n\n\nAbbildungÂ 4.10: Die zwei Phasen des unÃ¼berwachten Lernens\n\n\n\nUngeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. AbbildungÂ 4.11):\n\nFallreduzierendes Modellieren (Clustering)\nDimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\n\n\n\nAbbildungÂ 4.11: Zwei Arten des ungeleitete Modellieren"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#ziele-des-ml",
    "href": "040-Statistisches-Lernen.html#ziele-des-ml",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.6 Ziele des ML",
    "text": "4.6 Ziele des ML\nMan kann vier Ziele des ML unterscheiden, s. AbbildungÂ 4.12.\n\n\n\n\nflowchart TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[ErklÃ¤rung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --&gt; V\n  ML --&gt; E\n  ML --&gt; B\n  ML --&gt; DimRed\n\n\nAbbildungÂ 4.12: Ziele des maschinellen Lernens\n\n\n\nVorhersage bezieht sich auf die SchÃ¤tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit). ErklÃ¤rung meint die kausale Analyse von ZusammenhÃ¤ngen. Beschreibung ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken. Dimensionsreduktion ist ein Oberbegriff fÃ¼r Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s\nWie â€œgutâ€ ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von ModellgÃ¼te oder model fit. Je schlechter die ModellgÃ¼te, desto hÃ¶her der Modellfehler, vgl. AbbildungÂ 4.13.\n\n\nAbbildungÂ 4.13: Wenig (links) vs.Â viel (rechts) Vorhersagefehler\n\nDie ModellgÃ¼te eines Modells ist v.a. relevant fÃ¼r neue Beobachtungen, an denen das Modell nicht trainiert wurde."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#sec-overfit",
    "href": "040-Statistisches-Lernen.html#sec-overfit",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.7 Ãœber- vs.Â Unteranpassung",
    "text": "4.7 Ãœber- vs.Â Unteranpassung\n\nDefinition 4.3 (Overfitting) Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als â€œbare MÃ¼nzeâ€, also fÃ¤lschlich als Signal. Solche Modelle haben zu viel Varianz in ihren Vorhersagen.\\(\\square\\)\n\n\nDefinition 4.4 (Underfitting) Ein Modell ist zu simpel (ungenau, grobkÃ¶rnig) - es unterschlÃ¤gt Nuancen des tatsÃ¤chlichen Musters. Solche Modelle haben zu viel Verzerrung (Bias) in ihren Vorhersagen.\\(\\square\\)\n\n\n4.7.1 Beispiel 1\nWelches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. AbbildungÂ 4.14), vgl. (Sauer 2019), Kap. 15?\n\n\n\n\nAbbildungÂ 4.14: Over- vs.Â Underfitting\n\n\n\nWelches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?\nModell D zeigt sehr gute Beschreibung (â€œRetrodiktionâ€) der Werte, anhand derer das Modell trainiert wurde (â€œTrainingsstichprobeâ€). Wird es aber â€œehrlichâ€ getestet, d.h. anhand neuer Daten (â€œTest-Stichprobeâ€), wird es vermutlich nicht so gut abschneiden.\nEs gilt, ein Modell mit â€œmittlererâ€ KomplexitÃ¤t zu finden, um Ãœber- und Unteranpassung in Grenzen zu halten. Leider ist es nicht mÃ¶glich, vorab zu sagen, was der richtige, â€œmittlereâ€ Wert an KomplexitÃ¤t eines Modells ist, vgl. AbbildungÂ 4.15 aus (Sauer 2019).\n\n4.7.2 Beispiel 2\n?fig-overfitting-4-plots zeigt Ãœber- und Unteranpassung an einem Beispiel.\n\nTeil A: Die â€˜wahre Funktionâ€™, \\(f\\), die die Daten erzeugt. Man spricht auch von der â€œdatengenerierenden Funktionâ€. Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das heiÃŸt nicht, dass die wahre Funktion die Daten perfekt erklÃ¤rt, schlieÃŸlich kann die Funktion zwar wahr, aber unvollstÃ¤ndig sein oder unsere Messinstrumente sind nicht perfekt prÃ¤zise.\nTeil B: Die Daten, erzeugt aus A plus etwas zufÃ¤lliges Fehler (Rauschen).\nTeil C: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\nTeil D: Ein zu komplexes Modell: Ãœberanpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\nTeil E: Ein Modell mittlerer KomplexitÃ¤t. Keine Ãœberanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.\n\n4.7.3 Mittlere ModellkomplexitÃ¤t ist optimal\nWie AbbildungÂ 4.15 zeigt, ist eine â€œmittlereâ€ ModellkomplexitÃ¤t (oft) optimal. Fragt sich nur, was bzw. wo â€œmittelâ€ genau liegt. ğŸ¤·â€â™€ï¸\n\n\nAbbildungÂ 4.15: Mittlere ModellkomplexitÃ¤t fÃ¼hrt zur besten VorhersagegÃ¼te: Gute Balance von Bias und PrÃ¤zision\n\n\n4.7.4 Do-it-yourself Under-/Overfitting\nErkunden wir die Effekte von Under- und Overfitting an einem einfachen, simulierten Datenbeispiel:\n\nd &lt;- tibble(\n  x = -2:2,\n  y = c(-1, -.5, 0, 0.1, 2)\n)\n\nJetzt â€œfittenâ€ wir eine zunehmend komplexe Funktion in diese Daten. Als Funktion wÃ¤hlen wir ein Polynom von Grad 1 bis 4.\n\nEin Polynom 1. Grades ist eine lineare Funktion: \\(y \\sim xÂ¹\\).\nEin Polynom 2. Grades ist eine quadratische Funktion: \\(y \\sim xÂ² + x\\)\n\nEin Polynom \\(n\\). Grades ist eine Funktion der Form \\(y \\sim x^n + x^{n-1} + x^{n-2} + \\ldots + x\\)\n\n\nPolynome werden flexibler (mehr â€œTÃ¤lerâ€ und â€œGipfelâ€ haben), je hÃ¶her ihr Grad ist. Daher stellt sich die Frage, welcher Grad der â€œrichtigeâ€ ist. Leider wissen wir in der Praxis nicht, welche Funktion die Natur ausgewÃ¤hlt hat. Daher wÃ¤re eine LÃ¶sung, die Funktion auszuwÃ¤hlen, welche die Daten am besten erklÃ¤rt.\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE)\n\n\n\n\n\n(a) Grad 1\n\n\n\n\n\n(b) Grad 2\n\n\n\n\n\n\n\n(c) Grad 3\n\n\n\n\n\n(d) Grad 4\n\n\n\nAbbildungÂ 4.16: Polynome vom Grad 1-4\n\n\n\nWie man sieht, wird der Modellfehler immer kleiner, der â€œFitâ€ zunehmens besser.\nDas kann man sich natÃ¼rlich auch prÃ¤ziser berechnen lassen.\n\nlm1 &lt;- lm(y ~ poly(x, 1), data = d)\nlm2 &lt;- lm(y ~ poly(x, 2), data = d)\nlm3 &lt;- lm(y ~ poly(x, 3), data = d)\nlm4 &lt;- lm(y ~ poly(x, 4), data = d)\n\nresults &lt;-\n  tibble(r2_lm1 = r2(lm1)$R2,\n         r2_lm2 = r2(lm2)$R2,\n         r2_lm3 = r2(lm3)$R2,\n         r2_lm4 = r2(lm4)$R2)\n\nresults\n\n\n\n  \n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nJe komplexer das Modell, desto besser der Fit1 in dem Modell, in das Modell berechnet wurde.\n\n\nAber wie gut werden die Vorhersagen fÃ¼r neue Daten sein?\nSagen wir, in Wirklichkeit ist der datengenerierende Prozess2 (DGP) eine einfache lineare Funktion, plus etwas Rauschen (Fehler, \\(\\epsilon\\)):\n\\(y \\sim x + \\epsilon\\)\nSagen wir, das Rauschen ist normalverteilt mit Streuung 0.5.\nSimulieren wir uns jetzt ein paar neue Daten, die aus dieser Funktion resultieren.\n\nd1 &lt;- tibble(\n  x = -2:2,\n  e = rnorm(n = 5, mean = 0, sd = .5), \n  y = x,  # \"wahrer\" Wert\n  y_hat = y + e  # beobachteter Wert mit Rauschen\n)\n\nd1\n\n\n\n  \n\n\n\n\nDefinition 4.5 (Train- und Test-Datensatz) Den Datensatz, in dem man ein Modell berechnet (â€œfittetâ€), nennt man auch Train-Datensatz. Einen anderen Datensatz, den man nutzt, um die GÃ¼te des Modells zu Ã¼berprÃ¼fen, nennt man Test-Datensatz\n\nDamit wir eine stabilere Datenbasis haben, simulieren wir aber pro X-Wert (-2, -1, 0, 1, 2) nicht nur einen Wert, sondern, sagen wir, 10:\n\nd2 &lt;- \n  tibble(\n    x = rep(-2:2, times = 10),\n    e = rnorm(n = 50, mean = 0, sd = .5),  # Rauschen, Fehlerterm\n    y_hat = x,  # \"wahrer\" Wert\n    y = x + e  # beobachteter Wert mit Rauschen\n  )\n\nd2\n\n\n\n  \n\n\n\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE) +\n  geom_point(data = d2, color = \"blue\") \n\n\n\nAbbildungÂ 4.17: In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut\n\n\n\nJetzt sieht das R-Quadrat schon nicht mehr so gut aus, s. AbbildungÂ 4.17. Berechnen wir mal das R-Quadrat:\n\nrsq(data = d2, truth = y, estimate = y_hat)\n\n\n\n  \n\n\n\n\nÃœbungsaufgabe 4.1 (Overfitting) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine einfache lineare Funktion sein (Polynom 1. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)\n\n\nÃœbungsaufgabe 4.2 (Overfitting 2) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine Polynomfunktion sein (Polynom 2. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#no-free-lunch",
    "href": "040-Statistisches-Lernen.html#no-free-lunch",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.8 No free lunch",
    "text": "4.8 No free lunch\n\n\nYoda meint: Es gibt nicht â€œdasâ€ beste Modell\n\nQuelle: ImgFlip Meme Generator\nWenn \\(f\\) (die Beziehung zwischen \\(Y\\) und \\(X\\), auch datengenerierender Prozess genannt) linear oder fast linear ist, dann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. @ref(fig:2-10) aus James u.Â a. (2021), dort zeigt die schwarze Linie den â€œwahren Zusammenhangâ€, also \\(f\\) an. In orange sieht man ein lineares Modell, in grÃ¼n ein hoch komplexes Modell, das sich in einer â€œwackligenâ€ Funktion - also mit hoher Varianz - niederschlÃ¤gt. Das grÃ¼ne Modell kÃ¶nnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \\(y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon\\). Das lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias. Daher ist es fÃ¼r dieses \\(f\\) gut passend. Die grÃ¼ne Funktion zeigt dagegen Ãœberanpassung (overfitting), also viel Modellfehler (fÃ¼r eine Test-Stichprobe).\n\n\n\n\n\n\nVorsicht\n\n\n\nDie grÃ¼ne Funktion in AbbildungÂ 4.18 wird neue, beim Modelltraining unbekannte Beobachtungen (\\(y_0\\)) vergleichsweise schlecht vorhersagen. In AbbildungÂ 4.19 ist es umgekehrt.\n\n\n\n\nAbbildungÂ 4.18: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem hÃ¶heren Vorhersagefehler (bei neuen Daten!) resultieren\n\nBetrachten wir im Gegensatz dazu AbbildungÂ 4.19 aus James u.Â a. (2021), die (in schwarz) eine hochgradig nichtlineare Funktion \\(f\\) zeigt. Entsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. Ein lineares Modell wird der KomplexitÃ¤t von \\(f\\) nicht gerecht, Unteranpassung (underfitting) liegt vor.\n\n\nAbbildungÂ 4.19: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#bias-varianz-abwÃ¤gung",
    "href": "040-Statistisches-Lernen.html#bias-varianz-abwÃ¤gung",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.9 Bias-Varianz-AbwÃ¤gung",
    "text": "4.9 Bias-Varianz-AbwÃ¤gung\nDer Gesamtfehler \\(E\\) des Modells ist die Summe dreier Terme:\n\\[E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon\\]\nDabei meint \\(\\epsilon\\) den nicht reduzierbaren Fehler, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).\nBias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. AbbildungÂ 4.20 aus Sauer (2019).\n\n\nAbbildungÂ 4.20: AbwÃ¤ngung von Bias vs.Â Varianz"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#vertiefung",
    "href": "040-Statistisches-Lernen.html#vertiefung",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.10 Vertiefung",
    "text": "4.10 Vertiefung\n\nVerdienst einer deutschen Data Scientistin\nWeitere Fallstudie zum Thema Regression auf Kaggle\nCrashkurs Data Science (Coursera, Johns Hopkins University) mit â€˜Star-Dozentenâ€™\nArbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf\nWerfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise\nWiederholen Sie unser Vorgehen in der Fallstudie zu den FlugverspÃ¤tungen"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#aufgaben",
    "href": "040-Statistisches-Lernen.html#aufgaben",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.11 Aufgaben:",
    "text": "4.11 Aufgaben:\n\nMachen Sie sich mit â€˜Kaggleâ€™ vertraut\nBearbeiten Sie die Fallstudie â€˜TitaRnicâ€™ auf Kaggle\nMachen Sie sich mit dieser einfachen Fallstudie zur linearen Regression vertraut: The Movie Data Base Revenue (Kaggle)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#videos",
    "href": "040-Statistisches-Lernen.html#videos",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "\n4.12 Videos",
    "text": "4.12 Videos\n\nPrognose-Wettbewerbe bei Kaggle am Beispiel von The Movie Data Base Revenue\n\n\n\n\n\nBaumer, Benjamin S., Daniel T. Kaplan, und Nicholas J. Horton. 2017. Modern Data Science with R (Chapman & Hall/CRC Texts in Statistical Science). Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#footnotes",
    "href": "040-Statistisches-Lernen.html#footnotes",
    "title": "\n4Â  Statistisches Lernen\n",
    "section": "",
    "text": "ceteris paribusâ†©ï¸\ndata-generating process, DGPâ†©ï¸"
  },
  {
    "objectID": "050-R-Vertiefung.html#lernsteuerung",
    "href": "050-R-Vertiefung.html#lernsteuerung",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Literatur\n\nRhys, Kap. 2\nMODAR, Kap. 5\n\n5.1.2 Lernziele\n\nSie kÃ¶nnen Funktionen, in R schreiben.\nSie kÃ¶nnen DatensÃ¤tze vom Lang- und Breit-Format wechseln.\nSie kÃ¶nnen Wiederholungsstrukturen wie Mapping-Funktionen anwenden.\nSie kÃ¶nnen eine dplyr-Funktion auf mehrere Spalten gleichzeitig anwenden.\n\n5.1.3 Vorbereitung\n\nLesen Sie die Literatur."
  },
  {
    "objectID": "050-R-Vertiefung.html#objekttypen-in-r",
    "href": "050-R-Vertiefung.html#objekttypen-in-r",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.2 Objekttypen in R",
    "text": "5.2 Objekttypen in R\nNÃ¤heres zu Objekttypen findet sich in Sauer (2019), Kap. 5.2.\n\n5.2.1 Ãœberblick\nIn R ist praktisch alles ein Objekt.\n\nDefinition 5.1 (Objekt (Informatik)) Ein Objekt meint ein im Computerspeicher reprÃ¤sentiertes Ding, etwa eine Tabelle.\\(\\square\\)\n\n\nBeispiel 5.1 (Beispiele fÃ¼r Objekte) Vektoren und Dataframes (Tibbles) sind die vielleicht gÃ¤ngigsten Objektarten in R (vgl. AbbildungÂ 5.1), aus Sauer (2019)).\\(\\square\\)\n\n\n\nAbbildungÂ 5.1: Zentrale Objektarten in R\n\nEs gibt in R keine (Objekte fÃ¼r) Skalare (einzelne Zahlen). Stattdessen nutzt R Vektoren der LÃ¤nge 1.\nEin nÃ¼tzliches Schema stammt aus Wickham und Grolemund (2016), s. AbbildungÂ 5.2).\n\n\nAbbildungÂ 5.2: Objektarten hierarchisch gegliedert\n\n\n5.2.2 Taxonomie\nUnter homogenen Objektiven verstehen wir Datenstrukturen, die nur eine Art von Daten (wie Text oder Ganze Zahlen) fassen. Sonstige Objekte nennen wir heterogen.\n\nHomogene Objekte\n\nVektoren\nMatrizen\n\n\nHeterogen\n\nListe\nDataframes (Tibbles)\n\n\n\n\n5.2.2.1 Vektoren\nVektoren sind insofern zentral in R, als dass die Ã¼brigen Datenstrukturen auf ihnen aufbauen, vgl. AbbildungÂ 5.3 aus Sauer (2019).\nReine (atomare) Vektoren in R sind eine geordnete Liste von Daten eines Typs.\n\n\nAbbildungÂ 5.3: Vektoren stehen im Zentrum der Datenstrukturen in R\n\n\nein_vektor &lt;- c(1, 2, 3)\nnoch_ein_vektor &lt;- c(\"A\", \"B\", \"C\")\nlogischer_vektor &lt;- c(TRUE, FALSE, TRUE)\n\nMit str() kann man sich die Struktur eines Objektsausgeben lassen:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\nstr(noch_ein_vektor)\n##  chr [1:3] \"A\" \"B\" \"C\"\nstr(logischer_vektor)\n##  logi [1:3] TRUE FALSE TRUE\n\nVektoren kÃ¶nnen von folgenden Typen sein:\n\nKommazahlen ( double) genannt\nGanzzahlig (integer, auch mit L fÃ¼r Long abgekÃ¼rzt)\nText (Â´character`, String)\nlogische AusdrÃ¼cke (logical oder lgl) mit TRUE oder FALSE\n\n\nKommazahlen und Ganze Zahlen zusammen bilden den Typ numeric (numerisch) in R.\nDen Typ eines Vektors kann man mit typeof() ausgeben lassen:\n\ntypeof(ein_vektor)\n## [1] \"double\"\n\n\n5.2.2.2 Faktoren\n\nsex &lt;- factor(c(\"Mann\", \"Frau\", \"Frau\"))\n\nInteressant:\n\nstr(sex)\n##  Factor w/ 2 levels \"Frau\",\"Mann\": 2 1 1\n\nVertiefende Informationen findet sich in Wickham und Grolemund (2016).\n\n5.2.2.3 Listen\n\neine_liste &lt;- list(titel = \"EinfÃ¼hrung\",\n                   woche = 1,\n                   datum = c(\"2022-03-14\", \"2202-03-21\"),\n                   lernziele = c(\"dies\", \"jenes\", \"und noch mehr\"),\n                   lehre = c(TRUE, TRUE, TRUE)\n                   )\nstr(eine_liste)\n## List of 5\n##  $ titel    : chr \"EinfÃ¼hrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\n\n5.2.2.4 Tibbles\nFÃ¼r tibble() brauchen wir tidyverse:\n\nlibrary(tidyverse)\n\n\n\nstudentis &lt;-\n  tibble(\n    name = c(\"Anna\", \"Berta\"),\n    motivation = c(10, 20),\n    noten = c(1.3, 1.7)\n  )\nstr(studentis)\n## tibble [2 Ã— 3] (S3: tbl_df/tbl/data.frame)\n##  $ name      : chr [1:2] \"Anna\" \"Berta\"\n##  $ motivation: num [1:2] 10 20\n##  $ noten     : num [1:2] 1.3 1.7\n\n\n5.2.3 Indizieren\nEinen Teil eines Objekts auszulesen, bezeichnen wir als Indizieren.\n\n5.2.3.1 Reine Vektoren\nZur Erinnerung:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\n\n\nein_vektor[1]\n## [1] 1\nein_vektor[c(1,2)]\n## [1] 1 2\n\nAber nicht so:\n\nein_vektor[1,2]\n## Error in ein_vektor[1, 2]: incorrect number of dimensions\n\nMan darf Vektoren auch wie Listen ansprechen, also eine doppelte Eckklammer zum Indizieren verwenden\n\nein_vektor[[2]]\n## [1] 2\n\nDer Grund ist, dass Listen auch Vektoren sind, nur eben ein besonderer Fall eines Vektors:\n\nis.vector(eine_liste)\n## [1] TRUE\n\nWas passiert, wenn man bei einem Vektor der LÃ¤nge 3 das 4. Element indiziert?\n\nein_vektor[4]\n## [1] NA\n\nEin schnÃ¶des NA ist die Antwort. Das ist interessant: Wir bekommen keine Fehlermeldung, sondern den Hinweis, das angesprochene Element sei leer bzw. nicht verfÃ¼gbar.\nIn Sauer (2019), Kap. 5.3.1 findet man weitere IndizierungsmÃ¶glichkeiten fÃ¼r reine Vektoren.\n\n5.2.3.2 Listen\n\neine_liste %&gt;% str()\n## List of 5\n##  $ titel    : chr \"EinfÃ¼hrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\nListen kÃ¶nnen wie Vektoren, also mit [ ausgelesen werden. Dann wird eine Liste zurÃ¼ckgegeben.\n\neine_liste[1]\n## $titel\n## [1] \"EinfÃ¼hrung\"\neine_liste[2]\n## $woche\n## [1] 1\n\nDas hat den technischen Hintergrund, dass Listen als eine bestimmte Art von Vektoren implementiert sind.\nMann kann auch die â€œdoppelte Eckklammerâ€, [[ zum Auslesen verwenden; dann wird anstelle einer Liste die einfachere Struktur eines Vektors zurÃ¼ckgegeben:\n\neine_liste[[1]]\n## [1] \"EinfÃ¼hrung\"\n\nMan kÃ¶nnte sagen, die â€œÃ¤uÃŸere Schichtâ€ des Objekts, die Liste, wird abgeschÃ¤lt, und man bekommnt die â€œinnereâ€ Schicht, den Vektor.\nMann die Elemente der Liste entweder mit ihrer Positionsnummer (1, 2, â€¦) oder, sofern vorhanden, ihren Namen ansprechen:\n\neine_liste[[\"titel\"]]\n## [1] \"EinfÃ¼hrung\"\n\nDann gibt es noch den Dollar-Operator, mit dem Mann benannte Elemente von Listen ansprechen kann:\n\neine_liste$titel\n## [1] \"EinfÃ¼hrung\"\n\nMan kann auch tiefer in eine Liste hinein indizieren. Sagen wir, uns interessiert das 4. Element der Liste eine_liste - und davon das erste Element.\nDas geht dann so:\n\neine_liste[[4]][[1]] \n## [1] \"dies\"\n\nEine einfachere Art des Indizierens von Listen bietet die Funktion pluck(), aus dem Paket purrr, das Hilfen fÃ¼r den Umgang mit Listen bietet.\n\npluck(eine_liste, 4)\n## [1] \"dies\"          \"jenes\"         \"und noch mehr\"\n\nUnd jetzt aus dem 4. Element das 1. Element:\n\npluck(eine_liste, 4, 1)\n## [1] \"dies\"\n\nProbieren Sie mal, aus einer Liste der LÃ¤nge 5 das 6. Element auszulesen:\n\neine_liste %&gt;% length()\n## [1] 5\n\n\neine_liste[[6]]\n## Error in eine_liste[[6]]: subscript out of bounds\n\nUnser Versuch wird mit einer Fehlermeldung quittiert.\nSprechen wir die Liste wie einen (atomaren) Vektor an, bekommen wir hingegen ein NA bzw. ein NULL:\n\neine_liste[6]\n## $&lt;NA&gt;\n## NULL\n\n\n5.2.3.3 Tibbles\nTibbles lassen sich sowohl wie ein Vektor als auch wie eine Liste indizieren.\n\nstudentis[1]\n\n\n\n  \n\n\n\nDie Indizierung eines Tibbles mit der einfachen Eckklammer liefert einen Tibble zurÃ¼ck.\n\nstudentis[\"name\"]\n\n\n\n  \n\n\n\nMit doppelter Eckklammer bekommt man, analog zur Liste, einen Vektor zurÃ¼ck:\n\nstudentis[[\"name\"]]\n## [1] \"Anna\"  \"Berta\"\n\nBeim Dollar-Operator kommt auch eine Liste zurÃ¼ck:\n\nstudentis$name\n## [1] \"Anna\"  \"Berta\"\n\n\n5.2.4 WeiterfÃ¼hrende Hinweise\n\n\nTutorial zum Themen Indizieren von Listen von Jenny BC.\n\n5.2.5 Indizieren mit dem Tidyverse\nNatÃ¼rlich kann man auch die Tidyverse-Verben zum Indizieren verwenden. Das bietet sich an, wenn zwei Bedingungen erfÃ¼llt sind:\n\nWenn man einen Tibble als Input und als Output hat\nWenn man nicht programmieren mÃ¶chte"
  },
  {
    "objectID": "050-R-Vertiefung.html#datensÃ¤tze-von-lang-nach-breit-umformatieren",
    "href": "050-R-Vertiefung.html#datensÃ¤tze-von-lang-nach-breit-umformatieren",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.3 DatensÃ¤tze von lang nach breit umformatieren",
    "text": "5.3 DatensÃ¤tze von lang nach breit umformatieren\nManchmal findet man DatensÃ¤tze im sog. langen Format vor, manchmal im breiten.\nIn der Regel mÃ¼ssen die Daten â€œtidyâ€ sein, was meist dem langen Format entspricht, vgl. AbbildungÂ 5.4 aus Sauer (2019).\n\n\nAbbildungÂ 5.4: Von lang nach breit und zurÃ¼ck\n\nIn einer neueren Version des Tidyverse werden diese beiden Befehle umbenannt bzw. erweitert, s. AbbildungÂ 5.5.\n\n\ngather() -&gt; pivot_longer()\n\n\nspread() -&gt; pivot_wider()\n\n\n\n\nAbbildungÂ 5.5: Von â€œweitâ€ zu â€œbreitâ€ und zurÃ¼ck, eine Animation\n\nWeitere Informationen findet sich in Wickham und Grolemund (2016), in diesem Abschnitt, 12.3."
  },
  {
    "objectID": "050-R-Vertiefung.html#funktionen",
    "href": "050-R-Vertiefung.html#funktionen",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.4 Funktionen",
    "text": "5.4 Funktionen\nEine Funktion kann man sich als analog zu einer Variable vorstellen. Es ist ein Objekt, das nicht Daten, sondern Syntax beinhaltet, vgl. AbbildungÂ 5.6 aus Sauer (2019).\n\n\nAbbildungÂ 5.6: Sinnbild einer Funktion\n\n\nmittelwert &lt;- function(x){\n  \n  summe &lt;- sum(x, na.rm = TRUE)\n  mw &lt;- summe/length(x)\n  return(mw)\n  \n}\n\n\nmittelwert(c(1, 2, 3))\n## [1] 2\n\nWeitere Informationen finden sich in Kapitel 19 in Wickham und Grolemund (2016). Alternativ findet sich ein Abschnitt dazu (28.1) in Sauer (2019)."
  },
  {
    "objectID": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "href": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.5 Wiederholungen programmieren",
    "text": "5.5 Wiederholungen programmieren\nHÃ¤ufig mÃ¶chte man eine Operation mehrfach ausfÃ¼hren. Ein Beispiel wÃ¤re die Anzahl der fehlenden Werte pro Spalte auslesen. NatÃ¼rlich kann man die Abfrage einfach hÃ¤ufig tippen, nervt aber irgendwann. Daher brauchtâ€™s Strukturen, die Wiederholungen beschreiben.\nDafÃ¼r gibt es verschiedene AnsÃ¤tze.\n\n5.5.1 across()\n\nHandelt es sich um Spalten von Tibbles, dann bietet sich die Funktion across(.col, .fns) an. across wendet eine oder mehrere Funktionen (mit .fns bezeichnet) auf die Spalten .col an.\nDas erklÃ¤rt sich am besten mit einem Beispiel:\nNatÃ¼rlich hÃ¤tte man in diesem Fall auch anders vorgehen kÃ¶nnen:\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = mean))\n\n\n\n  \n\n\n\nMÃ¶chte man der Funktion .fns Parameter Ã¼bergeben, so nutzt man diese Syntax (â€œPurrr-Lambdaâ€):\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = ~ mean(., na.rm = TRUE)))\n\n\n\n  \n\n\n\nHier findet sich ein guter Ãœberblick zu across().\n\n5.5.2 map()\n\nmap() ist eine Funktion aus dem R-Paket purrr und Teil des Tidyverse.\nmap(x, f) wenden die Funktion f auf jedes Element von x an. Ist x ein Tibble, so wird f demnach auf jede Spalte von x angewendet (â€œzugeordnetâ€, daher map), vgl. AbbildungÂ 5.7 aus Sauer (2019).\n\n\nAbbildungÂ 5.7: Sinnbild fÃ¼r map aus purrr\n\nHier ein Beispiel-Code:\n\ndata(mtcars)\n\nmtcars &lt;- mtcars %&gt;% select(1:3)  # nur die ersten 3 Spalten\n\nmap(mtcars, mean)\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\nMÃ¶chte man der gemappten Funktion Parameter Ã¼bergeben, nutzt man wieder die â€œKringel-Schreibweiseâ€:\n\nmap(mtcars, ~ mean(., na.rm = TRUE))\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\n\n5.5.3 WeiterfÃ¼hrende Hinweise\nWeiteres zu map() findet sich z.B. in Wickham und Grolemund (2016), Kapitel 21.5 oder in Sauer (2019), Kap. 28.2.\nTutorial zu map() von Jenny BC."
  },
  {
    "objectID": "050-R-Vertiefung.html#listenspalten",
    "href": "050-R-Vertiefung.html#listenspalten",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.6 Listenspalten",
    "text": "5.6 Listenspalten\n\n5.6.1 Wozu Listenspalten?\nListenspalten sind immer dann sinnvoll, wenn eine einfache Tabelle nicht komplex genug fÃ¼r unsere Daten ist.\nZwei FÃ¤lle stechen dabei ins Auge:\n\nUnsere Datenstruktur ist nicht rechteckig\nIn einer Zelle der Tabelle soll mehr als ein einzelner Wert stehen: vielleicht ein Vektor, eine Liste oder eine Tabelle\n\nDer erstere Fall (nicht reckeckig) lieÃŸe sich noch einfach lÃ¶sen, in dem man mit NA auffÃ¼llt.\nDer zweite Fall verlangt schlichtweg nach komplexeren Datenstrukturen.\nKap. 25.3 aus Wickham und Grolemund (2016) bietet einen guten Einstieg in das Konzept von Listenspalten (list-columns) in R.\n\n5.6.2 Beispiele fÃ¼r Listenspalten\n\n5.6.2.1 tidymodel\nWenn wir mit tidymodels arbeiten, werden wir mit Listenspalten zu tun haben. Daher ist es praktisch, sich schon mal damit zu beschÃ¤ftigen.\nHier ein Beispiel fÃ¼r eine \\(v=3\\)-fache Kreuzvalidierung:\n\nlibrary(tidymodels)\nmtcars_cv &lt;-\n  vfold_cv(mtcars, v = 3)\n\nmtcars_cv\n\n\n\n  \n\n\n\nBetrachten wir das Objekt mtcars_cv nÃ¤her. Die Musik spielt in der 1. Spalte.\nLesen wir den Inhalt der 1. Spalte, 1 Zeile aus (nennen wir das mal â€œPosition 1,1â€):\n\npos11 &lt;- mtcars_cv[[1]][[1]]\npos11\n## &lt;Analysis/Assess/Total&gt;\n## &lt;21/11/32&gt;\n\nIn dieser Zelle findet sich eine Aufteilung des Komplettdatensatzes in den Analyseteil (Analysis sample) und den Assessmentteil (Assessment Sample).\nSchauen wir jetzt in dieses Objekt nÃ¤her an. Das kÃ¶nnen wir mit str() tun. str() zeigt uns die Strktur eines Objekts.\n\nstr(pos11)\n## List of 4\n##  $ data  :'data.frame':  32 obs. of  3 variables:\n##   ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n##   ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n##   ..$ disp: num [1:32] 160 160 108 258 360 ...\n##  $ in_id : int [1:21] 1 2 4 9 10 12 15 16 17 18 ...\n##  $ out_id: logi NA\n##  $ id    : tibble [1 Ã— 1] (S3: tbl_df/tbl/data.frame)\n##   ..$ id: chr \"Fold1\"\n##  - attr(*, \"class\")= chr [1:2] \"vfold_split\" \"rsplit\"\n\nOh! pos11 ist eine Liste, und zwar eine durchaus komplexe. Wir mÃ¼ssen erkennen, dass in einer einzelnen Zelle dieses Dataframes viel mehr steht, als ein Skalar bzw. ein einzelnes, atomares Element.\nDamit handelt es sich bei Spalte 1 dieses Dataframes (mtcars_cv) also um eine Listenspalte.\nÃœben wir uns noch etwas im Indizieren.\nSprechen wir in pos11 das erste Element an (data) und davon das erste Element:\n\npos11[[\"data\"]][[1]]\n##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n## [31] 15.0 21.4\n\nWir haben hier die doppelten Eckklammern benutzt, um den â€œeigentlichenâ€ oder â€œinnerenâ€ Vektor zu bekommen, nicht die â€œauÃŸenâ€ herumgewickelte Liste. Zur Erinnerung: Ein Dataframe ist ein Spezialfall einer Liste, also auch eine Liste, nur eine mit bestimmten Eigenschaften.\nZum Vergleich indizieren wir mal mit einer einfachen Eckklammer:\n\npos11[[\"data\"]][1] %&gt;% \n  head()\n\n\n\n  \n\n\n\nMit pluck() bekommen wir das gleiche Ergebnis, nur etwas komfortabler, da wir keine Eckklammern tippen mÃ¼ssen:\n\npluck(pos11, \"data\", 1, 1)\n## [1] 21\n\nWie man sieht, kÃ¶nnen wir beliebig tief in das Objekt hineinindizieren.\n\n5.6.3 Programmieren mit dem Tidyverse\nDas Programmieren mit dem Tidyvers ist nicht ganz einfach und hier nicht nÃ¤her ausgefÃ¼hrt. Eine EinfÃ¼hrung findet sich z.B.\n\nTidyeval in fÃ¼nf Minuten (Video)\nIn Kapiteln 17-21 in Advanced R, 2nd Ed\n\nEin Ãœberblicksdiagramm findet sich hier Quelle."
  },
  {
    "objectID": "050-R-Vertiefung.html#r-ist-schwierig",
    "href": "050-R-Vertiefung.html#r-ist-schwierig",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.7 R ist schwierig",
    "text": "5.7 R ist schwierig\nManche behaupten, R sei ein Inferno.\nZum GlÃ¼ck gibt es auch aufmunternde Stimmen:\n\npraise::praise()\n## [1] \"You are groundbreaking!\"\n\nHat jemand einen guten Rat fÃ¼r uns? Vielleicht ist der hÃ¤ufigste Rat, dass man die Dokumentation lesen solle."
  },
  {
    "objectID": "050-R-Vertiefung.html#aufgaben",
    "href": "050-R-Vertiefung.html#aufgaben",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\n\nFallstudie FlugverspÃ¤tungen\nFallstudie Getreideernte"
  },
  {
    "objectID": "050-R-Vertiefung.html#vertiefung",
    "href": "050-R-Vertiefung.html#vertiefung",
    "title": "\n5Â  R, zweiter Blick\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\n\nFunktionale Programmierung mit R\nLernen Sie Wiederholungsstrukturen mit ggplot\n\n\n\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nWickham, Hadley, und Garrett Grolemund. 2016. R for Data Science: Visualize, Model, Transform, Tidy, and Import Data. Oâ€™Reilly Media. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "060-tidymodels.html#lernsteuerung",
    "href": "060-tidymodels.html#lernsteuerung",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\n\nSie sind in der Lage, Regressionsmodelle mit dem tidymodels-Ansatz zu spezifizieren.\nSie kÃ¶nnen Begriffe des statistischen Lernens in das Vokabular von tidymodels Ã¼bersetzen."
  },
  {
    "objectID": "060-tidymodels.html#vorbereitung",
    "href": "060-tidymodels.html#vorbereitung",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.2 Vorbereitung",
    "text": "6.2 Vorbereitung\n\nLesen Sie TMWR, Kapitel 1\n\nLesen Sie Ã¼brige Literatur zu diesem Thema: TMWR, Kap. 1, 5, 6, 7, 8, 9\n\n\n6.2.1 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ntidymodels ist ein Metapaket: Ein (R-)Paket, das mehrere andere Paket startet und uns damit das Leben einfacher macht, analog zu tidyverse. Eine Liste der R-Pakete, die durch tidymodels gestartet werden, findet sich hier. Probieren Sie auch mal ?tidymodels.\nEine Liste aller Pakete, die in Tidymodels benutzt werden, die dependencies, kann man sich so ausgeben lassen:\n\npkg_deps(x = \"tidymodels\", recursive = FALSE)"
  },
  {
    "objectID": "060-tidymodels.html#daten",
    "href": "060-tidymodels.html#daten",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.3 Daten",
    "text": "6.3 Daten\nDieser Abschnitt bezieht sich auf Kapitel 4 in Silge und Kuhn (2022).\nWir benutzen den Datensatz zu Immobilienpreise aus dem Ames County in Iowa, USA, gelegen im Zentrum des Landes.\n\ndata(ames)  # Daten wurden Ã¼ber tidymodels mit geladen\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price))\n\nHier wurde die AV log-transformiert. Das hat zwei (wichtige) Effekte:\n\nDie Verteilung ist symmetrischer, nÃ¤her an der Normalverteilung. Damit gibt es mehr Daten im Hauptbereich des Ranges von Sale_Price, was die Vorhersagen stabiler machen dÃ¼rfte.\nLogarithmiert man die Y-Variable, so kommt dies einem multiplikativen Modell gleich, s. auch hier."
  },
  {
    "objectID": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "href": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.4 Train- vs Test-Datensatz aufteilen",
    "text": "6.4 Train- vs Test-Datensatz aufteilen\nDieser Abschnitt bezieht sich auf Kapitel 5 in Silge und Kuhn (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nDas Aufteilen in Train- und Test-Datensatz ist einer der wesentlichen GrundsÃ¤tze im maschinellen Lernen. Das Ziel ist, Overfitting abzuwenden. Im Train-Datensatz werden alle Modelle berechnet. Der Test-Datensatz wird nur einmal verwendet, und zwar zur ÃœberprÃ¼fung der ModellgÃ¼te.\n\n\n\n\nEine Faustregel ist es, 70-80% der Daten in das Train-Sample und die Ã¼brigen 20-30% in das Test-Sample zu stecken, s. AbbildungÂ 6.1\n\n\n\n\npie title Train-Test-Aufteilung\n    \"Train\" : 80\n    \"Test\" : 19\n    \"The Unkown God\": 1\n\n\nAbbildungÂ 6.1: 80-20-Aufteilung der Daten in Train- bzw. Test-Sample\n\n\n\nPraktisch funktioniert das in Silge und Kuhn (2022) wie folgt.\nWir laden die Daten und erstellen einen Index, der jeder Beobachtung die Zuteilung zu Train- bzw. zum Test-Datensatz zuweist.\nDas kann, mit tidymodels so aussehen:\n\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\n\ninitial_split() speichert fÃ¼r spÃ¤tere komfortable Verwendung auch die Daten. Aber eben auch der Index, der bestimmt, welche Beobachtung im Train-Set landet:\n\names_split$in_id %&gt;% head(n = 10)\n##  [1] 28 30 31 32 33 35 79 83 84 87\nlength(ames_split$in_id)\n## [1] 2342\n\nPraktisch ist auch, dass die AV-Verteilung in beiden DatensÃ¤tzen Ã¤hnlich gehalten wird (Stratifizierung), das besorgt das Argument strata.\nDie eigentlich Aufteilung in die zwei DatensÃ¤tze geht dann so:\n\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)"
  },
  {
    "objectID": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "href": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.5 Grundlagen der Modellierung mit tidymodels",
    "text": "6.5 Grundlagen der Modellierung mit tidymodels\nDieser Abschnitt bezieht sich auf Kapitel 6 in Silge und Kuhn (2022).\ntidymodels ist eine Sammlung mehrerer, zusammengehÃ¶riger Pakete, eben zum Thema statistische Modellieren.\nDas kann man analog zur Sammlung tidyverse verstehen, zu der z.B. das R-Paket dplyr gehÃ¶rt.\nDas R-Paket innerhalb von tidymodels, das zum â€œFittenâ€ von Modellen zustÃ¤ndig ist, heiÃŸt parsnip.\nEine Liste der verfÃ¼gbaren Modelltypen, Modellimplementierungen und Modellparameter, die in Parsnip aktuell unterstÃ¼tzt werden, findet sich hier.\n\n6.5.1 Modelle spezifizieren\nEin (statistisches) Modell wird in Tidymodels mit drei Elementen spezifiziert, vgl. AbbildungÂ 6.2.\n\n\n\n\nflowchart LR\n   \n  \n\n  subgraph Modus\n  r2[regresssion]\n  classification\n  end\n  \n  subgraph Implementierung\n  lm\n  stan_glm\n  div2[...]\n  end\n  \n  subgraph Algorithmus\n  R[Regression]\n  NN[Neuronale Netze]\n  div[...]\n  end \n  \n\n\n\nAbbildungÂ 6.2: Definition eines Models in tidymodels\n\n\n\nDie Definition eines Modells in tidymodels folgt diesen Ideen:\n\nDas Modell sollte unabhÃ¤ngig von den Daten spezifiziert sein\nDas Modell sollte unabhÃ¤ngig von den Variablen (AV, UVs) spezifiziert sein\nDas Modell sollte unabhÃ¤ngig von etwaiger Vorverarbeitung (z.B. z-Transformation) spezifiziert sein\n\nDa bei einer linearen Regression nur der Modus â€œRegressionâ€ mÃ¶glich ist, muss der Modus in diesem Fall nicht angegeben werden. Tidymodels erkennt das automatisch.\n\nlm_model &lt;-   \n  linear_reg() %&gt;%   # Algorithmus, Modelltyp\n  set_engine(\"lm\")  # Implementierung\n  # Modus hier nicht nÃ¶tig, da lineare Modelle immer numerisch klassifizieren\n\n\n6.5.2 Modelle berechnen\nNach Rhys (2020) ist ein Modell sogar erst ein Modell, wenn die Koeffizienten berechnet sind. Tidymodels kennt diese Unterscheidung nicht. Stattdessen spricht man in Tidymodels von einem â€œgefittetenâ€ Modell, sobald es berechnet ist. Ã„hnlich fancy kÃ¶nnte man von einem â€œinstantiiertenâ€ Modell sprechen.\nFÃ¼r das Beispiel der einfachen linearen Regression heiÃŸt das, das Modell ist gefittet, sobald die Steigung und der Achsenabschnitt (sowie die Residualstreuung) berechnet sind.\n\nlm_form_fit &lt;- \n  lm_model %&gt;% \n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)\n\n\n6.5.3 Vorhersagen\nIm maschinellen Lernen ist man primÃ¤r an den Vorhersagen interessiert, hÃ¤ufig nur an PunktschÃ¤tzungen. Schauen wir uns also zunÃ¤chst diese an.\nVorhersagen bekommt man recht einfach mit der predict() Methode von tidymodels1:\n\npredict(lm_form_fit, new_data = ames_test) %&gt;% \n  head()\n\n\n\n  \n\n\n\nDie Syntax zum Vorhersagen lautet also: predict(modell, daten_zum_vorhersagen).\n\n6.5.4 Vorhersagen im Train-Datensatz\nVorhersagen im Train-Datensatz machen kaum Sinn, da sie nicht gegen Overfitting geschÃ¼tzt sind und daher deutlich zu optimistisch sein kÃ¶nnen.\nBei einer linearen Regression ist diese Gefahr nicht so hoch, aber bei anderen, flexibleren Modellen, ist diese Gefahr absurd groÃŸ.\n\n6.5.5 Modellkoeffizienten im Train-Datensatz\nGibt man den Namen des Modellobjekts ein, so wird ein Ãœberblick an relevanten Modellergebnissen am Bildschirm gedruckt:\n\nlm_form_fit\n## parsnip model object\n## \n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -314.955       -2.134        2.863\n\nInnerhalb des Ergebnisobjekts findet sich eine Liste namens fit, in der die Koeffizienten (der â€œFitâ€) abgelegt sind:\n\nlm_form_fit %&gt;% pluck(\"fit\")\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -314.955       -2.134        2.863\n\nZum Herausholen dieser Infos kann man auch alternativ die Funktion extract_fit_engine() verwenden:\n\nlm_fit &lt;-\n  lm_form_fit %&gt;% \n  extract_fit_engine()\n\nlm_fit\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -314.955       -2.134        2.863\n\n\n\n\n\n\n\nHinweis\n\n\n\nMÃ¶chten Sie wissen, was sich in lm_form_fit alles verbirgt, bietet sich die Funktion str an. Alternativ kÃ¶nnen Sie in RStudio unter Environment das Objekt â€œaufklappenâ€.\n\n\nDas extrahierte Objekt ist, in diesem Fall, das typische lm() Objekt. Entsprechend kann man daruaf coef() oder summary() anwenden.\n\ncoef(lm_fit)\n## (Intercept)   Longitude    Latitude \n## -314.954598   -2.133832    2.863270\nsummary(lm_fit)\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.02404 -0.09525 -0.01574  0.09584  0.54193 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -314.9546    14.3978  -21.88   &lt;2e-16 ***\n## Longitude     -2.1338     0.1274  -16.75   &lt;2e-16 ***\n## Latitude       2.8633     0.1804   15.87   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1588 on 2339 degrees of freedom\n## Multiple R-squared:  0.1794, Adjusted R-squared:  0.1787 \n## F-statistic: 255.6 on 2 and 2339 DF,  p-value: &lt; 2.2e-16\n\nSchicker sind die Pendant-Befehle aus broom, die jeweils einen Tibble zuÃ¼ckliefern:\n\nlibrary(broom)\ntidy(lm_fit) # Koeffizienten\n\n\n\n  \n\n\nglance(lm_fit) # ModellgÃ¼te\n\n\n\n  \n\n\n\nEine weitere Alternative sind die Befehle zur Modell-Performance von easystatsÂ´^[Paketperformance`]:\n\nlibrary(easystats)\nparameters(lm_form_fit)\n\n\n\n  \n\n\nr2(lm_form_fit)\n## # R2 for Linear Regression\n##        R2: 0.179\n##   adj. R2: 0.179\nmae(lm_form_fit)\n## [1] 0.1211582\n\n\n6.5.6 Parsnip RStudio add-in\nMit dem Add-in von Parsnip kann man sich eine Modellspezifikation per Klick ausgeben lassen. Nett!\n\nparsnip_addin()"
  },
  {
    "objectID": "060-tidymodels.html#workflows",
    "href": "060-tidymodels.html#workflows",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.6 Workflows",
    "text": "6.6 Workflows\nDieser Abschnitt bezieht sich auf Kapitel 7 in Silge und Kuhn (2022).\n\n6.6.1 Konzept des Workflows in Tidymodels\n\n\n\nDefinition eines Models in tidymodels\n\n\n\n6.6.2 Einfaches Beispiel\nWir initialisieren einen Workflow, verzichten auf Vorverarbeitung und fÃ¼gen ein Modell hinzu:\n\nlm_workflow &lt;- \n  workflow() %&gt;%  # init\n  add_model(lm_model) %&gt;%   # Modell hinzufÃ¼gen\n  add_formula(Sale_Price ~ Longitude + Latitude)  # Modellformel hinzufÃ¼gen\n\nWerfen wir einen Blick in das Workflow-Objekt:\n\nlm_workflow\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Sale_Price ~ Longitude + Latitude\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nWie man sieht, gehÃ¶rt die Modellformel (y ~ x) zur Vorverarbeitung aus Sicht von Tidymodels.\nWas war nochmal im Objekt lm_model enthalten?\n\nlm_model\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nJetzt kÃ¶nnen wir das Modell berechnen (fitten):\n\nlm_fit &lt;- \n  lm_workflow %&gt;%\n  fit(ames_train)\n\nNatÃ¼rlich kann man synonym auch schreiben:\n\nlm_fit &lt;- fit(lm_wflow, ames_train)\n\nSchauen wir uns das Ergebnis an:\n\nlm_fit\n## â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Sale_Price ~ Longitude + Latitude\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -314.955       -2.134        2.863\n\n\n6.6.3 Vorhersage mit einem Workflow\nDie Vorhersage mit einem Tidymodels-Workflow ist einerseits komfortabel, da man einfach sagen kann:\nâ€œNimm die richtigen Koeffizienten des Modells aus dem Train-Set und wende sie auf das Test-Sample an. Berechne mir die Vorhersagen und die ModellgÃ¼te.â€\nSo sieht das aus:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nAlso, last_fit kÃ¼mmert sich um Folgendes:\n\nBerechne Modell im (kompletten) Train-Sample\nSage Daten im Test-Sample vorher\nBerechne ModellgÃ¼te im Test-Sample\n\nEs wird ein recht komplexes Objekt zurÃ¼ckgeliefert, das man erst mal durchschauen muss.\nWie man sieht, gibt es mehrere Listenspalten in final_lm_res. Besonders interessant erscheinen natÃ¼rlich die Listenspalten .metrics und .predictions.\nSchauen wir uns die Vorhersagen an. Diese finden sich im resultierenden Objekt von last_fit, zusammen mit anderen Informationen wie MOdellgÃ¼te. Die .predictions sind selber ein Tibble, wo in der ersten Spalte die Vorhersagen stehen.\n\nlm_preds &lt;- final_lm_res %&gt;% pluck(\".predictions\", 1)\n\nEs gibt auch eine Funktion, die obige Zeile vereinfacht (also synonym ist):\n\nlm_preds &lt;- collect_predictions(final_lm_res)\nlm_preds %&gt;% slice_head(n = 5)\n\n\n\n  \n\n\n\n\n6.6.4 ModellgÃ¼te\nDieser Abschnitt bezieht sich auf Kapitel 9 in Silge und Kuhn (2022).\nDie Vorhersagen bilden die Basis fÃ¼r die ModellgÃ¼te (â€œMetrikenâ€), die schon fertig berechnet im Objekt final_lm_res liegen und mit collect_metrics herausgenommen werden kÃ¶nnen:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\n\nAlternativ kommt man mit pluck(final_lm_res, \".metrics\") an die gleichen Informationen.\n\n\n\n\n\n\n\n.metric\n      .estimator\n      .estimate\n      .config\n    \n\n\nrmse\nstandard\n1.70 Ã— 10âˆ’1\n\nPreprocessor1_Model1\n\n\nrsq\nstandard\n1.48 Ã— 10âˆ’1\n\nPreprocessor1_Model1\n\n\n\n\n\n\nMan kann auch angeben, welche Metriken der ModellgÃ¼te man bekommen mÃ¶chte:\n\names_metrics &lt;- metric_set(rmse, rsq)\n\names_metrics(data = lm_preds, \n             truth = Sale_Price, \n             estimate = .pred)\n\n\n6.6.5 Vorhersage von Hand\nMan kann sich die Metriken auch von Hand ausgeben lassen, wenn man direktere Kontrolle haben mÃ¶chte als mit last_fit und collect_metrics.\n\names_test_small &lt;- ames_test %&gt;% slice(1:5)\npredict(lm_form_fit, new_data = ames_test_small)\n\n\n\n  \n\n\n\nJetzt binden wir die Spalten zusammen, also die â€œWahrheitâ€ (\\(y\\), die beobachteten, tatsÃ¤chlichen Y-Werte) und die Vorhersagen (\\(\\hat{y}\\)):\n\names_test_small2 &lt;- \n  ames_test_small %&gt;% \n  select(Sale_Price) %&gt;% \n  bind_cols(predict(lm_form_fit, ames_test_small)) %&gt;% \n  # Add 95% prediction intervals to the results:\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) \n\n\nrsq(ames_test_small2, \n   truth = Sale_Price,\n   estimate = .pred\n   )\n\n\n\n  \n\n\n\nAndere Koeffizienten der ModellgÃ¼te kÃ¶nnen mit rmse oder mae2 abgerufen werden."
  },
  {
    "objectID": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "href": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.7 Rezepte zur Vorverarbeitung",
    "text": "6.7 Rezepte zur Vorverarbeitung\nDieser Abschnitt bezieht sich auf Kapitel 8 in Silge und Kuhn (2022).\n\n6.7.1 Was ist Rezept und wozu ist es gut?\nSo kÃ¶nnte ein typischer Aufruf von lm() aussehen:\n\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, \n   data = ames)\n\nNeben dem Fitten des Modells besorgt die Formel-Schreibweise noch einige zusÃ¤tzliche nÃ¼tzliche Vorarbeitung:\n\nDefinition von AV und AV\nLog-Transformation von Gr_Liv_Area\n\nTransformation der nominalen Variablen in Dummy-Variablen\n\nDas ist schÃ¶n und nÃ¼tzlich, hat aber auch Nachteile:\n\nDas Modell wird nicht nur spezifiziert, sondern auch gleich berechnet. Das ist unpraktisch, weil man die Modellformel vielleicht in anderen Modell wiederverwenden mÃ¶chte. AuÃŸerdem kann das Berechnen lange dauern.\nDie Schritte sind ineinander vermengt, so dass man nicht einfach und Ã¼bersichtlich die einzelnen Schritte bearbeiten kann.\n\nPraktischer wÃ¤re also, die Schritte der Vorverarbeitung zu ent-flechten. Das geht mit einem â€œRezeptâ€ aus Tidymodels:\n\nsimple_ames &lt;- \n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) %&gt;%\n  step_log(Gr_Liv_Area, base = 10) %&gt;% \n  step_dummy(all_nominal_predictors())\nsimple_ames\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Rezept berechnet kein Modell. Es macht nichts auÃŸer die Vorverarbeitung des Modells zu spezifizieren (inklusive der Modellformel).\n\n\n\n6.7.2 Workflows mit Rezepten\nJetzt definieren wir den Workflow nicht nur mit einer Modellformel, sondern mit einem Rezept:\n\nlm_workflow &lt;-\n  workflow() %&gt;% \n  add_model(lm_model) %&gt;% \n  add_recipe(simple_ames)\n\nSonst hat sich nichts geÃ¤ndert.\nWie vorher, kÃ¶nnen wir jetzt das Modell berechnen und uns im Test-Set die Vorhersagen berechnen lassen:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nHier ist die ModellgÃ¼te:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\nlm_metrics\n\n\n\n  \n\n\n\n\n6.7.3 Spaltenrollen\nEine praktische Funktion ist es, bestimmte Spalten nicht als PrÃ¤diktor, sondern als ID-Variable zu nutzen. Das kann man in Tidymodels komfortabel wie folgt angeben:\n\names_recipe &lt;-\n  simple_ames %&gt;% \n  update_role(Neighborhood, new_role = \"id\")\n\names_recipe\n\n\n6.7.4 Preppen und Backen\nEin Rezept ist erstmal nur, ja, ein Rezept: Eine Beschreibung von Schritten und Zutaten. Es ist noch nichts gebacken. Um aus einen Rezept einen â€œKuchenâ€ - den transformierten Datensatz - zu bekommen, sind zwei Schritte nÃ¶tig:\n\n\nVorbereiten (to prep): Die Parameter des Rezeptschritte berechnen. So muss der Schritt step_center(var) den Mittelwert von var wissen, sonst kann der Schritt nicht durchgefÃ¼hrt werden.\n\nBacken ist das Rezept vorbereitet, kann der Datensatz damit gebacken werden.\n\nPraktischerweise erledigt Tidymodels das alles automatisch fÃ¼r uns, wir haben da nichts zu tun.\nAllerdings ist es manchmal praktisch, den durch das Rezept â€œgebackenenâ€ (transformierten) Datensatz zu sehen, daher sollte man wissen, wie man das â€œpreppenâ€ und â€œbackenâ€ von Hand erledigt.\n\nPreppen:\n\n\names_recipe_prepped &lt;-\n  ames_recipe %&gt;% \n  prep()\n\names_recipe_prepped\n\n\nBacken:\n\n\names_train_baked &lt;- \n  ames_recipe_prepped %&gt;% bake(new_data = NULL) \n\names_train_baked %&gt;% \n  head()\n\n\n\n  \n\n\n\n\n6.7.5 Fazit\nMehr zu Rezepten findet sich hier. Ein Ãœberblick zu allen Schritten der Vorverarbeitung findet sich hier."
  },
  {
    "objectID": "060-tidymodels.html#aufgaben",
    "href": "060-tidymodels.html#aufgaben",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\n\ntidymodels-ames-01\ntidymodels-ames-02\ntidymodels-ames-03\ntidymodels-ames-04\nbike01"
  },
  {
    "objectID": "060-tidymodels.html#fallstudien",
    "href": "060-tidymodels.html#fallstudien",
    "title": "\n6Â  tidymodels\n",
    "section": "\n6.9 Fallstudien",
    "text": "6.9 Fallstudien\n\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\n\n\n\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "060-tidymodels.html#footnotes",
    "href": "060-tidymodels.html#footnotes",
    "title": "\n6Â  tidymodels\n",
    "section": "",
    "text": "im Gegensatz zum predict() von lm mit Unterstrich bei new_data, also nicht newdata.â†©ï¸\nAchtung: Die Funktion mae gibt es sowohl in tidymodels auch in easystats, hier kann es zu Konflikten kommen.â†©ï¸"
  },
  {
    "objectID": "070-knn.html#lernsteuerung",
    "href": "070-knn.html#lernsteuerung",
    "title": "\n7Â  kNN\n",
    "section": "\n7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 Ãœberblick\nIn diesem Kapitel geht es um das Verfahren KNN, K-NÃ¤chste-Nachbarn (\\(k\\) nearest neighbors).\n\n7.1.2 Lernziele\n\nSie sind in der Lage, einfache Klassifikationsmodelle zu spezifizieren mit tidymodels\nSie kÃ¶nnen den knn-Algorithmus erlÃ¤utern\nSie kÃ¶nnen den knn-Algorithmus in tidymodels anwenden\nSie kÃ¶nnen die GÃ¼temetriken von Klassifikationsmodellen einschÃ¤tzen\n\n7.1.3 Literatur\n\nRhys, Kap. 3\nTimbers et al., Kap. 5"
  },
  {
    "objectID": "070-knn.html#benÃ¶tigte-r-pakete",
    "href": "070-knn.html#benÃ¶tigte-r-pakete",
    "title": "\n7Â  kNN\n",
    "section": "\n7.2 BenÃ¶tigte R-Pakete",
    "text": "7.2 BenÃ¶tigte R-Pakete\n\nlibrary(tidymodels)\nlibrary(tidyverse)"
  },
  {
    "objectID": "070-knn.html#intuitive-erklÃ¤rung",
    "href": "070-knn.html#intuitive-erklÃ¤rung",
    "title": "\n7Â  kNN\n",
    "section": "\n7.3 Intuitive ErklÃ¤rung",
    "text": "7.3 Intuitive ErklÃ¤rung\nK-NÃ¤chste-Nachbarn (\\(k\\) nearest neighbors, kNN) ist ein einfacher Algorithmus des maschinellen Lernens, der sowohl fÃ¼r Klassifikation als auch fÃ¼r numerische Vorhersage (Regression) genutzt werden kann. Wir werden kNN als Beispiel fÃ¼r eine Klassifikation betrachten.\nBetrachen wir ein einfÃ¼hrendes Beispiel von Rhys (2020), fÃ¼r das es eine Online-Quelle gibt. Stellen Sie sich vor, wir laufen durch englische Landschaft, vielleicht die Grafschaft Kent, und sehen ein kleines Tier durch das Gras huschen. Eine Schlange?! In England gibt es (laut Rhys (2020)) nur eine giftige Schlange, die Otter (Adder). Eine andere Schlange, die Grass Snake ist nicht giftig, und dann kommt noch der Slow Worm in Frage, der gar nicht zur Familie der Schlangen gehÃ¶rt. PrimÃ¤r interessiert uns die Frage, haben wir jetzt eine Otter gesehen? Oder was fÃ¼r ein Tier war es?\nZum GlÃ¼ck wissen wir einiges Ã¼ber Schlangen bzw. schlangenÃ¤hnliche Tiere Englands. NÃ¤mlich kÃ¶nnen wir die betreffenden Tierarten in GrÃ¶ÃŸe und AggressivitÃ¤t einschÃ¤tzen, das ist in Abbildung AbbildungÂ 7.1 dargestellt.\n\n\n\n\nAbbildungÂ 7.1: Haben wir gerade eine Otter gesehen?\n\n\n\nDer Algorithmus von kNN sieht einfach gesagt vor, dass wir schauen, welcher Tierarten Tiere mit Ã¤hnlicher AggressivitÃ¤t und GrÃ¶ÃŸe angehÃ¶ren. Die Tierart die bei diesen â€œNachbarnâ€ hinsichtlich Ã„hnlichkeit relevanter Merkmale am hÃ¤ufigsten vertreten ist, ordnen wir die bisher unklassifizierte Beobachtung zu.\nEtwas zugespitzt:\n\nWenn es quakt wie eine Ente ğŸ¦†, lÃ¤uft wie eine Ente ğŸ¦†und aussieht wie eine Ente ğŸ¦†, dann ist es eine Ente ğŸ¦†.\n\nDie Anzahl \\(k\\) der nÃ¤chsten Nachbarn kÃ¶nnen wir frei wÃ¤hlen; der Wert wird nicht vom Algorithmuss bestimmt. Solche vom Nutzi zu bestimmenden GrÃ¶ÃŸen nennt man auch Tuningparameter."
  },
  {
    "objectID": "070-knn.html#krebsdiagnostik-1",
    "href": "070-knn.html#krebsdiagnostik-1",
    "title": "\n7Â  kNN\n",
    "section": "\n7.4 Krebsdiagnostik 1",
    "text": "7.4 Krebsdiagnostik 1\nBetrachten wir ein Beispiel von Timbers, Campbell, und Lee (2022), das hier frei eingesehen werden kann.\nDie Daten sind so zu beziehen:\n\ndata_url &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv\"\ncancer &lt;- read.csv(data_url)\n\nIn diesem Beispiel versuchen wir Tumore der Brust zu klassifizieren, ob sie einen schweren Verlauf (maligne, engl. malignant) oder einen weniger schweren Verlauf (benigne, engl. benign) erwarten lassen. Der Datensatz ist hier nÃ¤her erlÃ¤utert.\nWie in AbbildungÂ 7.2 ersichtlich, steht eine Tumordiagnose (malignant vs.Â benign) in AbhÃ¤ngigkeit von Umfang (engl. perimeter) und KonkavitÃ¤t, die â€œGekrÃ¼mmtheit nach innenâ€.\n\n\n\n\nAbbildungÂ 7.2: Streudiagramm zur EinschÃ¤tzung von Tumordiagnosen\n\n\n\nIn diesem Code-Beispiel wird die seit R 4.1.0 verfÃ¼gbare R-native Pfeife verwendet. Wichtig ist vielleicht vor allem, dass diese Funktion nicht lÃ¤uft auf R-Versionen vor 4.1.0. Einige Unterschiede zur seit lÃ¤ngerem bekannten Magrittr-Pfeife sind hier erlÃ¤utert.\nWichtig ist, dass die Merkmale standardisiert sind, also eine identische Skalierung aufweisen, da sonst das Merkmal mit kleinerer Skala weniger in die Berechnung der NÃ¤he (bzw. Abstand) eingeht.\nFÃ¼r einen neuen, bisher unklassifizierten Fall suchen nur nun nach einer Diagnose, also nach der am besten passenden Diagnose (maligne oder benigne), s. AbbildungÂ 7.3, wieder aus Timbers, Campbell, und Lee (2022). Ihr Quellcode fÃ¼r dieses Diagramm (und das ganze Kapitel) findet sich hier.\n\n\n\n\nAbbildungÂ 7.3: Ein neuer Fall, bisher unklassifiziert\n\n\n\nWir kÃ¶nnen zunÃ¤chst den (im euklidischen Koordinatensystem) nÃ¤chst gelegenen Fall (der â€œnÃ¤chste Nachbarâ€) betrachten, und vereinbaren, dass wir dessen Klasse als SchÃ¤tzwert fÃ¼r den unklassiffizierten Fall Ã¼bernehmen, s. AbbildungÂ 7.4.\n\n\nAbbildungÂ 7.4: Ein nÃ¤chster Nachbar\n\nBetrachten wir einen anderen zu klassifizierenden Fall, s. AbbildungÂ 7.5. Ob hier die Klassifikation von â€œbenignâ€ korrekt ist? WomÃ¶glich nicht, denn viele andere Nachbarn, die etwas weiter weg gelegen sind, gehÃ¶ren zur anderen Diagnose, malign.\n\n\n\n\nAbbildungÂ 7.5: TrÃ¼gt der nÃ¤chste Nachbar?\n\n\n\nUm die Vorhersage zu verbessern, kÃ¶nnen wir nicht nur den nÃ¤chstgelegenen Nachbarn betrachten, sondern die \\(k\\) nÃ¤chstgelegenen, z.B. \\(k=3\\), s. Abb AbbildungÂ 7.6.\n\n\n\n\nAbbildungÂ 7.6: kNN mit k=3\n\n\n\nDie Entscheidungsregel ist dann einfach eine Mehrheitsentscheidung: Wir klassifizieren den neuen Fall entsprechend der Mehrheit in den \\(k\\) nÃ¤chst gelegenen Nachbarn."
  },
  {
    "objectID": "070-knn.html#berechnung-der-nÃ¤he",
    "href": "070-knn.html#berechnung-der-nÃ¤he",
    "title": "\n7Â  kNN\n",
    "section": "\n7.5 Berechnung der NÃ¤he",
    "text": "7.5 Berechnung der NÃ¤he\nEs gibt verschiedenen Algorithmen, um die NÃ¤he bzw. Distanz der Nachbarn zum zu klassifizieren Fall zu berechnen.\nEine gebrÃ¤uchliche Methode ist der euklidische Abstand, der mit Pythagoras berechnet werden kann, s. AbbildungÂ 7.7 aus Sauer (2019).\n\n\n\n\nAbbildungÂ 7.7: Euklidischer Abstand wird mit der Regel von Pythagoras berechnet\n\n\n\nWie war das noch mal?\n\\[c^2 = a^2 + b^2\\]\nIm Beispiel oben also:\n\\(c^2 = 3^2 + 4^2 = 5^2\\)\nDamit gilt: \\(c = \\sqrt{c^2} = \\sqrt{5^2}=5\\).\nIm 2D-Raum ist das so einfach, dass man das (fast) mit bloÃŸem Augenschein entscheiden kann. In mehr als 2 Dimensionen wird es aber schwierig fÃ¼r das Auge, wie ein Beispiel aus Timbers, Campbell, und Lee (2022) zeigt.\nAllerdings kann man den guten alten Pythagoras auch auf Dreiecke mit mehr als zwei Dimensionen anwenden, s. AbbildungÂ 7.8 aus Sauer (2019), Kap. 21.1.2.\n\n\n\n\n\n(a) Pythagoras mit mehr als zwei Dimensionen\n\n\n\n\n\n(b) Pythagoras mit mehr als zwei Dimensionen\n\n\n\nAbbildungÂ 7.8: Pythagoras in der Ebene (links) und in 3D (rechts)\n\n\nBleiben wir beim Beispiel von Anna und Berta und nehmen wir eine dritte Variable hinzu (Statistikliebe). Sagen wir, der Unterschied in dieser dritten Variable zwischen Anna und Berta betrage 2.\nEs gilt:\n\\[\n\\begin{aligned}\ne^2 &= c^2 + d^2 \\\\\ne^2 &= 5^2 + 2^2 \\\\\ne^2 &= 25 + 4\\\\\ne &= \\sqrt{29} \\approx 5.4\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "070-knn.html#knn-mit-tidymodels",
    "href": "070-knn.html#knn-mit-tidymodels",
    "title": "\n7Â  kNN\n",
    "section": "\n7.6 kNN mit Tidymodels",
    "text": "7.6 kNN mit Tidymodels\n\n7.6.1 Analog zu Timbers et al.\nEine Anwendung von kNN mit Tidymodels ist in Timbers, Campbell, und Lee (2022), Kap. 5.6, hier beschrieben.\nDie Daten aus Timbers, Campbell, und Lee (2022) finden sich in diesem Github-Repo-\nDie (z-transformierten) Daten zur Tumorklassifikation kÃ¶nnen hier bezogen werden.\n\ndata_url &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv\"\ncancer &lt;- read_csv(data_url)\n\nTimbers, Campbell, und Lee (2022) verwenden in Kap. 5 auch noch nicht standardisierte Daten, unscales_wdbc.csv, die hier als CSV-Datei heruntergeladen werden kÃ¶nnen.\n\ncancer_unscales_path &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv\"\n\nunscaled_cancer &lt;- read_csv(cancer_unscales_path) |&gt;\n  mutate(Class = as_factor(Class)) |&gt;\n  select(Class, Area, Smoothness)\nunscaled_cancer\n\n\n\n  \n\n\n\n\nDamit Tidymodels ein Modell als Klassifikation versteht, muss die AV als factor definiert sein. Man sollte diese Transformation auÃŸerhalb eines Rezepts druchfÃ¼hren.\\(\\square\\)\n\n\n7.6.2 Rezept definieren\n\nuc_recipe &lt;- recipe(Class ~ ., data = unscaled_cancer)\nprint(uc_recipe)\n\nUnd jetzt die z-Transformation:\n\nuc_recipe &lt;- \n  uc_recipe |&gt;\n  step_scale(all_predictors()) |&gt;\n  step_center(all_predictors())\n\nDie Schritte prep() und bake() sparen wir uns, da fit() und predict() bzw. last_fit() das fÃ¼r uns besorgen.\n\n7.6.3 Modell definieren\nTidymodels greift auf den Engine (das Paket) kknn zurÃ¼ck, das im Standard die Euklidische Distanz aus DistanzmaÃŸ berechnet. Daher muss die Engine nicht extra spezifiziert werden.\n\nknn_spec &lt;-\n  nearest_neighbor() |&gt;\n  set_mode(\"classification\")\nknn_spec\n## K-Nearest Neighbor Model Specification (classification)\n## \n## Computational engine: kknn\n\nIn der Voreinstellung wird \\(k=5\\) gewÃ¤hlt.\n\n\n\n\n\n\n\\(k\\) ist ein Tuningparameter\n\n\n\nDer Parameter \\(k\\) im knn-Algorithmus wird nicht Ã¼ber die Daten bestimmt, sondern muss durch dis Nutzi ausgewÃ¤hlt werden. Solche Parameter nennt man Tuningparameter (synonym: Hyperparameter), s. KapitelÂ 8.\\(\\square\\)\n\n\nDas Paket dials (Teil von Tidymodels) schlÃ¤gt Werte fÃ¼r \\(k\\) vor, das ist praktisch. Mehr dazu in KapitelÂ 8.\n\n7.6.4 Workflow definieren und fitten\nUnser Workflow ist die â€œSummeâ€ von Rezept und Modell:\n\nknn_wf &lt;- workflow() |&gt;\n  add_recipe(uc_recipe) |&gt;\n  add_model(knn_spec) \n\nWelche Variablen waren noch mal Teil des Rezepts? Mit str(uc_recipe) bekommt man eine Einblick in die struktur eines Objekts. Dann ziehen wir uns das Objekt, das die Infos zu den Variablen im Rezept beheimatet:\n\nuc_recipe %&gt;% \n  pluck(\"var_info\")\n\n\n\n  \n\n\n\nNatÃ¼rlich kann man auch einfach seinen Code anschauen. ğŸ˜\nDen Workflow fitten wir dann:\n\nknn_fit &lt;- \n  knn_wf |&gt; \n  fit(data = unscaled_cancer)\n\nknn_fit\n## â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 2 Recipe Steps\n## \n## â€¢ step_scale()\n## â€¢ step_center()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## \n## Call:\n## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5,     data, 5))\n## \n## Type of response variable: nominal\n## Minimal misclassification: 0.1072056\n## Best kernel: optimal\n## Best k: 5\n\n\n7.6.5 Vorhersagen\n\nnew_observation &lt;- \n  tibble(\n    Area = c(500, 1500), \n    Smoothness = c(0.075, 0.1)\n  )\n\nprediction &lt;- predict(knn_fit, new_observation)\n\nprediction"
  },
  {
    "objectID": "070-knn.html#krebsdiagnostik-2",
    "href": "070-knn.html#krebsdiagnostik-2",
    "title": "\n7Â  kNN\n",
    "section": "\n7.7 Krebsdiagnostik 2",
    "text": "7.7 Krebsdiagnostik 2\nIm Kapitel 5 greifen Timbers, Campbell, und Lee (2022) die Aufteilung in Train- vs.Â Test-Sample noch nicht auf (aber in Kapitel 6).\nDa in diesem Kurs diese Aufteilung aber schon besprochen wurde, soll dies hier auch dargestellt werden.\n\ncancer_split &lt;- initial_split(cancer, strata = Class)\ncancer_train &lt;- training(cancer_split)\ncancer_test &lt;- testing(cancer_split) \n\n\n7.7.1 Rezept definieren\n\ncancer_recipe &lt;- recipe(\n  Class ~ Smoothness + Concavity, data = cancer_train) |&gt;\n  step_scale(all_predictors()) |&gt;\n  step_center(all_predictors())\n\n\n7.7.2 Modell definieren\n\nknn_spec &lt;- nearest_neighbor() |&gt;\n  #set_engine(\"kknn\") |&gt;\n  set_mode(\"classification\")\n\n\n7.7.3 Workflow definieren\n\nknn_wf &lt;- workflow() %&gt;%  \n  add_recipe(cancer_recipe) %&gt;% \n  add_model(knn_spec) \n\nknn_wf\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 2 Recipe Steps\n## \n## â€¢ step_scale()\n## â€¢ step_center()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## K-Nearest Neighbor Model Specification (classification)\n## \n## Computational engine: kknn\n\n\n7.7.4 Vorhersagen\nIm Gegensatz zu Timbers, Campbell, und Lee (2022) verwenden wir hier last_fit() und collect_metrics(), da wir dies bereits eingefÃ¼hrt haben und kÃ¼nftig darauf aufbauen werden.\n\ncancer_test_fit &lt;- last_fit(knn_wf, cancer_split)\n\ncancer_test_fit\n\n\n\n  \n\n\n\n\n7.7.5 ModellgÃ¼te\n\ncancer_test_fit %&gt;% collect_metrics()\n\n\n\n  \n\n\n\nDie eigentlichen Predictions stecken in der Listenspalte .predictions im Fit-Objekt.\n\nnames(cancer_test_fit)\n## [1] \"splits\"       \"id\"           \".metrics\"     \".notes\"       \".predictions\"\n## [6] \".workflow\"\n\nGenau genommen ist .predictions eine Listenspalte, in der in jeder Zeile (und damit Zelle) eine Tabelle (Tibble) steht. Wir haben nur eine Zeile und wollen das erste Element dieser Spalte herausziehen, die Vorhersagen (Wahrscheinlichkeit) fÃ¼r benigne Struktur (\\(\\hat{y}\\); die Spalte heiÃŸt Ã¼brigens .pred_B). AuÃŸerdem brauchen wir die tatsÃ¤chlichen Diagnosen, \\(y\\), die â€œwohnenâ€ in der Spalte mit Namen Class. Das Element .predictions ist eine Liste(nspalte), die aus Tibbles besteht. Ziehen wir uns den ersten Tibble heraus mit pluck():\n\ncancer_test_fit %&gt;%  \n  pluck(\".predictions\", 1) %&gt;% str()\n## tibble [143 Ã— 6] (S3: tbl_df/tbl/data.frame)\n##  $ .pred_B    : num [1:143] 0 0.36 0 0 0.84 0 1 0.04 0.2 0 ...\n##  $ .pred_M    : num [1:143] 1 0.64 1 1 0.16 1 0 0.96 0.8 1 ...\n##  $ .row       : int [1:143] 1 5 6 9 14 18 22 27 35 36 ...\n##  $ .pred_class: Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 1 2 1 2 2 2 ...\n##  $ Class      : Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 2 2 1 2 2 2 ...\n##  $ .config    : chr [1:143] \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" ...\n\nNatÃ¼rlich kann man auch (einfacher) collect_predictions verwenden anstelle von pluck.\nHat man die Vorhersagen (und die wahren Werte) zur Hand, kann man die richtigen und falschen Werte gegenÃ¼berstellen lassen. So eine Tabelle nennt man auch eine Konfusionsmatrix1:\n\ncancer_test_predictions &lt;- \ncancer_test_fit %&gt;% \n  collect_predictions()  # alternativ: pluck(\".predictions\", 1)\n\nconfusion &lt;- cancer_test_predictions |&gt;\n             conf_mat(truth = Class, estimate = .pred_class)\n\nconfusion\n##           Truth\n## Prediction  B  M\n##          B 75  6\n##          M 15 47\n\n\n7.7.6 Schwellenwerte\nIm Standard wird eine Beobachtung der Klasse mit der hÃ¶chsten Wahrscheinlichkeit zugeordnet. MÃ¶chte man das Ã¤ndern, hilft das R-Paket probably.\n\n7.7.7 Visualisierung\nVerbildlichen wir die Konfusionsmatrix, so dass wir sehen welche B als B klassifiziert wurden und welche M als M klassifiziert wurden (bzw. welche nicht), s. ?fig-conf-bm.\n\n# autoplot(confusion, type = \"mosaic\")"
  },
  {
    "objectID": "070-knn.html#klassifikationsgÃ¼te",
    "href": "070-knn.html#klassifikationsgÃ¼te",
    "title": "\n7Â  kNN\n",
    "section": "\n7.8 KlassifikationsgÃ¼te",
    "text": "7.8 KlassifikationsgÃ¼te\n\n7.8.1 Die vier mÃ¶glichen Ergebnisse eines Tests\nEin Test kann vier verschiedenen Ergebnisse haben:\n\n\n\n\n\n\nVier Arten von Ergebnissen von Klassifikationen\n  \nWahrheit\n      Als negativ (-) vorhergesagt\n      Als positiv (+) vorhergesagt\n      Summe\n    \n\n\nIn Wahrheit negativ (-)\nRichtig negativ (RN)\nFalsch positiv (FP)\nN\n\n\nIn Wahrheit positiv (+)\nFalsch negativ (FN)\nRichtig positiv (RN)\nP\n\n\nSumme\nN*\nP*\nN+P\n\n\n\n\n\n\nVon den vier mÃ¶glichen Ergebnissen sind zwei falsch (und zwei richtig). Ein Test kann also zwei Arten von Fehlern machen, s. AbbildungÂ 7.9. Dort kann man die Punkte im roten Hintergrund als kranke Menschen verstehen (links des schrÃ¤gen Strichs); auf der anderen Seite sind man gesunde Menschen (grÃ¼ner Hintergrund). Die Punkte in der Ellipse zeigen die Klassifikationsergebnisse bzw. -fehler.\n\nFehler erster Art: Gesunde als krank klassifizieren (â€œFehlalarmâ€)\nFehler zweiter Art: Kranke als gesund klassifizieren (â€œÃœbersehfehlerâ€)\n\n\n\nAbbildungÂ 7.9: Zwei Fehlerarten einer Klassifikation\n\nQuelle: Von Nichtich - Eigenes Werk, Gemeinfrei\nBei Wikipedia findet sich eine nÃ¼tzliche ErlÃ¤uterung der Kennzahlen der KlassifikationsgÃ¼te, vgl. AbbildungÂ 7.10 und AbbildungÂ 7.11.\n\n\n\n\n\n(a) SensitivitÃ¤t\n\n\n\n\n\n(b) FN-Rate\n\n\n\nAbbildungÂ 7.10: SensitivitÃ¤t und Falsch-Negativrate addieren sich zu 1.\n\n\n\n\n\n\n\n(a) SpezifitÃ¤t\n\n\n\n\n\n(b) FP-Rate\n\n\n\nAbbildungÂ 7.11: SpezifitÃ¤t und FP-Rate addieren sich zu 1.\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEs ist einfach, in nur einem der beiden Fehlerarten gut abzuschneiden. So kÃ¶nnte ein Test alle Personen als krank klassifizieren. Damit hÃ¤tte er auomatisch keine Ãœbersehfehler. Leider wÃ¤ren aber potenziell viele Fehlalarme dabei. Die HÃ¶he des Ãœbersehfehler und die HÃ¶he der Fehlalarme mÃ¼ssen daher nicht gleich sein. Man muss daher beide Fehlerarten berÃ¼cksichtigen, um die GÃ¼te eines Tests einzuschÃ¤tzen. Welcher Fehler schwerer wiegt, der Fehlalarm oder der Ãœbersehfehler, hÃ¤ngt vom Sachgegenstand ab und ist keine Frage der Statistik.\\(\\square\\)\n\n\n\n7.8.2 Kennzahlen der Klassfikation\nEs gibt eine (verwirrende) Vielfalt von Kennzahlen, um die GÃ¼te einer Klassifikation einzuschÃ¤tzen. In TabelleÂ 7.1 sind einige davon aufgefÃ¼hrt.\n\n\n\n\nTabelleÂ 7.1: GelÃ¤ufige Kennwerte der Klassifikation. F: Falsch. R: Richtig. P: Positiv. N: Negativ\n\n\n\n\n\n\nName\nDefinition\nSynonyme\n\n\n\nFP-Rate\nFP/N\nAlphafehler, Typ-1-Fehler, 1-SpezifitÃ¤t, Fehlalarm\n\n\nRP-Rate\nRP/N\nPower, SensitivitÃ¤t, 1-Betafehler, Recall\n\n\nFN-Rate\nFN/N\nFehlender Alarm, Befafehler\n\n\nRN-Rate\nRN/N\nSpezifitÃ¤t, 1-Alphafehler\n\n\nPos. Vorhersagewert\nRP/P*\nPrÃ¤zision, Relevanz\n\n\nNeg. Vorhersagewert\nRN/N*\nSegreganz\n\n\nRichtigkeit\n(RP+RN)/(N+P)\nKorrektklassifikationsrate, Gesamtgenauigkeit\n\n\nYouden-Index\nRN-Rate+RP-Rate-1\nDurchschnitt von SensitivitÃ¤t und SpezifitÃ¤t\n\n\n\n\n\n\nIn Sauer (2019), Kap. 19.6, findet sich einige ErklÃ¤rung zu Kennzahlen der KlassifikationsgÃ¼te.\nAuf der Seite des R-Pakets yardstick finden Sie eine Ãœbersicht an unterstÃ¼tzter Kennzahlen.\n\n7.8.3 Schwellenwerte der Klassifiktion\nIm Standard wird ein Fall der Klasse zugeordnet, die die hÃ¶chste Wahrscheinlichkeit hat. Mit dem R-Paket probably kann man (als Teil eines Post-Processing des Modellierens) diese Schwellenwerte2 Ã¤ndern.\n\nBeispiel 7.1 Da eine Ã„rztin auf keinen Fall einen Krebsfall Ã¼bersehen mÃ¶chte - da Sie den Ãœbersehfehler als deutlich schlimmer einschÃ¤tzt als den Fehlalarm - setzt sie die Schwelle fÃ¼r die Klasse â€œGesundâ€ auf 95%.\\(\\square\\)\n\n\n7.8.4 ROC-Kurve\nEine ROC-Kurve3 ist ein Graph, der die ModellgÃ¼te eines Klassfikationsmodells zu allen Schwellenwerten aufzeigt. Eine ROC-Kurve ist eine nÃ¼tzliche und gebrÃ¤uchliche Methode zur Bestimmung der insgesamten KlassifikationsgÃ¼te eines Modells.\nDie Kurve hat zwei Parameter:\n\nTP-Rate (Y-Achse)\nFP-Rate (X-Achse)\n\nPraktisch wÃ¼rde man fÃ¼r die vorhergesagten Wahrscheinlichkeiten eines Klassifikationsmodells viele Schwellenwerte anlegen, z.B. von 0%, 1%, â€¦, 100%. FÃ¼r jeden Schwellenwert berechnet man die vorhergesagte Klasse. In tidymodels besorgt roc_curve diesen Job:\n\ncancer_roc &lt;- \ncancer_test_predictions %&gt;% \n  roc_curve(truth = Class, .pred_B)\ncancer_roc\n\n\n\n  \n\n\n\nMit autoplot kann man dann die ROC-Kurve zeichnen, s. AbbildungÂ 7.12.\n\ncancer_test_predictions %&gt;% \n  roc_curve(truth = Class, .pred_B) %&gt;% \n  autoplot()\n\n\n\nAbbildungÂ 7.12: ROC-Kurve fÃ¼r das Fallbeispiel der Krebsdiagnostik\n\n\n\nDie FlÃ¤che unter der Kurve (area under curve, AUC), bezogen auf die ROC-Kurve, ist ein MaÃŸ fÃ¼r die GÃ¼te der Klassifikation. AbbildungÂ 7.13 aus Sauer (2019) stellt drei Beispiele von KlassifikationsgÃ¼ten dar: sehr gute (A), gute (B) und schlechte (C). Ein hohe KlassifikationsgÃ¼te zeigt sich daran, dass eine hohe Richtig-Positiv-Rate mit einer geringen Fehlalarmquote einhergeht: Wir finden alle Kranken, aber nur die Kranken. Die ROC-Kurve â€œhÃ¤ngt oben links an der Deckeâ€; der AUC-Wert geht gegen 1. Ein schlechter Klassifikator trifft so gut wie ein MÃ¼nzwurf: Ist das Ereignis selten, hat er eine hohe Falsch-Positiv-Rate und eine geringe Falsch-Negativ-Rate. Ist das Ereignis hingegen hÃ¤ufig, liegen die FehlerhÃ¶hen genau umgekehrt: Eine hohe Richtig-Positiv-Rate geht dann mit einer hohen Falsch-Positiv-Rate einher.\n\n\n\n\nAbbildungÂ 7.13: Beispiel fÃ¼r eine sehr gute (A), gute (B) und schlechte (C) Klassifikation\n\n\n\n\n7.8.5 Krebstest-Beispiel\nBetrachten wir diese Daten eines fiktiven Krebstest, aber mit realistischen Werte, s. AbbildungÂ 7.14.\n\nkrebstest &lt;- read_csv(\"data/krebstest.csv\")\n\n\n## # A tibble: 1 Ã— 7\n##   format width height colorspace matte filesize density\n##   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n## 1 PNG      500    429 sRGB       TRUE     40643 72x72\n\n\n\nAbbildungÂ 7.14: Kennwerte zu tatsÃ¤chlichem und laut Test Krebs-Status\n\n\n\nWie gut ist dieser Test? Berechnen wir einige Kennzahlen.4\nDa die Funktionen zur Klassifikation stets einen Faktor wollen, wandeln wir die relevanten Spalten zuerst in einen Faktor um (aktuell sind es numerische Spalten).\n\nkrebstest &lt;-\n  krebstest  %&gt;% \n  mutate(Krebs = factor(Krebs),\n         Test = factor(Test))\n\nDie Konfusionsmatrix ist in AbbildungÂ 7.15 gezeigt.\n\ncm_krebs &lt;- conf_mat(krebstest, truth = Krebs, estimate = Test)\ncm_krebs\n##           Truth\n## Prediction  0  1\n##          0 84  2\n##          1 11  3\n\n\n\n\n\nAbbildungÂ 7.15: Konfusionsmatrix fÃ¼r das Krebs-Beispiel\n\n\n\nGesamtgenauigkeit:\n\naccuracy(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nDie Kennzahl der Gesamtgenauigkeit zÃ¤hlt nur den Anteil richtiger Klassifikation. Sind z.B. 95% der Menschen gesund, und wir klassifizieren alle Menschen als gesund, erreichen wir auf einfachem Weg eine Gesamtgenauigkeit von 95%. Trotz dieses scheinbar hohen Werts haben wir alle kranken Menschen fehlklassifiziert. In dem Fall, wie die Klassen (krank vs.Â gesund) ungleich groÃŸ sind, sinkt die NÃ¼tzlichkeit dieser Kennzahl. Aber sie kann als Referenzwert herhalten, an dem sich andere Modelle messen lassen mÃ¼ssen. NÃ¼tzliche Alternativen sind dann z.B. Cohens Kappa oder ROC-AUC. Oder man schaut sich mehrere Kennwerte an, was meist der richtige Weg ist. \\(\\square\\)\n\n\nSensitivitÃ¤t:\n\nsens(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nSpezifitÃ¤t:\n\nyardstick::spec(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nCohens Kappa:\n\nyardstick::kap(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nEin Wert von 0 zeigt eine Klassifikation an, die von einer Zufallzuordnung nicht zu unterscheiden ist. Ein Wert von 1 zeigt eine perfekte Klassifikation an. Damit ist Kappa eine Kennzahl der Gesamtgenauigkeit einer Klassifikation, die das Problem ungleicher KlassengrÃ¶ÃŸen, worunter die Kennzahl Gesamtgenauigkeit leider, umgeht.\nPositiver Vorhersagewert:\n\nppv(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nNegativer Vorhersagewert:\n\nnpv(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nWÃ¤hrend SensitivitÃ¤t und SpezitivitÃ¤t sehr hoch sind, ist die der negative Vorhersagewert sehr gering:\nWenn man einen positiven Test erhÃ¤lt, ist die Wahrscheinlichkeit, in Wahrheit krank zu sein gering, zum GlÃ¼ck!\nMit metrics kann man sich eine Auswahl von Metriken (der ModellgÃ¼te) anzeigen lassen:\n\nmetrics(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nMan kann sich auch eine â€œeigeneâ€ Funktion metrics erstellen, bzw. metrics Ã¤ndern:\n\nmy_metrics &lt;- metric_set(accuracy, ppv, sensitivity)\n\nDiese Funktion ruft man dann genauso auf wie metrics:\n\nmy_metrics(krebstest, truth = Krebs, estimate = Test)"
  },
  {
    "objectID": "070-knn.html#knn-als-regression",
    "href": "070-knn.html#knn-als-regression",
    "title": "\n7Â  kNN\n",
    "section": "\n7.9 kNN als Regression",
    "text": "7.9 kNN als Regression\nDer kNN-Algorithmus kann nicht nur zur Klassifikation, sondern auch zur Regression (numerische Vorhersage) verwendet werden.\nDie Vorhersage ist dann nicht der Modus der Nachbarn, sondern der Mittelwert der Nachbarn."
  },
  {
    "objectID": "070-knn.html#aufgaben",
    "href": "070-knn.html#aufgaben",
    "title": "\n7Â  kNN\n",
    "section": "\n7.10 Aufgaben",
    "text": "7.10 Aufgaben\n\nArbeiten Sie sich so gut als mÃ¶glich durch diese Analyse zum Verlauf von Covid-FÃ¤llen\n\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu VulkanausbrÃ¼chen\nFallstudie Himalaya\n\nFallstudie Immobilienpreise von Jan Kirzenz; diese Fallstudie beinhaltet mehrere Lernalgorithmen, die Sie vielleicht noch nicht kennen.\n\nFalls Sie in einer Fallstudie auf Inhalte treffen, die Sie noch nicht kennen: Im Zweifel einfach ignorieren."
  },
  {
    "objectID": "070-knn.html#fazit",
    "href": "070-knn.html#fazit",
    "title": "\n7Â  kNN\n",
    "section": "\n7.11 Fazit",
    "text": "7.11 Fazit\nKeep kalm and proceed ğŸ˜\n\n\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, und Melissa Lee. 2022. Data science: an introduction. First edition. Statistics. Boca Raton: CRC Press."
  },
  {
    "objectID": "070-knn.html#footnotes",
    "href": "070-knn.html#footnotes",
    "title": "\n7Â  kNN\n",
    "section": "",
    "text": "seltener â€œWahrheitsmatrixâ€â†©ï¸\nengl. thresholds, cutoffsâ†©ï¸\nReceiver Operating Characteristic Curveâ†©ï¸\naus dem Paket yardstick, das Teil von Tidymodels ist. Hier ist die Hilfeseite zum Paket.â†©ï¸"
  },
  {
    "objectID": "080-Resampling-Tuning.html#lernsteuerung",
    "href": "080-Resampling-Tuning.html#lernsteuerung",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Lernziele\n\nSie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.\nSie kÃ¶nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.\n\n8.1.2 Vorbereitung\n\nLesen Sie die Literatur.\n\n8.1.3 Literatur\n\nRhys, Kap. 3\nTMWR, Kap. 10, 12\n\n8.1.4 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\n\n\n8.1.5 Daten\n\ndata(ames)"
  },
  {
    "objectID": "080-Resampling-Tuning.html#Ã¼berblick",
    "href": "080-Resampling-Tuning.html#Ã¼berblick",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.2 Ãœberblick",
    "text": "8.2 Ãœberblick\n\n8.2.1 Train- und Test-Sample vervielfacht\nIn KapitelÂ 4.7 haben wir gelernt, dass ein Modell in einem zweiten Datensatz auf seine ModellgÃ¼te hin Ã¼berprÃ¼ft werden und sollte und nicht in dem (ersten) Datensatz, in dem die Modellparameter berechnet wurden.\nIn diesem Kapitel werden wir wir von einem Modell mehrere Varianten berechnen, daher benÃ¶tigen wir fÃ¼r jeden dieser Varianten oder â€œModellkandidatenâ€ eine eigene Train-Test-Aufteilung. Zur Klarheit der Begrifflichkeiten nennt man die resultierenden Teile in dem Fall Analyse- und Assessment-Sample, s. AbbildungÂ 8.1 dargestellt aus Kap. 10.2 in Silge und Kuhn (2022) (Quelle).\n\n\nAbbildungÂ 8.1: Die Aufteilung der Daten im Falle mehrerer Modellkandidaten\n\n\n8.2.2 Standardablauf\nEin Standardablauf des maschinellen Lernens ist in AbbildungÂ 8.2 dargestellt.\n\n\n\n\nflowchart TD\n   \nGesamtdatensatz --&gt; Split[In Train- und Test aufteilen]\nsubgraph Fit[FÃ¼r jeden Modellkandidaten i]\n  subgraph Kand[Modellkandidat i]\n  F[Fitte im Train-S] --&gt; T[Teste im Assessment-S]\n  end\nend\nSplit --&gt; Fit\nFit --&gt; Best[Bestimmte besten Kandidaten]\nBest --&gt; lastFit[Fitte ihn im ganzen Train-S]\nlastFit --&gt; test[Teste im Test-S]\n\n\nAbbildungÂ 8.2: Standardablauf des maschinellen Lernens mit Tuning und Resampling (S: Sample bzw. Stichprobe)\n\n\n\n\n8.2.3 Datensatz aufteilen\nBisher haben wir den Gesamt-Datensatz stets in ein Train- und ein Test-Sample aufgeteilt.\nAber es kÃ¶nnte ja sein, dass die Aufteilung just die â€œschwer zu vorherzusagendenâ€ FÃ¤lle in das Test-Sample befÃ¶rdert. Dann wÃ¼rde sich unser Modell Ã¼ber die MaÃŸen schwer tun und zu schlecht abschneiden. Umgekehrt kÃ¶nnte es ja passieren, dass die â€œeinfach zu vorherzusagendenâ€ FÃ¤lle ins Test-Sample wandern, einfach durch die ZufÃ¤lligkeit der Aufteilung von Train- und Test-Sample.\nEine LÃ¶sung, die sich anbietet, lautet, die Train-Test-Aufteilung ein paar Mal durchzufÃ¼hren, und sich dann mit dem Mittelwert der ModellgÃ¼te zu begnÃ¼gen. VoilÃ : Resampling!\n\n8.2.4 Resampling\nResampling ist eine Verallgemeinerung des einfachen Aufteilens in Train- und Test-Sample. Im Kern wird aus dem Datensatz mehrere Stichproben durch wiederholtes Ziehen gezogen. Durch Resampling kann die ModellgÃ¼te besser bestimmt werden als durch einfaches Train-Test-Aufteilen.\\(\\square\\)\n\n\n\n\n\n\nHinweis\n\n\n\nVerschiedene (zufÃ¤llige) Aufteilung eines Datensatzes in Train- und Test-Sample kÃ¶nnen zu verschiedenen ModellgÃ¼ten fÃ¼hren. So kÃ¶nnten im Train-Sample durch eine bestimmte Zufallsaufteilung relativ viele (oder wenige) schwer zu klassifizierende FÃ¤lle zusammen kommen.\\(\\square\\)\n\n\n\n8.2.5 Resampling-Varianten\nVergleichen Sie die drei FÃ¤lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:\n\nWir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe â€œvorherâ€. Wir finden eine Gesamtgenauigkeit von 80%.\nWir fitten ein Klassifikationsmodell in einem Teil der ursprÃ¼nglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der ursprÃ¼nglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.\nWir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der FÃ¤lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.\n\nWelchen der drei FÃ¤lle finden Sie am sinnvollsten? Warum? Fall Nummer 3 bezeichnet man als Kreuzvalidierung.\n\n8.2.6 Illustration des Resampling\nResampling stellt einen Oberbegriff dar; Kreuzvalidierung ist ein Unterbegriff dazu. Es gibt noch andere Arten des Resampling, etwa Bootstrapping oder Leave-One-Out-Cross-Validation (LOOCV).\nIm Folgenden ist nur die Kreuzvalidierung dargestellt, da es eines der wichtigsten und vielleicht das am hÃ¤ufigsten verwendete Verfahren des Resampling ist. In vielen Quellen finden sich ErlÃ¤uterungen anderer Verfahren dargestellt, etwa in Silge und Kuhn (2022), James u.Â a. (2021) oder Rhys (2020)."
  },
  {
    "objectID": "080-Resampling-Tuning.html#umsetzung-in-tidymodels",
    "href": "080-Resampling-Tuning.html#umsetzung-in-tidymodels",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.3 Umsetzung in tidymodels",
    "text": "8.3 Umsetzung in tidymodels\nBetrachten wir dieses Konzept an einem konkreten Beispiel mit Tidymodels.\n\n8.3.1 Keine Train-Test-Aufteilung\nWir teilen beim Resampling nicht einmal in Train- und Test-Sample, sondern mehrfach. Daher kÃ¶nnen wir uns die einfache Train-Test-Aufteilung sparen.\n\n\n\n\n\n\nVorsicht\n\n\n\nWenn man ein Model auch tuned, also Tuning verwendet, dann werden wir wiederum die Train-Test-Aufteilung verwenden. Dazu spÃ¤ter mehr.\\(\\square\\)\n\n\n\n8.3.2 AbhÃ¤ngige Variable transformieren\nWir beginnen mit etwas Datenvorverarbeitung. Hier transformieren wir die abhÃ¤ngige Variable, und zwar mit einer Log-Transformation.\n\nMÃ¶chte man eine abhÃ¤ngige Variable transformieren, so sollte das auÃŸerhalb des Rezepts passieren, da Tidymodels das â€œBackenâ€ nicht auf die outcome-Variable ausfÃ¼hrt.\\(\\square\\)\n\nAus der Dokumentation von step_scale:\n\nskip - A logical. Should the step be skipped when the recipe is baked by bake()? While all operations are baked when prep() is run, some operations may not be able to be conducted on new data (e.g.Â processing the outcome variable(s)). Care should be taken when using skip = TRUE as it may affect the computations for subsequent operations.\n\n\names &lt;-\n  ames %&gt;% \n  mutate(Sale_Price = log(Sale_Price, base = 10))\n\nHier finden Sie eine Antwort, warum tidymodels sich weigert, Informationen Ã¼ber die AV vom Train- in das Test-Sample zu transferieren.\n\n8.3.3 Rezept, Modell und Workflow definieren\nIn gewohnter Weise definieren wir zunÃ¤chst den Workflow mit einem kNN-Modell.\n\names_rec &lt;-\n  recipe(Sale_Price ~ Lot_Area + Fireplaces + Longitude + Latitude,\n         data = ames) %&gt;%\n  step_zv(all_predictors()) %&gt;% \n  step_normalize(all_predictors()) %&gt;% \n  step_impute_median(all_predictors())\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\"\n  ) \n\names_wflow1 &lt;-\n  workflow() %&gt;%\n  add_recipe(ames_rec) %&gt;%\n  add_model(knn_model)\n\nZur Erinnerung: Mit dem Rezept kNN-Modell ist noch nicht *berechnet, es ist nur ein â€œRezeptâ€ erstellt.\n\n8.3.4 Einfache v-fache Kreuzvalidierung\nAbbildungÂ 8.3 illustriert die zufÃ¤llige Aufteilung von \\(n=10\\) FÃ¤llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe. Man spricht von Kreuzvalidierung (cross validation, CV).\nIn diesem Fall wurden 70% der (\\(n=10\\)) FÃ¤lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe); ein willkÃ¼rlicher, aber nicht unÃ¼blicher Anteil. Diese Aufteilung wurde \\(v=3\\) Mal vorgenommen, es resultieren drei â€œResampling-Stichprobenâ€, die manchmal auch als â€œFaltungenâ€ bezeichnet werden.\n\n\n\n\nAbbildungÂ 8.3: Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt\n\n\n\nSauer (2019) stellt das Resampling so dar (S. 259), s. AbbildungÂ 8.4.\n\n\n\n\nAbbildungÂ 8.4: Kreuzvalidierung, Aufteilung in Train- vs.Â Testsample\n\n\n\nDer Gesamtfehler der Vorhersage (die ModellgÃ¼te) wird als Mittelwert der Vorhersagefehler in den einzelnen Faltungen berechnet.\nWarum ist die Vorhersage besser, wenn man mehrere Faltungen, mehrere SchÃ¤tzungen fÃ¼r \\(y\\) also, vornimmt?\nDer Grund ist das Gesetz der groÃŸen Zahl, nachdem sich eine SchÃ¤tzung in Mittelwert und VariabilitÃ¤t stabilisiert mit steigendem Stichprobenumfang, dem wahren Mittelwert also prÃ¤ziser schÃ¤tzt.1 Mit mehr Faltungen nÃ¤hern wir uns also einem â€œwahrenâ€ Mittelwert der ModellgÃ¼te (und sonstiger Kennzahlen) nÃ¤her an.\nHÃ¤ufig werden \\(v=10\\) Faltungen verwendet, was sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.\nDie Nachteile der Kreuzvalidierung sind:\n\nDie Rechenzeit steigt (in der Regel) etwa proportional zur Anzahl der \\(v\\) Faltungen.\nDa die Train-Stichprobe kleiner ist (als bei der einfachen Train-Test-Aufteilung), wird die SchÃ¤tzung der Modellkoeffizienten ungenauer sein und damit die ModellgÃ¼te geringer.\n\nInsgesamt Ã¼berwiegen zumeist die Vorteiler eines Resamplings (wie eine Kreuzvalidierung) im Vergleich zu einfachen Train-Test-Aufteilung.\n\n8.3.5 Wiederholte Kreuzvalidierung\nDie \\(r\\)-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (nÃ¤mlich \\(r=4\\) mal), Sauer (2019) stellt das Resampling so dar (S. 259), s. AbbildungÂ 8.5.\n\n\n\n\nAbbildungÂ 8.5: Wiederholte Kreuzvalidierung\n\n\n\nDie wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.\n\n\n\n\n\n\nWarum ist die Wiederholung der Kreuzvalidierung nÃ¼tzlich?\nDie Kreuvalidierung liefert einen SchÃ¤tzwert der Modellparameter, die wahren Modellparameter werden also anhand einer Stichprobe von \\(n=1\\) geschÃ¤tzt. Mit hÃ¶herem Stichprobenumfang kann diese SchÃ¤tzung natÃ¼rlich prÃ¤zisiert werden.\nDa jede Stichprobenverteilung bei \\(n \\rightarrow \\infty\\) normalverteilt ist - ein zentrales Theorem der Statistik, der Zentrale Grenzwertsatz (Central Limit Theorem) - kann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem \\(n\\) ebenfalls annÃ¤hernd normalverteilt2. Dann sind die Quantile bekannt und man kann die Streuung der SchÃ¤tzers, \\({\\sigma }_{\\bar {x}}\\), z.B. fÃ¼r den Mittelwert, einfach schÃ¤tzen:\n\\[{\\displaystyle {\\sigma }_{\\bar {x}}\\ ={\\frac {\\sigma }{\\sqrt {n}}}}\\]"
  },
  {
    "objectID": "080-Resampling-Tuning.html#vertiefung",
    "href": "080-Resampling-Tuning.html#vertiefung",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.4 Vertiefung",
    "text": "8.4 Vertiefung\n\n8.4.1 Andere Illustrationen\nEs gibt eine Reihe nÃ¼tzlicher, vergleichbarer Illustrationen in anderen BÃ¼chern zum Resampling:\n\nTimbers, Campbell & Lee, 2022, Kap. 6\nSilge & Kuhn, 2022, 10.1\nSilge & Kuhn, 2022, 10.2\nSilge & Kuhn, 2022, 10.3\nJames, Witten, hastie & Tishirani, 2021, 5.3\n\n8.4.2 Gesetz der groÃŸen Zahl\nNach dem Gesetz der groÃŸen Zahl (Law of Large Numbers) sollte sich der Mittelwert einer groÃŸen Stichprobe dem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess) sehr nahe kommen.\n\\[\\displaystyle \\lim _{n\\to \\infty }\\sum _{i=1}^{n}{\\frac {X_{i}}{n}}={\\overline {X}}\\]\nDavid Salazar visualisiert das folgendermaÃŸen in diesem Post seines lesenswerten Blogs, s. AbbildungÂ 8.6).\n\n\n\n\nAbbildungÂ 8.6: Gesetz der groÃŸen Zahl\n\n\n\nWie man sieht, nÃ¤hert sich der empirische Mittelwert (also in der Stichprobe) immer mehr dem theoretischen Mittelwert, 0, an.\nAchtung: Bei randlastigen Verteilungen darf man dieses schÃ¶ne, wohlerzogene Verhalten nicht erwarten (Taleb 2019)."
  },
  {
    "objectID": "080-Resampling-Tuning.html#kreuzvalidierung-in-tidymodels",
    "href": "080-Resampling-Tuning.html#kreuzvalidierung-in-tidymodels",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.5 Kreuzvalidierung in tidymodels",
    "text": "8.5 Kreuzvalidierung in tidymodels\n\n8.5.1 Kreuzvalidierung definieren\nSo kann man eine einfache v-fache Kreuzvalidierung (cross-validation, CV) in Tidymodels auszeichnen3:\n\nset.seed(2453)\names_folds &lt;- vfold_cv(ames, strata = \"Sale_Price\")\names_folds\n\n\n\n  \n\n\n\nWerfen wir einen Blick in die Spalte splits, erste Zeile:\n\names_folds %&gt;% pluck(1, 1)\n## &lt;Analysis/Assess/Total&gt;\n## &lt;2635/295/2930&gt;\n\nMÃ¶chte man die Defaults von vfold_cv wissen, schaut man in der Hilfe nach: ?vfold_cv:\nvfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)\nProbieren wir \\(v=10\\) und \\(r=10\\):\n\names_folds_rep &lt;- vfold_cv(ames, \n                           strata = \"Sale_Price\", \n                           v = 10,\n                           repeats = 10)\names_folds_rep\n\n\n\n  \n\n\n\n\n8.5.2 Resamples fitten\nHat unser Computer mehrere Rechenkerne, dann kÃ¶nnen wir diese nutzen und die Berechnungen beschleunigen. Im Standard wird sonst nur ein Kern verwendet.\n\nmycores &lt;- parallel::detectCores(logical = FALSE)\nmycores\n## [1] 4\n\nAuf Unix/MacOC-Systemen kann man dann die Anzahl der parallelen Kerne so einstellen4:\n\nlibrary(doMC)\nregisterDoMC(cores = mycores)\n\nSo, und jetzt fitten wir die Resamples und betrachten die ModellgÃ¼te in den Resamples:\n\ntic()\names_resamples_fit &lt;- \n  ames_wflow1 %&gt;% \n  fit_resamples(ames_folds)\ntoc()\n## 1.564 sec elapsed\n\n\n ames_resamples_fit %&gt;%\n  collect_metrics()\n\n\n\n  \n\n\n\n\n8.5.3 Streuung in der ModellgÃ¼te zwischen den Resamples\nBetrachten wir die Streuungen der ModellgÃ¼te (RSMSE) in der 10-fachen, nicht wiederholten Kreuzvalidierung, s. AbbildungÂ 8.7.\nJetzt wiederholen wir die Kreuzvalidierung \\(r=5\\) mal und betrachten wieder die Streuung der ModellgÃ¼te. Da wir \\(r\\) mal so viele Modelle berechnen, benÃ¶tigen wir - wenn nur ein einzelnen Rechenkern benutzt wird - \\(r\\) mal so viel Rechenzeit5.\nZuerst berechnen wir die wiederholte Kreuzvalidierung, das kann etwas dauern:\n\ntic()\names_resamples_fit_rep &lt;- \n  ames_wflow1 %&gt;% \n  fit_resamples(ames_folds_rep)\ntoc()\n## 7.843 sec elapsed\n\nUnd hier sind die GÃ¼tekennzahlen der wiederholten Kreuzvalidierung.\n\names_resamples_fit_rep %&gt;% \n  collect_metrics()\n\n\n\n  \n\n\n\nWie man sieht, ist der Standardfehler (std_err), also die Streuung der ModellgÃ¼ten deutlich kleiner in der wiederholten Kreuzvalidierung (verglichen mit der einfachen, r=1, Kreuzvalidierung).\nAuf dieser Basis visualisieren wir die Ergebnisse: Wie man sieht, streuen die \\(v=10\\) Faltungen in ihre ModellgÃ¼te, s. AbbildungÂ 8.7, links.\n\n\n\n\n\n\nHinweis\n\n\n\nHÃ¤tten wir nur ein Mal, nicht 10 Mal, in Train- und Test-Sample aufgeteilt, hÃ¤ttten wir einen Wert der ModellgÃ¼te (z.B. den ersten) beobachtet. Wir hÃ¤tten (vielleicht) nicht geahnt, dass unser Wert nicht der einzig mÃ¶gliche ist. Jetzt sehen wir aber, dass ein einzelner Wert nicht zuverlÃ¤ssig ist. Erst mehrere Wiederholungen (Resamples) ermÃ¶glichen eine zuverlÃ¤ssige(re) SchÃ¤tzung der ModellgÃ¼te.\\(\\square\\)\n\n\nAbbildungÂ 8.7, rechts, zeigt ein zweites PhÃ¤nomen. Durch das Wiederholen (\\(r=5\\)) sinkt, nach dem Gesetz der groÃŸen Zahl, die Streuung. Geringere Streuung bedeutet eine genauere SchÃ¤tzung des wahren GÃ¼tewerts.\n\n\n\n\n\n(a) Streuung der ModellgÃ¼te (RMSE) mit v=10 r=1 CV\n\n\n\n\n\n(b) Streuung der ModellgÃ¼te (RMSE) mit v=10 r=5 CV\n\n\n\nAbbildungÂ 8.7: Streuung der ModellgÃ¼te (RMSE) bei nicht wiederholter und wiederholter CV\n\n\nPuh, das war recht theoretisch. Ja, das Leben des Data-Scientisten ist nicht immer einfach, findet auch Grumpy Cat, s. AbbildungÂ 8.8.\n\n\nAbbildungÂ 8.8: Grumpy Cat und die Schwierigkeiten im Leben des Data-Scientisten\n\nQuelle: imgflip"
  },
  {
    "objectID": "080-Resampling-Tuning.html#tuning",
    "href": "080-Resampling-Tuning.html#tuning",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.6 Tuning",
    "text": "8.6 Tuning\n\n8.6.1 Tuning\n\nğŸ‘¨â€ğŸ« Hey ChatGPT: Definiere Tuning mit maschinellen Lernen am Beispiel von knn und dem Parameter k.\n\n\nğŸ¤– KNN (K-nearest neighbors) ist ein Machine-Learning-Algorithmus, bei dem die Vorhersage eines neuen Datenpunkts auf der Basis der k nÃ¤chsten Nachbarn im Trainingsdatensatz getroffen wird. Der Parameter k gibt an, wie viele Nachbarn zur Vorhersage verwendet werden sollen. Eine wichtige Aufgabe beim Tuning von KNN besteht darin, den optimalen Wert fÃ¼r den Parameter k zu finden. Wenn k zu klein gewÃ¤hlt wird, kann dies zu einer Ãœberanpassung an den Trainingsdatensatz fÃ¼hren, wÃ¤hrend bei zu groÃŸ gewÃ¤hltem k das Modell unteranpassung aufweisen kann. Durch Tuning kann ein optimales k gefunden werden, das zu einer besseren Leistung des Modells auf einem Validierungsdatensatz fÃ¼hrt. Es gibt verschiedene Methoden zum Tuning des k-Parameters. Eine MÃ¶glichkeit besteht darin, ein Rastersuchverfahren durchzufÃ¼hren, bei dem eine vordefinierte Menge von k-Werten getestet wird, um dasjenige zu finden, das die beste Leistung auf einem Validierungsdatensatz aufweist. Eine andere MÃ¶glichkeit besteht darin, eine zufÃ¤llige Suche durchzufÃ¼hren, indem man zufÃ¤llig verschiedene k-Werte auswÃ¤hlt und deren Leistung bewertet. Das Ziel des Tunings ist es, den besten Wert fÃ¼r den Parameter k zu finden, um das KNN-Modell zu verbessern und die Vorhersagegenauigkeit auf einem Testdatensatz zu maximieren. Das Tuning sollte jedoch immer mit einem unabhÃ¤ngigen Testdatensatz durchgefÃ¼hrt werden, um sicherzustellen, dass das Modell nicht Ã¼berangepasst wird und auf neuen Daten gut funktioniert.6\\(\\square\\)\n\n\n8.6.2 Tuning am Beispiel von knn\nIm K-NÃ¤chste-Nachbarn-Modell (Klassifikation) ist der vorhergesagt Wert, \\(\\hat{y}\\) fÃ¼r eine neue Beobachtung \\(x_0\\) der Modus der \\(K\\) nÃ¤chsten Nachbarn.\nDie Wahl von \\(K\\) hat einen zentralen Einfluss auf die Vorhersagen und damit auf die VorhersagegÃ¼te. Allerdings wird \\(K\\) nicht vom Modell geschÃ¤tzt. Es liegt an uns, diesen Wert zu wÃ¤hlen.\n\n8.6.3 Tuningparmaeter\nParameter eines Lernmodells, die vom Nutzer zu bestimmen sind, also nicht vom Lernmodell geschÃ¤tzt werden, nennt man Tuningparameter.\\(\\square\\)\n\nğŸ§‘â€ğŸ“ Hab ich nicht genau verstanden!\n\n\nğŸ‘¨â€ğŸ« Lies es hier oder anderer Stelle noch einmal nach. Oder frag mal einen Bot wie ChatGPT!\n\n\n8.6.4 Tuning in Tidymodels\nIn der Modellspezifikation des Modells kÃ¶nnen wir mit tune() auszeichnen, welche Parameter wir tunen mÃ¶chten.\n\nknn_model2 &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()  # Wir tunen den Parameter \"neighbors\"\n  ) \n\nWir kÃ¶nnen dem Tuningparameter auch einen Namen (ID/Label) geben, z.B. â€œKâ€:\n\nknn_model2a &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\")\n  ) \n\n\n\n\n\n\n\nHinweis\n\n\n\nTidymodels trennt generell das Spezifizieren vom Evaluieren: Erst definieren wir ein Rezept und ein Modell, dann fitten wir es. Das gilt auch fÃ¼r das Tunen: Erst weisen wir Parameter zum Tunen aus, dann wÃ¤hlen wir Tuningparameter und tunen.\\(\\square\\)\n\n\nIn tidymodels kann man mit tune() angeben, dass man einen bestimmten Parameter tunen mÃ¶chte. tidymodels fÃ¼hrt das dann ohne weiteres Federlesens fÃ¼r uns durch.\n\n\n\n\n\n\n\n\nDie Ausgabe informiert uns, dass es nur einen Tuningparameter gibt in diesem Modell und dass der Name (Label, ID) des Tuningparameters â€œKâ€ ist. AuÃŸerdem erfahren wir, dass der Tuningparmaeter die Anzahl der zu berÃ¼cksichtigen Nachbarn bezeichent. Der Tuningparameter ist numerisch; das sieht man an nparam[+]. Tidymodels wÃ¤hlt einen Range von 1 bis 15 Nachbarn.\n\n\n\n\n\n\nHinweis\n\n\n\nPraktisch! Oft ist es nicht leicht zu wissen, was ein gutes Spektrum an Werten eines Tuningparameters ist. tidymodels bzw. dials macht es einfach: Es gibt uns einen Bereich plausibler Tuningwerte vor.\\(\\square\\)\n\n\nJetzt aktualisieren wir unseren Workflow mit dem neuen knn_model2, in dem jetzt ein Modellparameter (\\(k\\)) zum Tunen ausgezeichnet ist:\n\names_wflow2 &lt;-\n  ames_wflow1 %&gt;% \n  update_model(knn_model2)\n\nNatÃ¼rlich hÃ¤tten wir auch von Anfang an den Workflow mit Tuning auszeichnen kÃ¶nnen:\n\names_wflow2 &lt;- \n  workflow() %&gt;% \n  add_model(knn_model2) %&gt;% \n  add_recipe(ames_rec)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.6.5 Doch wieder Train- und Test-Sample\nWenn man Tuning betreibt, benÃ¶tigt man doch wieder die Aufteilung von Train- und Test-Sample. Um Overfitting zu vermeiden, sollte man das Test-Sample nur einmal verwenden. WÃ¼rde man viele Modelle am Test-Sample Ã¼berprÃ¼fen, wÃ¤re es nur eine Frage der Zeit, bis man - allein durch Rauschen - eine (scheinbar) hohe ModellgÃ¼te findet. Daher fÃ¼hrt man Tuning und Resampling nur im Train-Sample durch. Den besten, â€œfinalenâ€ Wert des Tuningparameters nutzt man dann um das ganze Train-Sample auf dieser Basis zu fitten. SchlieÃŸlich sagt man dann das Test-Sample vorher.\n\nset.seed(4595)\ndata_split &lt;- initial_split(ames, strata = \"Sale_Price\")\n\names_train &lt;- training(data_split)\names_test &lt;- testing(data_split)\n\n\n8.6.6 Modelle mit Tuning berechnen\nNachdem wir die Tuningwerte bestimmt haben, kÃ¶nnen wir jetzt das Modell berechnen: FÃ¼r jeden Wert des Tuningparameters wird ein Modell berechnet:\n\names_grid_search &lt;-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,\n    grid = 5  # 5 Tuningwerte insgesamt\n  )\names_grid_search\n\n\n\n  \n\n\n\nIm Default berechnet tiymodels 10 verschiedene Tuningparamweterwerte (â€œKandidatenmodelleâ€). Hier haben wir mit grid = 5 uns mit 5 verschiedenen Werten zufrieden gegeben. Tidymodels sucht uns nach einigen (recht vernÃ¼nftigen) Daumenregeln ein paar Werte aus.\nDie Spalte .metrics beinhaltet die ModellgÃ¼te fÃ¼r jedes Kandidatenmodell.\n\names_grid_search %&gt;% \n  collect_metrics()\n\n\n\n  \n\n\n\nIm Standard wird bei Regression (numerischer Vorhersage) der RMSE und R-Quadrat ausgegeben.\nDie ModellgÃ¼te in AbhÃ¤ngigkeit der Tuningwerte kÃ¶nnen wir uns einfach visualisieren lassen:\n\nautoplot(ames_grid_search)\n\n\n\n\nAuf Basis dieser Ergebnisse kÃ¶nnte es Sinn machen, noch grÃ¶ÃŸere Werte fÃ¼r \\(K\\) zu Ã¼berprÃ¼fen.\nTidymodels bietet verschiedene Optionen, um ein â€œGitterâ€ (grid) an Werten von einem oder (in vielen Modellen) mehreren Tuningparametern zu durchsuchen.\nAm einfachsten ist es, wenn wir ein Gitter an Werten als Tabelle (Tibble) vorgeben:\n\ngrid1 &lt;- \n  tibble(neighbors = 1:10)\n\nDabei mÃ¼ssen die Spalten so heiÃŸen, wie Tidymodels die Tuningparameter benennt.\n\n\n\n\n\n\nTipp\n\n\n\nDie Namen der Tuningparameter erfÃ¤hrt man auf der Hilfeseite des Modells, z.B. nearest_neighbor. Oder mit show_model_info(\"nearest_neighbor\"). Am komfortabelsten geht es mit extract_parameter_set_dials(ames_wflow2).\\(\\square\\)\n\n\nEine andere MÃ¶glichkeit ist, ein Gitter mit regelmÃ¤ÃŸigen AbstÃ¤nden der Werte zu erstellen, z.B. mit 5 AusprÃ¤gungen pro Tuningparameter:\n\ngrid2 &lt;- \n  grid_regular(\n    neighbors(range = c(5L, 30L)),\n    levels = 5\n    )\ngrid2\n\n\n\n  \n\n\n\n\names_grid_search2 &lt;-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,  \n    grid = grid2\n  )\names_grid_search2\n\n\n\n  \n\n\n\n\n8.6.7 Workflow finalisieren\nWelcher Modellkandidat war jetzt am besten?\n\nbester_modellkandidat &lt;- select_best(ames_grid_search2)\nbester_modellkandidat\n\n\n\n  \n\n\n\nAha! Mit diesem Wert updaten bzw. â€œfinalisierenâ€ wir jetzt unseren Workflow. Dann fitten wir zum letzten Mal mit diesem finalisierten Workflow das ganze Train-Sample, um dann, endlich, das Test-Sample vorherzusagen.\n\names_wflow2_final &lt;- finalize_workflow(ames_wflow2, bester_modellkandidat)\names_wflow2_final\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 3 Recipe Steps\n## \n## â€¢ step_zv()\n## â€¢ step_normalize()\n## â€¢ step_impute_median()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = 11\n## \n## Computational engine: kknn\n\n\names_last_fit &lt;- last_fit(ames_wflow2_final, data_split)\n\nModellgÃ¼te im Test-Sample:\n\ncollect_metrics(ames_last_fit)"
  },
  {
    "objectID": "080-Resampling-Tuning.html#mini-projekt",
    "href": "080-Resampling-Tuning.html#mini-projekt",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.7 Mini-Projekt",
    "text": "8.7 Mini-Projekt\nMan lernt eine Sache erst richtig, wenn man sie anwendet. ZuhÃ¶ren reicht nicht. Daher sollten Sie nicht nur den Stoff hÃ¶ren/lesen/sehen, sondern vor allen Dingen selber anwenden.\n\nÃœbungsaufgabe 8.1 (Erstellen Sie eine prÃ¤diktive Modellierung) Erstellen Sie eine prÃ¤diktive Modellierung umgesetzt mit R/tidymodels entsprechend der hier vermittelten Methoden. Stellen Sie Code und Ergebnis bereit, am besten in Form eines Quarto-Dokuments auf einem geeigneten Github-Repositorium. Von (hohem) Nutzen ist, wenn Ihre Analyse reproduzierbar ist, also von Dritten nachprÃ¼fbar ist. Kurz gesagt heiÃŸt das: Stellen Sie Code und Daten bereit. Den zu analyisierenden Datensatz kÃ¶nnen Sie selber bestimmen. Bereiten Sie sich darauf vor, Ihre Analyse (ca. 5 Min.) zu prÃ¤sentieren bzw. im GesprÃ¤ch Ihre Analyse zu diskutieren.\\(\\square\\)"
  },
  {
    "objectID": "080-Resampling-Tuning.html#aufgaben",
    "href": "080-Resampling-Tuning.html#aufgaben",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.8 Aufgaben",
    "text": "8.8 Aufgaben\n\ntidymodels-penguins01\ntidymodels-penguins02\ntidymodels-penguins03\ntidymodels-penguins04\ntidymodels-penguins05\ntidymodels-poly01\ntidymodels-poly02\nknn-ames01"
  },
  {
    "objectID": "080-Resampling-Tuning.html#fallstudien",
    "href": "080-Resampling-Tuning.html#fallstudien",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.9 Fallstudien",
    "text": "8.9 Fallstudien\nIn KapitelÂ 16 finden Sie eine ausfÃ¼hrliche Liste an Fallstudien.\n\nArbeiten Sie sich so gut als mÃ¶glich durch diese Analyse zum Verlauf von Covid-FÃ¤llen\n\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu VulkanausbrÃ¼chen (Resampling and kein Tuning)\nFallstudie Himalaya (Resampling and kein Tuning)\nFallstudie Serie The Office: Lasso tunen\nFallstudie BÃ¤ume in San Francisco: Random Forest tunen"
  },
  {
    "objectID": "080-Resampling-Tuning.html#vertiefung-1",
    "href": "080-Resampling-Tuning.html#vertiefung-1",
    "title": "8Â  Resampling und Tuning",
    "section": "\n8.10 Vertiefung",
    "text": "8.10 Vertiefung\nFields arranged by purity, xkcd 435\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nTaleb, Nassim Nicholas. 2019. The statistical consequences of fat tails, papers and commentaries. Monograph. https://nassimtaleb.org/2020/01/final-version-fat-tails/."
  },
  {
    "objectID": "080-Resampling-Tuning.html#footnotes",
    "href": "080-Resampling-Tuning.html#footnotes",
    "title": "8Â  Resampling und Tuning",
    "section": "",
    "text": "Bei Normalverteilungen klappt das gut bei randlastigen Verteilungen leider nicht mehr (Taleb 2019).â†©ï¸\nDas klappt bei randlastigen Verteilungen nichtâ†©ï¸\n\\(v=10\\) in der Voreinstellungâ†©ï¸\nIn Windows gibt es andere Wege.â†©ï¸\ntheoretischâ†©ï¸\nhttps://chat.openai.com/chat, 2023-04-06â†©ï¸"
  },
  {
    "objectID": "090-glm.html#lernsteuerung",
    "href": "090-glm.html#lernsteuerung",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Vorbereitung\nFrischen Sie Ihr Wissen zur logistischen Regression auf bzw. machen Sie sich mit den Grundlagen des Verfahrens vertraut.\n\n9.1.2 Lernziele\nSie verstehen den Zusammenhang von linearen und logistischen Modellen Sie kÃ¶nnen die logistische Regression mit Methoden von tidymodels anwenden\n\n9.1.3 Literatur\nRhys, Kap. 4\n\n9.1.4 BenÃ¶tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\n\neasystats ist, wie Tidymodels und Tidyverse, ein Metapaket, ein R-Paket also, das mehrere Pakete verwaltet und startet. Hier findet sich mehr Info zu Easystats.\nEinen flotten Spruch bekommen wir von Easystats gratis dazu:\n\neasystats_zen()\n## [1] \"Patience you must have my young padawan.\""
  },
  {
    "objectID": "090-glm.html#intuitive-erklÃ¤rung",
    "href": "090-glm.html#intuitive-erklÃ¤rung",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.2 Intuitive ErklÃ¤rung",
    "text": "9.2 Intuitive ErklÃ¤rung\nDie logistische Reression ist ein Spezialfall des linearen Modells (lineare Regression), der fÃ¼r binÃ¤re (dichotom) AV eingesetzt wird (es gibt auch eine Variante fÃ¼r multinominale AV). Es kÃ¶nnen eine oder mehrere UV in eine logistische Regression einflieÃŸen, mit beliebigem Skalenniveau.\nBeispiele fÃ¼r Forschungsfragen, die mit der logistischen Regression modelliert werden sind:\n\nWelche Faktoren sind prÃ¤diktiv, um vorherzusagen, ob jemand einen Kredit zurÃ¼ckzahlen kann oder nicht?\nHaben weibliche Passagiere aus der 1. Klasse eine hÃ¶here Ãœberlebenschance als andere Personen auf der Titanic?\nWelche Faktoren hÃ¤ngen damit zusammen, ob ein Kunde eine Webseite verlÃ¤sst, bevor er einen Kauf abschlieÃŸt?\n\nDer Name stammt von der logistischen Funktion, die man in der einfachsten Form so darstellen kann:\n\\[f(x) = \\frac{x}{1+e^{-x}}\\]\nDa die AV als dichotom modelliert wird, spricht man von einer Klassifikation.\nAllerdings ist das Modell reichhaltiger als eine bloÃŸe Klassifikation, die (im binÃ¤ren Fall) nur 1 Bit Information liefert: â€œjaâ€ vs.Â â€œneinâ€ bzw. 0 vs.Â 1.\nDas Modell liefert nÃ¤mlich nicht nur eine Klassifikation zurÃ¼ck, sondern auch eine Indikation der StÃ¤rke (epistemologisch) der KlassenzugehÃ¶rigkeit.\nEinfach gesagt heiÃŸt das, dass die logistische Regression eine Wahrscheinlichkeit der KlassenzugehÃ¶rigkeit zurÃ¼ckliefert.\n\n\n\n\nflowchart LR\n  Daten --&gt; Modell --&gt; Wskt --&gt; Klasse\n\n\n\nAbbildungÂ 9.1: Ablauf einer Klassifikation"
  },
  {
    "objectID": "090-glm.html#profil",
    "href": "090-glm.html#profil",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.3 Profil",
    "text": "9.3 Profil\nDas Profil des Modells kann man wie folgt charakterisieren, vgl. Tab. TabelleÂ 9.1.\n\n\n\n\n\n\n\nTabelleÂ 9.1:  Profil der logistischen Regression \n  \nMerkmal\n      Logistische Regression\n    \n\n\nKlassifikation\nja\n\n\nRegression\nnein\n\n\nLerntyp\nÃ¼berwacht\n\n\nparametrisch\nja"
  },
  {
    "objectID": "090-glm.html#warum-nicht-die-lineare-regression-verwenden",
    "href": "090-glm.html#warum-nicht-die-lineare-regression-verwenden",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.4 Warum nicht die lineare Regression verwenden?",
    "text": "9.4 Warum nicht die lineare Regression verwenden?\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: HÃ¤ngen Spritverbrauch und Getriebeart, s. AbbildungÂ 9.2? (Datensatz mtcars)\n\ndata(mtcars)\nd &lt;-\n  mtcars %&gt;% \n  mutate(mpg_z = standardize(mpg),\n         iv = mpg_z,\n         dv = am)\n\nm81 &lt;- lm(dv ~ iv, data = d)\ncoef(m81)\n## (Intercept)          iv \n##   0.4062500   0.2993109\n\n\n\n\n\nAbbildungÂ 9.2: Klassifikation von am\n\n\n\n\\(Pr(\\text{am}=1|m91,\\text{mpgz}=0) = 0.46\\): Die Wahrscheinlichkeit einer manuelle Schaltung, gegeben einem durchschnittlichen Verbrauch (und dem Modell m81) liegt bei knapp 50%.\n\n9.4.1 Lineare Modelle running wild\nWie groÃŸ ist die Wahrscheinlichkeit fÃ¼r eine manuelle Schaltung â€¦\n\nâ€¦ bei mpg_z = -2?\n\n\npredict(m81, newdata = data.frame(iv = -2))\n##          1 \n## -0.1923719\n\n\\(Pr(\\hat{y})&lt;0\\) macht keinen Sinn. âš¡\n\nâ€¦ bei mpg_z = +2?\n\n\npredict(m81, newdata = data.frame(iv = +2))\n##        1 \n## 1.004872\n\n\\(Pr(\\hat{y})&gt;1\\) macht keinen Sinn. âš¡\nSchauen Sie sich mal die Vorhersage an fÃ¼r mpg_z=5 ğŸ¤¯\n\n9.4.2 Wir mÃ¼ssen die Regressionsgerade umbiegen\nâ€¦ wenn der vorhergesagte Wert eine Wahrscheinlichkeit, \\(p_i\\), ist, s. AbbildungÂ 9.3.\n\n\n\n\nAbbildungÂ 9.3: Wir biegen die Regressionsgeraden in eine S-Form\n\n\n\nDie schwarze Gerade verlÃ¤sst den Wertebereich der Wahrscheinlichkeit. Die blaue Kurve, \\(\\mathcal{f}\\), bleibt im erlaubten Bereich, \\(Pr(y) \\in [0,1]\\). Wir mÃ¼ssen also die linke oder die rechte Seite des linearen Modells transformieren: \\(p_i = f(\\alpha + \\beta \\cdot x)\\) bzw.:\n\\(f(p) = \\alpha + \\beta \\cdot x\\)\n\\(\\mathcal{f}\\) nennt man eine Link-Funktion.\n\n9.4.3 Verallgemeinerte lineare Modelle zur Rettung\nFÃ¼r metrische AV mit theoretisch unendlichen Grenzen des Wertebereichs haben wir bisher eine Normalverteilung verwendet:\n\\[y_i \\sim \\mathcal{N}(\\mu_i, \\sigma)\\]\nDann ist die Normalverteilung eine voraussetzungsarme Wahl (maximiert die Entropie).\nAber wenn die AV binÃ¤r ist bzw. HÃ¤ufigkeiten modelliert, braucht man eine Variable die nur positive Werte zulÃ¤sst.\nDiese Verallgemeinerung des linearen Modells bezeichnet man als verallgemeinertes lineares Modell (generalized linear model, GLM).\nIm Falle einer binÃ¤ren (bzw. dichotomen) AV liegt eine bestimmte Form des GLM vor, die man als logistische Regression bezeichnet."
  },
  {
    "objectID": "090-glm.html#der-logit-link",
    "href": "090-glm.html#der-logit-link",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.5 Der Logit-Link",
    "text": "9.5 Der Logit-Link\nDer Logit-Link wird auch \\(\\mathcal{L}\\), logit, Log-Odds oder Logit-Funktion genannt.\nEr â€œbiegtâ€ die lineare Funktion in die richtige Form.\nDer Logit-Link ordnet einen Parameter, der als Wahrscheinlichkeitsmasse definiert ist (und daher im Bereich von 0 bis 1 liegt), einem linearen Modell zu (das jeden beliebigen reellen Wert annehmen kann):\n\\[\n\\begin{align}\n    \\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{align}\n\\]\n\nDie Logit-Funktion \\(\\mathcal{L}\\) ist definiert als der (natÃ¼rliche) Logarithmus des VerhÃ¤ltnisses der Wahrscheinlichkeit zu Gegenwahrscheinlichkeit:\n\n\\[\\mathcal{L} = \\text{log} \\frac{p_i}{1-p_i}\\]\n\nDas VerhÃ¤ltnis der Wahrscheinlichkeit zu Gegenwahrscheinlichkeit nennt man auch Odds.\nAlso:\n\n\\[\\mathcal{L} = \\text{log} \\frac{p_i}{1-p_i} = \\alpha + \\beta x_i\\]"
  },
  {
    "objectID": "090-glm.html#aber-warum",
    "href": "090-glm.html#aber-warum",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.6 Aber warum?",
    "text": "9.6 Aber warum?\nForschungsfrage: HÃ¤ngt das Ãœberleben (statistisch) auf der Titanic vom Geschlecht ab?\nWie war eigentlich insgesamt, also ohne auf einen (oder mehrere) PrÃ¤diktoren zu bedingen, die Ãœberlebenswahrscheinlichkeit?\n\ndata(titanic_train, package = \"titanic\")\n\nm82 &lt;- lm(Survived ~ 1, data = titanic_train)\ncoef(m82)\n## (Intercept) \n##   0.3838384\n\nDie Wahrscheinlichkeit zu Ãœberleben \\(Pr(y=1)\\) lag bei einem guten Drittel (0.38).\nDas hÃ¤tte man auch so ausrechnen:\n\ntitanic_train %&gt;% \n  count(Survived) %&gt;% \n   mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nAnders gesagt: \\(p(y=1) = \\frac{549}{549+342} \\approx 0.38\\)\n\n9.6.1 tidymodels, m83\nBerechnen wir jetzt ein lineares Modell fÃ¼r die AV Survived mit dem Geschlecht als PÃ¤diktor:\n\nd &lt;-\n  titanic_train %&gt;% \n  filter(Fare &gt; 0) %&gt;% \n  mutate(iv = log(Fare),\n         dv = factor(Survived))\n\nDie Faktorstufen, genannt levels von Survived sind:\n\nlevels(d$dv)\n## [1] \"0\" \"1\"\n\nUnd zwar genau in dieser Reihenfolge."
  },
  {
    "objectID": "090-glm.html#lm83-glm",
    "href": "090-glm.html#lm83-glm",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.7 lm83, glm",
    "text": "9.7 lm83, glm\nDie klassische Methoden in R, ein logistisches Modell zu berechnen, ist mit der Funktion glm(). Tidymodels greift intern auf diese Funktion zurÃ¼ck. Daher sind die Ergebnisse numerisch identisch.\n\nlm83 &lt;- glm(dv ~ iv, data = d, family = \"binomial\")\ncoef(lm83)\n## (Intercept)          iv \n##  -2.6827432   0.7479317\n\n\nAV: Ãœberleben (binÃ¤r/Faktor)\nUV: Ticketpreis\n\nMit easystats kann man sich model_parameter() einfach ausgeben lassen:\n\nlibrary(easystats)\n\n\nmodel_parameters(lm83)\n\n\n\n  \n\n\n\nUnd auch visualisieren lassen:\n\nplot(model_parameters(lm83))"
  },
  {
    "objectID": "090-glm.html#m83-tidymodels",
    "href": "090-glm.html#m83-tidymodels",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.8 m83, tidymodels",
    "text": "9.8 m83, tidymodels\nAchtung! Bei tidymodels muss bei einer Klassifikation die AV vom Type factor sein. AuÃŸerdem wird bei tidymodels, im Gegensatz zu (g)lm nicht die zweite, sondern die erste als Ereignis modelliert wird.\nDaher wechseln wir die referenzkategorie, wir â€œre-levelnâ€, mit relevel():\n\nd2 &lt;-\n  d %&gt;% \n  mutate(dv = relevel(dv, ref = \"1\"))\n\nCheck:\n\nlevels(d2$dv)\n## [1] \"1\" \"0\"\n\nPasst.\nDie erste Stufe ist jetzt 1, also Ãœberleben.\nJetzt berechnen wir das Modell in gewohnter Weise mit tidymodels.\n\nm83_mod &lt;-\n  logistic_reg()\n\nm83_rec &lt;-\n  recipe(dv ~ iv, data = d2)\n\nm83_wf &lt;-\n  workflow() %&gt;% \n  add_model(m83_mod) %&gt;% \n  add_recipe(m83_rec)\n\nm83_fit &lt;-\n  fit(m83_wf, data = d2)\n\nHier sind die Koeffizienten, die kann man sich aus m83_fit herausziehen:\n\n\n\n\n\n\n\nterm\n      estimate\n      std.error\n      statistic\n      p.value\n    \n\n\n(Intercept)\n2.68\n0.26\n10.46\n0.00\n\n\niv\nâˆ’0.75\n0.08\nâˆ’9.13\n0.00\n\n\n\n\n\n## [1]  2.6827432 -0.7479317\n\n\n\n\n\n  \n\n\n\nDie Koeffizienten werden in Logits angegeben.\nIn AbbildungÂ 9.4 ist das Modell und die Daten visualisiert.\n\n\n\n\nAbbildungÂ 9.4: Modell m83 und die Titanic-Daten\n\n\n\nDefinieren wir als \\(y=1\\) das zu modellierende Ereignis, hier â€œÃœberleben auf der Titanicâ€ (hat also Ã¼berlebt).\nWie wir oben schon gesehen haben, funktioniert die lineare Regression nicht einwandfrei bei binÃ¤ren (oder dichotomen) AV.\n\n9.8.1 Wahrscheinlichkeit in Odds\nProbieren wir Folgendes: Rechnen wir die Wahrscheinlichkeit zu Ãœberlegen fÃ¼r \\(y\\), kurz \\(p\\), in Odds (Chancen) um.\n\\(odds = \\frac{p}{1-p}\\)\nIn R:\n\nodds &lt;- 0.38 / 0.62\nodds\n## [1] 0.6129032\n\nBildlich gesprochen sagen die Odds: fÃ¼r 38 Menschen, die Ã¼berlebt haben, kommen (ca.) 62 Menschen, die nicht Ã¼berlebt haben, s. AbbildungÂ 9.5.\n\n\n\n\nAbbildungÂ 9.5: Odds: 38 zu 62\n\n\n\nPlotten wir die Odds als Funktion der UV, s. AbbildungÂ 9.6.\n\n\n\n\nAbbildungÂ 9.6: Odds als Funktion der UV\n\n\n\nWir sind noch nicht am Ziel; die Variable ist noch nicht â€œrichtig gebogenâ€.\n\n9.8.2 Von Odds zu Log-Odds\nWenn wir jetzt den Logarithmus (der Odds) berechnen bekommen wir eine â€œbrav gebogenenâ€ Funktion, die Log-Odds, \\(\\mathcal{L}\\), als Funktion der UV, s. AbbildungÂ 9.7.\n\\[\\mathcal{L} = log (odds) = log \\left(\\frac{p}{1-p}\\right)\\]\n\n\n\n\nAbbildungÂ 9.7: Logit als Funktion der UV\n\n\n\nLinear!\nEs gilt also:\n\\[\\text {log-odds} = b_0 + b_1x\\]\nLog-Odds (Log-Odds) bezeichnet man auch als Logits."
  },
  {
    "objectID": "090-glm.html#inverser-logit",
    "href": "090-glm.html#inverser-logit",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.9 Inverser Logit",
    "text": "9.9 Inverser Logit\nUm nach \\(p\\) aufzulÃ¶sen, mÃ¼ssen wir einige Algebra bemÃ¼hen:\n\\[\n\\begin{align}\n\\text{log} \\frac{p}{1-p} &= \\alpha + \\beta x & & \\text{Exponentieren}\\\\\n\\frac{p}{1-p} &= e^{\\alpha + \\beta x} \\\\\np_i &= e^{\\alpha + \\beta x_i} (1-p) & & \\text{Zur Vereinfachung: } x := e^{\\alpha + \\beta x_i} \\\\\np_i &= x (1-p) \\\\\n&= x - xp \\\\\np + px &= x \\\\\np(1+x) &= x \\\\\np &= \\frac{x} {1+x} & & \\text{LÃ¶sen wir x wieder auf.} \\\\\np &= \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}} = \\mathcal{L}^{-1}\n\\end{align}\n\\]\nDiese Funktion nennt man auch inverser Logit, \\(\\text{logit}^{-1}, \\mathcal{L}^{-1}\\).\nZum GlÃ¼ck macht das alles die Rechenmaschine fÃ¼r uns ğŸ˜„.\n\n9.9.1 Vom Logit zur Klasse\nPraktisch kÃ¶nnen wir uns die Logits und ihre zugehÃ¶rige Wahrscheinlichkeit einfach ausgeben lassen mit R. Und die vorhergesagte Klasse (.pred_class) auch:\n\nd3 &lt;-\n  d2 %&gt;% \n  bind_cols(predict(m83_fit, new_data = d2, type = \"prob\")) %&gt;% \n  bind_cols(predict(m83_fit, new_data = d2)) %&gt;%  # Klasse\n  bind_cols(logits = predict(m83_fit, new_data = d2, type = \"raw\"))  # Logits\n  \nd3 %&gt;% \n  slice_head(n = 3) %&gt;% \n  select(Name, last_col())\n\n\n\n  \n\n\n\n\n9.9.2 Grenzwert wechseln\nIm Standard wird 50% als Grenzwert fÃ¼r die vorhergesagte Klasse \\(c\\) genommen:\n\nwenn \\(p &lt;= .5 \\rightarrow c = 0\\)\n\nwenn \\(p &gt; .5 \\rightarrow c = 1\\)\n\n\nMan kann aber den Grenzwert beliebig wÃ¤hlen, um Kosten-Nutzen-AbwÃ¤gungen zu optimieren; mehr dazu findet sich z.B. hier."
  },
  {
    "objectID": "090-glm.html#logit-und-inverser-logit",
    "href": "090-glm.html#logit-und-inverser-logit",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.10 Logit und Inverser Logit",
    "text": "9.10 Logit und Inverser Logit\n\n9.10.1 Logit\n\\((0,1) \\rightarrow (-\\infty, +\\infty)\\)\nAbbildungÂ 9.8 zeigt die VerÃ¤nderung des Wertebereichs bei Umrechnung von Wahrscheinlichkeit zu Logit.\n\n\n\n\nAbbildungÂ 9.8: Der Wertebereich der Wahrscheinlichkeit ist [0,1]; der Wertebereich des Logits [-Inf,+Inf].\n\n\n\nPraktisch, um Wahrscheinlichkeit zu modellieren.\n\\[p \\rightarrow \\fbox{logit} \\rightarrow \\alpha + \\beta x\\]\n\n9.10.2 Inv-Logit\nBeim Inversen Logit (Inv-Logit) ist es genau umgekehrt wie beim Logit. AbbildungÂ 9.9 zeigt die VerÃ¤nderung des Wertebereichs des Inv-Logits.\n\\((-\\infty, +\\infty) \\rightarrow (0,1)\\)\n\n\n\n\nAbbildungÂ 9.9: VerÃ¤nderung der Wertebereichs durch die Inv-Logit-Umrechnung\n\n\n\nPraktisch, um in Wahrscheinlichkeiten umzurechnen.\n\\[p \\leftarrow \\fbox{inv-logit} \\leftarrow \\alpha + \\beta x\\]"
  },
  {
    "objectID": "090-glm.html#logistische-regression-im-Ã¼berblick",
    "href": "090-glm.html#logistische-regression-im-Ã¼berblick",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.11 Logistische Regression im Ãœberblick",
    "text": "9.11 Logistische Regression im Ãœberblick\n\nEine Regression mit binomial verteilter AV und Logit-Link nennt man logistische Regression.\n\nMan verwendet die logistische Regression um binomial verteilte AV zu modellieren, z.B.\n\nWie hoch ist die Wahrscheinlichkeit, dass ein Kunde das Produkt kauft?\nWie hoch ist die Wahrscheinlichkeit, dass ein Mitarbeiter kÃ¼ndigt?\nWie hoch ist die Wahrscheinlichkeit, die Klausur zu bestehen?\n\n\nDie logistische Regression ist eine normale, lineare Regression fÃ¼r den Logit von \\(Pr(y=1)\\), wobei \\(y\\) (AV) binomialvereteilt mit \\(n=1\\) angenommen wird:\n\n\\[\n\\begin{align}\ny_i &\\sim \\mathcal{B}(1, p_i) \\\\\n\\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{align}\n\\]\n\nDa es sich um eine normale, lineare Regression handelt, sind alle bekannten Methoden und Techniken der linearen Regression zulÃ¤ssig.\nDa Logits nicht einfach zu interpretieren sind, rechnet man nach der Berechnung des Modells den Logit hÃ¤ufig in Wahrscheinlichkeiten um.\n\n\n9.11.1 Die Koeffizienten sind schwer zu interpretieren\nPuhhh, s. AbbildungÂ 9.10\n\n\n\n\nAbbildungÂ 9.10: Die Koeffizienten der logistischen Regression sind nicht normal - im additiven Sinne - zu interpretieren.\n\n\n\n\nIn der logistischen Regression gilt nicht mehr, dass eine konstante VerÃ¤nderung in der UV mit einer konstanten VerÃ¤nderung in der AV einhergeht.\nStattdessen geht eine konstante VerÃ¤nderung in der UV mit einer konstanten VerÃ¤nderung im Logit der AV einher.\nBeim logistischen Modell hier gilt, dass in der NÃ¤he von \\(x=0\\) die grÃ¶ÃŸte VerÃ¤nderung in \\(p\\) von statten geht; je weiter weg von \\(x=0\\), desto geringer ist die VerÃ¤nderung in \\(p\\).\n\n9.11.2 Logits vs.Â Wahrscheinlichkeiten\nTabelleÂ 9.2 zeigt Beispiele zur Umrechnung von Logits Ã¼ber Odds in Wahrscheinlichkeiten (und retour).\n\n\n\n\n\n\n\nTabelleÂ 9.2:  Tabelle zur Umrechnung von Logit zu Wahrscheinlichkeit (p) \n  \nlogit\n      p\n      odds\n    \n\n\nâˆ’10.00\n0.00\n0.00\n\n\nâˆ’3.00\n0.05\n0.05\n\n\nâˆ’2.00\n0.12\n0.14\n\n\nâˆ’1.00\n0.27\n0.37\n\n\nâˆ’0.50\n0.38\n0.61\n\n\nâˆ’0.25\n0.44\n0.78\n\n\n0.00\n0.50\n1.00\n\n\n0.25\n0.56\n1.28\n\n\n0.50\n0.62\n1.65\n\n\n1.00\n0.73\n2.72\n\n\n2.00\n0.88\n7.39\n\n\n3.00\n0.95\n20.09\n\n\n10.00\n1.00\n22,026.47"
  },
  {
    "objectID": "090-glm.html#aufgaben",
    "href": "090-glm.html#aufgaben",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.12 Aufgaben",
    "text": "9.12 Aufgaben\n\nFallstudien zu StudiengebÃ¼hren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF"
  },
  {
    "objectID": "090-glm.html#vertiefung",
    "href": "090-glm.html#vertiefung",
    "title": "\n9Â  Logistische Regression\n",
    "section": "\n9.13 Vertiefung",
    "text": "9.13 Vertiefung\nFallstudie Diabetes mit logististischer Regression"
  },
  {
    "objectID": "100-baeume.html#lernsteuerung",
    "href": "100-baeume.html#lernsteuerung",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Lernziele\n\nSie kÃ¶nnen den rpart-Algorithmus erklÃ¤ren\nSie wissen, wie man Overfitting bei EntscheidungsbÃ¤ume begrenzen kann\nSie kÃ¶nnen EntscheidungsbÃ¤ume in R berechnen\n\n10.1.2 Literatur\n\nRhys, Kap. 7\n\n10.1.3 R-Pakete und Daten\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(titanic)  # Datensatz Titanic\n#library(rpart)  # Berechnung von EntscheidungsbÃ¤umen\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\nlibrary(readr)  # rds\nlibrary(rpart.plot)  # Visualisierung der BÃ¤ume\n\nIn diesem Kapitel werden folgende Daten benÃ¶tigt:\n\ndata(titanic_train)\ndata(titannic_test)"
  },
  {
    "objectID": "100-baeume.html#entscheidungbÃ¤ume",
    "href": "100-baeume.html#entscheidungbÃ¤ume",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.2 EntscheidungbÃ¤ume",
    "text": "10.2 EntscheidungbÃ¤ume\n\n10.2.1 Anatomie eines Baumes\nEin Baum ğŸŒ³ hat (u.a.):\n\nWurzel\nBlÃ¤tter\nÃ„ste\n\nIn einem Entscheidungsbaum ist die Terminologie Ã¤hnlich, s. AbbildungÂ 10.1. Allgemein gesagt, kann ein Entscheidungsbaum in einem baumÃ¤hnlichen Graphen visualisiert werden. Dort gibt es Knoten, die durch Kanten verbunden sind, wobei zu einem Knoten genau ein Kanten fÃ¼hrt.\nEin Beispiel fÃ¼r einen einfachen Baum sowie die zugehÃ¶rige rekursive Partionierung ist in AbbildungÂ 10.1 dargestellt; man erkennt \\(R=3\\) Regionen bzw. BlÃ¤tter (James u.Â a. 2021).\n\n\n\n\n\n(a) Ein einfacher Baum\n\n\n\n\n\n(b) Die rekursiven, rechteckigen Partionierungen eines Baumes\n\n\n\nAbbildungÂ 10.1: Einfaches Beispiel fÃ¼r einen Baum sowie der zugehÃ¶rigen rekursiven Partionierung\n\n\nIn AbbildungÂ 10.1 wird der Knoten an der Spitze auch als Wurzel(knoten) bezeichnet. Von diesem Knoten entspringen alle Pfade. Ein Pfad ist die geordnete Menge der Pfade mit ihren Knoten ausgehend von der Wurzel bis zu einem Blatt. Knoten, aus denen kein Kanten mehr wegfÃ¼hrt (â€œEndknotenâ€) werden als BlÃ¤tter bezeichnet. Von einem Knoten gehen zwei Kanten aus (oder gar keine). Knoten, von denen zwei Kanten ausgehen, spiegeln eine Bedingung (PrÃ¼fung) wider, im Sinne einer Aussage, die mit ja oder nein beantwortet werden kann. Die Anzahl der Knoten eines Pfads entsprechen den Ebenen bzw. der Tiefe des Baumes. Von der obersten Ebene (Wurzelknoten) kann man die \\(e\\) Ebenen aufsteigend durchnummerieren, beginnend bei 1: \\(1,2,\\ldots,e\\).\n\n10.2.2 BÃ¤ume als Regelmaschinen rekursiver Partionierung\nEin Baum kann man als eine Menge von Regeln, im Sinne von Wenn-dann-sonst-Aussagen, sehen:\nWenn PrÃ¤diktor A = 1 ist dann\n|  Wenn PrÃ¤diktor B = 0 ist dann p = 10%\n|  sonst p = 30%\nsonst p = 50%\nIn diesem Fall, zwei PrÃ¤diktoren, ist der PrÃ¤diktorenraum in drei Regionen unterteilt: Der Baum hat drei BlÃ¤tter.\nFÃ¼r AbbildungÂ 10.2 ergibt sich eine komplexere Aufteilung, s. auch AbbildungÂ 10.3.1\n\n\n\n\nAbbildungÂ 10.2: Beispiel fÃ¼r einen Entscheidungsbaum\n\n\n\nKleine Lesehilfe fÃ¼r AbbildungÂ 10.2:\n\nFÃ¼r jeden Knoten steht in der ersten Zeile der vorhergesagte Wert, z.B. 0 im Wurzelknoten\ndarunter steht der Anteil (die Wahrscheinlichkeit) fÃ¼r die in diesem Knoten vorhergesagte Kategorie (0 oder 1)\ndarunter (3. Zeile) steht der Anteil der FÃ¤lle (am Gesamt-Datensatz) in diesem Knoten, z.B. 100%\n\n\n\n\n\n\nAbbildungÂ 10.3: Partionierung in Rechtecke durch EntscheidungsbÃ¤ume\n\n\n\nWie der Algorithmus oben zeigt, wird der PrÃ¤diktorraum wiederholt (rekursiv) aufgeteilt, und zwar in Rechtecke,s. AbbildungÂ 10.3. Man nennt (eine Implementierung) dieses Algorithmus auch rpart.\nDas Regelwerk zum Baum aus AbbildungÂ 10.2 sieht so aus:\n\n## parsnip model object\n## \n## n= 891 \n## \n## node), split, n, loss, yval, (yprob)\n##       * denotes terminal node\n## \n##   1) root 891 342 0 (0.61616162 0.38383838)  \n##     2) Pclass&gt;=2.5 491 119 0 (0.75763747 0.24236253)  \n##       4) Age&gt;=6.5 461 102 0 (0.77874187 0.22125813) *\n##       5) Age&lt; 6.5 30  13 1 (0.43333333 0.56666667) *\n##     3) Pclass&lt; 2.5 400 177 1 (0.44250000 0.55750000)  \n##       6) Age&gt;=17.5 365 174 1 (0.47671233 0.52328767)  \n##        12) Pclass&gt;=1.5 161  66 0 (0.59006211 0.40993789) *\n##        13) Pclass&lt; 1.5 204  79 1 (0.38725490 0.61274510)  \n##          26) Age&gt;=44.5 67  32 0 (0.52238806 0.47761194)  \n##            52) Age&gt;=60.5 14   3 0 (0.78571429 0.21428571) *\n##            53) Age&lt; 60.5 53  24 1 (0.45283019 0.54716981)  \n##             106) Age&lt; 47.5 13   3 0 (0.76923077 0.23076923) *\n##             107) Age&gt;=47.5 40  14 1 (0.35000000 0.65000000) *\n##          27) Age&lt; 44.5 137  44 1 (0.32116788 0.67883212) *\n##       7) Age&lt; 17.5 35   3 1 (0.08571429 0.91428571) *\n\nKleine Lesehilfe: Ander Wurzel root des Baumes, Knoten 1)haben wir 891 FÃ¤lle, von denen 342 nicht unserer Vorhersage yval entsprechen, also loss sind, das ist ein Anteil, (yprob) von 0.38. Unsere Vorhersage ist 0, da das die Mehrheit in diesem Knoten ist, dieser Anteil betrÃ¤gt ca. 61%. In der Klammer stehen also die Wahrscheinlichkeiten fÃ¼r alle AusprÃ¤gungen von Y:, 0 und 1, in diesem Fall. Entsprechendes gilt fÃ¼r jeden weiteren Knoten.\nEin kurzer Check der HÃ¤ufigkeit am Wurzelknoten:\n\ncount(titanic_train, Survived)\n\n\n\n  \n\n\n\nSolche EntscheidungsbÃ¤ume zu erstellen, ist nichts neues. Man kann sie mit einer einfachen Checkliste oder Entscheidungssystem vergleichen. Der Unterschied zu EntscheidungsbÃ¤umen im maschinellen Lernen ist nur, dass die Regeln aus den Daten gelernt werden, man muss sie nicht vorab kennen.\nNoch ein Beispiel ist in AbbildungÂ 10.4 gezeigt (James u.Â a. 2021): Oben links zeigt eine unmÃ¶gliche Partionierung (fÃ¼r einen Entscheidungsbaum). Oben rechts zeigt die Regionen, die sich durch den Entscheidungsbaum unten links ergeben. Untenrechts ist der Baum in 3D dargestellt.\n\n\n\n\nAbbildungÂ 10.4: Ein weiteres Beispiel zur Darstellung von EntscheidungsbÃ¤umen"
  },
  {
    "objectID": "100-baeume.html#klassifikation",
    "href": "100-baeume.html#klassifikation",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.3 Klassifikation",
    "text": "10.3 Klassifikation\nBÃ¤ume kÃ¶nnen fÃ¼r Zwecke der Klassifikation (nominal skalierte AV) oder Regression (numerische AV) verwendet werden. Betrachten wir zunÃ¤chst die binÃ¤re Klassifikation, also fÃ¼r eine zweistufige (nominalskalierte) AV. Das Ziel des Entscheidungsmodel-Algorithmus ist es, zu BlÃ¤ttern zu kommen, die mÃ¶glichst â€œsortenreinâ€ sind, sich also mÃ¶glichst klar fÃ¼r eine (der beiden) Klassen \\(A\\) oder \\(B\\) aussprechen. Nach dem Motto: â€œWenn PrÃ¤diktor 1 kleiner \\(x\\) und wenn PrÃ¤diktor 2 gleich \\(y\\), dann handelt es sich beim vorliegenden Fall ziemlich sicher um Klasse \\(A\\).â€\n\nJe homogener die Verteilung der AV pro Blatt, desto genauer die Vorhersagen.\n\nUnsere Vorhersage in einem Blatt entspricht der Merheit bzw. der hÃ¤ufigsten Kategorie in diesem Blatt.\n\n10.3.1 Gini als Optimierungskriterium\nEs gibt mehrere Kennzahlen, die zur Optimierung bzw. zur Entscheidung zum Aufbau des Entscheidungsbaum herangezogen werden. Zwei Ã¼bliche sind der Gini-Koeffizient und die Entropie. Bei Kennzahlen sind MaÃŸ fÃ¼r die HomogenitÃ¤t oder â€œSortenreinheitâ€ (vs.Â HeterogenitÃ¤t, engl. auch impurity).\nDen Algorithmus zur Erzeugung des Baumes kann man so darstellen:\nWiederhole fÃ¼r jede Ebenes\n|  prÃ¼fe fÃ¼r alle PrÃ¤diktoren alle mÃ¶glichen Bedingungen\n|  wÃ¤hle denjenigen PrÃ¤diktor mit derjenigen Bedingung, der die HomogenitÃ¤t maximiert\nsolange bis Abbruchkriterium erreicht ist.\nEin Bedingung kÃ¶nnte sein Age &gt;= 18 oder Years &lt; 4.5.\nEs kommen mehrere Abbruchkriterium in Frage:\n\nEine Mindestanzahl von Beobachtungen pro Knoten wird unterschritten (minsplit)\nDie maximale Anzahl an Ebenen ist erreicht (maxdepth)\nDie minimale Zahl an Beobachtungen eines Blatts wird unterschritten (minbucket)\n\nDer Gini-Koeffizient ist im Fall einer UV mit zwei Stufen, \\(c_A\\) und \\(c_B\\), so definiert:\n\\[G = 1 - \\left(p(c_A)^2 + (1-p(c_A))^2\\right)\\]\nDer Algorithmus ist â€œgierigâ€ (greedy): Optimiert werden lokal optimale Aufteilungen, auch wenn das bei spÃ¤teren Aufteilungen im Baum dann insgesamt zu geringerer HomogenitÃ¤t fÃ¼hrt.\nDie Entropie ist definiert als\n\\[D = - \\sum_{k=1}^K p_k \\cdot log(p_k),\\]\nwobei \\(K\\) die Anzahl der Kategorien indiziert.\nGini-Koeffizient und Entropie kommen oft zu Ã¤hnlichen numerischen Ergebnissen, so dass wir uns im Folgenden auf den Gini-Koeffizienten konzentieren werden.\n\nBeispiel\nVergleichen wir drei Bedingungen mit jeweils \\(n=20\\) FÃ¤llen, die zu unterschiedlich homogenen Knoten fÃ¼hren:\n\n10/10\n15/5\n19/1\n\nWas ist jeweils der Wert des Gini-Koeffizienten?\n\nG1 &lt;- 1 - ((10/20)^2 + (10/20)^2)\nG1\n## [1] 0.5\n\nG2 &lt;- 1 - ((15/20)^2 + (5/20)^2)\nG2\n## [1] 0.375\n\nG3 &lt;- 1 - ((19/20)^2 + (1/20)^2)\nG3\n## [1] 0.095\n\nWie man sieht, sinkt der Wert des Gini-Koeffizienten (â€œG-Wertâ€), je homogener die Verteilung ist. Maximal heterogen (â€œgemischtâ€) ist die Verteilung, wenn alle Werte gleich oft vorkommen, in diesem Fall also 50%/50%.\n\nNeben dem G-Wert fÃ¼r einzelne Knoten kann man den G-Wert fÃ¼r eine Aufteilung (â€œSplitâ€) berechnen, also die Fraeg beantworten, ob die Aufteilung eines Knoten in zwei zu mehr HomogenitÃ¤t fÃ¼hrt. Der G-Wert einer Aufteilung ist die gewichtete Summe der G-Werte der beiden Knoten (links, \\(l\\) und rechts, \\(r\\)):\n\\[G_{split} = p(l) G_{l} + p(r) G_r\\]\nDer Gewinn (gain) an HomogenitÃ¤t ist dann die Differenz des G-Werts der kleineren Ebene und der Aufteilung:\n\\[G_{gain} = G - G_{split}\\]\nDer Algorithmus kann auch bei UV mit mehr als zwei, also \\(K\\) Stufen, \\(c_1, c_2, \\ldots, c_K\\) verwendet werden:\n\\[G= 1- \\sum_{k=1}^K p(c_k)^2\\]\n\n10.3.2 Metrische PrÃ¤diktoren\nAuÃŸerdem ist es mÃ¶glich, Bedingung bei metrischen UV auf ihre HomogenitÃ¤t hin zu bewerten, also Aufteilungen der Art Years &lt; 4.5 zu tÃ¤tigen. Dazu muss man einen Wert identifieren, bei dem man auftrennt.\nDas geht in etwa so:\nSortiere die Werte eines PrÃ¤diktors (aufsteigend)\nFÃ¼r jedes Paar an aufeinanderfolgenden Werten berechne den G-Wert\nFinde das Paar mit dem hÃ¶chsten G-Wert aus allen Paaren\nNimm den Mittelwert der beiden Werte dieses Paares: Das ist der Aufteilungswert\nAbbildung AbbildungÂ 10.5 stellt dieses Vorgehen schematisch dar (Rhys 2020).\n\n\n\n\nAbbildungÂ 10.5: Aufteilungswert bei metrischen PrÃ¤diktoren"
  },
  {
    "objectID": "100-baeume.html#regressionbÃ¤ume",
    "href": "100-baeume.html#regressionbÃ¤ume",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.4 RegressionbÃ¤ume",
    "text": "10.4 RegressionbÃ¤ume\nBei RegressionsbÃ¤umen wird nicht ein HomogenitÃ¤tsmaÃŸ wie der Gini-Koeffizient als Optimierungskriterium herangezogen, sondern die RSS (Residual Sum of Squares) bietet sich an.\nDie \\(J\\) Regionen (Partionierungen) des PrÃ¤diktorraums \\(R_1, R_2, \\ldots, R_J\\) mÃ¼ssen so gewÃ¤hlt werden, dass RSS minimal ist:\n\\[RSS = \\sum^J_{j=1}\\sum_{i\\in R_j}(u_i - \\hat{y}_{R_j})^2,\\]\nwobei \\(\\hat{y}\\) der (vom Baum) vorhergesagte Wert ist fÃ¼r die \\(j\\)-te Region."
  },
  {
    "objectID": "100-baeume.html#baum-beschneiden",
    "href": "100-baeume.html#baum-beschneiden",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.5 Baum beschneiden",
    "text": "10.5 Baum beschneiden\nEin Problem mit EntscheidungsbÃ¤umen ist, dass ein zu komplexer Baum, â€œzu verÃ¤steltâ€ sozusagen, in hohem MaÃŸe Overfitting ausgesetzt ist: Bei hÃ¶heren Ebenen im Baum ist die Anzahl der Beobachtungen zwangslÃ¤ufig klein, was bedeutet, dass viel Rauschen gefittet wird.\nUm das Overfitting zu vermeiden, gibt es zwei auf der Hand liegende MaÃŸnahmen:\n\nDen Baum nicht so groÃŸ werden lassen\nDen Baum â€œzurÃ¼ckschneidenâ€\n\nDie 1. MaÃŸnahme beruht auf dem Festlegen einer maximalen Zahl an Ebenen (maxdepth) oder einer minimalen Zahl an FÃ¤llen pro Knoten (minsplit) oder im Blatt (minbucket).\nDie 2. MaÃŸnahme, das ZurÃ¼ckschneiden (pruning) des Baumes hat als Idee, einen â€œTeilbaumâ€ \\(T\\) zu finden, der so klein wie mÃ¶glich ist, aber so gut wie mÃ¶glich prÃ¤zise Vorhersagen erlaubt. Dazu belegen wir die RSS eines Teilbaums (subtree) mit einem Strafterm \\(s = \\alpha |T|\\), wobei \\(|T|\\) die Anzahl der BlÃ¤tter des Baums entspricht. \\(\\alpha\\) ist ein Tuningparameter, also ein Wert, der nicht vom Modell berechnet wird, sondern von uns gesetzt werden muss - zumeist durch schlichtes Ausprobieren. \\(\\alpha\\) wÃ¤gt ab zwischen KomplexitÃ¤t und Fit (geringe RSS). Wenn \\(\\alpha=0\\) haben wir eine normalen, unbeschnittenen Baum \\(T_0\\). Je grÃ¶ÃŸer \\(\\alpha\\) wird, desto hÃ¶her wird der â€œPreisâ€ fÃ¼r viele BlÃ¤tter, also fÃ¼r KomplexitÃ¤t und der Baum wird kleiner. Dieses Vorgehen nennt man auch cost complexity pruning. Daher nennt man den zugehÃ¶rigen Tuningparameter auch Cost Complexity \\(C_p\\)."
  },
  {
    "objectID": "100-baeume.html#das-rechteck-schlÃ¤gt-zurÃ¼ck",
    "href": "100-baeume.html#das-rechteck-schlÃ¤gt-zurÃ¼ck",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.6 Das Rechteck schlÃ¤gt zurÃ¼ck",
    "text": "10.6 Das Rechteck schlÃ¤gt zurÃ¼ck\nEntscheidungsbÃ¤ume zeichnen sich durch rechtecke (rekursive) Partionierungen des PrÃ¤diktorenraums aus. Lineare Modelle durch eine einfache lineare Partionierung (wenn man Klassifizieren mÃ¶chte), AbbildungÂ 10.6 verdeutlicht diesen Unterschied (James u.Â a. 2021).\n\n\n\n\nAbbildungÂ 10.6: Rechteckige vs.Â lineare Partionierung\n\n\n\nJetzt kann sich fragen: Welches Vorgehen ist besser - das rechteckige oder das lineare Partionierungen. Da gibt es eine klare Antwort: Es kommt drauf an. Wie AbbildungÂ 10.6 gibt es Datenlagen, in denen das eine Vorgehen zu homogenerer Klassifikation fÃ¼hrt und Situationen, in denen das andere Vorgehen besser ist."
  },
  {
    "objectID": "100-baeume.html#tidymodels",
    "href": "100-baeume.html#tidymodels",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.7 Tidymodels",
    "text": "10.7 Tidymodels\nProbieren wir den Algorithmus EntscheidungsbÃ¤ume an einem einfachen Beispiel in R mit Tidymodels aus.\nDie Aufgabe sei, Spritverbrauch (mÃ¶glichst exakt) vorherzusagen.\nEin Ã¤hnliches Beispiel, mit analogem Vorgehen, findet sich in dieser Fallstude.\n\n10.7.1 Initiale Datenaufteilung\n\nlibrary(tidymodels)\n\n\ndata(\"mtcars\")\n\nset.seed(42)  # Reproduzierbarkeit\nd_split &lt;- initial_split(mtcars, strata = mpg)\n## Warning: The number of observations in each quantile is below the recommended threshold of 20.\n## â€¢ Stratification will use 1 breaks instead.\n## Warning: Too little data to stratify.\n## â€¢ Resampling will be unstratified.\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nDie Warnung zeigt uns, dass der Datensatz sehr klein ist; stimmt. Ignorieren wir hier einfach.\nWie man auf der Hilfeseite der Funktion sieht, wird per Voreinstellung 3/1 aufgeteilt, also 75% in das Train-Sample, 25% der Daten ins Test-Sample.\nBei \\(n=32\\) finden also 8 Autos ihren Weg ins Test-Sample und die Ã¼brigen 24 ins Train-Sample. Bei der kleinen Zahl kÃ¶nnte man sich (berechtigterweise) fragen, ob es Sinn macht, die spÃ¤rlichen Daten noch mit einem Test-Sample weiter zu dezimieren. Der Einwand ist nicht unberechtigt, allerdings zieht der Verzicht auf ein Test-Sample andere Probleme, Overfitting namentlich, nach sich.\n\n10.7.2 Kreuzvalidierung definieren\n\nd_cv &lt;- vfold_cv(d_train, strata = mpg, repeats = 5, v = 5) \nd_cv\n\n\n\n  \n\n\n\nDie Defaults (Voreinstellungen) der Funktion vfold_cv() kÃ¶nnen, wie immer, auf der Hilfeseite der Funktion nachgelesen werden.\nDa die Stichprobe sehr klein ist, bietet es sich an, eine kleine Zahl an Faltungen (folds) zu wÃ¤hlen. Bei 10 Faltungen beinhaltete eine Stichprobe gerade 10% der FÃ¤lle in Train-Sample, also etwa â€¦ 2!\nZur Erinnerung: Je grÃ¶ÃŸer die Anzahl der Repeats, desto genauer schÃ¤tzen wir die ModellgÃ¼te.\n\n10.7.3 Rezept definieren\nHier ein einfaches Rezept:\n\nrecipe1 &lt;-\n  recipe(mpg ~ ., data = d_train) %&gt;% \n  step_impute_knn() %&gt;% \n  step_normalize() %&gt;% \n  step_dummy() %&gt;% \n  step_other(threshold = .1)\n\n\n10.7.4 Modell definieren\n\ntree_model &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n  \n\nWenn Sie sich fragen, woher Sie die Optionen fÃ¼r die Tuningparameter wissen sollen: Schauen Sie mal in die Hilfeseite des Pakets {{dials}}; das Paket ist Teil von Tidymodels.\nDie Berechnung des Modells lÃ¤uft Ã¼ber das Paket {{rpart}}, was wir durch set_engine() festgelegt haben.\nDer Parameter Cost Complexity, \\(C_p\\) oder manchmal auch mit \\(\\alpha\\) bezeichnet, hat einen typischen Wertebereich von \\(10^{-10}\\) bis \\(10^{-1}\\):\n\ncost_complexity()\n## Cost-Complexity Parameter (quantitative)\n## Transformer: log-10 [1e-100, Inf]\n## Range (transformed scale): [-10, -1]\n\nHier ist der Wert in Log-Einheiten angegeben. Wenn Sie sich fragen, woher Sie das bitteschÃ¶n wissen sollen: Naja, es steht auf der Hilfeseite ğŸ˜„.\nUnser Modell ist also so definiert:\n\ntree_model\n## Decision Tree Model Specification (regression)\n## \n## Main Arguments:\n##   cost_complexity = tune()\n##   tree_depth = tune()\n##   min_n = tune()\n## \n## Computational engine: rpart\n\nMit tune() weist man den betreffenden Parameter als â€œzu tunenâ€ aus - gute Werte sollen durch Ausprobieren wÃ¤hrend des Berechnens bestimmt werden. Genauer gesagt soll das Modell fÃ¼r jeden Wert (oder jede Kombination an Werten von Tuningparametern) berechnet werden.\nEine Kombination an Tuningparameter-Werten, die ein Modell spezifizieren, sozusagen erst â€œfertig definierenâ€, nennen wir einen Modellkandidaten.\nDefinieren wir also eine Tabelle (grid) mit Werten, die ausprobiert, â€œgetunedâ€ werden sollen. Wir haben oben dre Tuningparameter bestimmt. Sagen wir, wir hÃ¤tten gerne jeweils 5 Werte pro Parameter.\n\ntree_grid &lt;-\n  grid_regular(\n    cost_complexity(),\n    tree_depth(),\n    min_n(),\n    levels = 4\n  )\n\nFÃ¼r jeden Parameter sind Wertebereiche definiert; dieser Wertebereich wird gleichmÃ¤ÃŸig (daher grid regular) aufgeteilt; die Anzahl der verschiedenen Werte pro Parameter wird druch levels gegeben.\nMehr dazu findet sich auf der Hilfeseite zu grid_regular().\nWenn man die alle miteinander durchprobiert, entstehen \\(4^3\\) Kombinationen, also Modellkandidaten.\nAllgemeiner gesagt sind das bei \\(n\\) Tuningparametern mit jeweils \\(m\\) verschiedenen Werten \\(m^n\\) MÃ¶glichkeiten, spricht Modellkandidaten. Um diesen Faktor erhÃ¶ht sich die Rechenzeit im Vergleich zu einem Modell ohne Tuning. Man sieht gleich, dass die Rechenzeit schnell unangenehm lang werden kann.\nEntsprechend hat unsere Tabelle diese Zahl an Zeilen. Jede Zeile definiert einen Modellkandidaten, also eine Berechnung des Modells.\n\ndim(tree_grid)\n## [1] 64  3\n\n\nhead(tree_grid)\n\n\n\n  \n\n\n\nMan beachte, dass auÃŸer Definitionen bisher nichts passiert ist â€“ vor allem haben wir noch nichts berechnet. Sie scharren mit den Hufen? Wollen endlich loslegen? Also gut.\n\n10.7.5 Workflow definieren\nFast vergessen: Wir brauchen noch einen Workflow.\n\ntree_wf &lt;-\n  workflow() %&gt;% \n  add_model(tree_model) %&gt;% \n  add_recipe(recipe1)\n\n\n10.7.6 Modell tunen und berechnen\nAchtung: Das Modell zu berechnen kann etwas dauern. Es kann daher Sinn machen, das Modell abzuspeichern, so dass Sie beim erneuten Durchlaufen nicht nochmal berechnen mÃ¼ssen, sondern einfach von der Festplatte laden kÃ¶nnen; das setzt natÃ¼rlich voraus, dass sich am Modell nichts geÃ¤ndert hat.\n\ndoParallel::registerDoParallel()  # mehrere Kerne parallel nutzen\n\nset.seed(42)\ntic()  # Stoppuhr an\ntrees_tuned &lt;-\n  tune_grid(\n    object = tree_wf,\n    grid = tree_grid,\n    resamples = d_cv\n  )\ntoc()  # Stoppuhr aus\n\nFÃ¼gt man den Parameter control = control_grid(verbose = TRUE) zu tune _grid hinzu, dann bekommt man man ausfÃ¼hrlicheren Output.\nEs bietet sich vielleicht in dem Fall an, das Ergebnis-Objekt als R Data serialized (rds) abzuspeichern:\n\nwrite_rds(trees_tuned, \"objects/trees1.rds\")\n\nBzw. so wieder aus der RDS-Datei zu importieren:\n\ntrees_tuned &lt;- read_rds(\"objects/trees1.rds\")\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Zwischenspeichern von Modellobjekten ist praktisch, weil es Rechenzeit spart. Allerdings hat es auch Nachteile: Es ist gefÃ¤hrlich. Wenn Sie Ihre Modellspezifikation Ã¤ndern, mÃ¼ssen Sie auch Ihr gespeichertes Modell aktualisieren. Das vergisst man leicht. Dann hat man falsche Ergebnisse und man wird nicht durch eine Fehlermeldung gewarnt.\n\n\nHier oder hier kann man einiges zum Unterschied einer RDS-Datei vs.Â einer â€œnormalenâ€ R-Data-Datei nachlesen. Wenn man mÃ¶chte ğŸ˜‰.\n\ntrees_tuned\n\n\n\n  \n\n\n\nDie Warnhinweise kann man sich so ausgeben lassen:\n\ncollect_notes(trees_tuned)\n\n\n\n  \n\n\n\nWie gesagt, in diesem Fall war die StichprobengrÃ¶ÃŸe sehr klein.\n\n10.7.7 ModellgÃ¼te evaluieren\n\ncollect_metrics(trees_tuned)\n\n\n\n  \n\n\n\nPraktischerweise gibt es eine Autoplot-Funktion, um die besten Modellparameter auszulesen:\n\nautoplot(trees_tuned)\n\n\n\n\n\n10.7.8 Bestes Modell auswÃ¤hlen\nAus allen Modellkandidaten wÃ¤hlen wir jetzt das beste Modell aus:\n\nselect_best(trees_tuned)\n\n\n\n  \n\n\n\nMit diesem besten Kandidaten definieren wir jetzt das â€œfinaleâ€ Modell, wir â€œfinalisierenâ€ das Modell mit den besten Modellparametern:\n\ntree_final &lt;-\n  finalize_workflow(tree_wf, parameters = select_best(trees_tuned))\n\ntree_final\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: decision_tree()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 4 Recipe Steps\n## \n## â€¢ step_impute_knn()\n## â€¢ step_normalize()\n## â€¢ step_dummy()\n## â€¢ step_other()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Decision Tree Model Specification (regression)\n## \n## Main Arguments:\n##   cost_complexity = 1e-04\n##   tree_depth = 10\n##   min_n = 2\n## \n## Computational engine: rpart\n\n\n10.7.9 Final Fit\nJetzt fitten wir dieses Modell auf das ganze Train-Sample und predicten auf das Test-Sample:\n\ntree_fit_final &lt;-\n  tree_final %&gt;% \n  last_fit(d_split)\n\ntree_fit_final\n\n\n\n  \n\n\n\nHier ist, unser finaler Baum ğŸŒ³.\n\ncollect_metrics(tree_fit_final)\n\n\n\n  \n\n\n\nVoilÃ : Die ModellgÃ¼te fÃ¼r das Test-Sample: Im Schnitt liegen wir ca. 4 Meilen daneben mit unseren Vorhersagen, wenn wir RMSE mal so locker interpretieren wollen.\nIn der Regel ist Ã¼brigens RMSE interessanter als R-Quadrat, da R-Quadrat die GÃ¼te eines Korrelationsmusters vorhersagt, aber RMSE die PrÃ¤zision der Vorhersage, also sozusagen die KÃ¼rze der Fehlerbalken.\n\n10.7.10 Baum ansehen\nDas Ergebnisobjekt von rpart, dem zugrundeliegenden Paketkann man mitextract_fit_engine` bekommen. Ruft man dieses Objekt auf, so sieht man die Wenn-Dann-Regeln des Baumes:\n\ntree_fit_rpart &lt;- extract_fit_engine(tree_fit_final)\ntree_fit_rpart\n## n= 24 \n## \n## node), split, n, deviance, yval\n##       * denotes terminal node\n## \n##  1) root 24 6.269983e+02 18.95833  \n##    2) hp&gt;=116.5 14 1.062286e+02 15.52857  \n##      4) hp&gt;=192.5 6 2.218833e+01 13.01667  \n##        8) disp&gt;=450 2 0.000000e+00 10.40000 *\n##        9) disp&lt; 450 4 1.647500e+00 14.32500  \n##         18) drat&gt;=3.635 1 0.000000e+00 13.30000 *\n##         19) drat&lt; 3.635 3 2.466667e-01 14.66667  \n##           38) drat&lt; 3.22 1 0.000000e+00 14.30000 *\n##           39) drat&gt;=3.22 2 4.500000e-02 14.85000 *\n##      5) hp&lt; 192.5 8 1.778875e+01 17.41250  \n##       10) drat&lt; 3.075 4 2.700000e+00 16.10000  \n##         20) qsec&gt;=17.8 1 0.000000e+00 15.20000 *\n##         21) qsec&lt; 17.8 3 1.620000e+00 16.40000  \n##           42) qsec&lt; 17.5 2 4.050000e-01 15.95000  \n##             84) disp&gt;=296.9 1 0.000000e+00 15.50000 *\n##             85) disp&lt; 296.9 1 0.000000e+00 16.40000 *\n##           43) qsec&gt;=17.5 1 0.000000e+00 17.30000 *\n##       11) drat&gt;=3.075 4 1.307500e+00 18.72500  \n##         22) qsec&gt;=18.6 1 0.000000e+00 17.80000 *\n##         23) qsec&lt; 18.6 3 1.666667e-01 19.03333  \n##           46) qsec&lt; 17.035 1 0.000000e+00 18.70000 *\n##           47) qsec&gt;=17.035 2 0.000000e+00 19.20000 *\n##    3) hp&lt; 116.5 10 1.255240e+02 23.76000  \n##      6) hp&gt;=92 7 3.620000e+00 21.70000  \n##       12) hp&gt;=96 5 2.320000e-01 21.26000  \n##         24) vs&lt; 0.5 2 0.000000e+00 21.00000 *\n##         25) vs&gt;=0.5 3 6.666667e-03 21.43333 *\n##       13) hp&lt; 96 2 0.000000e+00 22.80000 *\n##      7) hp&lt; 92 3 2.288667e+01 28.56667  \n##       14) disp&gt;=78.85 2 8.450000e-01 26.65000  \n##         28) disp&gt;=99.65 1 0.000000e+00 26.00000 *\n##         29) disp&lt; 99.65 1 0.000000e+00 27.30000 *\n##       15) disp&lt; 78.85 1 0.000000e+00 32.40000 *\n\nMit der Funktion rpart.plot (aus {rpart.plot}) kann man sich einen ansehnlichen Baum anzeigen lassen:\n\nlibrary(rpart.plot)\nrpart.plot(tree_fit_rpart)\n\n\n\n\n\n10.7.11 Nur zum SpaÃŸ: Vergleich mit linearem Modell\nEin einfaches lineares Modell, was hÃ¤tte das jetzt wohl fÃ¼r eine ModellgÃ¼te?\n\nlm_model &lt;-\n  linear_reg()\n\n\nlm_wf &lt;-\n  workflow() %&gt;% \n  add_model(lm_model) %&gt;% \n  add_recipe(recipe1)\n\n\ntic()\nlm_fit &lt;-\n  fit_resamples(\n    lm_wf,\n    resamples = d_cv\n  )\ntoc()\n## 2.327 sec elapsed\n\n\ncollect_metrics(lm_fit)\n\n\n\n  \n\n\n\n\nlm_fit_final &lt;- \n  last_fit(lm_wf, d_split)\n\nWie prÃ¤zise ist die Vorhersage im Test-Sample?\n\ncollect_metrics(lm_fit_final)\n\n\n\n  \n\n\n\nDas lineare Modell schneidet etwas (deutlich?) schlechter ab als das einfache Baummodell.\nMan beachte, dass die ModellgÃ¼te im Train-Sample hÃ¶her ist als im Test-Sample (Overfitting)."
  },
  {
    "objectID": "100-baeume.html#vertiefung",
    "href": "100-baeume.html#vertiefung",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.8 Vertiefung",
    "text": "10.8 Vertiefung\n\nVisualisierung des ML-Ablaufs am Beispiel des Entscheidungsbaums, Teil 1\nVisualisierung des ML-Ablaufs am Beispiel des Entscheidungsbaums, Teil 2"
  },
  {
    "objectID": "100-baeume.html#aufgaben",
    "href": "100-baeume.html#aufgaben",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.9 Aufgaben",
    "text": "10.9 Aufgaben\nDiese Aufgaben bei Datenwerk behandeln den Stoff dieses Kapitels:\n\nregr-tree01\nregr-tree02\nregr-tree03\nFlex-vs-nichtflex-Methode\nFlex-vs-nichtflex-Methode2\n\nFlex-vs-nichtflex-Methode3\ntidymodels-penguins07\nTengku-Hanis01\nbike01\nbike02\nbike03\nbike04\n\nSchauen Sie sich mal die Kategorie trees auf Datenwerk an.\nAlternativ bietet die Kategorie tidymodels eine Sammlung von Aufgaben rund um das R-Paket Tidymodels; dort kÃ¶nnen Sie sich Aufgaben anpassen."
  },
  {
    "objectID": "100-baeume.html#fallstudien",
    "href": "100-baeume.html#fallstudien",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "\n10.10 Fallstudien",
    "text": "10.10 Fallstudien\n\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\nFitting Regression Trees aus â€œISLR tidymodels labsâ€\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications."
  },
  {
    "objectID": "100-baeume.html#footnotes",
    "href": "100-baeume.html#footnotes",
    "title": "\n10Â  EntscheidungsbÃ¤ume\n",
    "section": "",
    "text": "mit library(rpart.plot)â†©ï¸"
  },
  {
    "objectID": "110-ensemble.html#lernsteuerung",
    "href": "110-ensemble.html#lernsteuerung",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Lernziele\n\nSie kÃ¶nnen Algorithmen fÃ¼r Ensemble-Lernen erklÃ¤ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest\nSie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann\nSie kÃ¶nnen diese Verfahren in R berechnen\n\n11.1.2 Literatur\n\nRhys, Kap. 8"
  },
  {
    "objectID": "110-ensemble.html#vorbereitung",
    "href": "110-ensemble.html#vorbereitung",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.2 Vorbereitung",
    "text": "11.2 Vorbereitung\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variable importance plot\nlibrary(readr)  # read_rds"
  },
  {
    "objectID": "110-ensemble.html#hinweise-zur-literatur",
    "href": "110-ensemble.html#hinweise-zur-literatur",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.3 Hinweise zur Literatur",
    "text": "11.3 Hinweise zur Literatur\nDie folgenden AusfÃ¼hrungen basieren primÃ¤r auf Rhys (2020), aber auch auf James u.Â a. (2021) und (weniger) Kuhn und Johnson (2013)."
  },
  {
    "objectID": "110-ensemble.html#wir-brauchen-einen-wald",
    "href": "110-ensemble.html#wir-brauchen-einen-wald",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.4 Wir brauchen einen Wald",
    "text": "11.4 Wir brauchen einen Wald\nEin Pluspunkt von EntscheidungsbÃ¤umen ist ihre gute Interpretierbarkeit. Man kÃ¶nnte behaupten, dass BÃ¤ume eine typische Art des menschlichen Entscheidungsverhalten nachahmen: â€œWenn A, dann tue B, ansonsten tue Câ€ (etc.). Allerdings: Einzelne EntscheidungsbÃ¤ume haben oft keine so gute Prognosegenauigkeit. Der oder zumindest ein Grund ist, dass sie (zwar wenig Bias aber) viel Varianz aufweisen. Das sieht man z.B. daran, dass die Vorhersagegenauigkeit stark schwankt, wÃ¤hlt man eine andere Aufteilung von Train- vs.Â Test-Sample. Anders gesagt: BÃ¤ume overfitten ziemlich schnell. Und obwohl das No-Free-Lunch-Theorem zu den Grundfesten des maschinellen Lernens (oder zu allem wissenschaftlichen Wissen) gehÃ¶rt, kann man festhalten, dass sog. Ensemble-Lernen fast immer besser sind als einzelne Baummodelle. Kurz gesagt: Wir brauchen einen Wald: ğŸŒ³ğŸŒ³ğŸŒ³.1"
  },
  {
    "objectID": "110-ensemble.html#was-ist-ein-ensemble-lerner",
    "href": "110-ensemble.html#was-ist-ein-ensemble-lerner",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.5 Was ist ein Ensemble-Lerner?",
    "text": "11.5 Was ist ein Ensemble-Lerner?\nEnsemble-Lerner kombinieren mehrere schwache Lerner zu einem starken Lerner. Das Paradebeispiel sind baumbasierte Modelle; darauf wird sich die folgende AusfÃ¼hrung auch begrenzen. Aber theoretisch kann man jede Art von Lerner kombinieren. Bei numerischer PrÃ¤diktion wird bei Ensemble-Lerner zumeist der Mittelwert als Optmierungskriterium herangezogen; bei Klassifikation (nominaler PrÃ¤diktion) hingegen die modale Klasse (also die hÃ¤ufigste). Warum hilft es, mehrere Modelle (Lerner) zu einem zu aggregieren? Die Antwort lautet, dass die Streuung der Mittelwerte sinkt, wenn die StichprobengrÃ¶ÃŸe steigt. Zieht man Stichproben der GrÃ¶ÃŸe 1, werden die Mittelwerte stark variieren, aber bei grÃ¶ÃŸeren Stichproben (z.B. GrÃ¶ÃŸe 100) deutlich weniger2. Die Streuung der Mittelwerte in den Stichproben nennt man bekanntlich Standardefehler (se). Den se des Mittelwerts (\\(se_M\\)) fÃ¼r eine normalverteilte Variable \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\) gilt: \\(se_{M} = \\sigma / \\sqrt(n)\\), wobei \\(\\sigma\\) die SD der Verteilung und \\(\\mu\\) den Erwartungswert (â€œMittelwertâ€) meint, und \\(n\\) ist die StichprobengrÃ¶ÃŸe.\n\n\n\n\n\n\nHinweis\n\n\n\nJe grÃ¶ÃŸer die Stichprobe, desto kleiner die Varianz des SchÃ¤tzers (ceteris paribus). Anders gesagt: GrÃ¶ÃŸere Stichproben schÃ¤tzen genauer als kleine Stichproben.\n\n\nAus diesem Grund bietet es sich an, schwache Lerner mit viel Varianz zu kombinieren, da die Varianz so verringert wird."
  },
  {
    "objectID": "110-ensemble.html#bagging",
    "href": "110-ensemble.html#bagging",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.6 Bagging",
    "text": "11.6 Bagging\n\n11.6.1 Bootstrapping\nDas erste baumbasierte Modell, was vorgestellt werden soll, basiert auf sog. Bootstrapping, ein Standardverfahren in der Statistik (James u.Â a. 2021).\nBootstrapping ist eine Nachahmung fÃ¼r folgende Idee: HÃ¤tte man viele Stichproben aus der relevanten Verteilung, so kÃ¶nnte man z.B. die Genauigkeit eines Modells \\(\\hat{f}_{\\bar{X}}\\) zur SchÃ¤tzung des Erwartungswertes \\(\\mu\\) einfach dadurch bestimmen, indem man se berechnet, also die Streuung der Mitterwerte \\(\\bar{X}\\) berechnet. AuÃŸerdem gilt, dass die PrÃ¤zision der SchÃ¤tzung des Erwartungswerts steigt mit steigendem Stichprobenumfang \\(n\\). Wir kÃ¶nnten also fÃ¼r jede der \\(B\\) Stichproben, \\(b=1,\\ldots, B\\), ein (Baum-)Modell berechnen, \\(\\hat{f}^b\\), und dann deren Vorhersagen aggregieren (zum Mittelwert oder Modalwert). Das kann man formal so darstellen (James u.Â a. 2021):\n\\[\\hat{f}_{\\bar{X}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^b\\]\nMit diesem Vorgehen kann die Varianz des Modells \\(\\hat{f}_{\\bar{X}}\\) verringert werden; die Vorhersagegenauigkeit steigt.\nLeider haben wir in der Regel nicht viele (\\(B\\)) DatensÃ¤tze.\nDaher â€œbauenâ€ wir uns aus dem einzelnen Datensatz, der uns zur VerfÃ¼gung steht, viele DatensÃ¤tze. Das hÃ¶rt sich nach â€œtoo good to be trueâ€ an3 Weil es sich unglaubwÃ¼rdig anhÃ¶rt, nennt man das entsprechende Verfahren (gleich kommt es!) auch â€œMÃ¼nchhausen-Methodeâ€, nach dem berÃ¼hmten LÃ¼bgenbaron. Die Amerikaner ziehen sich Ã¼brigens nicht am Schopf aus dem Sumpf, sondern mit den Stiefelschlaufen (die Cowboys wieder), daher spricht man im Amerikanischen auch von der â€œBoostrapping-Methodeâ€.\nDiese â€œPseudo-Stichprobenâ€ oder â€œBootstrapping-Stichprobenâ€ sind aber recht einfach zu gewinnen.. Gegeben sei Stichprobe der GrÃ¶ÃŸe \\(n\\):\n\nZiehe mit ZurÃ¼cklegen (ZmZ) aus der Stichprobe \\(n\\) Beobachtungen\nFertig ist die Bootstrapping-Stichprobe.\n\nAbbildungÂ 11.1 verdeutlicht das Prinzip des ZMZ, d.h. des Bootstrappings. Wie man sieht, sind die Bootstrap-Stichproben (rechts) vom gleichen Umfang \\(n\\) wie die Originalstichprobe (links). Allerdins kommen nicht alle FÃ¤lle (in der Regel) in den â€œBoostrap-Beutelâ€ (in bag), sondern einige FÃ¤lle werden oft mehrfach gezogen, so dass einige FÃ¤lle nicht gezogen werden (out of bag).\n\n\n\n\nAbbildungÂ 11.1: Bootstrapping: Der Topf links symbolisiert die Original-Stichprobe, aus der wir hier mehrere ZMZ-Stichproben ziehen (Rechts), dargestellt mit â€˜in bagâ€™\n\n\n\nMan kann zeigen, dass ca. 2/3 der FÃ¤lle gezogen werden, bzw. ca. 1/3 nicht gezogen werden. Die nicht gezogenen FÃ¤lle nennt man auch out of bag (OOB).\nFÃ¼r die Entwicklung des Bootstrapping wurde der Autor, Bradley Efron, im Jahr 2018 mit dem internationalen Preis fÃ¼r Statistik ausgezeichnet;\n\nâ€œWhile statistics offers no magic pill for quantitative scientific investigations, the bootstrap is the best statistical pain reliever ever produced,â€ says Xiao-Li Meng, Whipple V. N. Jones Professor of Statistics at Harvard University.â€œ\n\n\n11.6.2 Bagging-Algorithmus\nBagging, die Kurzform fÃ¼r Bootstrap-Aggregation ist wenig mehr als die Umsetzung des Boostrappings.\nDer Algorithmus von Bagging kann so beschrieben werden:\n\nWÃ¤hle \\(B\\), die Anzahl der Boostrap-Stichproben und damit auch Anzahl der Submodelle (Lerner)\nZiehe \\(B\\) Boostrap-Stichproben\nBerechne das Modell \\(\\hat{f}^{*b}\\) fÃ¼r jede der \\(B\\) Stichproben (typischerweise ein einfacher Baum)\nSchicke die Test-Daten durch jedes Sub-Modell\nAggregiere ihre Vorhersage zu einem Wert (Modus bzw. Mittelwert) pro Fall aus dem Test-Sample, zu \\(\\hat{f}_{\\text{bag}}\\)\n\n\nAnders gesagt:\n\\[\\hat{f}_{\\text{bag}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^{*b}\\]\nDer Bagging-Algorithmus ist in Abbildung AbbildungÂ 11.2 dargestellt.\n\n\n\n\nflowchart LR\n  D[Datensatz] --&gt; B1[Baum 1] --&gt; M[Modus als Vorhersagewert]\n  D--&gt;B2[Baum 2] --&gt; M\n  D--&gt;B3[Baum ...]---&gt;M\n  D--&gt;B4[Baum B]---&gt;M\n\n\nAbbildungÂ 11.2: Bagging schematisch illustriert\n\n\n\nDie Anzahl der BÃ¤ume (allgemeiner: Submodelle) \\(B\\) ist hÃ¤ufig im oberen drei- oder niedrigem vierstelligen Bereich, z.B. \\(B=1000\\). Eine gute Nachricht ist, dass Bagging nicht Ã¼beranpasst, wenn \\(B\\) groÃŸ wird.\n\n11.6.3 Variablenrelevanz\nMan kann die Relevanz der PrÃ¤diktoren in einem Bagging-Modell auf mehrere Arten schÃ¤tzen. Ein Weg (bei numerischer PrÃ¤diktion) ist, dass man die RSS-Verringerung, die durch Aufteilung anhand eines PrÃ¤diktors erzeugt wird, mittelt Ã¼ber alle beteiligten BÃ¤ume (Modelle). Bei Klassifikation kann man die analog die Reduktion des Gini-Wertes Ã¼ber alle BÃ¤ume mitteln und als SchÃ¤tzwert fÃ¼r die Relevanz des PrÃ¤diktors heranziehen.\n\n11.6.4 Out-of-Bag-Vorhersagen\nDa nicht alle FÃ¤lle der Stichprobe in das Modell einflieÃŸen (sondern nur ca. 2/3), kann der Rest der FÃ¤lle zur Vorhersage genutzt werden. Bagging erzeugt sozusagen innerhalb der Stichprobe selbstÃ¤ndig ein Train- und ein Test-Sample. Man spricht von Out-of-Bag-SchÃ¤tzung (OOB-SchÃ¤tzung). Der OOB-Fehler (z.B. MSE bei numerischen Modellen und Genauigkeit bei nominalen) ist eine valide SchÃ¤tzung des typischen Test-Sample-Fehlers.\nHat man aber Tuningparameter, so wird man dennoch auf die typische Train-Test-Aufteilung zurÃ¼ckgreifen, um Overfitting durch das Ausprobieren der Tuning-Kandidaten zu vermeiden (was sonst zu Zufallstreffern fÃ¼hren wÃ¼rde bei genÃ¼gend vielen Modellkandidaten)."
  },
  {
    "objectID": "110-ensemble.html#random-forests",
    "href": "110-ensemble.html#random-forests",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.7 Random Forests",
    "text": "11.7 Random Forests\nRandom Forests (â€œZufallswÃ¤lderâ€) sind eine Weiterentwicklung von Bagging-Modellen. Sie sind Bagging-Modelle, aber haben noch ein Ass im Ã„rmel: Und zwar wird an jedem Slit (Astgabel, Aufteilung) nur eine Zufallsauswahl an \\(m\\) PrÃ¤diktoren berÃ¼cksichtigt. Das hÃ¶rt sich verrÃ¼ckt an: â€œWie, mit weniger PrÃ¤diktoren soll eine bessere Vorhersage erreicht werden?!â€ Ja, genau so ist es! Nehmen Sie an, es gibt im Datensatz einen sehr starken und ein paar mittelstarke PrÃ¤diktoren; der Rest der PrÃ¤diktoren ist wenig relevant. Wenn Sie jetzt viele â€œgebootstrapteâ€4 ziehen, werden diese BÃ¤ume sehr Ã¤hnlich sein: Der stÃ¤rkste PrÃ¤diktor steht vermutlich immer ob an der Wurzel, dann kommen die mittelstarken PrÃ¤diktoren. Jeder zusÃ¤tzliche Baum trÃ¤gt dann wenig neue Information bei. Anders gesagt: Die Vorhersagen der BÃ¤ume sind dann sehr Ã¤hnlich bzw. hoch korreliert. Bildet man den Mittelwert von hoch korrelierten Variablen, verringert sich leider die Varianzu nur wenig im Vergleich zu nicht oder gering korrelierten Variablen (James u.Â a. 2021). Dadurch dass Random Forests nur \\(m\\) der \\(p\\) PrÃ¤diktoren pro Split zulassen, werden die BÃ¤ume unterschiedlicher. Wir â€œdekorrelierenâ€ die BÃ¤ume. Bildet man den Mittelwert von gering(er) korrelierten Variablen, so ist die Varianzreduktion hÃ¶her - und die Vohersage genauer. LÃ¤sst man pro Split \\(m=p\\) PrÃ¤diktoren zu, so gleicht Bagging dem Random Forest. Die Anzahl \\(m\\) der erlaubten PrÃ¤diktoren werden als Zufallstichprobe aus den \\(p\\) PrÃ¤diktoren des Datensatzes gezogen (ohne ZurÃ¼cklegen). \\(m\\) ist ein Tuningparameter; \\(m=\\sqrt{p}\\) ist ein beliebter Startwert. In den meisten Implementationen wird \\(m\\) mit mtry bezeichnet (so auch in Tidymodels).\nDer Random-Forest-Algorithmus ist in AbbildungÂ 11.3 illustriert: Mit jedem Quadrat ist ein Baummodell symbolisiert. In jedem Baum wird an jedem Split (ohne ZurÃ¼cklegen) eine Auswahl an zu berÃ¼cksichtigenden PrÃ¤diktoren gezogen.\n\n\n\nAbbildungÂ 11.3: ZufallswÃ¤lder durch Ziehen mit ZurÃ¼cklegen (zmz) und Ziehen ohne ZurÃ¼cklegen (ZoZ)\n\n\nAbbildungÂ 11.4 vergleicht die Test-Sample-VorhersagegÃ¼te von Bagging- und Random-Forest-Algorithmen aus James u.Â a. (2021). In diesem Fall ist die VorhersagegÃ¼te deutlich unter der OOB-GÃ¼te; laut James u.Â a. (2021) ist dies hier â€œZufallâ€.\n\n\n\n\nAbbildungÂ 11.4: Test-Sample-VorhersagegÃ¼te von Bagging- und Random-Forest-Algorithmen\n\n\n\nDen Effekt von \\(m\\) (Anzahl der PrÃ¤diktoren pro Split) ist in AbbildungÂ 11.5 dargestellt (James u.Â a. 2021). Man erkennt, dass der Zusatznutzen an zusÃ¤tzlichen BÃ¤umen, \\(B\\), sich abschwÃ¤cht. Daher ist die Anzahl \\(B\\) an BÃ¤umen nicht wirklich ein Tuningparameter. Mit ein paar Hundert oder wenigen Tausend BÃ¤umen ist man auf der sicheren Seite.5. \\(m=\\sqrt{p}\\) schneidet wie erwartet am besten ab.\n\n\n\n\nAbbildungÂ 11.5: Test-Sample-VorhersagegÃ¼te von Bagging- und Random-Forest-Algorithmen\n\n\n\nDas schÃ¶ne an Random-Forest-Modellen ist, dass sie (oft) genau vorhersagen und dass sie einfach zu â€œwartenâ€ sind: Sie haben wenige Tuningparameter6 und produzieren kaum nebulÃ¶se Fehlermeldungen."
  },
  {
    "objectID": "110-ensemble.html#boosting",
    "href": "110-ensemble.html#boosting",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.8 Boosting",
    "text": "11.8 Boosting\nIm Unterschied zu Bagging und Random-Forest-Modellen wird beim Boosting der â€œWaldâ€ sequenziell entwickelt, nicht gleichzeitig wie bei den anderen vorgestellten â€œWald-Modellenâ€. Die zwei bekanntesten Implementierungen bzw. Algorithmus-Varianten sind AdaBoost und XGBoost. Gerade XGBoost hat den Ruf, hervorragende Vorhersagen zu leisten. Auf Kaggle gewinnt nach einigen Berichten oft XGBoost. Nur neuronale Netze schneiden besser ab. Random-Forest-Modelle kommen nach diesem Bereich auf Platz 3. Allerdings benÃ¶tigen neuronale Netzen oft riesige StichprobengrÃ¶ÃŸen und bei spielen ihre Nuanciertheit vor allem bei komplexen Daten wie Bildern oder Sprache aus. FÃ¼r â€œrechteckigeâ€ Daten (also aus einfachen, normalen Tabellen) wird ein baumbasiertes Modell oft besser abschneiden.\nDie Idee des Boosting ist es, anschaulich gesprochen, aus Fehlern zu lernen: Fitte einen Baum, schau welche FÃ¤lle er schlecht vorhergesagt hat, konzentriere dich beim nÃ¤chsten Baum auf diese FÃ¤lle und so weiter.\nWie andere Ensemble-Methoden auch kann Boosting theoretisch fÃ¼r beliebige Algorithmen eingesetzt werden. Es macht aber Sinn, Boosting bei â€œschwachen Lernernâ€ einzusetzen. Typisches Beispiel ist ein einfacher Baum; â€œeinfachâ€ soll heiÃŸen, der Baum hat nur wenig Gabeln oder vielleicht sogar nur eine einzige. Dann spricht man von einem Stumpf, was intuitiv gut passt.\n\n11.8.1 AdaBoost\nDer AdaBoost-Algorithmus funktioniert, einfach dargestellt, wie folgt. Zuerst hat jeder Fall \\(i\\) im Datensatz des gleiche Gewicht. Die erste (und alle weiteren) Stichprobe werden per Bootstrapping aus dem Datensatz gezogen. Dabei ist die Wahrscheinlichkeit, gezogen zu werden, proportional zum Gewicht des Falles, \\(w_i\\). Da im ersten Durchgang die Gewichte identisch sind, haben zunÃ¤chst alle FÃ¤lle die gleiche Wahrscheinlichkeit, in das Bootstrap-Sample gezogen zu werden. Die BÃ¤ume bei AdaBoost sind eigentlich nur â€œStÃ¼mpfeâ€: Sie bestehen aus einem einzelnen Split, s. AbbildungÂ 11.6.\n\n\n\n\nflowchart LR\n  root --&gt; leaf1\n  root --&gt; leaf2\n\n\nAbbildungÂ 11.6: Ein Baumstumpf bei AdaBoost\n\n\n\nNach Berechnung des Baumes und der Vorhersagen werden die richtig klassifizierten FÃ¤lle heruntergewichtet und die falsch klassifizierten FÃ¤lle hoch gewichtet, also stÃ¤rker gewichtet (bleiben wir aus GrÃ¼nden der Einfachheit zunÃ¤chst bei der Klassifikation). Dieses Vorgehen folgt dem Gedanken, dass man sich seine Fehler genauer anschauen muss, die falsch klassifizierten FÃ¤lle sozusagen mehr Aufmerksamkeit bedÃ¼rfen. Das nÃ¤chste (zweite) Modell zieht ein weiteres Bootstrap-Sample. Jetzt sind allerdings die Gewichte schon angepasst, so dass mehr FÃ¤lle, die im vorherigen Modell falsch klassifiziert wurden, in den neuen (zweiten) Baum gezogen werden. Das neue Modell hat also bessere Chancen, die Aspekte, die das VorgÃ¤nger-Modell Ã¼bersah zu korrigieren bzw. zu lernen. Jetzt haben wir zwei Modelle. Die kÃ¶nnen wir aggregieren, genau wie beim Bagging: Der Modus der Vorhersage Ã¼ber alle (beide) BÃ¤ume hinwig ist dann die Vorhersage fÃ¼r einen bestimmten Fall (â€œFallâ€ und â€œBeobachtungâ€ sind stets synonym fÃ¼r \\(y_i\\) zu verstehen). So wiederholt sich das Vorgehen fÃ¼r \\(B\\) BÃ¤ume: Die Gewichte werden angepasst, das neue Modell wird berechnet, alle Modelle machen ihre Vorhersagen, per Mehrheitsbeschluss - mit gewichteten Modellen - wird die Vorhersage bestimmt pro Fall. Irgendwann erreichen wir die vorab definierte Maximalzahl an BÃ¤umen, \\(B\\), und das Modell kommt zu einem Ende.\nDa das Modell die Fehler seiner VorgÃ¤nger reduziert, wird der Bias im Gesamtmodell verringert. Da wir gleichzeitig auch Bagging vornehmen, wird aber die Varianz auch verringert. Klingt schon wieder (fast) nach Too-Good-to-be-True!\nDas Gewicht \\(w_i^b\\) des \\(i\\)ten Falls im \\(b\\)ten Modell von \\(B\\) berechnet sich wie folgt (Rhys 2020):\n\\[ w_i^b = \\begin{cases}\nw_i^{b-1} \\cdot e^{-\\text{model weight}} \\qquad \\text{wenn korrekt klassifiziert} \\\\\nw_i^{b-1} \\cdot e^{\\text{model weight}} \\qquad \\text{wenn inkorrekt klassifiziert} \\\\\n\\end{cases}\\]\nDas Modellgewicht \\(mw\\) berechnet sich dabei so (Rhys 2020):\n\\[mw_b = 0.5 \\cdot log\\left( \\frac{1-p(\\text{inkorrect})}{p(\\text{korrekt})} \\right) \\propto \\mathcal{L(p)} \\]\n\\(p(\\cdot)\\) ist der Anteil (Wahrscheinlichkeit) einer Vorhersage.\nDas Modellgewicht ist ein Faktor, der schlechtere Modelle bestraft. Das folgt dem Gedanken, dass schlechteren Modellen weniger GehÃ¶rt geschenkt werden soll, aber schlecht klassifizierten FÃ¤llen mehr GehÃ¶r.\nDas Vorgehen von AdaBoost ist in AbbildungÂ 11.7 illustriert.\n\n\n\nAbbildungÂ 11.7: AdaBoost illustriert\n\n\n\n11.8.2 XGBoost\nXGBoost ist ein Gradientenverfahren, eine Methode also, die die Richtung des parziellen Ableitungskoeffizienten als Optimierungskriterium heranzieht. XGBoost ist Ã¤hnlich zu AdaBoost, nur dass Residuen modelliert werden, nicht \\(y\\). Die Vorhersagefehler von \\(\\hat{f}^b\\) werden die Zielvariable von \\(\\hat{f}^{b+1}\\). Ein Residuum ist der Vorhersagefehler, bei metrischen Modellen etwa RMSE, oder schlicht \\(r_i = y_i - \\hat{y}_i\\). Details finden sich z.B. hier, dem Original XGBoost-Paper (Chen und Guestrin 2016).\nDie hohe VorhersagegÃ¼te von Boosting-Modellen ist exemplarisch in AbbildungÂ 11.8 dargestellt (James u.Â a. 2021, 358ff). Allerdings verwenden die Autoren Friedmans (2001) Gradient Boosting Machine, eine weitere Variante des Boosting .\n\n\n\n\nAbbildungÂ 11.8: VorhersagegÃ¼te von Boosting und Random Forest"
  },
  {
    "objectID": "110-ensemble.html#tidymodels",
    "href": "110-ensemble.html#tidymodels",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.9 Tidymodels",
    "text": "11.9 Tidymodels\n\n11.9.1 Datensatz Churn\nWir betrachten einen Datensatz zur Kundenabwanderung (Churn) aus dieser Quelle; Datendatei.\nAllerdings liegen die Daten jetzt auch auf diesem Repo, da sich mein Browser jÃ¼ngst Ã¼ber Datenschutzprobleme bei Quellwebseite beschwert hat.\n\nchurn_df &lt;- read_rds('data/churn_data.rds')\n\nWerfen wir einen Blick in die Daten, s. TabelleÂ 11.1, um einen ersten Eindruck zu bekommen.\n\n\n\n\n\n\n\nTabelleÂ 11.1:  Churn-Datensatz \n  \ncanceled_service\n      enrollment_discount\n      spouse_partner\n      dependents\n      phone_service\n      internet_service\n      online_security\n      online_backup\n      device_protection\n      tech_support\n      streaming_tv\n      streaming_movies\n      contract\n      paperless_bill\n      payment_method\n      months_with_company\n      monthly_charges\n      late_payments\n    \n\n\nyes\nno\nno\nno\nmultiple_lines\nfiber_optic\nyes\nyes\nyes\nno\nno\nno\none_year\nno\ncredit_card\n30\n51.01440\n3\n\n\nyes\nno\nyes\nyes\nmultiple_lines\nfiber_optic\nno\nyes\nyes\nyes\nyes\nno\ntwo_year\nyes\nelectronic_check\n39\n80.42466\n4\n\n\nyes\nyes\nno\nno\nsingle_line\nfiber_optic\nno\nno\nno\nno\nyes\nyes\nmonth_to_month\nyes\nmailed_check\n1\n75.88737\n3\n\n\nyes\nno\nyes\nyes\nsingle_line\nfiber_optic\nyes\nno\nno\nno\nyes\nno\ntwo_year\nno\ncredit_card\n29\n81.96467\n3\n\n\nyes\nyes\nno\nno\nsingle_line\ndigital\nno\nno\nno\nno\nyes\nyes\nmonth_to_month\nyes\nbank_draft\n9\n101.34257\n5\n\n\nyes\nno\nyes\nno\nsingle_line\nfiber_optic\nyes\nyes\nno\nyes\nyes\nyes\nmonth_to_month\nno\nmailed_check\n14\n72.01285\n4\n\n\n\n\n\n\n\n\n11.9.2 Data Splitting und CV\n\nchurn_split &lt;- initial_split(churn_df, prop = 0.75, \n                             strata = canceled_service)\n\nchurn_training &lt;- churn_split %&gt;% training()\n\nchurn_test &lt;- churn_split %&gt;% testing()\n\nchurn_folds &lt;- vfold_cv(churn_training, v = 5)\n\n\n11.9.3 Feature Engineering\nHier definieren wir zwei Rezepte. Gleichzeitig verÃ¤ndern wir die PrÃ¤diktoren (normalisieren, dummysieren, â€¦). Das nennt man auch Feature Engineering.\n\nchurn_recipe1 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% \n                       step_normalize(all_numeric(), -all_outcomes()) %&gt;% \n                       step_dummy(all_nominal(), -all_outcomes())\n\nchurn_recipe2 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% \n                       step_YeoJohnson(all_numeric(), -all_outcomes()) %&gt;% \n                       step_normalize(all_numeric(), -all_outcomes()) %&gt;% \n                       step_dummy(all_nominal(), -all_outcomes())\n\nstep_YeoJohnson() reduziert Schiefe in der Verteilung.\n\n11.9.4 Modelle\n\ntree_model &lt;- decision_tree(cost_complexity = tune(),\n                            tree_depth = tune(),\n                            min_n = tune()) %&gt;% \n              set_engine('rpart') %&gt;% \n              set_mode('classification')\n\nrf_model &lt;- rand_forest(mtry = tune(),\n                        trees = tune(),\n                        min_n = tune()) %&gt;% \n            set_engine('ranger') %&gt;% \n            set_mode('classification')\n\n\nboost_model &lt;- boost_tree(mtry = tune(),\n                        min_n = tune(),\n                        trees = tune()) %&gt;% \n  set_engine(\"xgboost\", nthreads = parallel::detectCores()) %&gt;% \n  set_mode(\"classification\")\n\n\nglm_model &lt;- logistic_reg()\n\n\n11.9.5 Modelle berechnen mit Tuning, einzeln\nWir kÃ¶nnten jetzt jedes Modell einzeln tunen, wenn wir wollen.\n\n11.9.5.1 Baum\n\ntree_wf &lt;-\n  workflow() %&gt;% \n  add_model(tree_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\ntree_fit &lt;-\n  tree_wf %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, yardstick::spec)\n    )\ntoc()\n## 9.933 sec elapsed\n\nIm Standard werden 10 Modellkandidaten getuned.\n\ntree_fit\n\n\n\n  \n\n\n\nSchauen wir uns das Objekt etwas nÃ¤her an:\n\ntree_fit$.metrics[[1]]\n\n\n\n  \n\n\n\n30 Zeilen: 3 GÃ¼temetriken (Sens, Spec, ROC AUC) mit je 10 Werten (Submodellen), gibt 30 Koeffizienten.\nFÃ¼r jeden der 5 Faltungen haben wir also 10 Submodelle.\nWelches Modell ist das beste?\n\nshow_best(tree_fit)\n\n\n\n  \n\n\n\nAha, das sind die fÃ¼nf besten Modelle, bzw. ihre Tuningparameter, ihre mittlere GÃ¼te zusammen mit dem Standardfehler.\n\nautoplot(tree_fit)\n\n\n\n\n\n11.9.5.2 RF\nWas fÃ¼r Tuningparameter hat den der Algorithmus bzw. seine Implementierung?\n\nshow_model_info(\"rand_forest\")\n## Information for `rand_forest`\n##  modes: unknown, classification, regression, censored regression \n## \n##  engines: \n##    classification: randomForest, rangerÂ¹, spark\n##    regression:     randomForest, rangerÂ¹, spark\n## \n## Â¹The model can use case weights.\n## \n##  arguments: \n##    ranger:       \n##       mtry  --&gt; mtry\n##       trees --&gt; num.trees\n##       min_n --&gt; min.node.size\n##    randomForest: \n##       mtry  --&gt; mtry\n##       trees --&gt; ntree\n##       min_n --&gt; nodesize\n##    spark:        \n##       mtry  --&gt; feature_subset_strategy\n##       trees --&gt; num_trees\n##       min_n --&gt; min_instances_per_node\n## \n##  fit modules:\n##          engine           mode\n##          ranger classification\n##          ranger     regression\n##    randomForest classification\n##    randomForest     regression\n##           spark classification\n##           spark     regression\n## \n##  prediction modules:\n##              mode       engine                    methods\n##    classification randomForest           class, prob, raw\n##    classification       ranger class, conf_int, prob, raw\n##    classification        spark                class, prob\n##        regression randomForest               numeric, raw\n##        regression       ranger     conf_int, numeric, raw\n##        regression        spark                    numeric\n\nDa die Berechnung einiges an Zeit braucht, kann man das (schon frÃ¼her einmal berechnete) Ergebnisobjekt von der Festplatte lesen (sofern es existiert). Ansonsten berechnet man neu:\n\nif (file.exists(\"objects/rf_fit1.rds\")){\n  rf_fit1 &lt;- read_rds(\"objects/rf_fit1.rds\")\n} else {\nrf_wf1 &lt;-\n  workflow() %&gt;% \n  add_model(rf_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\nrf_fit1 &lt;-\n  rf_wf1 %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, spec)\n    )\ntoc()\n}\n\nSo kann man das berechnete Objekt abspeichern auf Festplatte, um kÃ¼nftig Zeit zu sparen7:\n\nwrite_rds(rf_fit1, file = \"objects/rf_fit1.rds\")\n\n\nrf_fit1\n\n\n\n  \n\n\n\n\nshow_best(rf_fit1)\n\n\n\n  \n\n\n\n\n11.9.5.3 XGBoost\n\nboost_wf1 &lt;-\n  workflow() %&gt;% \n  add_model(boost_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\nboost_fit1 &lt;-\n  boost_wf1 %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, spec)\n    )\ntoc()\n\nWieder auf Festplatte speichern:\n\nwrite_rds(boost_fit1, file = \"objects/boost_fit1.rds\")\n\nUnd so weiter.\n\n11.9.6 Workflow-Sets\n\n11.9.6.1 Workflow-Set definieren\nEin Workflow-Set besteht aus\n\neinem oder mehreren Rezepten\neinem oder mehreren Modellen\n\ndie beliebig kombiniert sein kÃ¶nnen. Im Standard werden alle Rezepte mit allen Modellen kombiniert.\n\nBeispiel 11.1 In einem Workflow-Set sind 3 Rezepte und 4 Modelle definiert. Daher werden im Standard 12 Workflows gefittet.\\(\\square\\)\n\n\npreproc &lt;- list(rec1 = churn_recipe1, rec2 = churn_recipe2)\nmodels &lt;- list(tree1 = tree_model, \n               rf1 = rf_model, \n               boost1 = boost_model, \n               glm1 = glm_model)\n \nall_workflows &lt;- workflow_set(preproc, models)\n\nInfos zu workflow_set bekommt man wie gewohnt mit ?workflow_set.\nIm Standard werden alle Rezepte und Modelle miteinander kombiniert (cross = TRUE), also preproc * models Modelle gefittet.\n\n11.9.7 Workflow-Set tunen\n\nif (file.exists(\"objects/churn_model_set.rds\")) {\n  churn_model_set &lt;- read_rds(\"objects/churn_model_set.rds\")\n} else {\n  tic()\n  churn_model_set &lt;-\n    all_workflows %&gt;% \n    workflow_map(\n      resamples = churn_folds,\n      grid = 20,\n      metrics = metric_set(roc_auc),\n      seed = 42,  # reproducibility\n      verbose = TRUE)\n  toc()\n}\n\nDa die Berechnung schon etwas Zeit braucht, kann es vielleicht Sinn machen, das Modell (bzw. das Ergebnisobjekt) auf Festplatte zu speichern:\n\nwrite_rds(churn_model_set, file = \"objects/churn_model_set.rds\")\n\n\n\n\n\n\n\nVorsicht\n\n\n\nAchtung Dieser Schritt ist gefÃ¤hrlich: Wenn Sie Ihr Rezept und Fit-Objekt Ã¤ndern, kriegt das Ihre Festplatte nicht unbedingt mit. Sie kÃ¶nnten also unbemerkt mit dem alten Objekt von Ihrer Festplatte weiterarbeiten, ohne durch eine Fehlermeldung gewarnt zu werden. Ein viel besserer Ansatz wird durch das R-Paket targets bereitgestellt.\n\n\nEntsprechend kann man ein auf der Festplatte geparktes Modellobjekt wieder importieren:\n\nchurn_model_set &lt;- read_rds(file = \"objects/churn_model_set.rds\")\n\n\n11.9.8 Ergebnisse im Train-Sest\nHier ist die Rangfolge der Modelle unseres Workflow-Sets, geordnet nach mittlerem ROC-AUC:\n\nrank_results(churn_model_set, rank_metric = \"roc_auc\")\n\n\n\n  \n\n\n\nDie Rangfolge der ModellgÃ¼te (in den Validierungs-Samples) kann man sich mit autoplot komformtabel ausgeben lassen, s. AbbildungÂ 11.9.\n\nautoplot(churn_model_set, metric = \"roc_auc\")\n\n\n\nAbbildungÂ 11.9: Autoplot zur ModellgÃ¼te aller Workflows eines Workflow-Sets\n\n\n\n\n11.9.9 Bestes Modell\nUnd hier nur der beste Kandidat pro Algorithmus:\n\nautoplot(churn_model_set, metric = \"roc_auc\", select_best = \"TRUE\") +\n  geom_text(aes(y = mean - .01, label = wflow_id), angle = 90, hjust = 1) +\n  theme(legend.position = \"none\") +\n  lims(y = c(0.85, 1))\n\n\n\n\nBoosting hat - knapp - am besten abgeschnitten. Allerdings sind Random Forest und die schlichte, einfache logistische Regression auch fast genau so gut. Das wÃ¤re ein Grund fÃ¼r das einfachste Modell, das GLM, zu votieren. Zumal die Interpretierbarkeit am besten ist. Alternativ kÃ¶nnte man sich fÃ¼r das Boosting-Modell aussprechen.\nMan kann sich das beste Submodell auch von Tidymodels bestimmen lassen. Das scheint aber (noch) nicht fÃ¼r ein Workflow-Set zu funktionieren, sondern nur fÃ¼r das Ergebnisobjekt von tune_grid.\n\nselect_best(churn_model_set, metric = \"roc_auc\")\n## Error in `select_best()`:\n## ! No `select_best()` exists for this type of object.\n\nrf_fit1 haben wir mit tune_grid() berechnet; mit diesem Modell kann select_best() arbeiten:\n\nselect_best(rf_fit1)\n\n\n\n  \n\n\n\nAber wir kÃ¶nnen uns hÃ¤ndisch behelfen.\nSchauen wir uns mal die Metriken (VorhersagegÃ¼te) an:\n\nchurn_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n\n\n  \n\n\n\nrec1_boost1 scheint das beste Modell zu sein.\n\nbest_model_params &lt;-\nextract_workflow_set_result(churn_model_set, \"rec1_boost1\") %&gt;% \n  select_best()\n\nbest_model_params\n\n\n\n  \n\n\n\n\n11.9.10 Finalisisieren\nWir entscheiden uns mal fÃ¼r das Boosting-Modell, rec1_boost1. Diesen Workflow, in finalisierter Form, brauchen wir fÃ¼r den â€œfinal Fitâ€. Finalisierte Form heiÃŸt:\n\nSchritt 1: Nimm den passenden Workflow, hier rec1 und boost1; das hatte uns oben rank_results() verraten.\nSchritt 2: Update (Finalisiere) ihn mit den besten Tuningparameter-Werten\n\n\n# Schritt 1:\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_boost1\")\n\nbest_wf\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 2 Recipe Steps\n## \n## â€¢ step_normalize()\n## â€¢ step_dummy()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Boosted Tree Model Specification (classification)\n## \n## Main Arguments:\n##   mtry = tune()\n##   trees = tune()\n##   min_n = tune()\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\nJetzt finalisieren wir den Workflow, d.h. wir setzen die Parameterwerte des besten Submodells ein:\n\n# Schritt 2:\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 2 Recipe Steps\n## \n## â€¢ step_normalize()\n## â€¢ step_dummy()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Boosted Tree Model Specification (classification)\n## \n## Main Arguments:\n##   mtry = 6\n##   trees = 80\n##   min_n = 21\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\n\n11.9.11 Last Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  last_fit(churn_split)\n\nfit_final\n\n\n\n  \n\n\n\n\ncollect_metrics(fit_final)\n\n\n\n  \n\n\n\n\n11.9.12 Variablenrelevanz\nUm die Variablenrelevanz zu plotten, mÃ¼ssen wir aus dem Tidymodels-Ergebnisobjekt das eigentliche Ergebnisobjekt herausziehen, von der R-Funktion, die die eigentliche Berechnung durchfÃ¼hrt, das wÃ¤re glm() bei einer logistischen Regression oder xgboost::xgb.train() bei XGBoost:\n\nfit_final %&gt;% \n  extract_fit_parsnip()\n## parsnip model object\n## \n## ##### xgb.Booster\n## raw: 100.9 Kb \n## call:\n##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n##     colsample_bytree = 1, colsample_bynode = 0.285714285714286, \n##     min_child_weight = 21L, subsample = 1), data = x$data, nrounds = 80L, \n##     watchlist = x$watchlist, verbose = 0, nthreads = 8L, nthread = 1, \n##     objective = \"binary:logistic\")\n## params (as set within xgb.train):\n##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.285714285714286\", min_child_weight = \"21\", subsample = \"1\", nthreads = \"8\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\n## xgb.attributes:\n##   niter\n## callbacks:\n##   cb.evaluation.log()\n## # of features: 21 \n## niter: 80\n## nfeatures : 21 \n## evaluation_log:\n##     iter training_logloss\n##        1        0.5565164\n##        2        0.4757130\n## ---                      \n##       79        0.1926248\n##       80        0.1922523\n\nDieses Objekt Ã¼bergeben wir dann an vip:\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()\n\n\n\n\n\n11.9.13 ROC-Curve\nEine ROC-Kurve berechnet SensitivitÃ¤t und SpezifitÃ¤t aus den Vorhersagen, bzw. aus dem Vergleich von Vorhersagen und wahrem Wert (d.h. der beobachtete Wert).\nZiehen wir also zuerst die Vorhersagen heraus:\n\nfit_final %&gt;% \n  collect_predictions()\n\n\n\n  \n\n\n\nPraktischerweise werden die â€œwahren Werteâ€ (also die beobachtaten Werte), canceled_service, ausch angegeben.\nDann berechnen wir die roc_curve und autoplotten sie, s. AbbildungÂ 11.10.\n\nfit_final %&gt;% \n  collect_predictions() %&gt;% \n  roc_curve(canceled_service, .pred_yes) %&gt;% \n  autoplot()\n\n\n\nAbbildungÂ 11.10: Die ROC-Kurve fÃ¼r unser Model"
  },
  {
    "objectID": "110-ensemble.html#aufgaben",
    "href": "110-ensemble.html#aufgaben",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.10 Aufgaben",
    "text": "11.10 Aufgaben\nSchauen Sie sich mal die Kategorie trees auf Datenwerk an.\nAlternativ bietet die Kategorie tidymodels eine Sammlung von Aufgaben rund um das R-Paket Tidymodels; dort kÃ¶nnen Sie sich Aufgaben anpassen."
  },
  {
    "objectID": "110-ensemble.html#fallstudien",
    "href": "110-ensemble.html#fallstudien",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.11 Fallstudien",
    "text": "11.11 Fallstudien\n\n11.11.1 Fallstudien mit Workflow-Sets\n\nModeling human/computer interactions on Star Trek from #TidyTuesday with workflowsets\nPredict #TidyTuesday giant pumpkin weights with workflowsets\nTuning and comparing models\n\n11.11.2 Weitere Fallstudien mit Tidymodels-Bezug\n\nFallstudie VulkanausbrÃ¼che\nFallstudie Brettspiele mit XGBoost\nEinfache DurchfÃ¼hrung eines Modellierung mit XGBoost\nFallstudie Oregon Schools\nFallstudie Churn\nFallstudie Ikea\nFallstudie Wasserquellen in Sierra Leone\nFallstudie BÃ¤ume in San Francisco\nFallstudie VulkanausbrÃ¼che\nFallstudie Brettspiele mit XGBoost"
  },
  {
    "objectID": "110-ensemble.html#vertiefung",
    "href": "110-ensemble.html#vertiefung",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "\n11.12 Vertiefung",
    "text": "11.12 Vertiefung\nNutzen Sie StackOverflow als Forum fÃ¼r Ihre Fragen - Hier ein Beispiel zu einer Fehlermeldung, die mir Kopfzerbrechen bereitete\n\n\n\n\nChen, Tianqi, und Carlos Guestrin. 2016. â€XGBoost: A Scalable Tree Boosting Systemâ€œ. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785â€“94. KDD â€™16. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/2939672.2939785.\n\n\nFriedman, J. 2001. â€Greedy function approximation: A gradient boosting machine.â€œ https://doi.org/10.1214/AOS/1013203451.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, und Kjell Johnson. 2013. Applied predictive modeling. Bd. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "110-ensemble.html#footnotes",
    "href": "110-ensemble.html#footnotes",
    "title": "\n11Â  Ensemble Lerner\n",
    "section": "",
    "text": "Ãœbrigens gehÃ¶rt zu den weiteren Vorteilen von BÃ¤umen, dass sie die Temperatur absenken; zu Zeiten von Hitzewellen kÃ¶nnte das praktisch sein. Ansonsten erzeugen sie aber nur Luft und haben auch sonst kaum erkennbaren Nutzen. BÃ¤ume stellen zum Beispiel nie WLAN bereit.â†©ï¸\nbei Fat-Tails-Variablen muss man diese Aussage einschrÃ¤nkenâ†©ï¸\nWenn es einen No-Free-Lunch-Satz gibt, mÃ¼sste es auch einen Too-Good-to-be-True-Satz geben, den wir hiermit postulieren.â†©ï¸\nSchlimmes Denglischâ†©ï¸\nWer sich die Rechenressourcen leisten kann ğŸ’¸â†©ï¸\nLaut Silge und Kuhn (2022) in dieser FuÃŸnote ist es oft nicht nÃ¶tig, mtry zu tunen, da der Standardwert Ã¼ber gute Performanz verfÃ¼gt.â†©ï¸\nAber Vorsicht, dass man nicht vergisst, diese Objekte zu aktualisieren.â†©ï¸"
  },
  {
    "objectID": "120-regularisierte-modelle.html#lernsteuerung",
    "href": "120-regularisierte-modelle.html#lernsteuerung",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\n\nSie kÃ¶nnen Algorithmen fÃ¼r regularisierte lineare Modell erklÃ¤ren, d.h. Lasso- und Ridge-Regression\nSie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann\nSie kÃ¶nnen diese Verfahren in R berechnen\n\n12.1.2 Literatur\n\nRhys, Kap. 11\n\n12.1.3 Hinweise\nRhys und ISLR sind eine gute Quelle zum Einstieg in das Thema.\n\n12.1.4 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung"
  },
  {
    "objectID": "120-regularisierte-modelle.html#regularisierung",
    "href": "120-regularisierte-modelle.html#regularisierung",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.2 Regularisierung",
    "text": "12.2 Regularisierung\n\n12.2.1 Was ist Regularisierung?\nRegularisieren (oder regulieren) verweist auf â€œregulÃ¤râ€; laut Duden bedeutet das Wort so viel wie â€œden Regeln, Bestimmungen, Vorschriften entsprechend; vorschriftsmÃ¤ÃŸig, ordnungsgemÃ¤ÃŸ, richtigâ€ oder â€œÃ¼blichâ€.\nIm Englischen spricht man auch von â€œpenalized modelsâ€, â€œbestrafte Modellâ€ und von â€œshrinkageâ€, von â€œSchrumpfungâ€ im Zusammenhang mit dieer Art von Modellen.\nRegularisierung ist ein Meta-Algorithmus, also ein Verfahren, was als zweiter Schritt â€œaufâ€ verschiedene Modelle angewendet werden kann - zumeist aber auf lineare Modelle, worauf wir uns im Folgenden konzentrieren.\nDas Ziel von Regularisierung ist es, Overfitting zu vermeiden, in dem die KomplexitÃ¤t eines Modells reduziert wird. Der Effekt von Regularisierung ist, dass die Varianz der Modelle verringert wird und damit das Overfitting. Der Preis ist, dass der Bias erhÃ¶ht wird, aber oft (?) geht die Rechnung auf, dass der Gewinn grÃ¶ÃŸer ist als der Verlust, zumindest ist das die Hoffnung.\nIm Kontext von linearen Modellen bedeutet das, dass die Koeffizienten (\\(\\beta\\)s) im Betrag verringert werden durch Regularisierung, also in Richtung Null â€œgeschrumpftâ€ werden.\nDem liegt die Idee zugrunde, dass extreme Werte in den Koeffizienten vermutlich nicht â€œechtâ€, sondern durch Rauschen fÃ¤lschlich vorgegaukelt werden.\nDie bekanntesten Vertreter dieser Modellart sind Ridge Regression, \\(L2\\), das Lasso, \\(L1\\), sowie Elastic Net.\n\n12.2.2 Ã„hnliche Verfahren\nEin Ã¤hnliches Ziel wie der Regulaisierung liegt dem Pruning zugrunde, dem nachtrÃ¤glichen Beschneiden von EntscheidungsbÃ¤umen. In beiden FÃ¤llen wird die KomplexitÃ¤t des Modells verringert, und damit die Varianz auf Kosten eines mÃ¶glichen Anstiegs der Verzerrung (Bias) des Modells. Unterm Strich hofft man, dass der Gewinn die Kosten Ã¼bersteigt und somit der Fit im Test-Sample besser wird.\nEine Andere Art der Regularisierung wird durch die Verwendung von Bayes-Modellen erreicht: Setzt man einen konservativen Prior, etwa mit Mittelwert Null und kleiner Streuung, so werden die Posteriori-Koeffizienten gegen Null hin geschrumpft werden.\nMit Mehrebenen-Modellen (Multi Level Models) lÃ¤sst sich ein Ã¤hnlicher Effekt erreichen.\n\n12.2.3 Normale Regression (OLS)\nMan kann sich fragen, warum sollte man an der normalen Least-Square-Regression (OLS: Ordinary Least Square) weiter herumbasteln wollen, schlieÃŸlich garantiert das Gauss-Markov-Theorem, dass eine lineare Regression den besten linearen unverzerrten SchÃ¤tzwert (BLUE, best linear unbiased estimator) stellt, vorausgesetzt die Voraussetzungen der Regression sind erfÃ¼llt.\nJa, die SchÃ¤tzwerte (Vorhersagen) der Regression sind BLUE, schÃ¤tzen also den wahren Wert korrekt und maximal prÃ¤zise. Das gilt (natÃ¼rlich) nur, wenn die Voraussetzungen der Regression erfÃ¼llt sind, also vor allem, dass die Beziehung auch linear-additiv ist.\nZur Erinnerung, mit OLS minimiert man man den quadrierten Fehler, \\(RSS\\), Residual Sum of Square:\n\\[RSS = \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)\\]\nMan sucht also diejenigen Koeffizientenwerte \\(\\beta\\) (Argumente der Loss-Funktion RSS), die RSS minimieren:\n\\[\\beta = \\underset {\\beta}{\\operatorname {arg\\,min(RSS)}}\\]\nEs handelt sich hier um SchÃ¤tzwerte, die meist mit dem HÃ¼tchen \\(\\hat{\\beta}\\) ausgedrÃ¼ckt werden, hier aber zur einfacheren Notation weggelassen sind.\nAbb. AbbildungÂ 12.1 visualisiert die Optimierung mit OLS (Quelle). An gleicher Stelle findet sich eine gute Darstellung zu den (mathematischen) Grundlagen der OLS-Regression.\n\n\nAbbildungÂ 12.1: Visualisierung der Minimierung der RSS durch OLS\n\nÃœbrigens nennt man Funktionen, die man minimiert mit Hilfe von Methoden des maschinellen Lernens mit dem Ziel die optimalen Koeffizienten (wie \\(\\beta\\)s) zu finden, auch Loss Functions (Kostenfunktion).\nDas Problem der Regression ist, dass die schÃ¶ne Eigenschaft BLUE nur im Train-Sample, nicht (notwendig) im Test-Sample gilt."
  },
  {
    "objectID": "120-regularisierte-modelle.html#ridge-regression-l2",
    "href": "120-regularisierte-modelle.html#ridge-regression-l2",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.3 Ridge Regression, L2",
    "text": "12.3 Ridge Regression, L2\n\n12.3.1 Strafterm\nRidge Regression ist sehr Ã¤hnlich zum OLS-Algorithmus, nur das ein â€œStrafterm aufgebrummtâ€ wird, der \\(RSS\\) erhÃ¶ht.\nDer Gesamtterm, der optimiert wird, \\(L_{L2}\\) (Loss Level 2) ist also die Summe aus RSS und dem Strafterm:\n\\[L_{L2} = RSS + \\text{Strafterm}\\]\nDer Strafterm ist so aufgebaut, dass (im Absolutbetrag) grÃ¶ÃŸere Koeffizienten mehr zum Fehler beitragen, also eine Funktion der (quadrierten) Summe der Absolutwerte der Koeffizienten:\n\\[\\text{Strafterm} = \\lambda \\sum_{j=1}^p \\beta_j^2\\]\nMan nennt den L2-Strafterm auch L2-Norm1.\nDabei ist \\(\\lambda\\) (lambda) ein Tuningparameter, der bestimmt, wie stark die Bestrafung ausfÃ¤llt. Den Wert von \\(\\lambda\\) lassen wir durch Tuning bestimmen, wobei \\(\\lambda \\in \\mathbb{R}^+\\setminus\\{0\\}\\). Es gilt: Je grÃ¶ÃŸer lambda, desto stÃ¤rker die Schrumpfung der Koeffizienten gegen Null, da der gesamte zu minimierende Term, \\(L_{L2}\\) entsprechend durch lambda vergrÃ¶ÃŸert wird.\nDer Begriff â€œL2â€ beschreibt dass es sich um eine quadrierte Normierung handelt.\nDer Begriff â€œNormâ€ stammt aus der Vektoralgebra. Die L2-Norm eines Vektors \\(||v||\\) mit \\(k\\) Elementen ist so definiert (Quelle):\n\\[||v|| = \\left(|{v_1}|^2+ |{v_2}|^2+ |{v_i}|^2+ \\ldots + |{v_k}|^2 \\right)^{1/2} \\] wobei \\(|{v_i}|\\) den Absolutwert (Betrag) meint de Elements \\(v_i\\) meint. Im Falle von reellen Zahlen und Quadrierung braucht es hier die Absolutfunktion nicht.\nIm Falle von zwei Elementen vereinfacht sich obiger Ausdruck zu:\n\\[||v|| = \\sqrt{\\left({v_1}^2+ {v_2}^2\\right)} \\]\nDas ist nichts anderes als Pythagorasâ€™ Gesetz im euklidischen Raum.\nDer Effekt von \\(\\lambda \\sum_{j=1}^p \\beta_j^2\\) ist wie gesagt, dass die Koeffizienten in Richtung Null geschrumpft werden. Wenn \\(\\lambda = 0\\), resultiert OLS. Wenn \\(\\lambda \\rightarrow \\infty\\), werden alle Koeffizienten auf Null geschÃ¤tzt werden, Abb. AbbildungÂ 12.2 verdeutlicht dies (James u.Â a. 2021).\n\n\nAbbildungÂ 12.2: Links: Regressionskoeffizienten als Funktion von lambda. Rechts: L2-Norm der Ridge-Regression im VerhÃ¤ltnis zur OLS-Regression\n\n\n12.3.2 Standardisierung\nDie Straftermformel sagt uns, dass die Ridge-Regression abhÃ¤ngig von der Skalierung der PrÃ¤diktoren ist. Daher sollten die PrÃ¤diktoren vor der Ridge-Regression zunÃ¤chst auf \\(sd=1\\) standardisiert werden. Da wir \\(\\beta_0\\) nicht schrumpfen wollen, sondern nur die Koeffizienten der PrÃ¤diktoren bietet es sich an, die PrÃ¤diktoren dazu noch zu zentieren. Kurz: Die z-Transformation bietet sich als Vorverarbeitung zur Ridge-Regression an."
  },
  {
    "objectID": "120-regularisierte-modelle.html#lasso-l1",
    "href": "120-regularisierte-modelle.html#lasso-l1",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.4 Lasso, L1",
    "text": "12.4 Lasso, L1\n\n12.4.1 Strafterm\nDer Strafterm in der â€œLasso-Varianteâ€ der regularisierten Regression lautet so:\n\\[\\text{Strafterm} = \\lambda \\sum_{j=1}^p |\\beta_j|,\\]\nist also analog zur Ridge-Regression konzipiert.\nGenau wie bei der L2-Norm-Regularisierung ist ein â€œguterâ€ Wert von lambda entscheidend. Dieser Wert wird, wie bei der Ridge-Regression, durch Tuning bestimmt.\nDer Unterschied ist, dass die L1-Norm (Absolutwerte) und nicht die L2-Norm (Quadratwerte) verwendet werden.\nDie L1-Norm eines Vektors ist definiert durch \\(||\\beta||_1 = \\sum|\\beta_j|\\).\n\n12.4.2 Variablenselektion\nGenau wie die Ridge-Regression fÃ¼hrt ein hÃ¶here lambda-Wert zu einer Regularisierung (Schrumpfung) der Koeffizienten. Im Unterschied zur Ridge-Regression hat das Lasso die Eigenschaft, einzelne Parameter auf exakt Null zu schrumpfen und damit faktisch als PrÃ¤diktor auszuschlieÃŸen. Anders gesagt hat das Lasso die praktische Eigenschaft, Variablenselektion zu ermÃ¶glichen.\nAbb. AbbildungÂ 12.3 verdeutlicht den Effekt der Variablenselektion, vgl. James u.Â a. (2021), Kap. 6.2. Die Ellipsen um \\(\\hat{beta}\\) herum nent man Kontourlinien. Alle Punkte einer Kontourlinie haben den gleiche RSS-Wert, stehen also fÃ¼r eine gleichwertige OLS-LÃ¶sung.\n\n\nAbbildungÂ 12.3: lambda in der Lasso-Regression\n\nWarum erlaubt die L1-Norm Variablenselektion, die L2-Norm aber nicht? Abb. AbbildungÂ 12.4 verdeutlicht den Unterschied zwischen L1- und L2-Norm. Es ist eine Regression mit zwei PrÃ¤diktoren, also den zwei Koeffizienten \\(\\beta1, \\beta_2\\) dargestellt.\n\n\nAbbildungÂ 12.4: Verlauf des Strafterms bei der L1-Norm (links) und der L2-Norm (rechts); pink: Test-MSE, schwarz: Bias, grÃ¼n: Varianz\n\nBetrachten wir zunÃ¤chst das rechte Teilbild fÃ¼r die L2-Norm aus Abb. AbbildungÂ 12.4, das in Abb. AbbildungÂ 12.5 in den Fokus gerÃ¼ckt wird (Rhys 2020).\n\n\nAbbildungÂ 12.5: OLS-Fehlerkontur (blaues Oval) und Kontur des L2-Strafterms, Bildquelle: Rhys, 2020\n\nWenn lambda gleich Null ist, entspricht \\(L_{L2}\\) genau der OLS-LÃ¶sung. VergrÃ¶ÃŸert man lambda, so liegt \\(L_{L2}\\) dem Schnittpunkt des OLS-Kreises mit dem zugehÃ¶rigen lambda-Kreis. Wie man sieht, fÃ¼hrt eine ErhÃ¶hung von lambda zu einer Reduktion der Absolutwerte von \\(\\beta_1\\) und \\(\\beta_2\\). Allerdings werden, wie man im Diagramm sieht, auch bei hohen lambda-Werten die Regressionskoeffizienten nicht exakt Null sein.\nWarum lÃ¤sst die L2-Norm fÃ¼r bestimmte lambda-Werte den charakteristischen Kreis entstehen? Die Antwort ist, dass die LÃ¶sungen fÃ¼r \\(\\beta_1^2 + \\beta_2^2=1\\) (mit \\(\\lambda=1\\)) graphisch als Kreis dargestellt werden kÃ¶nnen.\nAnders ist die Situation bei der L1-Norm, dem Lasso, vgl. Abb. AbbildungÂ 12.6.\n\n\nAbbildungÂ 12.6: OLS-Fehlerkontur (blaues Oval) und Kontur des L1-Strafterms, Bildquelle: Rhys, 2020\n\nEine ErhÃ¶hung von $ fÃ¼hrt aufgrund der charakteristischen Kontourlinie zu einem Schnittpunkt (von OLS-LÃ¶sung und lambda-Wert), der - wenn lambda groÃŸ genug ist, stets auf einer der beiden Achsen liegt, also zu einer Nullsetzung des Parameters fÃ¼hrt.\nDamit kann man argumentieren, dass das Lasso implizit davon ausgeht, dass einige Koeffizienten in Wirklichkeit exakt Null sind, die L2-Norm aber nicht."
  },
  {
    "objectID": "120-regularisierte-modelle.html#l1-vs.-l2",
    "href": "120-regularisierte-modelle.html#l1-vs.-l2",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.5 L1 vs.Â L2",
    "text": "12.5 L1 vs.Â L2\n\n12.5.1 Wer ist stÃ¤rker?\nMan kann nicht sagen, dass die L1- oder die L2-Norm strikt besser sei. Es kommt auf den Datensatz an. Wenn man einen Datensatz hat, in dem es einige wenige starke PrÃ¤diktoren gibt und viele sehr schwache (oder exakt irrelevante) PrÃ¤diktoren gibt, dann wird L1 tendenziell zu besseren Ergebnissen fÃ¼hren (James u.Â a. 2021, 246). Das Lasso hat noch den Vorteil der Einfachheit, da weniger PrÃ¤diktoren im Modell verbleiben.\nRidge-Regression wird dann besser abschneiden (tendenziell), wenn die PrÃ¤diktoren etwa alle gleich stark sind.\n\n12.5.2 Elastic Net als Kompromiss\nDas Elastic Net (EN) ist ein Kompromiss zwischen L1- und L2-Norm. \\(\\lambda\\) wird auf einen Wert zwischen 1 und 2 eingestellt; auch hier wird der Wert fÃ¼r \\(\\lambda\\) wieder per Tuning gefunden.\n\\[L_{EN} = RSS + \\lambda\\left((1-\\alpha))\\cdot \\text{L2-Strafterm} + \\alpha \\cdot  \\text{L1-Strafterm}\\right)\\]\n\\(\\alpha\\) ist ein Tuningparameter, der einstellt, wie sehr wir uns Richtung L1- vs.Â L2-Norm bewegen. Damit wird sozusagen die â€œMischungâ€ eingestellt (von L1- vs.Â L2).\nSpezialfÃ¤lle:\n\nWenn \\(\\alpha=0\\) resultiert die Ridge-Regression (L1-Strafterm wird Null)\nWenn \\(\\alpha=1\\) resultiert die Lasso-Regression (L2-Strafterm wird Null)"
  },
  {
    "objectID": "120-regularisierte-modelle.html#aufgaben",
    "href": "120-regularisierte-modelle.html#aufgaben",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.6 Aufgaben",
    "text": "12.6 Aufgaben\nSchauen Sie sich die Aufgaben auf dem Datenwerk an, die das Tag stat-learning oder tidymodels haben. Auch wenn eine Aufgabe nicht explizit regulierte lineare Modelle verwendet, macht das eigentlich nichts, denn auÃŸer dem Tuningparameter Ã¤ndert sich nichts am typischen Tidymodels-Ablauf."
  },
  {
    "objectID": "120-regularisierte-modelle.html#fallstudien",
    "href": "120-regularisierte-modelle.html#fallstudien",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "\n12.7 Fallstudien",
    "text": "12.7 Fallstudien\n\nFallstudie Serie The Office\nFallstudie NBER Papers\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications."
  },
  {
    "objectID": "120-regularisierte-modelle.html#footnotes",
    "href": "120-regularisierte-modelle.html#footnotes",
    "title": "\n12Â  Regularisierte Modelle\n",
    "section": "",
    "text": "Streng genommen ist er eine Funktion der L2-Norm bzw. mit Lambda-Gewichtet und ohne die Wurzel, die zur Vektornorm gehÃ¶rtâ†©ï¸"
  },
  {
    "objectID": "125-feature-engineeering.html#lernsteuerung",
    "href": "125-feature-engineeering.html#lernsteuerung",
    "title": "\n13Â  Feature Engineering\n",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\n\nSie wissen, dass â€œFeature Engineeringâ€ letztlich das Gleiche ist wie â€œDatenaufbereitungâ€.\nSie kÃ¶nnen gÃ¤ngige Methoden des Feature Engineeering in GrÃ¼ndzÃ¼gen erlÃ¤utern.\nSie kÃ¶nnen gÃ¤ngige Methoden des Feature Engineeering in R fÃ¼r das Modellieren anwenden.\n\n13.1.2 Hinweise\nDieses Kapitel basiert auf (kuhn_feature_2020?).\n\n13.1.3 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen"
  },
  {
    "objectID": "125-feature-engineeering.html#transformation-nominaler-variablen",
    "href": "125-feature-engineeering.html#transformation-nominaler-variablen",
    "title": "\n13Â  Feature Engineering\n",
    "section": "\n13.2 Transformation nominaler Variablen",
    "text": "13.2 Transformation nominaler Variablen\nViele Lernalgorithmen verkraften keine nominalen Variablen. Beispiele sind lineare Modelle. Wichtige Ausnahmen sind aber EntscheidungsbÃ¤ume und Naive-Bayes-Modelle; diese Lernalgorithmen kÃ¶nnen mit mit nominalskalierten Werten umgehen.\nBei vielen Lernalgorithmen ist es (oft) nÃ¶tig, nominale Variablen zu dummysieren. In Tidymodels ist dies mit step_dummy mÃ¶glich.\nBevor man dummysiert, kann es sinnvoll sein, Faktorstufen, die nur im Test-Sample aber nicht im Train-Sample vorkomme, abzufangen. In Tidymodels gibt es dazu step_novel.\nLiegt eine groÃŸe Zahl an seltenen Faktorstufen vor, kann es Sinn machen mittels step_other diese Faktorstufen zusammenzufassen zu einer â€œOther-Kategorieâ€ (auch dieser Schritt ist vor dem Dummysieren durchzufÃ¼hren). Ã„hnliches gilt fÃ¼r den Fall von Variablen (fast) ohne Varianz.\nAlternativ kann man eine Methode verwenden, die man als Effekt- oder Likelihood-Enkodierung bezeichnet. Hier wird fÃ¼r jede Faktorstufe ihr Betagewicht als neuer PrÃ¤diktorwert kodiert."
  },
  {
    "objectID": "125-feature-engineeering.html#transformation-numerischer-variablen",
    "href": "125-feature-engineeering.html#transformation-numerischer-variablen",
    "title": "\n13Â  Feature Engineering\n",
    "section": "\n13.3 Transformation numerischer Variablen",
    "text": "13.3 Transformation numerischer Variablen\nEine hÃ¤ufige Malaise mit numerischen Variablen ist Schiefe. Schiefe Variablen lassen sich hÃ¤ufig schlecht vorhersagen oder zum Vorhersagen nutzen. Der Grund ist, dass bei schiefen Variablen (per Definition) nur wenig FÃ¤lle einen groÃŸen Wertebereichs des PrÃ¤diktors bevÃ¶lkern. Daher tut sich ein Modell schwer. Transformationen zu mehr Symmetrie (oder Normalverteilung) hin kÃ¶nnen daher nÃ¼tzlich sein. Ein klassisches Beispiel einer solchen Transformation ist die Log-Transformation. Allerdings kÃ¶nnen bei der Log-Transformation nur Werte grÃ¶ÃŸer Null verarbeitet werden. Eine Verallgemeinerung der Log-Transformation ist die Box-Cox-Transformation. Eine Alternative zur Box-Cox-Transformation ist die Yeo-Johson-Transformation, die den Vorteil hat, auch Werte die Null sind oder kleiner verarbeiten zu kÃ¶nnen.\nEin anderes Problem kÃ¶nnen hoch korrelierte (kollineare) Variablen darstellen. Abhilfe kann schaffen, eine von zwei hoch korrelierten Variablen zu entfernen. In Tidymodels hilft hier step_corr."
  },
  {
    "objectID": "125-feature-engineeering.html#umgang-mit-fehlenden-werten",
    "href": "125-feature-engineeering.html#umgang-mit-fehlenden-werten",
    "title": "\n13Â  Feature Engineering\n",
    "section": "\n13.4 Umgang mit fehlenden Werten",
    "text": "13.4 Umgang mit fehlenden Werten\nViele bekannte Lernalgorithmen verkraften keine fehlenden Werte, z.B. glmnet, neuronale Netze oder SVM. Manche kÃ¶nnen aber damit umgehen, etwa CART-Modelle (eine Implementierung von EntscheidungsbÃ¤umen, die in Tidymodels implementiert ist1).\nWie so oft gibt es hier kein einfaches Standardrezept. Insbesondere hÃ¤ngt das zu wÃ¤hlende Vorgehen davon ab, warum die Werte fehlen: Ist es rein zufÃ¤llig (MCAR) oder nicht (MAR, NMAR)?\nEin einfaches Vorgehen wÃ¤re, alle FÃ¤lle mit einem oder mehr fehlenden Werten zu lÃ¶schen. NatÃ¼rlich kann das schnell teuer mit Blick auf die GrÃ¶ÃŸe des Train-Samples werden. Auch das LÃ¶schen von PrÃ¤diktoren mit fehlenden Werten kann leicht unangenehm werden.\nAlternativ kann man fehlende Werte ersetzen (imputieren). MÃ¶chte man mit kNN imputieren, so kann man step_impute_knn imputieren, dabei ist aber Gowers Metrik zu bevorzugen.\n\n13.4.1 Ausreisser entfernen\nEs kann oft sinnvoll sein, Ausreisser zu entfernen, etwas wenn diese zuviel Einfluss haben auf die Parameter. Im Rahmen von Tidymodels gibt es ein spezialisiertes Paket tidy.outliers, das das Entfernen von Extremwerten im Rahmens eines Rezept unterstÃ¼tzt."
  },
  {
    "objectID": "125-feature-engineeering.html#feature-selection-prÃ¤diktorenwahl",
    "href": "125-feature-engineeering.html#feature-selection-prÃ¤diktorenwahl",
    "title": "\n13Â  Feature Engineering\n",
    "section": "\n13.5 Feature Selection (PrÃ¤diktorenwahl)",
    "text": "13.5 Feature Selection (PrÃ¤diktorenwahl)\nEinige Modelle haben intrinsische Feature-Selection-FÃ¤higkeiten, etwa LASSO. Ein sehr einfaches Ansatz zur Auswahl von PrÃ¤diktoren ist es, einfache Korrelationen der PrÃ¤diktoren (ggf. dummyisiert) mit der Zielvariablen zu berechnen.\nWichtig fÃ¼r eine gute Auswahl von PrÃ¤diktoren ist, dass der Auswahlprozess im Resampling-Prozess integriert ist, um Overfitting zu vermeiden.\nDas Paket recipesselector stellt dafÃ¼r eine Infrastruktur (innerhalb des Tidymodels-Rahmen) bereit.2"
  },
  {
    "objectID": "125-feature-engineeering.html#footnotes",
    "href": "125-feature-engineeering.html#footnotes",
    "title": "\n13Â  Feature Engineering\n",
    "section": "",
    "text": "https://parsnip.tidymodels.org/reference/details_decision_tree_rpart.htmlâ†©ï¸\nHier ist ein Video dazu: https://www.youtube.com/watch?v=1AKug0tgux8.â†©ï¸"
  },
  {
    "objectID": "130-kaggle.html#lernsteuerung",
    "href": "130-kaggle.html#lernsteuerung",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.1 Lernsteuerung",
    "text": "14.1 Lernsteuerung\n\n14.1.1 Lernziele\n\nSie wissen, wie man einen Datensatz (eine â€œSubmissionâ€) fÃ¼r einen Prognosewettbwerb bei Kaggle einreicht\nSie kennen einige Beispiele von Notebooks auf Kaggle (fÃ¼r die Sprache R)\nSie wissen, wie man ein Workflow-Set in Tidymodels berechnet\nSie wissen, dass Tidymodels im Rezept keine Transformationen im Test-Sample berÃ¼cksichtigt und wie man damit umgeht\n\n14.1.2 Hinweise\n\nMachen Sie sich mit Kaggle vertraut. Als Ãœbungs-Wettbewerb dient uns TMDB Box-office Revenue (s. Aufgaben)\n\n14.1.3 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen\nlibrary(lubridate)  # Datumsangaben\nlibrary(VIM)  # fehlende Werte\nlibrary(visdat)  # Datensatz visualisieren"
  },
  {
    "objectID": "130-kaggle.html#was-ist-kaggle",
    "href": "130-kaggle.html#was-ist-kaggle",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.2 Was ist Kaggle?",
    "text": "14.2 Was ist Kaggle?\n\nKaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n\nQuelle\nKaggle as AirBnB for Data Scientists?!"
  },
  {
    "objectID": "130-kaggle.html#fallstudie-tmdb",
    "href": "130-kaggle.html#fallstudie-tmdb",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.3 Fallstudie TMDB",
    "text": "14.3 Fallstudie TMDB\nWir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movieâ€™s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall fÃ¼r Filme.\n\n14.3.1 Aufgabe\nReichen Sie bei Kaggle eine Submission fÃ¼r die Fallstudie ein! Berichten Sie den Score!\n\n14.3.2 Hinweise\n\nSie mÃ¼ssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym mÃ¶glich); alternativ kÃ¶nnen Sie sich mit einem Google-Konto anmelden.\nHalten Sie das Modell so einfach wie mÃ¶glich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere SchnÃ¶rkel.\nLogarithmieren Sie budget und revenue.\nMinimieren Sie die Vorverarbeitung (steps) so weit als mÃ¶glich.\nVerwenden Sie tidymodels.\nDie ZielgrÃ¶ÃŸe ist revenue in Dollars; nicht in â€œLog-Dollarsâ€. Sie mÃ¼ssen also rÃ¼cktransformieren, wenn Sie revenue logarithmiert haben.\n\n14.3.3 Daten\nDie Daten kÃ¶nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nWir importieren die Daten von der Online-Quelle:\n\nd_train_raw &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nMal einen Blick werfen:\n\nglimpse(d_train_raw)\n## Rows: 3,000\n## Columns: 23\n## $ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1â€¦\n## $ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine Câ€¦\n## $ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00â€¦\n## $ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, 'â€¦\n## $ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"htâ€¦\n## $ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148â€¦\n## $ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", â€¦\n## $ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries â€¦\n## $ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the Inâ€¦\n## $ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807â€¦\n## $ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEhâ€¦\n## $ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'namâ€¦\n## $ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States ofâ€¦\n## $ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/â€¦\n## $ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119â€¦\n## $ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'â€¦\n## $ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", â€¦\n## $ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Violâ€¦\n## $ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries â€¦\n## $ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96â€¦\n## $ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'â€¦\n## $ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'depâ€¦\n## $ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,â€¦\nglimpse(d_test)\n## Rows: 4,398\n## Columns: 22\n## $ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, â€¦\n## $ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'PokÃ©mon Collection', 'pâ€¦\n## $ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06â€¦\n## $ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'nâ€¦\n## $ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-â€¦\n## $ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595â€¦\n## $ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", â€¦\n## $ original_title        &lt;chr&gt; \"ãƒ‡ã‚£ã‚¢ãƒ«ã‚¬VSãƒ‘ãƒ«ã‚­ã‚¢VSãƒ€ãƒ¼ã‚¯ãƒ©ã‚¤\", \"Attack of tâ€¦\n## $ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newcoâ€¦\n## $ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680â€¦\n## $ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1â€¦\n## $ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',â€¦\n## $ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3â€¦\n## $ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11â€¦\n## $ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,â€¦\n## $ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_â€¦\n## $ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", â€¦\n## $ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is Bâ€¦\n## $ title                 &lt;chr&gt; \"PokÃ©mon: The Rise of Darkrai\", \"Attack of the 5â€¦\n## $ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pokâˆšÂ©mon'}, {'id': 1155â€¦\n## $ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_iâ€¦\n## $ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'depâ€¦\n\n\n14.3.4 Train-Set verschlanken\nDa wir aus GrÃ¼nden der Einfachheit einige Spalten nicht berÃ¼cksichtigen, entfernen wir diese Spalten, was die GrÃ¶ÃŸe des Datensatzes massiv reduziert.\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(popularity, runtime, revenue, budget, release_date) \n\n\n14.3.5 Datensatz kennenlernen\n\nlibrary(visdat)\nvis_dat(d_train)\n\n\n\n\n\n14.3.6 Fehlende Werte prÃ¼fen\nWelche Spalten haben viele fehlende Werte?\n\nvis_miss(d_train)\n\n\n\n\nMit VIM kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\n\naggr(d_train)"
  },
  {
    "objectID": "130-kaggle.html#rezept",
    "href": "130-kaggle.html#rezept",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.4 Rezept",
    "text": "14.4 Rezept\n\n14.4.1 Rezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  #update_role(all_predictors(), new_role = \"id\") %&gt;% \n  #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% \n  #update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_mutate(release_date = mdy(release_date)) %&gt;% \n  step_date(release_date, features = c(\"year\", \"month\"), \nkeep_original_cols = FALSE) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal())\n\nrec1\n\n\ntidy(rec1)\n\n\n\n  \n\n\n\n\n14.4.2 Check das Rezept\n\nprep(rec1, verbose = TRUE)\n## oper 1 step mutate [training] \n## oper 2 step log [training] \n## oper 3 step mutate [training] \n## oper 4 step date [training] \n## oper 5 step impute knn [training] \n## oper 6 step dummy [training] \n## The retained training set is ~ 0.37 Mb  in memory.\n\n\nprep(rec1) %&gt;% \n  bake(new_data = NULL) \n\n\n\n  \n\n\n\nWir definieren eine Helper-Funktion:\n\nsum_isna &lt;- function(x) {sum(is.na(x))}\n\nUnd wenden diese auf jede Spalte an:\n\nprep(rec1) %&gt;% \n  bake(new_data = NULL) %&gt;%  \n  map_df(sum_isna)\n\n\n\n  \n\n\n\nKeine fehlenden Werte mehr in den PrÃ¤diktoren.\nNach fehlenden Werten kÃ¶nnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train)\n\n\n\n  \n\n\n\nSo bekommt man gleich noch ein paar Infos Ã¼ber die Verteilung der Variablen. Praktische Sache.\n\n14.4.3 Check Test-Sample\nDas Test-Sample backen wir auch mal.\nWichtig: Wir preppen den Datensatz mit dem Train-Sample.\n\nbake(prep(rec1), new_data = d_test) %&gt;% \n  head()"
  },
  {
    "objectID": "130-kaggle.html#kreuzvalidierung",
    "href": "130-kaggle.html#kreuzvalidierung",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.5 Kreuzvalidierung",
    "text": "14.5 Kreuzvalidierung\n\ncv_scheme &lt;- vfold_cv(d_train,\n  v = 5, \n  repeats = 3)"
  },
  {
    "objectID": "130-kaggle.html#modelle",
    "href": "130-kaggle.html#modelle",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.6 Modelle",
    "text": "14.6 Modelle\n\n14.6.1 Baum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\ntree_depth = tune(),\nmode = \"regression\")\n\n\n14.6.2 Random Forest\n\ndoParallel::registerDoParallel()\n\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"regression\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n\n14.6.3 XGBoost\n\nmod_boost &lt;- boost_tree(mtry = tune(),\nmin_n = tune(),\ntrees = tune()) %&gt;% \n  set_engine(\"xgboost\", nthreads = parallel::detectCores()) %&gt;% \n  set_mode(\"regression\")\n\n\n14.6.4 LM\n\nmod_lm &lt;-\n  linear_reg()"
  },
  {
    "objectID": "130-kaggle.html#workflows",
    "href": "130-kaggle.html#workflows",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.7 Workflows",
    "text": "14.7 Workflows\n\npreproc &lt;- list(rec1 = rec1)\nmodels &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm)\n \n \nall_workflows &lt;- workflow_set(preproc, models)"
  },
  {
    "objectID": "130-kaggle.html#fitten-und-tunen",
    "href": "130-kaggle.html#fitten-und-tunen",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.8 Fitten und tunen",
    "text": "14.8 Fitten und tunen\n\nif (file.exists(\"objects/tmdb_model_set.rds\")) {\n  tmdb_model_set &lt;- read_rds(\"objects/tmdb_model_set.rds\")\n} else {\n  tic()\n  tmdb_model_set &lt;-\nall_workflows %&gt;% \nworkflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n#  metrics = metric_set(rmse),\n  seed = 42,  # reproducibility\n  verbose = TRUE)\n  toc()\n}\n\nMan kÃ¶nnte sich das Ergebnisobjekt abspeichern, um kÃ¼nftig Rechenzeit zu sparen:\n\nwrite_rds(tmdb_model_set, \"objects/tmdb_model_set.rds\")\n\nAber Achtung: Wenn Sie vergessen, das Objekt auf der Festplatte zu aktualisieren, haben Sie eine zusÃ¤tzliche Fehlerquelle. Gefahr im Verzug. Professioneller ist der Ansatz mit dem R-Paket target."
  },
  {
    "objectID": "130-kaggle.html#finalisieren",
    "href": "130-kaggle.html#finalisieren",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.9 Finalisieren",
    "text": "14.9 Finalisieren\n\n14.9.1 Welcher Algorithmus schneidet am besten ab?\nGenauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz.\n\ntune::autoplot(tmdb_model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nR-Quadrat ist nicht entscheidend; rmse ist wichtiger.\nDie Ergebnislage ist nicht ganz klar, aber einiges spricht fÃ¼r das Boosting-Modell, rec1_boost1.\n\ntmdb_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean) %&gt;% \n  head(10)\n\n\n\n  \n\n\n\n\nbest_model_params &lt;-\nextract_workflow_set_result(tmdb_model_set, \"rec1_boost1\") %&gt;% \n  select_best()\n\nbest_model_params\n\n\n\n  \n\n\n\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_boost1\")\n\n#best_wf\n\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 6 Recipe Steps\n## \n## â€¢ step_mutate()\n## â€¢ step_log()\n## â€¢ step_mutate()\n## â€¢ step_date()\n## â€¢ step_impute_knn()\n## â€¢ step_dummy()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## Boosted Tree Model Specification (regression)\n## \n## Main Arguments:\n##   mtry = 6\n##   trees = 100\n##   min_n = 4\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\n\n14.9.2 Final Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  fit(d_train)\n## [21:41:04] WARNING: src/learner.cc:767: \n## Parameters: { \"nthreads\" } are not used.\n\nfit_final\n## â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 6 Recipe Steps\n## \n## â€¢ step_mutate()\n## â€¢ step_log()\n## â€¢ step_mutate()\n## â€¢ step_date()\n## â€¢ step_impute_knn()\n## â€¢ step_dummy()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## ##### xgb.Booster\n## raw: 257.9 Kb \n## call:\n##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n##     colsample_bytree = 1, colsample_bynode = 0.4, min_child_weight = 4L, \n##     subsample = 1), data = x$data, nrounds = 100L, watchlist = x$watchlist, \n##     verbose = 0, nthreads = 8L, nthread = 1, objective = \"reg:squarederror\")\n## params (as set within xgb.train):\n##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.4\", min_child_weight = \"4\", subsample = \"1\", nthreads = \"8\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\n## xgb.attributes:\n##   niter\n## callbacks:\n##   cb.evaluation.log()\n## # of features: 15 \n## niter: 100\n## nfeatures : 15 \n## evaluation_log:\n##     iter training_rmse\n##        1     122355586\n##        2     100873316\n## ---                   \n##       99      28074964\n##      100      27979563\n\n\nd_test$revenue &lt;- NA\n\nfinal_preds &lt;- \n  fit_final %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)"
  },
  {
    "objectID": "130-kaggle.html#submission",
    "href": "130-kaggle.html#submission",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.10 Submission",
    "text": "14.10 Submission\n\n14.10.1 Submission vorbereiten\n\nsubmission_df &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"objects/submission.csv\")\n\nDiese CSV-Datei reichen wir dann bei Kagglei ein.\n\n14.10.2 Kaggle Score\nDiese Submission erzielte einen Score von 4.79227 (RMSLE)."
  },
  {
    "objectID": "130-kaggle.html#miniprojekt",
    "href": "130-kaggle.html#miniprojekt",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.11 Miniprojekt",
    "text": "14.11 Miniprojekt\nReichen Sie Ihre Vorhersagen fÃ¼r die TMDB-Competition bei Kaggle ein!\nStellen Sie auch (im Rahmen dieses Wettbewerbs) Ihre Syntax offen.\nBereiten Sie sich vor, Ihre Analyse zu prÃ¤sentieren."
  },
  {
    "objectID": "130-kaggle.html#aufgaben",
    "href": "130-kaggle.html#aufgaben",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.12 Aufgaben",
    "text": "14.12 Aufgaben\nSchauen Sie sich mal die Kategorie tmdb auf Datenwerk an.\nAlternativ bietet die Kategorie tidymodels eine Sammlung von Aufgaben rund um das R-Paket Tidymodels; dort kÃ¶nnen Sie sich Aufgaben anpassen."
  },
  {
    "objectID": "130-kaggle.html#kaggle-fallstudien",
    "href": "130-kaggle.html#kaggle-fallstudien",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.13 Kaggle-Fallstudien",
    "text": "14.13 Kaggle-Fallstudien\n\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfache lineare Regression in Base-R, AnfÃ¤ngerniveau, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB"
  },
  {
    "objectID": "130-kaggle.html#vertiefung",
    "href": "130-kaggle.html#vertiefung",
    "title": "\n14Â  Kaggle\n",
    "section": "\n14.14 Vertiefung",
    "text": "14.14 Vertiefung\n\nKaggle-Blog"
  },
  {
    "objectID": "140-faden.html#lernsteuerung",
    "href": "140-faden.html#lernsteuerung",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.1 Lernsteuerung",
    "text": "15.1 Lernsteuerung\n\n15.1.1 Ãœberblick\nMittlerweile haben wir einiges zum Thema Data Science bzw. maschinelles Lernen behandelt (und sie hoffentlich viel gelernt).\nDa ist es an der Zeit, einen Schritt zurÃ¼ck zu treten, um sich einen Ãœberblick Ã¼ber den gegangenen Weg zu verschaffen, den berÃ¼hmten â€œroten Fadenâ€ zu sehen, den zurÃ¼ckgelegten Weg nachzuzeichnen in den groben Linien, um einen (klareren) Ãœberblick Ã¼ber das Terrain zu bekommen.\nIn diesem Kapitel werden wir verschiedene â€œAussichtspfadeâ€ suchen, um im Bild zu bleiben, die uns einen Ãœberblick Ã¼ber das GelÃ¤nde versprechen.\n\n15.1.2 Lernziele\n\nSie erarbeiten sich einen Ãœberblick Ã¼ber den bisher gelernten Stoff bzw. verfeinern Ihren bestehenden Ãœberblick\n\n15.1.3 Literatur\n\nRhys im Ãœberblick\n\n15.1.4 R-Pakete und Daten\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-1-blick-vom-hohen-berg",
    "href": "140-faden.html#aussichtspunkt-1-blick-vom-hohen-berg",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.2 Aussichtspunkt 1: Blick vom hohen Berg",
    "text": "15.2 Aussichtspunkt 1: Blick vom hohen Berg\nUnd so zeigt sich ein â€œFlussbildâ€1 (AbbildungÂ 15.1).\n\n\n\n\nflowchart LR\n  Vv[Vorverarbeitung] --&gt; W[Workflow]\n  MF[Modellformel] --&gt; W[Workflow]\n  Mo[Modell] --&gt; W[Workflow]\n  Al[Algorithmus] --&gt; Mo\n  Im[Implementierung] --&gt; Mo\n  Mod[Modus] --&gt; Mo\n  St[z.B. Standardisierung] --&gt; Vv\n  FW[z.B. Fehlende Werte] --&gt; Vv\n  W -- fÃ¼r jeden Workflow --&gt; Tuning\n  subgraph Tuning\nsubgraph Resampling\n  subgraph Fitten\n  end\nend\n  end\n  Tuning --&gt; bM[bester Modellkandidat]\n  bM --&gt; FT[Fitten auf ganz Train-Sample]\n  FT --&gt; PT[Predict auf Test-Sample]\n  PT --&gt;  MG[ModellgÃ¼te]\n  MG --&gt; num[numerisch]\n  MG --&gt; klas[klassifikatorisch]\n\n\n\nAbbildungÂ 15.1: Ein Flussbild des maschinellen Lernens\n\n\n\nDer ReisefÃ¼hrer erzÃ¤hlt uns zu diesem Bild folgende Geschichte:\n\n\nVideo-Geschichte"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-2-blick-in-den-hof-der-handwerker",
    "href": "140-faden.html#aussichtspunkt-2-blick-in-den-hof-der-handwerker",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.3 Aussichtspunkt 2: Blick in den Hof der Handwerker",
    "text": "15.3 Aussichtspunkt 2: Blick in den Hof der Handwerker\nWenn man auf einem hohen Berg gestanden ist, hat man zwar einen guten Ãœberblick Ã¼ber das Land bekommen, aber das konkrete Tun bleibt auf solchen HÃ¶hen verborgen.\nMÃ¶chte man wissen, wie das geschÃ¤ftige Leben ablÃ¤uft, muss man also den tÃ¤tigen Menschen Ã¼ber die Schulter schauen. Werfen wir also einen Blick in den â€œHof der Handwerkerâ€, wo grundlegende WerkstÃ¼cke gefertigt werden, und wir jeden Handgriff aus der NÃ¤he mitverfolgen kÃ¶nnen.\n\n15.3.1 Ein maximale einfaches WerkstÃ¼ck mit Tidymodels\nWeniger blumig ausgedrÃ¼ckt: Schauen wir uns ein maximal einfaches Beispiel an, wie man mit Tidymodels Vorhersagen tÃ¤tigt. Genauer gesagt bearbeiten wir einen sehr einfachen Ansatz fÃ¼r einen Kaggle-Prognosewettbewerb.\n\n\n\n15.3.2 Ein immer noch recht einfaches WerkstÃ¼ck mit Tidymodels\nDieses Beispiel ist nur wenig aufwÃ¤ndiger als das vorherige."
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-3-der-nebelberg-quiz",
    "href": "140-faden.html#aussichtspunkt-3-der-nebelberg-quiz",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.4 Aussichtspunkt 3: Der Nebelberg (Quiz)",
    "text": "15.4 Aussichtspunkt 3: Der Nebelberg (Quiz)\nDa der â€œNebelbergâ€ zumeist in Wolken verhÃ¼llt ist, muss man, wenn man ihn ersteigt und ins Land hinunterschaut, erraten, welche Teile zu sehen sind. Sozusagen eine Art Landschafts-Quiz.\nVoilÃ , hier ist es, das Quiz zum maschinellen Lernen:\n\nLoadingâ€¦"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-4-der-exerzitien-park",
    "href": "140-faden.html#aussichtspunkt-4-der-exerzitien-park",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.5 Aussichtspunkt 4: Der Exerzitien-Park",
    "text": "15.5 Aussichtspunkt 4: Der Exerzitien-Park\nWir stehen vor dem Eingang zu einem Park, in dem sich viele Menschen an merkwÃ¼rdigen Ãœbungen, Exerzitien, befleiÃŸigen. Vielleicht wollen Sie sich auch an einigen Ãœbungen abhÃ¤rten? Bitte schÃ¶n, lassen Sie sich nicht von mir aufhalten.\n\nYACSDA: Yet Another Case Study on Data Analysis\nâ€¦\nNUR EXPLORATIVE DATENANALYSE\n\nDatenjudo mit Pinguinen\nData-Wranglinng-Aufgaben zur Lebenserwartung\nAufgabe zur Datenvisualisierung des Diamantenpreises\nFallstudie FlugverspÃ¤tungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten FlugverspÃ¤tungen, Datensatz â€˜nycflights13â€™\n\nNUR LINEARE MODELL\n\nBeispiel fÃ¼r Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel fÃ¼r Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel fÃ¼r Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von FlugverspÃ¤tungen\nMovies\nFallstudie Einfache lineare Regression in Base-R, AnfÃ¤ngerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\n\nYouTube-PLAYLISTS\n\nPlaylist YACSDAs\nPlaylist zur PrÃ¼fungsleistung Prognosewettbewerb\nKaggle-Fallstudie TMDB: einfache lineare Regression\nPlaylist zum statistischen Modellieren\n\nMASCHINELLES LERNEN MIT TIDYMODELS\n\nExperimenting with machine learning in R with tidymodels and the Kaggle titanic dataset\nTutorial on tidymodels for Machine Learning\nClassification with Tidymodels, Workflows and Recipes\nA (mostly!) tidyverse tour of the Titanic\nPersonalised Medicine - EDA with tidy R\nTidy TitaRnic\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\nAnalyse zum Verlauf von Covid-FÃ¤llen\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu VulkanausbrÃ¼chen\nFallstudie Himalaya\nFallstudien zu StudiengebÃ¼hren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\nEinfache DurchfÃ¼hrung eines Modellierung mit XGBoost\nFallstudie Oregon Schools\nFallstudie Churn\nFallstudie Ikea\nFallstudie Wasserquellen in Sierra Leone\nFallstudie BÃ¤ume in San Francisco\nFallstudie VulkanausbrÃ¼che\nFallstudie Brettspiele mit XGBoost\nFallstudie Serie The Office\nFallstudie NBER Papers\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Titanic mit Tidymodels bei Kaggle\nEinfache Fallstudie mit Tidymodels bei Kaggle"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-5-in-der-bibliothek",
    "href": "140-faden.html#aussichtspunkt-5-in-der-bibliothek",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.6 Aussichtspunkt 5: In der Bibliothek",
    "text": "15.6 Aussichtspunkt 5: In der Bibliothek\nEinen Ãœberblick Ã¼ber eine Landschaft gewinnt man nicht nur von ausgesetzten Wegpunkten aus, sondern auch, manchmal, aus SchriftstÃ¼cken. Hier ist eine Auswahl an Literatur, die Grundlagen zu unserem Landstrich erlÃ¤utert.\n\nRhys (2020)\nSilge und Kuhn (2022)\n\nEtwas weiter leiten uns diese ErzÃ¤hler:\n\nJames u.Â a. (2021)\nKuhn und Johnson (2013)"
  },
  {
    "objectID": "140-faden.html#krafttraining",
    "href": "140-faden.html#krafttraining",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.7 Krafttraining",
    "text": "15.7 Krafttraining\nUm die Aussicht genieÃŸen zu kÃ¶nnen, muss man manchmal ausgesetzte PlÃ¤tze in schwindelerregenden einigermaÃŸen steilen als HÃ¼gel erkennbaren HÃ¶hen erreichenâ€¦\nSportliche Leistungen erreicht nur, wer trainiert ist. Das ist im Land des Data Science nicht anders.\nHier ist eine Liste von Ãœbungen, die Ihre Datenkraft stÃ¤hlen soll:\n\n\nLerngruppe: Den Wert einer Lerngruppe kann man kaum unterschÃ¤tzen. Die Motivation, der Austausch, der Zwang seine Gedanken geordnet darzustellen, das wechselseitige Abfragen - diese Dinge machen eine Lerngruppe zu einem der wichtigsten Erfolgsgarant in Ihren LernbemÃ¼hungen.\n\nExzerpte: Exzerpte, Zusammenfassungen also, sind nÃ¶tig, um von einer vermeintlichen â€œJaja, easy, versthe ich allesâ€ OberflÃ¤chen-Verarbeitung zu einem (ausgeprÃ¤gterem) TiefenverstÃ¤ndnis vorzudringen.\n\nAufgaben: Manchmal stellt ein Dozent Aufgaben ein. Die Chance sollte man nutzen, denn zwar ist vieles in der Didaktikforschung noch unsicher, aber dass Aufgaben lÃ¶sen beim Lernen hilft, und zwar viel, ist eines der wenigen unstrittigen Erkenntnisse.\n\nFallstudien: Ã„hnliches wie Aufgaben, die oft kleinteilig-akademisch angelegt sind, hilft die groÃŸe Schwester der schnÃ¶den Aufgabe, die Fallstudie, beim Vordringen in VerstÃ¤ndnistiefen.\n\nLesen: Ja, Lesen ist voll Old School. Aber so was Ã„hnliches wie Updaten der Brain-Software. NÃ¼tzlich, weil die alte Software irgendwann nicht mehr supported wird.\n\nForum: Sie haben eine Frage, aber Sie kÃ¶nnen unmÃ¶glich ein paar Tage warten, bis Sie den Dozenten im Unterricht sprechen? Posten Sie die Frage in einem Forum! Vielleicht im Forum des Moduls oder aber in einem geeigneten Forum im Internet.\n\nYoutube: Zwar wettern Dozentis gerne Ã¼ber die mangelnde Verarbeitungstiefe beim Fern schauen. AuÃŸerdem sind Lehrvideos didaktisch echt asbachuralt. Aber okay, manchmal und in Ã¼berschaubarer Dosis ist ein Lehrvideo eine nÃ¼tzliche ErgÃ¤nzung zu den Ã¼brigen MaÃŸnahmen."
  },
  {
    "objectID": "140-faden.html#ressourcen",
    "href": "140-faden.html#ressourcen",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.8 Ressourcen",
    "text": "15.8 Ressourcen\n\n15.8.1 Aufgaben\nIm Datenwerk unter dem Tag stat-learning und tidymodels finden Sie einen Fundus an Aufgaben zur prÃ¤diktiven Modellierung.\n\n15.8.2 Kaggle-Fallstudien\nIn KapitelÂ 16.4 finden Sie eine Fallstudien-Sammlung.\n\nEinfache Random-Forest-Modellierung bei Kaggle (TMDB)\nEinfache Workflow-Set-Modellierung bei Kaggle (TMDB)\nBearbeiten Sie so viele Fallstudien der Fallstudiensammlung wie nÃ¶tig, um den Stoff flÃ¼ssig zu beherrschen\n\n15.8.3 Rollenspiel: Ace your Case\nDie Lernziele dieses Moduls sind kompetenzorientiert; Theorie spielt nur die zweite Geige. Aber im praktischem Leben genÃ¼gt es (oft) nicht, bestimmte Kompetenzen zu besitzen. Man muss auch Menschen Ã¼berzeugen, dass man diese Kompetenzen besitzt. Daher sollten Sie sich darin Ã¼ben, andere von Ihrer Kompetenz zu Ã¼berzeugen.\nDazu simulieren wir im Rahmen eines Rollenspiels eine Bewerbungsinterview, in dem Sie Fachfragen oder eine Fallstudie (â€œCaseâ€) durchsprechen und hier brillieren wollen (â€œAce your Caseâ€).\n\nStudenti A ğŸ§‘â€ğŸ“ - Bewerber\nStudenti B ğŸ‘©â€ğŸ“ - Interviewer\n\n15.8.4 LinkedIn Skill Assessments\nDie LinkedIn Skill Assessments sind eine Sammlung von Quizzen, die LinkedIn bereitstellt. Man kann diese Quizze antreten, und wenn man besteht, fÃ¼gt LinkedIn ein entsprechendes Badge zum persÃ¶nlichen Profil hinzu.\nFÃ¼r Data Science sind z.B. die Quizze fÃ¼r Machine Learning und Programmiersprachen wie R interessant.\nPraktischerweise kann man sich anhand relevanter Fragen (und deren LÃ¶sungen) Ã¼ben; hier finden sich Fragen und Antworten zum Data Science Quiz. FÃ¼r R findet sich in diesem R eine Auswahl von Quizfragen sowie deren LÃ¶sungen.\n\n15.8.5 Blaupausen (Template) via usemodel\n\nEine MÃ¶glichkeit, sich die Syntax fÃ¼r eine typische Tidymodels-Analyse ausgeben zu lassen, bietet das Paket usemodels.\nLassen wir uns einen Code-Schnipsel ausgeben fÃ¼r ein Random-Forest-Modell mit dem Engine ranger:\n\nlibrary(usemodels)\nuse_ranger(am ~ ., data = mtcars)\n## ranger_recipe &lt;- \n##   recipe(formula = am ~ ., data = mtcars) \n## \n## ranger_spec &lt;- \n##   rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %&gt;% \n##   set_mode(\"classification\") %&gt;% \n##   set_engine(\"ranger\") \n## \n## ranger_workflow &lt;- \n##   workflow() %&gt;% \n##   add_recipe(ranger_recipe) %&gt;% \n##   add_model(ranger_spec) \n## \n## set.seed(4113)\n## ranger_tune &lt;-\n##   tune_grid(ranger_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\n\n\n15.8.6 Blaupause: Code-Schnipsel fÃ¼r tidymodels\n\n\n# Setup:\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(tictoc)  # Zeitmessung\nlibrary(&lt;other_package_you_might_need_for_modelling&gt;)  # tidymodels uses existing packages for modelling so you need to make them available\n\n\n# Data:\nd_path &lt;- \"Enter data path here\"\nd &lt;- read_csv(d_path)\n\nset.seed(42)\nd_split &lt;- initial_split(d)\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\n\n# model:\nmod1 &lt;-\n  &lt;enter_parsnip_model_name_here&gt;(mode = \"&lt;choose_regression_or_classification&gt;\",\n           cost_complexity = tune())\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(d_train)\n\n\n# recipe:\nrec1 &lt;- recipe(&lt;enter_output_variable&gt; ~  ., data = d_train)\n\n\n# workflow:\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n# tuning:\ntic()\nwf1_fit &lt;-\n  wf1 %&gt;% \n  tune_grid(\n    resamples = rsmpl)\ntoc()\n\n# best candidate:\nshow_best(wf1_fit)\n\n\n# finalize wf:\nwf1_final &lt;-\n  wf1 %&gt;% \n  finalize_workflow(select_best(wf1_fit))\n\n\nwf1_fit_final &lt;-\n  wf1_final %&gt;% \n  last_fit(d_split)\n\n\n# ModellgÃ¼te im Test-Set:\ncollect_metrics(wf1_fit_final)\n\nTipp: Copy-Paste me ğŸ˜„\nAuch hier auf dem Datenwerk finden Sie Ã¤hnliche Vorlagen."
  },
  {
    "objectID": "140-faden.html#vertiefung",
    "href": "140-faden.html#vertiefung",
    "title": "\n15Â  Der rote Faden\n",
    "section": "\n15.9 Vertiefung",
    "text": "15.9 Vertiefung\n\nMathematische Grundlagen kÃ¶nnen Sie z.B. hier vertiefen\nGute Fallstudie bei Kaggle fÃ¼r Regressionsprobleme: House Prices\nSie mÃ¶chten schnell ein Code-Schnipsel (Ã¶ffentlich sichtbar) teilen? Probieren Sie Github Gists aus\nIf in doubt, scream and shout â€¦ and ask ChatGPT: ChatGPT kann Ihnen Code-Schnipsel erstellen, wenn Sie ihn nach einer bestimmten Aufgabenstellung fragen.\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, und Kjell Johnson. 2013. Applied predictive modeling. Bd. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "140-faden.html#footnotes",
    "href": "140-faden.html#footnotes",
    "title": "\n15Â  Der rote Faden\n",
    "section": "",
    "text": "Wem das Bild zu klein gezeichnet ist, der nehme entweder eine Lupe oder Ã¶ffne das Bild per Rechtsklick in einem neuen Tab.â†©ï¸"
  },
  {
    "objectID": "150-fallstudien.html#lernsteuerung",
    "href": "150-fallstudien.html#lernsteuerung",
    "title": "16Â  Fallstudien",
    "section": "\n16.1 Lernsteuerung",
    "text": "16.1 Lernsteuerung\n\n16.1.1 Lernziele\n\nSie kÃ¶nnen die Techniken des Maschinellen Lernens mit dem Tidymodels-Ansatz flÃ¼ssig anbringen.\n\n16.1.2 Literatur\n\nRhys, Kap. 12"
  },
  {
    "objectID": "150-fallstudien.html#fallstudien-zur-explorativen-datenanalyse",
    "href": "150-fallstudien.html#fallstudien-zur-explorativen-datenanalyse",
    "title": "16Â  Fallstudien",
    "section": "\n16.2 Fallstudien zur explorativen Datenanalyse",
    "text": "16.2 Fallstudien zur explorativen Datenanalyse\n\nFALLSTUDIEN - NUR EXPLORATIVE DATENANALYSE\n\nDatenjudo mit Pinguinen\nData-Wranglinng-Aufgaben zur Lebenserwartung\nCase study: data vizualization on flight delays using tidyverse tools\nAufgabe zur Datenvisualisierung des Diamantenpreises\nFallstudie FlugverspÃ¤tungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten FlugverspÃ¤tungen, Datensatz â€˜nycflights13â€™\nCleaning and visualizing genomic data: a case study in tidy analysis\nTidyverse Case Study: Exploring the Billboard Charts\nAnalyse einiger RKI-Coronadaten: Eine reproduzierbare Fallstudie\nOpenCaseStudies - Health Expenditure\nOpen Case Studies: School Shootings in the United States - includes dashboards\nOpen Case Studies: Disparities in Youth Disconnection\nYACSDA SeitensprÃ¼nge\nThe Open Case Study Search provides a nice collection of helpful case studies.\nifes@FOM Fallstudienseite"
  },
  {
    "objectID": "150-fallstudien.html#fallstudien-zu-linearen-modellen",
    "href": "150-fallstudien.html#fallstudien-zu-linearen-modellen",
    "title": "16Â  Fallstudien",
    "section": "\n16.3 Fallstudien zu linearen Modellen",
    "text": "16.3 Fallstudien zu linearen Modellen\n\nFALLSTUDIEN - NUR LINEARE MODELLE\n\nBeispiel fÃ¼r Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel fÃ¼r Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel fÃ¼r Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von FlugverspÃ¤tungen\nModelling movie successes: linear regression\nMovies\nFallstudie Einfache lineare Regression in Base-R, AnfÃ¤ngerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\nFallstudie zum Beitrag verschiedener Werbeformate zum Umsatz; eine Fallstudie in Python, aber mit etwas Erfahrung wird man den Code einfach in R umsetzen kÃ¶nnen (wenn man nicht in Python schreiben will)\nPractical Linear Regression with R: A case study on diamond prices\nCase Study: Italian restaurants in NYC\nVorhersage-Modellierung des Preises von Diamanten\nModellierung Diamantenpreis 2"
  },
  {
    "objectID": "150-fallstudien.html#sec-yacsdas-tidymodels",
    "href": "150-fallstudien.html#sec-yacsdas-tidymodels",
    "title": "16Â  Fallstudien",
    "section": "\n16.4 Fallstudien zum maschinellen Lernen mit Tidymodels",
    "text": "16.4 Fallstudien zum maschinellen Lernen mit Tidymodels\n\nFALLSTUDIEN - MASCHINELLES LERNEN MIT TIDYMODELS\n\nExperimenting with machine learning in R with tidymodels and the Kaggle titanic dataset\nTutorial on tidymodels for Machine Learning\nClassification with Tidymodels, Workflows and Recipes\nA (mostly!) tidyverse tour of the Titanic\nPersonalised Medicine - EDA with tidy R\nTidy TitaRnic\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\nAnalyse zum Verlauf von Covid-FÃ¤llen\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu VulkanausbrÃ¼chen (Resampling and kein Tuning)\nFallstudie Himalaya (Resampling and kein Tuning)\nFallstudien zu StudiengebÃ¼hren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\nEinfache DurchfÃ¼hrung eines Modellierung mit XGBoost\nFallstudie Oregon Schools\nFallstudie Churn\nFallstudie Ikea\nFallstudie Wasserquellen in Sierra Leone\nFallstudie BÃ¤ume in San Francisco: Random Forest tunen\nFallstudie VulkanausbrÃ¼che\nFallstudie Brettspiele mit XGBoost\nFallstudie Serie The Office: Lasso tunen\nFallstudie NBER Papers\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Titanic mit Tidymodels bei Kaggle\nEinfache Fallstudie mit Tidymodels bei Kaggle\nExploring the Star Wars â€œPrequel Renaissanceâ€ Using tidymodels and workflowsets\nClassification modelling workflow using tidymodels, Konstantinos Patelis\nTune xgboost models with early stopping to predict shelter animal status\nPredicting injuries for Chicago traffic crashes: Resampling BAG Tree\nUsing tidymodels to Predict Health Insurance Cost: Resmapling"
  },
  {
    "objectID": "150-fallstudien.html#vertiefung",
    "href": "150-fallstudien.html#vertiefung",
    "title": "16Â  Fallstudien",
    "section": "\n16.5 Vertiefung",
    "text": "16.5 Vertiefung\n\nProjektmanagement mit Targets\nWie man eine Data-Science-Projekt strukturiert\nHausmeisterarbeit mit {{janitor}}"
  },
  {
    "objectID": "150-fallstudien.html#aufgaben",
    "href": "150-fallstudien.html#aufgaben",
    "title": "16Â  Fallstudien",
    "section": "\n16.6 Aufgaben",
    "text": "16.6 Aufgaben\n\nBearbeiten Sie eine Auswahl von Fallstudien Ihrer Wahl aus dieser Sammlung"
  },
  {
    "objectID": "160-e.html#lernsteuerung",
    "href": "160-e.html#lernsteuerung",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.1 Lernsteuerung",
    "text": "17.1 Lernsteuerung\n\n17.1.1 Lernziele\n\nSie wissen um die Bedeutung von e\nSie kÃ¶nnen die Zahl e herleiten\n\n17.1.2 Literatur\n\nKen Benoit: Lineare Regression mit logarithmischen Transformationen"
  },
  {
    "objectID": "160-e.html#vorbereitung",
    "href": "160-e.html#vorbereitung",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.2 Vorbereitung",
    "text": "17.2 Vorbereitung\nIn diesem Kapitel werden folgende R-Pakete benÃ¶tigt:\n\nlibrary(tidyverse)\nlibrary(knitr)"
  },
  {
    "objectID": "160-e.html#staunen",
    "href": "160-e.html#staunen",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.3 Staunen",
    "text": "17.3 Staunen\nStaunen ist der Ursprung der Philosophie und damit des Denkens und damit vielleicht der Wissenschaft, wie es vielleicht recht treffend in diesem Cartoon von Doug Savage, 2014 dargestellt ist.\nStaunen rÃ¼hrt her vom Moment der Erkennens, dem Auftun von VerstÃ¤ndnistiefe.\nUnd Tiefe des VerstÃ¤ndnis findet sich vielleicht am deutlichsten in der Mathematik, meint XKCD."
  },
  {
    "objectID": "160-e.html#exponenzielles-wachstum",
    "href": "160-e.html#exponenzielles-wachstum",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.4 Exponenzielles Wachstum",
    "text": "17.4 Exponenzielles Wachstum\ne wie exponenzielles Wachstum: Wachstum mit konstantem Faktor.\nVerdoppeln ist eine wohl bekannte Art des exponenziellen Wachsens:\n\nEin Virus vermehrt sich wÃ¤hrend der Zeitperiode \\(z\\) um den Faktor 2, verdoppelt seine Zahl also.\nDas Kapitel einer Anlage verdoppelt sich wÃ¤hrend des Zeitraums \\(z\\).\nEine Population verdoppelt sich (wÃ¤hrend eines Zeitraums \\(z\\)).\n\nVisualisieren wir uns einen exponenziellen Prozess, s. AbbildungÂ 17.1.\n\nd1 &lt;-\n  tibble(z = 1:10,\n         y = 2^z)\n\nd1 %&gt;% \n  ggplot(aes(x = z, y = y)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\nAbbildungÂ 17.1: Ein exponenzieller Wachstumsprozess\n\n\n\nâ€œVerdoppelnâ€ meint das Gleiche wie â€œWachsen um 100%â€: Faktor 2 entspricht also 100%.\nSagen wir, eine Population mit StartgrÃ¶ÃŸe 1 verdoppelt sich drei Mal, Wachstum von 100% Ã¼ber drei Perioden:\n\\(1 \\cdot 2^3 = 8\\)\nDanach ist die Population also 8 mal so groÃŸ wie vorher.\nAllgemeiner kÃ¶nnen wir also schreiben\n\\(2^x = (1+ 100\\%)^x\\),\nwobei \\(x\\) die Anzahl der betrachteten Zeitperioden meint.\nWir kÃ¶nnen auf der Y-Achse auch die Anzahl der Verdopplungen auftragen, denn wir wissen ja, dass pro Zeitperiode eine Verdopplung dazu kommt, nach zwei Zeitperioden also zwei Verdopplungen, nach drei Zeitperioden drei Verdopplungen, nach vier Zeitperioden vier Verdopplungen â€¦\nNur sieht das Diagramm dann drÃ¶ge aus, s. AbbildungÂ 17.2. Diese Darstellung (Anzahl der Verdopplungsphasen) nennt man auch logarithmische Darstellung.\n\nd1a &lt;-\n  tibble(z = 1:10,\n         verdopplung = 1:10)\n\nd1a %&gt;% \n  ggplot(aes(x = z, y = verdopplung)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\nAbbildungÂ 17.2: Logarithmische Darstellung eines Wachstumsprozesses"
  },
  {
    "objectID": "160-e.html#sofortiges-wachstum",
    "href": "160-e.html#sofortiges-wachstum",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.5 Sofortiges Wachstum",
    "text": "17.5 Sofortiges Wachstum\nSagen wir, wir bringen ein Kapitel (in HÃ¶he von einer Geldeinheit) zur Bank. Die Bank bietet uns eine traumhafte Verzinsung (r wir Rate) von 100$ pro Jahr.\nUm den Zinzeszinseffekt auszunutzen, heben wir das Geld mehrfach unterjÃ¤hrig ab, um es sofort wieder anzulegen, s. AbbildungÂ 17.3.\n\nd2 &lt;-\n  tibble(\n    r = 1:20,\n    y = (1 + 1/r)^r\n  )\n\n\nd2 %&gt;% \n  ggplot() +\n  aes(x = r,\n      y = y) +\n  geom_point() +\n  geom_line()\n\n\n\nAbbildungÂ 17.3: Wachstum wenn wir das Geld mehrfach unterjÃ¤hrig abheben und neu einzahlen\n\n\n\nKÃ¶nnen wir mit dieser Methode unendlich viel Geld erzeugen? TabelleÂ 17.1 gibt eine Antwort.\n\nd2 &lt;-\n  tibble(x = 0:10,\n         r = 10^x,\n         y = (1 + 1/r)^r)\n\nd2 %&gt;% \n  kable(digits = 10)\n\n\n\nTabelleÂ 17.1: Zinswachstum bei hÃ¤ufiger Aus- und Einzahlung pro Jahr\n\nx\nr\ny\n\n\n\n0\n1e+00\n2.000000\n\n\n1\n1e+01\n2.593742\n\n\n2\n1e+02\n2.704814\n\n\n3\n1e+03\n2.716924\n\n\n4\n1e+04\n2.718146\n\n\n5\n1e+05\n2.718268\n\n\n6\n1e+06\n2.718280\n\n\n7\n1e+07\n2.718282\n\n\n8\n1e+08\n2.718282\n\n\n9\n1e+09\n2.718282\n\n\n10\n1e+10\n2.718282\n\n\n\n\n\n\nWenn \\(r\\) gegen unendlich geht:\n\\[w = e=\\lim _{n\\to \\infty }\\left(1+{\\frac {1}{r}}\\right)^{r}\\]\n\\(e\\) ist das maximale Wachstum, dass man mit sofortiger, stetiger Verzinsung erreichen kann."
  },
  {
    "objectID": "160-e.html#andere-wachstumsraten",
    "href": "160-e.html#andere-wachstumsraten",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.6 Andere Wachstumsraten",
    "text": "17.6 Andere Wachstumsraten\n50% Wachstum:\n\\[\\left(1+{\\frac {.50}{50}}\\right)^{50}=(1+0.01)^{50} \\approx 1.64\\]\nEtwas genauer:\n\n(1 + (.50/50))^50\n## [1] 1.644632\n\n50% Wachstum bedeutet also 50 Phasen mit je 1% Wachstum â€¦\nMoment, wenn wir 100% Wachstum so darstellen, also als 100 Wachstumsphasen mit je 1% Wachstum:\n\\[\\left(1+{\\frac {1.00}{100}}\\right)^{100}=(1+.01)^{100} \\approx e\\]\n\n(1 + (1.00/100))^100\n## [1] 2.704814"
  },
  {
    "objectID": "160-e.html#wachstum-mit-basis-e",
    "href": "160-e.html#wachstum-mit-basis-e",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.7 Wachstum mit Basis e",
    "text": "17.7 Wachstum mit Basis e\nZwei Perioden Wachstum mit sofortiger, stetiger Verzinsung (100%) erhÃ¶ht das Kapitel um den Faktor \\(e^2\\). Beginnt man mit dem Kapitel 1, so betrÃ¤gt das Endkapitel (Wachstum):\n\\[w = e \\cdot e = e^2\\]\nWÃ¤chst das Kapitel aber nur mit 50%, so gilt (fÃ¼r zwei Zeitperioden):\n\\[w= e^{0.5 \\cdot 2} = e^1\\]\nAllgemeiner:\nDas Wachstum \\(w\\) nach \\(t\\) Perioden und Wachstumsfaktor \\(r\\) betrÃ¤gt e hoch dem Produkt von \\(r\\) und \\(z\\):\n\\[w=e^{r\\cdot t}\\]"
  },
  {
    "objectID": "160-e.html#logarithmus",
    "href": "160-e.html#logarithmus",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.8 Logarithmus",
    "text": "17.8 Logarithmus\nWÃ¤chst eine GrÃ¶ÃŸe stetig (mit 100%) fÃ¼r \\(t\\) ZeitrÃ¤ume, so ist der resultierende Wachstumswert \\(w = e^r\\). Der Logarithmus (zur Basis \\(e\\)) liefert den Exponenten, \\(r\\) zurÃ¼ck.\nWachstum fÃ¼r zwei Perioden:\n\nw &lt;- exp(2)\nw\n## [1] 7.389056\n\nWie viele Perioden waren es noch mal?\n\nlog(w)\n## [1] 2\n\nWie lange dauert es, bis wir das Kapitel verdoppelt haben (stetige Verzinsung mit 100%)?\n\nlog(2)\n## [1] 0.6931472\n\nEs dauert ca. 0.7 Zeitperioden bis zur Verdopplung."
  },
  {
    "objectID": "160-e.html#regel-der-72",
    "href": "160-e.html#regel-der-72",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.9 Regel der 72",
    "text": "17.9 Regel der 72\nVon dieser Zahl her rÃ¼hrt die â€œRegel der 72â€.\n72 lÃ¤sst sich angenehm teilen (2,3,4,6,12, â€¦), besser als 69.31â€¦"
  },
  {
    "objectID": "160-e.html#fazit",
    "href": "160-e.html#fazit",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.10 Fazit",
    "text": "17.10 Fazit\n\n\nWolfi trÃ¤umt"
  },
  {
    "objectID": "160-e.html#vertiefung",
    "href": "160-e.html#vertiefung",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.11 Vertiefung",
    "text": "17.11 Vertiefung\n\nâ€œIntuitive ErklÃ¤rung zu eâ€"
  },
  {
    "objectID": "160-e.html#aufgaben",
    "href": "160-e.html#aufgaben",
    "title": "\n17Â  Staunen mit e\n",
    "section": "\n17.12 Aufgaben",
    "text": "17.12 Aufgaben\n\nâ€œFallstudien-Sammlung TMDBâ€"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baumer, Benjamin S., Daniel T. Kaplan, and Nicholas J. Horton. 2017.\nModern Data Science with r (Chapman & Hall/CRC\nTexts in Statistical Science). Boca Raton, Florida: Chapman;\nHall/CRC.\n\n\nChen, Tianqi, and Carlos Guestrin. 2016. â€œXGBoost: A\nScalable Tree Boosting System.â€ In Proceedings of the 22nd\nACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, 785â€“94. KDD â€™16.\nNew York, NY, USA: Association for Computing\nMachinery. https://doi.org/10.1145/2939672.2939785.\n\n\nFriedman, J. 2001. â€œGreedy Function Approximation: A Gradient\nBoosting Machine.â€ https://doi.org/10.1214/AOS/1013203451.\n\n\nHvitfeldt, Emil. 2022. ISLR Tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nr. Second edition. Springer Texts in Statistics. New York:\nSpringer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive\nModeling. Vol. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with r, the Tidyverse, and\nMlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse Mit r: Daten Einlesen,\nAufbereiten, Visualisieren Und Modellieren. 1. Auflage 2019.\nFOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, and Max Kuhn. 2022. Tidy Modeling with\nR. https://www.tmwr.org/.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87.\nhttps://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG.\n\n\nTaleb, Nassim Nicholas. 2019. The Statistical Consequences of Fat\nTails, Papers and Commentaries. Monograph. https://nassimtaleb.org/2020/01/final-version-fat-tails/.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, and Melissa Lee. 2022. Data\nScience: An Introduction. First edition. Statistics. Boca Raton:\nCRC Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data Science:\nVisualize, Model, Transform, Tidy, and Import Data. Oâ€™Reilly Media.\nhttps://r4ds.had.co.nz/index.html."
  }
]