[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "",
    "text": "1 Zu diesem Buch\nQuelle: ImageFlip"
  },
  {
    "objectID": "index.html#was-r√§t-meister-yoda",
    "href": "index.html#was-r√§t-meister-yoda",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.1 Was r√§t Meister Yoda?",
    "text": "1.1 Was r√§t Meister Yoda?\nMeister Yoda r√§t: Lesen Sie die Hinweise (Abbildung¬†1.1).\n\n\nAbbildung¬†1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\n\n\nQuelle: made at imageflip"
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.2 Zitation",
    "text": "1.2 Zitation\nNutzen Sie diese DOI, um dieses Buch zu zitieren:"
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.3 Technische Details",
    "text": "1.3 Technische Details\n\nDiese Version des Buches wurde erstellt am: 2023-03-13 14:21:16\nDie URL zu diesem Buch lautet https://sebastiansauer.github.io/datascience1/ und ist bei GitHub Pages gehostet.\nDen Quellcode finden Sie in diesem Github-Repo.\nSie haben Feedback, Fehlerhinweise oder W√ºnsche zur Weiterentwicklung? Am besten stellen Sie hier einen Issue ein.\nDieses Projekt steht unter der MIT-Lizenz.\nDieses Buch wurde in RStudio mit Hilfe von bookdown geschrieben.\nDiese Version des Buches wurde mit der R-Version R version 4.2.1 (2022-06-23) und den folgenden Paketen erstellt:\n\n\n\n\n\npackage\nversion\nsource\n\n\n\nbookdown\n0.32\nCRAN (R 4.2.0)\n\n\nbroom\n1.0.3\nCRAN (R 4.2.0)\n\n\ncorrr\nNA\nNA\n\n\ndials\n1.1.0\nCRAN (R 4.2.0)\n\n\ndownlit\n0.4.2\nCRAN (R 4.2.0)\n\n\ndplyr\n1.1.0\nCRAN (R 4.2.0)\n\n\nggplot2\n3.4.1\nCRAN (R 4.2.0)\n\n\nglmnet\n4.1-6\nCRAN (R 4.2.0)\n\n\ninfer\n1.0.4\nCRAN (R 4.2.0)\n\n\nISLR\nNA\nNA\n\n\nkknn\n1.3.1\nCRAN (R 4.2.0)\n\n\nklaR\n1.7-1\nCRAN (R 4.2.0)\n\n\nMASS\n7.3-58.2\nCRAN (R 4.2.0)\n\n\nmodeldata\n1.0.1\nCRAN (R 4.2.0)\n\n\nparsnip\n1.0.3\nCRAN (R 4.2.0)\n\n\npatchwork\n1.1.2\nCRAN (R 4.2.0)\n\n\npurrr\n1.0.1\nCRAN (R 4.2.0)\n\n\nrandomForest\n4.7-1.1\nCRAN (R 4.2.0)\n\n\nranger\n0.14.1\nCRAN (R 4.2.0)\n\n\nreadr\n2.1.4\nCRAN (R 4.2.0)\n\n\nrsample\n1.1.1\nCRAN (R 4.2.0)\n\n\nrstatix\n0.7.2\nCRAN (R 4.2.0)\n\n\ntibble\n3.1.8\nCRAN (R 4.2.0)\n\n\ntidymodels\n1.0.0\nCRAN (R 4.2.0)\n\n\ntidyr\n1.3.0\nCRAN (R 4.2.0)\n\n\ntidyverse\n1.3.2\nCRAN (R 4.2.0)\n\n\ntune\n1.0.1\nCRAN (R 4.2.0)\n\n\nvip\n0.3.2\nCRAN (R 4.2.0)\n\n\nworkflows\n1.1.2\nCRAN (R 4.2.0)\n\n\nworkflowsets\n1.0.0\nCRAN (R 4.2.0)\n\n\nxgboost\n1.6.0.1\nCRAN (R 4.2.0)\n\n\nyardstick\n1.1.0\nCRAN (R 4.2.0)"
  },
  {
    "objectID": "010-Hinweise.html#ihr-lernerfolg",
    "href": "010-Hinweise.html#ihr-lernerfolg",
    "title": "Lernhilfen",
    "section": "\n2.1 Ihr Lernerfolg",
    "text": "2.1 Ihr Lernerfolg\n\n2.1.1 Was Sie hier lernen und wozu das gut ist\nAlle Welt spricht von Big Data, aber ohne die Analyse sind die gro√üen Daten nur gro√ües Rauschen. Was letztlich interessiert, sind die Erkenntnisse, die Einblicke, nicht die Daten an sich. Dabei ist es egal, ob die Daten gro√ü oder klein sind. Nat√ºrlich erlauben die heutigen Datenmengen im Verbund mit leistungsf√§higen Rechnern und neuen Analysemethoden ein Verst√§ndnis, das vor Kurzem noch nicht m√∂glich war. Und wir stehen erst am Anfang dieser Entwicklung. Vielleicht handelt es sich bei diesem Feld um eines der dynamischsten Fachgebiete der heutigen Zeit. Sie sind dabei: Sie lernen einiges Handwerkszeugs des ‚ÄúDatenwissenschaftlers‚Äù. Wir konzentrieren uns auf das vielleicht bekannteste Teilgebiet: Ereignisse vorhersagen auf Basis von hoch strukturierten Daten und geeigneter Algorithmen und Verfahren. Nach diesem Kurs sollten Sie in der Lage sein, typisches Gebabbel des Fachgebiet mit L√§ssigkeit mitzumachen. Ach ja, und mit einigem Erfolg Vorhersagemodelle entwickeln.\n\n2.1.2 Lernziele\n\n\n\n\n\n\nWichtig\n\n\n\nKurz gesagt: Sie lernen die Grundlagen von Data Science.\\(\\square\\)\n\n\nNach diesem Kurs sollten Sie\n\ngrundlegende Konzepte des statistischen Lernens verstehen und mit R anwenden k√∂nnen\ng√§ngige Prognose-Algorithmen kennen, in Grundz√ºgen verstehen und mit R anwenden k√∂nnen\ndie G√ºte und Grenze von Prognosemodellen einsch√§tzen k√∂nnen\n\n2.1.3 √úberblick\nAbb. Abbildung¬†2.1 gibt einen √úberblick √ºber den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Grundlagen]\n      direction TB\n      E[R] --- Um[Statistisches&lt;br&gt;Lernen]\n      Um --- tm[tidymodels]\n    end\n    subgraph M[Lernalgorithmen]\n      direction TB\n      M1[Regression] --- Vis[Baeume]\n      Vis --- U[Regularisierung]\n      U --- G[...]\n    end\n    subgraph N[Anwendung]\n      direction TB\n      D[Fallstudien]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\nAbbildung¬†2.1: Ein ‚ÄòFahrplan‚Äô als ‚ÄòBig Picture‚Äô dieses Buches\n\n\n\n\n\n2.1.4 Modulzeitplan\n\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nStatistisches Lernen\n13.3. - 19.3.\nLehrbeginn ist am Mi., 15.3.23\n\n\n2\nStatistisches Lernen\n20.3. - 26.3.\nNA\n\n\n3\nR, zweiter Blick\n27.3. - 2.4.\nNA\n\n\n4\nR, zweiter Blick\n3.4. - 9.4\nKarwoche (kein Unterricht am Do. und Fr.)\n\n\n5\ntidymodels\n10.4. - 16.4.\nOsterwoche (kein Unterricht am Mo. und Di.)\n\n\n6\nknn\n17.4. - 23.4.\nNA\n\n\n7\nResampling und Tuning\n24.4. - 30.4.\nNA\n\n\n8\nLogistische Regression\n1.5. - 7.5.\nMaifeiertag (kein Unterricht am Mo.)\n\n\n9\nEntscheidungsb√§ume\n8.5. - 14.5.\nNA\n\n\n10\nBaumbasierte Modelle\n15.5. - 21.5.\nNA\n\n\n11\n-\n22.5. - 28.5.\nBlockwocke - kein regul√§rer Unterricht\n\n\n12\nRegularisierung\n29.6. - 4.6.\nPfingstwoche (kein Unterricht am Mo. und Di.)\n\n\n13\nRegularisierung\n5.6. - 11.6.\nFronleichnam (kein Unterricht am Do. und Fr.)\n\n\n14\nFallstudien bei Kaggle\n12.6. - 18.6.\nNA\n\n\n15\nDimensionsreduktion\n19.6. - 25.6.\nNA\n\n\n16\nDer rote Faden\n26.6. - 2.7.\nLetzter Lehrtag ist Fr., 30.6.\n\n\n\n\n\n\n\n2.1.5 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, m√∂glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse"
  },
  {
    "objectID": "010-Hinweise.html#lernhilfen",
    "href": "010-Hinweise.html#lernhilfen",
    "title": "Lernhilfen",
    "section": "\n2.2 Lernhilfen",
    "text": "2.2 Lernhilfen\n\n2.2.1 PDF-Version\nUm eine PDF-Version eines Kapitels zu erhalten, k√∂nnen Sie im Browser die Druckfunktion nutzen (Strg-P). W√§hlen Sie dort ‚ÄúPDF‚Äù als Ziel.\n\n2.2.2 Videos\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buchs. Besonders diese Playlist passt zu den Inhalten dieses Buchs.\n\n2.2.3 Software\nInstallieren Sie R und seine Freunde. F√ºr die Bayes-Inferenz brauchen Sie1 zus√§tzliche Software, was leider etwas Zusatzaufwand erfordert. Lesen Sie hier die Hinweise dazu. Installieren Sie die folgende R-Pakete2:\n\ntidyverse\neasystats\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n2.2.4 Online-Unterst√ºtzung\nDieser Kurs kann in Pr√§senz und Online angeboten werden. Wenn Sie die Wahl haben, empfehle ich die Teilnahme in Pr√§senz, da der Lernerfolg h√∂her ist. Online ist es meist schwieriger, sich zu konzentrieren. Aber auch online ist es m√∂glich, den Stoff gut zu lernen, s. Abbildung¬†2.2.\n\n\nAbbildung¬†2.2: We believe in you! Image Credit: Allison Horst\n\n\nBitte beachten Sie, dass bei einer Teilnahme in Pr√§senz eine aktive Mitarbeit erwartet wird. Hingegen ist bei einer Online-Teilnahme keine/kaum aktive Mitarbeit m√∂glich.\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen w√§hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\n\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeitr√§gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\nNutzen Sie das vom Dozenten bereitgestelle Forum, um Fragen zu stellen und Fragen zu beantworten.\n\n2.2.5 Lerntipps\n\n\n\n\n\n\nHinweis\n\n\n\nStetige Mitarbeit - auch und gerade au√üerhalb des Unterrichts - ist der Schl√ºssel zum Pr√ºfungserfolg.\n\n\n\n\nLerngruppe: Treten Sie einer Lerngruppe bei.\n\nTutorium: Besuchen Sie ein Tutorium, falls eines angeboten wird.\n\nVor- und Nachbereitung: Bereiten Sie den Unterricht vor und nach.\n\nSelbsttest: Testen Sie sich mit Flashcards (Karteikarten mit Vor- und R√ºckseite). Wenn Sie alle Aufgaben dieses Kurses aus dem FF beherrschen, sollte die Pr√ºfung kein Problem sein.\n\n√úbungen: Bearbeiten Sie alle √úbungsaufgaben gewissenhaft.\nPortal Datenwerk: Gehen Sie die Aufgaben auf dem Portal Datenwerk durch (soweit relevant).\n\nFallstudien: Schauen Sie sich meine Fallstudiensammlungen an: https://sebastiansauer-academic.netlify.app/courseware/casestudies/\n\nLehrkraft ansprechen: Sprechen Sie die Lehrkraft an, wenn Sie Fragen haben. Haben Sie keine Scheu! Bitte lesen Sie aber vorab die Hinweise, um Redundanz zu vermeiden.\n\n2.2.6 Selbstlernkontrolle\nF√ºr jedes Kapitel sind (am Kapitelende) Aufgaben eingestellt, jeweils mit L√∂sung. Ein Teil dieser Aufgaben hat eine kurze, eindeutige L√∂sung (z.B. ‚Äú42‚Äù oder ‚ÄúAntwort C‚Äù); ein (kleiner) Teil der Aufgaben verlangen komplexere Antworten (z.B. ‚ÄúWelche Arten von Prioris gibt es bei stan_glm()?). Nutzen Sie die Fragen mit eindeutiger, kurzer L√∂sung um sich selber zu pr√ºfen. Nutzen Sie die Fragen mit komplexerer, l√§ngerer L√∂sung, um ein Themengebiet tiefer zu erarbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nFortw√§hrendes Feedback zu Ihrem Lernfortschritt ist wichtig, damit Sie Ihre Lernbem√ºhungen steuern k√∂nnen. Bearbeiten Sie daher die bereitgestellten Arbeiten ernsthaft.\n\n\n\n2.2.7 Lernen lernen\nHier sind einige Quellen (Literatur), die Ihnen helfen sollen, das Lernen (noch besser) zu lernen:\n\nEssentielle Tipps f√ºr Bachelor-Studierende der Psychologie\nKonzentriert arbeiten: Regeln f√ºr eine Welt voller Ablenkungen\nWie man ein Buch liest\nErsti-Hilfe: 112 Tipps f√ºr Studienanf√§nger - erfolgreich studieren ab der ersten Vorlesung\nVon der K√ºrze des Lebens\nBlog ‚ÄúStudienscheiss‚Äù"
  },
  {
    "objectID": "010-Hinweise.html#literatur",
    "href": "010-Hinweise.html#literatur",
    "title": "Lernhilfen",
    "section": "\n2.3 Literatur",
    "text": "2.3 Literatur\nZentrale Kursliteratur f√ºr die theoretischen Konzepte ist Rhys (2020). Bitte pr√ºfen Sie, ob das Buch in einer Bibliothek verf√ºgbar ist. Die praktische Umsetzung in R basiert auf Silge und Kuhn (2022) (dem ‚ÄúTidymodels-Konzept‚Äù); das Buch ist frei online verf√ºgbar.\nEine gute Erg√§nzung ist das Lehrbuch von Timbers, Campbell, und Lee (2022), welches grundlegende Data-Science-Konzepte erl√§utert und mit tidymodels umsetzt.\nJames u.¬†a. (2021) haben ein weithin renommiertes und sehr bekanntes Buch verfasst. Es ist allerdings etwas anspruchsvoller aus Rhys (2020), daher steht es nicht im Fokus dieses Kurses, aber einige Schwenker zu Inhalten von James u.¬†a. (2021) gibt es. Schauen Sie mal rein, das Buch ist gut!\nIn einigen Punkten ist weiterhin Sauer (2019) hilfreich; das Buch ist √ºber SpringerLink in Ihrer Hochschul-Bibliothek verf√ºgbar. Eine gute Erg√§nzung ist das ‚ÄúLab-Buch‚Äù von Hvitfeldt (2022). In dem Buch wird das Lehrbuch James u.¬†a. (2021) in Tidymodels-Konzepte √ºbersetzt; durchaus nett!"
  },
  {
    "objectID": "010-Hinweise.html#faq",
    "href": "010-Hinweise.html#faq",
    "title": "Lernhilfen",
    "section": "\n2.4 FAQ",
    "text": "2.4 FAQ\n\n\nFolien\n\nFrage: Gibt es ein Folienskript?\nAntwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zug√§ngliche Literatur gibt, dort gibt es ein Skript.\n\n\n\nEnglisch\n\nIst die Literatur auf Englisch?\nJa. Allerdings ist die Literatur gut zug√§nglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca in Wissenschaft und Wirtschaft. Ein solides Verst√§ndnis englischer (geschriebener) Sprache ist f√ºr eine gute Ausbildung unerl√§sslich. Zu dem sollte die Kursliteratur fachlich passende und gute B√ºcher umfassen; oft sind das englische Titel.\n\n\n\nAnstrengend\n\nIst der Kurs sehr anstrengend, aufw√§ndig?\nDer Kurs hat ein mittleres Anspruchsniveau.\n\n\n\nMathe\n\nMuss man ein Mathe-Crack sein, um eine gute Note zu erreichen?\nNein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur an, sie werden wenig Mathe darin finden.\n\n\n\nPr√ºfungsliteratur\n\nWelche Literatur ist pr√ºfungsrelevant?\nPr√ºfungsrelevant im engeren Sinne ist das Skript sowie alles, was im Unterricht behandelt wurde.\n\n\n\nPr√ºfung\n\nWie sieht die Pr√ºfung aus?\nDie Pr√ºfung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, in der reines Wissen abgefragt wird.\n\n\n\nNur R?\n\nWird nur R in dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig.\nIn der Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. In einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit einger√§umt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen.\n\n\n\n\n\n\n\nHvitfeldt, Emil. 2022. ISLR tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, und Melissa Lee. 2022. Data science: an introduction. First edition. Statistics. Boca Raton: CRC Press."
  },
  {
    "objectID": "010-Hinweise.html#footnotes",
    "href": "010-Hinweise.html#footnotes",
    "title": "Lernhilfen",
    "section": "",
    "text": "nicht gleich zu Beginn, aber nach 2-3 Wochen‚Ü©Ô∏é\nfalls Sie die Pakete schon installiert haben, k√∂nnten Sie mal in RStudio auf ‚Äúupdate.packages‚Äù klicken‚Ü©Ô∏é"
  },
  {
    "objectID": "030-Pruefung.html#pr√ºfungleistung",
    "href": "030-Pruefung.html#pr√ºfungleistung",
    "title": "3¬† Pr√ºfung",
    "section": "3.1 Pr√ºfungleistung",
    "text": "3.1 Pr√ºfungleistung\nDie Pr√ºfungsleistung besteht aus einem Prognosewettbewerb.\n\nGegenstand dieser Pr√ºfungsform ist eine Projektarbeit."
  },
  {
    "objectID": "030-Pruefung.html#tldr-zusammenfassung",
    "href": "030-Pruefung.html#tldr-zusammenfassung",
    "title": "3¬† Pr√ºfung",
    "section": "3.2 tl;dr: Zusammenfassung",
    "text": "3.2 tl;dr: Zusammenfassung\nVorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. Wenn Sie den DAX-Stand von morgen genau vorhersagen k√∂nnen, rufen Sie mich bitte sofort an. Genau das ist Ihre Aufgabe in dieser Pr√ºfungsleistung: Sie sollen Werte vorhersagen.\nEtwas konkreter: Stellen Sie sich ein paar Studentis vor. Von allen wissen Sie, wie lange die Person f√ºr die Statistikklausur gelernt hat. Au√üerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. Und Sie wissen die Note jeder Person in der Statistikklausur. Auf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die Pr√ºfung in Statistik schreiben muss will: ‚ÄúSag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?‚Äù. Mit Hilfe Ihrer Analyse k√∂nnen Sie diese Frage (und andere) beantworten. Nat√ºrlich k√∂nnten Sie es sich leicht machen und antworten: ‚ÄúMei, der Notendurchschnitt war beim letzten Mal 2.7. Also ist 2.7 kein ganz doofer Tipp f√ºr deine Note.‚Äù Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, wenn man es geschickt anstellt. Da hilft Ihnen die Statistik (doch, wirklich).\nKurz gesagt gehen Sie so vor: Importieren Sie die Daten in R, starten Sie die n√∂tigen R-Pakete und schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. Dann nehmen Sie die vielversprechendsten Pr√§diktoren in ein Regressionsmodell und schauen sich an, wie gut die Vorhersage ist. Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. Je genauer Ihre Vorhersage, desto besser ist Ihr Pr√ºfungsergebnis."
  },
  {
    "objectID": "030-Pruefung.html#vorhersage",
    "href": "030-Pruefung.html#vorhersage",
    "title": "3¬† Pr√ºfung",
    "section": "3.3 Vorhersage",
    "text": "3.3 Vorhersage\nNeben der erkl√§renden, r√ºckw√§rtsgerichteten Modellierung spielt insbesondere in der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle: Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. f√ºr neue Kunden auf Basis von soziodemographischen Daten den Kundenwert ‚Äì m√∂glichst genau ‚Äì zu prognostizieren. Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden, d.h. inklusive des f√ºr diese Kunden bekannten Kundenwertes.\nIhnen werden zwei Teildatenmengen zur Verf√ºgung gestellt: Zum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet.\n\nBei den Trainingsdaten (Train-Sample) liegen sowohl die erkl√§renden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor. Auf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) gesch√§tzt. Es ist also die Variable \\(y\\) vorherszusagen.\nDieses gesch√§tzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(\\x_0\\), f√ºr die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({x}_0)\\) berechnet. Der unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.\n\nLiegt zu einem noch sp√§teren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, so kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden, d.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden.\nIn der praktischen Anwendung k√∂nnen zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben):\n\ndie Trainingsphase, d.h., die Phase f√ºr die sowohl erkl√§rende (\\(x\\)) als auch die erkl√§rte Variable (\\(y\\)) bekannt sind. Hier wird das Modell gesch√§tzt (gelernt): \\(\\hat{f}(x)\\). Daf√ºr wird der Trainingsdatensatz genutzt.\nIn der folgenden Anwendungsphase sind nur die erkl√§renden Variablen (\\(x_0\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.\nEvt. gibt es sp√§ter noch die Evaluierungsphase, f√ºr die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, so dass die Vorhersageg√ºte des Modells √ºberpr√ºft werden kann.\n\nIm Computer kann man dieses Anwendungsszenario simulieren: man teilt die Datenmenge zuf√§llig in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((x,y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((x_0)\\)) auf: Die Modellierung erfolgt auf den Trainingsdaten. Das Modell wird angewendet auf die Testdaten (Anwendungsdaten). Da man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden."
  },
  {
    "objectID": "030-Pruefung.html#hauptziel-genaue-prognose",
    "href": "030-Pruefung.html#hauptziel-genaue-prognose",
    "title": "3¬† Pr√ºfung",
    "section": "3.4 Hauptziel: Genaue Prognose",
    "text": "3.4 Hauptziel: Genaue Prognose\nIhre Aufgabe ist: Spielen Sie den Data-Scientist! Konstruieren Sie ein Modell auf Basis der Trainingsdaten \\((x,y\\)) und sagen Sie f√ºr die Testdaten (\\(x_0\\)) die Zielvariable m√∂glichst genau voraus (\\(\\hat{y}_0\\)).\nIhr(e) Dozent*in kennt den Wert der Zielvariable (\\(y_0\\)). Sie nicht.\nVon zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser, das weniger Vorhersagefehler aufweist (im Test-Datensatz), also genauer vorhersagt. Kurz gesagt: Genauer ist besser."
  },
  {
    "objectID": "030-Pruefung.html#einzureichende-dateien",
    "href": "030-Pruefung.html#einzureichende-dateien",
    "title": "3¬† Pr√ºfung",
    "section": "3.5 Einzureichende Dateien",
    "text": "3.5 Einzureichende Dateien\n\nFolgende* Dateiarten* sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, qmd-, Rmd-Notebook oder Rmd-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.qmd."
  },
  {
    "objectID": "030-Pruefung.html#zum-aufbau-ihrer-prognosedatei-im-csv-format",
    "href": "030-Pruefung.html#zum-aufbau-ihrer-prognosedatei-im-csv-format",
    "title": "3¬† Pr√ºfung",
    "section": "3.6 Zum Aufbau Ihrer Prognosedatei im CSV-Format",
    "text": "3.6 Zum Aufbau Ihrer Prognosedatei im CSV-Format\n\nDie CSV-Datei muss aus genau zwei Spalten mit exakt folgenden Spaltennamen bestehen:\n\n\nid: Den ID-Wert jedes vorhergesagten Wertes\npred: Der vorhergesagte Wert.\n\n\nUmlaute sind zu ersetzen (also S√º√ü wird Suess etc.).\nDie CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).\nDie CSV-Datei muss genau die Anzahl an Zeilen aufweisen, die der Zeilenl√§nge im Test-Datensatz entspricht.\nPr√ºfen Sie, dass Ihre CSV-Datei sich problemlos lesen l√§sst. Falls keine (funktionst√ºchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Pr√ºfung nicht bestanden. Tipp: √ñffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vern√ºnftig aussieht. Achtung: √ñffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, der CSV-Dateien verf√§lschen kann auch ohne dass man die Datei speichert.\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, Rmd-, qmd- oder Rmd-Notebook-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichten Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd."
  },
  {
    "objectID": "030-Pruefung.html#gliederung-ihrer-analyse",
    "href": "030-Pruefung.html#gliederung-ihrer-analyse",
    "title": "3¬† Pr√ºfung",
    "section": "3.7 Gliederung Ihrer Analyse",
    "text": "3.7 Gliederung Ihrer Analyse\nIhr Analysedokument stellt alle Ihre Schritte vor, die Sie im Rahmen der Bearbeitung der Pr√ºfungsaufgabe unternommen haben, zumindest was die Analyse der Daten betrifft.\nDas Dokument mischt drei Textarten: R-Syntax, R-Ausgaben sowie Prosa (Ihre Erkl√§rung zu Ihrer Analyse). Alle drei Aspekte sind gleicherma√üen wichtig f√ºr diese Analyse.\nWenn Sie das Dokument als R-Markdown-Datei (qmd- oder Rmd-Datei) anlegen, m√ºssen Sie R-Code in einem ‚ÄúR-Chunk‚Äù auszeichnen. Prosa wird in Rmd-Datei als Standard gesehen, sie brauchen ihn nicht extra auszuzeichnen (f√ºr R-Notebook-Dateien gilt das Gleiche). In R-Skript-Dateien ist es umgekehrt: Sie m√ºssen R-Code nicht extra auszeichnen, da in R-Skripten R als ‚ÄúStandard-Text‚Äù gesehen wird. Hingegen m√ºssen Sie Prosa als Kommentar einf√ºgen. Es bleibt Ihnen √ºberlassen, f√ºr welche Variante (R-, Rmd- oder R-Notebook) Sie sich entscheiden. Keine Option wird als besser oder schlechter gewertet (vermutlich ist Rmd f√ºr Sie am einfachsten).\nSie k√∂nnen Ihr Analysedokument z.B. so gliedern:\n\nForschungsfrage und Hintergrund (Beschreiben Sie kurz, worum es geht)\nVorbereitung (Pakete laden, Daten importieren, etc.)\nExplorative Datenanalyse (Untersuchen Sie den Datensatz nach Auff√§lligkeiten, die Sie dann beim Modellieren nutzen)\nModelle (z.B. via lm(av ~ uv))\nVorhersagen (Vorhersage der Test-Daten anhand des besten Vorhersagemodells und Einreichen)\n\nDie Gliederung ist kein Muss; andere Gliederung sind auch m√∂glich. Entscheidend ist die fachliche Angemessenheit.\n\n3.7.1 Abschnitt Forschungsfrage und Hintergrund\nIn diesem Abschnitt passiert noch keine Statistik bzw. keine Analyse. Stattdessen stellen Sie in ‚Äúnormaler Sprache‚Äù, also ohne intensiven Gebrauch vom (statistischem) Fachvokabular dar, was Ziel und was Hintergrund der Analyse ist. Sie k√∂nnen als Ziel bzw. Hintergrund den formalen Aspekt der Pr√ºfung anf√ºhren, wichtiger sind aber inhaltliche bzw. fachliche √úberlegungen: Worum geht es in der Analyse? Warum ist die Frage wichtig? Was wird untersucht? Anhand welcher Methodik wird die Frage untersucht?\n\n\n3.7.2 Vorbereitung\nIn diesem Abschnitt Ihres Analysedokuments f√ºhren Sie die technische Vorbereitung durch. Das betrifft vor allem das Importieren der Daten und das Starten aller R-Pakete, die in der Analyse verwendet werden.\nZum Importieren der Daten gehen Sie bitte so vor: Legen Sie f√ºr diese Analyse ein Projekt in Rstudio an. Speichern Sie in diesem Ordner (auf der Wurzelebene, nicht in Unterverzeichnissen) die zu analyiserenden Daten. √Ñndern Sie nicht den Dateinamen der Daten. Importieren Sie die Daten auf folgende Weise: d_train &lt;- read_csv(\"d_train.csv) bzw. d_test &lt;- read_csv(\"d_test.csv\"). Auf diese Weise ist die Reproduzierbarkeit Ihrer Analyse sichergestellt.\n\n\n3.7.3 Explorative Datenanalyse\nDie explorative Datenanalyse (EDA) meint sowohl die deskriptive Statistik als auch die Datenvisualisierung. Typische Schritte sind: das Bearbeiten (oder Entfernen) von Extremwerten und fehlenden Werten, die Untersuchung von Verteilungsformen oder das Suchen nach Mustern (Korrelationen, Gruppenunterschieden). Ein n√ºtzliches Ergebnis ist z.B. zu erkennen, welche Variablen sich als Pr√§diktoren eignen (f√ºr den n√§chsten Abschnitt der Modellierung). Ziel ist, dass Sie den folgenden Schritt vorbereiten, also Schritte unternehmen, damit Sie die AV m√∂glichst gut vorhersagen k√∂nnen.\n\n\n3.7.4 Modellierung\nIn diesem Schritt berechnen Sie Prognosemodelle. Das sind oft lineare Modelle, also etwa lm(av ~ uv). Es empfiehlt sich, mehrere Modelle zu berechnen und zu schauen, welches dieser Kandidaten am besten ist. Die G√ºte eines Prognosemodells bemisst sich letztlich nur an der Pr√§zision der Vorhersage neuer Daten, also des Test-Datensatzes. Wie gut Ihre Vorhersagen also wirklich sind, erfahren Sie erst mit der Notenbekanntgabe. Allerdings k√∂nnen Sie die Trainingsdaten nutzen, um die G√ºte Ihrere Modell abzusch√§tzen.\n\n\n3.7.5 Vorhersagen\nSchlie√ülich entscheiden Sie sich f√ºr einen Modellkandidaten. Diesen Modellkandidaten nehmen Sie her, um die (Ihenn unbekannten) Werte der AV (Zielvariablen) vorherzusagen. Diese Vorhersagen - zusammen mit der ID f√ºr jede Vorhersagen - speichern Sie als (regul√§re) CSV-Datei ab und reichen Sie als Ihre Pr√ºfungsleistung ein, zusammen mit Ihrer Analysedatei."
  },
  {
    "objectID": "030-Pruefung.html#tipps",
    "href": "030-Pruefung.html#tipps",
    "title": "3¬† Pr√ºfung",
    "section": "3.8 Tipps",
    "text": "3.8 Tipps\n\n3.8.1 Tipps f√ºr eine gute Prognose\n\nSchauen Sie in die Literatur.\nEvtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausrei√üern) helfen.\n√úberlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierf√ºr gibt es Algorithmen und R-Funktionen.\nVermeiden Sie √úber-Anpassung (Overfitting).\nVermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgef√ºllt.\nArbeiten Sie die bereitgestellten Fallstudien durch. Wenn Sie mehr tun m√∂chten, finden Sie im Internet eine F√ºlle von weiteren Fallstudien.\n\n\n\n3.8.2 Tipps zur Datenverarbeitung\n\nEin ‚Äúdeutsches‚Äù Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets k√∂nnen dies allerdings.\n\n\n\n3.8.3 Tipps zum Aufbau des Analyseskripts\n\nZu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.\nZu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (nicht von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Pr√ºfer, nicht lauff√§hig ist).\n\n\n\n3.8.4 Sonstiges\n\nLegen Sie regelm√§√üig Sicherheitskopien Ihrer Arbeit an (ggf. auf einem anderen Datentr√§ger).\nAchten Sie darauf, dass Sie nicht durcheinander kommen, in welcher Datei der aktuelle Stand Ihrer Arbeit liegt."
  },
  {
    "objectID": "030-Pruefung.html#bewertung",
    "href": "030-Pruefung.html#bewertung",
    "title": "3¬† Pr√ºfung",
    "section": "3.9 Bewertung",
    "text": "3.9 Bewertung\n\n3.9.1 Kriterien\n\nEs gibt drei Bewertungskriterien:\n\nFormalia: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, √úbersichtlichkeit der Analyse.\nMethode: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.\nInhalt: Vorhersageg√ºte.\n\nDas zentrale Bewertungskriterium ist Inhalt; die √ºbrigen beiden Kriterien flie√üen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein.\nDie quantitative Datenanalyse in Durchf√ºhrung und Interpretation ist der Schwerpunkt dieser Arbeit. Zuf√§lliges identisches Vorgehen, z.B. im R Code, ist sehr unwahrscheinlich und kann als Plagiat bewertet werden.\nDie Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.\nEs werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.\nEs werden keine Hinweise vergeben, stattdessen gibt es einen √úberblick an typischen Fehlern.\nEs wird keine Musterl√∂sugn ver√∂ffentlicht, um nachfolgende Kohorten nicht zu bevorteilen bzw. die aktuelle Kohorte nicht zu benachteiligen.\n\n\n\n3.9.2 Kennzahl der Modellg√ºte\nDie G√ºte der Vorhersage wird anhand des mittleren Absolutfehlers (mae) bemessen:\n\\[\\text{mae} = \\frac{1}{n} \\sum_{i=1}^n|(y_i - \\hat{y}_i)|\\]\n\n\n3.9.3 Notenstufen\nZur Vorhersageg√ºte: Die Vorhersageg√ºte eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\).\nIhre Bewertung erfolgt entsprechend Ihrer Vorhersageg√ºte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als \\(2,0\\)!\n\n\n3.9.4 Bewertungsprozess\nDer Gutachter legt im Nachgang der Pr√ºfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellg√ºte offen. Au√üerdem werden die vorherzusagenden Daten ver√∂ffentlicht sowie die Grenzwerte f√ºr jede Notenstufe. Auf dieser Basis ist es allen Teilnehmis m√∂glich, die Korrektheit Ihrer Note zu √ºberpr√ºfen."
  },
  {
    "objectID": "030-Pruefung.html#hinweise",
    "href": "030-Pruefung.html#hinweise",
    "title": "3¬† Pr√ºfung",
    "section": "3.10 Hinweise",
    "text": "3.10 Hinweise\nSie haben freie Methodenwahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie k√∂nnen aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen.\nEine Einf√ºhrung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling with R.2. Die B√ºcher beinhalten jeweils Beispiele und Anwendung mit R.\nAuch ist es Ihnen √ºberlassen, welche Variablen Sie zur Modellierung heranziehen ‚Äì und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausrei√üer bereinigen o.√Ñ.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchf√ºhren, auch auf den Testdaten (Anwendungsdaten) durchzuf√ºhren.\nHinweise zur Modellwahl usw. gibt es auch in erw√§hnter Literatur, aber auch in vielen B√ºchern zum Thema Data-Science.\nAlles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent sein. Im √úbrigen lautet die Aufgabe: Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine sch√∂ne Antwort, trifft die Wirklichkeit aber leider nicht immer. Eine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangsl√§ufig eine gute Vorhersage (Test-Set)."
  },
  {
    "objectID": "030-Pruefung.html#formalia",
    "href": "030-Pruefung.html#formalia",
    "title": "3¬† Pr√ºfung",
    "section": "3.11 Formalia",
    "text": "3.11 Formalia\n\nEs sind nur Einzelarbeiten zul√§ssig.\nIn der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in bereitgestellten Datensatz genutzt werden.\nAlle Analyseschritte bzw. alle Ver√§nderungen an den Daten m√ºssen im (eingereichten) Analyseskript nachvollziehbar aufgef√ºhrt sein. Das Analyseskript ist als R-Skript, qmd-Datei, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie k√∂nnen die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).\nDas Analyseskript muss grunds√§tzlich funktionst√ºchtig f√ºr den Pr√ºfer sein: Alle Befehle m√ºssen ohne Fehlermeldung durchlaufen. Ausnahmen: a) Installation fehlender Pakete, b) Daten sollen aus der Wurzelebene des Projektordners importiert werden..\nEs d√ºrfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzul√§ssig.\nNichtbeachtung der f√ºr dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug f√ºhren.\nDer Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.\nEs muss keine Literatur zitiert werden.\nEin ausgedrucktes Exemplar muss nicht abgegeben werden.\nW√§hrend der Pr√ºfungsphase werden keine inhaltlichen Fragen (‚Äúwie macht man nochmal eine Log-Transformation?‚Äù) und keine technischen Fragen (‚Äúwie installiert man nochmal ein R-Paket?‚Äù) beantwortet."
  },
  {
    "objectID": "030-Pruefung.html#ich-brauche-hilfe",
    "href": "030-Pruefung.html#ich-brauche-hilfe",
    "title": "3¬† Pr√ºfung",
    "section": "3.12 Ich brauche Hilfe!",
    "text": "3.12 Ich brauche Hilfe!\n\n3.12.1 Wo finde ich Beispiele und Vorlagen?\nIm Rahmen des Unterrichts wurden mehrere Fallstudien erarbeitet bzw. bereitgestellt, diese dienen Ihnen als ideale Vorlage.\nEine Beispiel-Modellierung finden Sie in der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd. Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen k√∂nnen, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt.\nIm Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen k√∂nnen.\n\n\n3.12.2 Probepr√ºfung f√ºr den Prognosewettbewerb\nJa, hier. In diesem Ordner liegen die Dokumente, die Sie f√ºr die echte Pr√ºfung auch bekommen:\n\nTrain-Datensatz\nTest-Datensatz\nHinweise zur vorherzusagenden Variablen\n\n\n\n3.12.3 Materialsammlung\nIn diesem Ordner finden Sie eine Materialsammlung zum Prognosewettbewerb.\n\n\n3.12.4 Videos\nDiese Playlist beinhaltet Videos, die die Rahmenbedingungen der Pr√ºfungsleistung vorstellt."
  },
  {
    "objectID": "030-Pruefung.html#plagiatskontrolle",
    "href": "030-Pruefung.html#plagiatskontrolle",
    "title": "3¬† Pr√ºfung",
    "section": "3.13 Plagiatskontrolle",
    "text": "3.13 Plagiatskontrolle\nDie eingereichten Arbeiten k√∂nnen automatisiert auf Plagiate √ºberpr√ºft werden. Gibt es substanzielle √úberschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungen√ºgend bewertet oder es folgt eine Abwertung der Note."
  },
  {
    "objectID": "030-Pruefung.html#footnotes",
    "href": "030-Pruefung.html#footnotes",
    "title": "3¬† Pr√ºfung",
    "section": "",
    "text": "https://link.springer.com/book/10.1007/978-3-658-21587-3‚Ü©Ô∏é\nhttps://www.tmwr.org/‚Ü©Ô∏é"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#lernsteuerung",
    "href": "040-Statistisches-Lernen.html#lernsteuerung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Vorbereitung\n\nLesen Sie die Hinweise zum Modul.\nInstallieren (oder Updaten) Sie die f√ºr dieses Modul angegeben Software. Lesen Sie die Literatur.\n\n4.1.2 Lernziele\n\nSie k√∂nnen erl√§utern, was man unter statistischem Lernen versteht. Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann. Sie kennen verschiedenen Arten von statistischem Lernen und k√∂nnen Algorithmen zu diesen Arten zuordnen.\n\n4.1.3 Literatur\n\nRhys, Kap. 1\nevtl. Sauer, Kap. 15\n\n4.1.4 Hinweise\n\nBitte beachten Sie die Hinweise zum Pr√§senzunterricht und der Streamingoption.\nBitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) l√§uft.\n\n4.1.5 R-Pakete\nBen√∂tigte R-Pakete f√ºr dieses Kapitel:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-data-science",
    "href": "040-Statistisches-Lernen.html#was-ist-data-science",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.2 Was ist Data Science?",
    "text": "4.2 Was ist Data Science?\nEs gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, und Horton (2017) definieren Data Science wie folgt (S. 4):\n\n\n\n\n\n\nHinweis\n\n\n\nThe science of extracting meaningful information from data.\\(\\square\\)\n\n\nAuf der anderen Seite entgegen viele Statistiker: ‚ÄúHey, das machen wir doch schon immer!‚Äù.\nEine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (‚ÄúDom√§ne‚Äù), die sozusagen den Empf√§nger bzw. die Kunden oder den Rahmen stellt. Dieser ‚ÄúDreiklang‚Äù ist in folgendem Venn-Diagramm dargestellt."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "href": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.3 Was ist Machine Learning?",
    "text": "4.3 Was ist Machine Learning?\n\nDefinition 4.1 Maschinelles Lernen (ML), oft auch (synonym) als statistisches Lernen (statistical learning) bezeichnet, ist ein Teilgebiet der k√ºnstlichen Intelligenz (KI; artificial intelligence, AI) (Rhys 2020). ML wird auch als data-based bezeichnet in Abgrenzung von rule-based, was auch als ‚Äúklassische KI‚Äù bezeichnet wird, vgl. Abbildung¬†4.1.\n\n\n\n\n\nflowchart LR\n  subgraph KI[K√ºnstliche Intelligenz KI]\n    rb[rule based]\n    db[data based]\n  end   \n\n\nAbbildung¬†4.1: KI und Maschinelles Lernen\n\n\n\n\nIn beiden F√§llen finden Algorithmen Verwendung.\n\nDefinition 4.2 (Algorithmus) Algorithmen sind nichts anderes als genaue Schritt-f√ºr-Schritt-Anleitungen, um etwas zu erledigen.\\(\\square\\)\n\n\nBeispiel 4.1 Ein Kochrezept ist ein klassisches Beispiel f√ºr einen Algorithmus.\\(\\square\\)\n\nHier findet sich ein Beispiel f√ºr einen einfachen Additionsalgorithmus.\nEs gibt viele ML-Algorithmen, vgl. Abbildung¬†4.2.\n\n\n\n\nflowchart LR\n  subgraph KI[KI]\n    subgraph ML[ML]\n      A[Regression]\n      B[Neuronale Netze]\n      C[weitere]\n    end\n  end\n\n\nAbbildung¬†4.2: ML-Matroschka\n\n\n\n\n\n4.3.1 Rule-based\nKlassische (√§ltere) KI implementiert Regeln ‚Äúhartverdrahtet‚Äù in ein Computersystem. Nutzer f√ºttern Daten in dieses System. Das System leitet dann daraus Antworten ab.\nRegeln kann man prototypisch mit Wenn-Dann-Abfragen darstellen:\n\nlernzeit &lt;- c(0, 10, 10, 20)\nschlauer_nebensitzer &lt;- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] &gt; 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}\n## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\n\nSicherlich k√∂nnte man das schlauer programmieren, vielleicht so:\n\nd &lt;- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %&gt;% \n  mutate(bestanden = ifelse(lernzeit &gt; 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))\n\n\n\n  \n\n\n\n\n4.3.2 Data-based\nML hat zum Ziel, Regeln aus den Daten zu lernen. Man f√ºttert Daten und Antworten in das System, das System gibt Regeln zur√ºck.\nJames u.¬†a. (2021) definieren ML so: Nehmen wir an, wir haben die abh√§ngige Variable \\(Y\\) und \\(p\\) Pr√§diktoren, \\(X_1,X_2, \\ldots, X_p\\). Weiter nehmen wir an, die Beziehung zwischen \\(Y\\) und \\(X = (X_1, X_2, \\ldots, X_p)\\) kann durch eine Funktion \\(f\\) beschrieben werden. Das kann man so darstellen:\n\\[Y = f(X) + \\epsilon\\]\nML kann man auffassen als eine Menge an Verfahren, um \\(f\\) zu sch√§tzen.\nEin Beispiel ist in Abb. Abbildung¬†4.3 gezeigt (James u.¬†a. 2021).\n\n\nAbbildung¬†4.3: Vorhersage des Einkommens durch Ausbildungsjahre\n\n\nNat√ºrlich kann \\(X\\) mehr als eine Variable beinhalten, vgl. Abbildung¬†4.4) (James u.¬†a. 2021).\n\n\nAbbildung¬†4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren\n\n\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gef√ºttert und liefern Antworten. ML-Systeme werden mit Daten und Antworten gef√ºttert und liefern Regeln zur√ºck, s. Abbildung¬†4.5.\n\n\n\n\nflowchart LR\n  subgraph rb[rule-based]\n  D[Daten] --&gt;A[Antworten]\n  R[Regeln] --&gt;A\n  end\n  subgraph db[data-based]\n  D2[Daten] --&gt; R2[Regeln]\n  A2[Antworten] --&gt; R2\n  end\n\n\nAbbildung¬†4.5: Vergleich von klassischer KI (rule-based) und ML (data-based)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "href": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.4 Modell vs.¬†Algorithmus",
    "text": "4.4 Modell vs.¬†Algorithmus\n\n4.4.1 Modell\nEin Modell, s. Abb. Abbildung¬†4.6) (Spurzem 2017)!\n\n\nAbbildung¬†4.6: Ein Modell-Auto\n\n\nWie man sieht, ist ein Modell eine vereinfachte Repr√§sentation eines Gegenstands.\nDer Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. Abbildung¬†4.7).\n\n\nAbbildung¬†4.7: Gegenstand und Modell\n\n\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln, die aus den Daten gelernt wurden.\n\n4.4.2 Beispiel f√ºr einen ML-Algorithmus\nUnter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren, anhand dessen die Beziehung zwischen \\(X\\) und \\(Y\\) ‚Äúgelernt‚Äù wird. Bei Rhys (2020) (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:\nBeispiel eines Regressionsalgorithmus\n\nSetze Gerade in die Daten mit \\(b_0 = \\hat{y}, b_1 = 0\\)\n\nBerechne \\(MSS = \\sum (y_i - \\hat{y_i})^2\\)\n\n‚ÄúDrehe‚Äù die Gerade ein bisschen, d.h. erh√∂he \\(b_1^{neu} = b_1^{alt} + 0.1\\)\n\nWiederhole 2-3 solange, bis \\(MSS &lt; \\text{Zielwert}\\)\n\n\nDiesen Algorithmus kann man ‚Äúvon Hand‚Äù z.B. mit dieser App durchspielen."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#taxonomie",
    "href": "040-Statistisches-Lernen.html#taxonomie",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.5 Taxonomie",
    "text": "4.5 Taxonomie\nMethoden des maschinellen Lernens lassen sich verschiedentlich gliedern. Eine typische Gliederung unterscheidet in supervidierte (geleitete) und nicht-supervidierte (ungeleitete) Algorithmen, s. Abb. Abbildung¬†4.8).\n\n\n\n\nflowchart LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --&gt; SL\n  ML --&gt; NSL\n  SL --&gt; Re\n  SL --&gt; Class\n  NSL --&gt; DimRed\n  NSL --&gt; Clust\n\n\n\nAbbildung¬†4.8: Taxonomie der Arten des maschinellen Lernens\n\n\n\n\n\n4.5.1 Geleitetes Lernen\nDie zwei Phasen des geleiteten Lernens sind in Abb. Abbildung¬†4.9) dargestellt.\n\n\n\n\nflowchart TD\n  subgraph A[Lernphase]\n    B[Daten mit Antwort] --&gt; C[Geleiteter Algorithmus]\n    C --&gt; D[Modell]\n  end\n  subgraph E[Vorhersagephase]\n    H[Neue Daten ohne Antwort] --&gt; F[Modell]\n    F --&gt; G[Antworten]\n  end\n  A--&gt;E\n\n\nAbbildung¬†4.9: Geleitetes Lernen geschieht in zwei Phasen\n\n\n\n\n\n4.5.1.1 Regression: Numerische Vorhersage\n\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n\n\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden G√ºtekoeffizienten gemessen:\n\nMean Squared Error (Mittlerer Quadratfehler):\n\n\\[MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\]\n\nMean Absolute Error (Mittlerer Absolutfehler):\n\n\\[MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|\\]\n\nWir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzusch√§tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.\n\n\n4.5.1.2 Klassifikation: Nominale Vorhersage\n\n\nBei einer Klassifikation wird nicht eine Zahl, sondern eine Klasse vorhergesagt\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit folgendem G√ºtekoeffizienten gemessen:\n\nMittlerer Klassifikationfehler \\(e\\):\n\n\\[e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) \\]\nDabei ist \\(I\\) eine Indikatorfunktion, die 1 zur√ºckliefert, wenn tats√§chlicher Wert und vorhergesagter Wert identisch sind.\n\n4.5.2 Ungeleitetes Lernen\nDie zwei Phasen des ungeleiteten Lernens sind in Abbildung¬†4.10 dargestellt.\n\n\n\n\nflowchart LR\n  subgraph X[Lernphase]\n    A[Daten ohne Antwort] --&gt; B[Ungeleiteter Algorithmus]\n    B --&gt; C[Modell]\n  end\n  subgraph D[Vorhersagephase]\n    E[Neue Daten, ohne Antwort] --&gt; C2[Modell]\n    C2 --&gt; F[Zuordnung zu den Regeln des Modells]\n  end  \n  X---&gt;D\n\n\nAbbildung¬†4.10: Die zwei Phasen des un√ºberwachten Lernens\n\n\n\n\nUngeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. Abbildung¬†4.11):\n\nFallreduzierendes Modellieren (Clustering)\nDimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\n\n\n\nAbbildung¬†4.11: Zwei Arten des ungeleitete Modellieren"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#ziele-des-ml",
    "href": "040-Statistisches-Lernen.html#ziele-des-ml",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.6 Ziele des ML",
    "text": "4.6 Ziele des ML\nMan kann vier Ziele des ML unterscheiden, s. Abbildung¬†4.12.\n\n\n\n\nflowchart TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[Erkl√§rung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --&gt; V\n  ML --&gt; E\n  ML --&gt; B\n  ML --&gt; DimRed\n\n\nAbbildung¬†4.12: Ziele des maschinellen Lernens\n\n\n\n\nVorhersage bezieht sich auf die Sch√§tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit). Erkl√§rung meint die kausale Analyse von Zusammenh√§ngen. Beschreibung ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken. Dimensionsreduktion ist ein Oberbegriff f√ºr Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s\nWie ‚Äúgut‚Äù ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellg√ºte oder model fit. Je schlechter die Modellg√ºte, desto h√∂her der Modellfehler, vgl. Abbildung¬†4.13.\n\n\nAbbildung¬†4.13: Wenig (links) vs.¬†viel (rechts) Vorhersagefehler\n\n\nDie Modellg√ºte eines Modells ist v.a. relevant f√ºr neue Beobachtungen, an denen das Modell nicht trainiert wurde."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#√ºber--vs.-unteranpassung",
    "href": "040-Statistisches-Lernen.html#√ºber--vs.-unteranpassung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.7 √úber- vs.¬†Unteranpassung",
    "text": "4.7 √úber- vs.¬†Unteranpassung\n\nDefinition 4.3 (Overfitting) Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als ‚Äúbare M√ºnze‚Äù, also f√§lschlich als Signal. Solche Modelle haben zu viel Varianz in ihren Vorhersagen.\\(\\square\\)\n\n\nDefinition 4.4 (Underfitting) Ein Modell ist zu simpel (ungenau, grobk√∂rnig) - es unterschl√§gt Nuancen des tats√§chlichen Musters. Solche Modelle haben zu viel Verzerrung (Bias) in ihren Vorhersagen.\\(\\square\\)\n\nWelches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. Abbildung¬†4.14), vgl. (Sauer 2019), Kap. 15?\n\n\n\n\nAbbildung¬†4.14: Over- vs.¬†Underfitting\n\n\n\n\nWelches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?\nModell D zeigt sehr gute Beschreibung (‚ÄúRetrodiktion‚Äù) der Werte, anhand derer das Modell trainiert wurde (‚ÄúTrainingsstichprobe‚Äù). Wird es aber ‚Äúehrlich‚Äù getestet, d.h. anhand neuer Daten (‚ÄúTest-Stichprobe‚Äù), wird es vermutlich nicht so gut abschneiden.\nEs gilt, ein Modell mit ‚Äúmittlerer‚Äù Komplexit√§t zu finden, um √úber- und Unteranpassung in Grenzen zu halten. Leider ist es nicht m√∂glich, vorab zu sagen, was der richtige, ‚Äúmittlere‚Äù Wert an Komplexit√§t eines Modells ist, vgl. Abbildung¬†4.15 aus (Sauer 2019).\n\n\nAbbildung¬†4.15: Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte: Gute Balance von Bias und Pr√§zision\n\n\n\n4.7.1 Do-it-yourself Under-/Overfitting\nErkunden wir die Effekte von Under- und Overfitting an einem einfachen, simulierten Datenbeispiel:\n\nd &lt;- tibble(\n  x = -2:2,\n  y = c(-1, -.5, 0, 0.1, 2)\n)\n\nJetzt ‚Äúfitten‚Äù wir eine zunehmend komplexe Funktion in diese Daten. Als Funktion w√§hlen wir ein Polynom von Grad 1 bis 4.\n\nEin Polynom 1. Grades ist eine lineare Funktion: \\(y \\sim x¬π\\).\nEin Polynom 2. Grades ist eine quadratische Funktion: \\(y \\sim x¬≤ + x\\)\n\nEin Polynom \\(n\\). Grades ist eine Funktion der Form \\(y \\sim x^n + x^{n-1} + x^{n-2} + \\ldots + x\\)\n\n\nPolynome werden flexibler (mehr ‚ÄúT√§ler‚Äù und ‚ÄúGipfel‚Äù haben), je h√∂her ihr Grad ist. Daher stellt sich die Frage, welcher Grad der ‚Äúrichtige‚Äù ist. Leider wissen wir in der Praxis nicht, welche Funktion die Natur ausgew√§hlt hat. Daher w√§re eine L√∂sung, die Funktion auszuw√§hlen, welche die Daten am besten erkl√§rt.\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE)\n\n\n\n\n\n(a) Grad 1\n\n\n\n\n\n\n(b) Grad 2\n\n\n\n\n\n\n\n\n(c) Grad 3\n\n\n\n\n\n\n(d) Grad 4\n\n\n\n\nAbbildung¬†4.16: Polynome vom Grad 1-4\n\n\n\nWie man sieht, wird der Modellfehler immer kleiner, der ‚ÄúFit‚Äù zunehmens besser.\nDas kann man sich nat√ºrlich auch pr√§ziser berechnen lassen.\n\nlm1 &lt;- lm(y ~ poly(x, 1), data = d)\nlm2 &lt;- lm(y ~ poly(x, 2), data = d)\nlm3 &lt;- lm(y ~ poly(x, 3), data = d)\nlm4 &lt;- lm(y ~ poly(x, 4), data = d)\n\nresults &lt;-\n  tibble(r2_lm1 = r2(lm1)$R2,\n         r2_lm2 = r2(lm2)$R2,\n         r2_lm3 = r2(lm3)$R2,\n         r2_lm4 = r2(lm4)$R2)\n\nresults\n\n\n\n  \n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nJe komplexer das Modell, desto besser der Fit1 in dem Modell, in das Modell berechnet wurde.\n\n\nAber wie gut werden die Vorhersagen f√ºr neue Daten sein?\nSagen wir, in Wirklichkeit ist der datengenerierende Prozess2 (DGP) eine einfache lineare Funktion, plus etwas Rauschen (Fehler, \\(\\epsilon\\)):\n\\(y \\sim x + \\epsilon\\)\nSagen wir, das Rauschen ist normalverteilt mit Streuung 0.5.\nSimulieren wir uns jetzt ein paar neue Daten, die aus dieser Funktion resultieren.\n\nd1 &lt;- tibble(\n  x = -2:2,\n  e = rnorm(n = 5, mean = 0, sd = .5), \n  y = x,  # \"wahrer\" Wert\n  y_hat = y + e  # beobachteter Wert mit Rauschen\n)\n\nd1\n\n\n\n  \n\n\n\n\nDefinition 4.5 (Train- und Test-Datensatz) Den Datensatz, in dem man ein Modell berechnet (‚Äúfittet‚Äù), nennt man auch Train-Datensatz. Einen anderen Datensatz, den man nutzt, um die G√ºte des Modells zu √ºberpr√ºfen, nennt man Test-Datensatz\n\nDamit wir eine stabilere Datenbasis haben, simulieren wir aber pro X-Wert (-2, -1, 0, 1, 2) nicht nur einen Wert, sondern, sagen wir, 10:\n\nd2 &lt;- \n  tibble(\n    x = rep(-2:2, times = 10),\n    e = rnorm(n = 50, mean = 0, sd = .5),  # Rauschen, Fehlerterm\n    y_hat = x,  # \"wahrer\" Wert\n    y = x + e  # beobachteter Wert mit Rauschen\n  )\n\nd2\n\n\n\n  \n\n\n\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE) +\n  geom_point(data = d2, color = \"blue\") \n\n\n\nAbbildung¬†4.17: In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut\n\n\n\n\nJetzt sieht das R-Quadrat schon nicht mehr so gut aus, s. Abbildung¬†4.17. Berechnen wir mal das R-Quadrat:\n\nrsq(data = d2, truth = y, estimate = y_hat)\n\n\n\n  \n\n\n\n\n√úbungsaufgabe 4.1 (Overfitting) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine einfache lineare Funktion sein (Polynom 1. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)\n\n\n√úbungsaufgabe 4.2 (Overfitting 2) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine Polynomfunktion sein (Polynom 2. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#no-free-lunch",
    "href": "040-Statistisches-Lernen.html#no-free-lunch",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.8 No free lunch",
    "text": "4.8 No free lunch\n\n\nYoda meint: Es gibt nicht ‚Äúdas‚Äù beste Modell\n\n\nQuelle: ImgFlip Meme Generator\nWenn \\(f\\) (die Beziehung zwischen \\(Y\\) und \\(X\\), auch datengenerierender Prozess genannt) linear oder fast linear ist, dann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. @ref(fig:2-10) aus James u.¬†a. (2021), dort zeigt die schwarze Linie den ‚Äúwahren Zusammenhang‚Äù, also \\(f\\) an. In orange sieht man ein lineares Modell, in gr√ºn ein hoch komplexes Modell, das sich in einer ‚Äúwackligen‚Äù Funktion - also mit hoher Varianz - niederschl√§gt. Das gr√ºne Modell k√∂nnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \\(y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon\\). Das lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias. Daher ist es f√ºr dieses \\(f\\) gut passend. Die gr√ºne Funktion zeigt dagegen √úberanpassung (overfitting), also viel Modellfehler (f√ºr eine Test-Stichprobe).\n\n\n\n\n\n\nVorsicht\n\n\n\nDie gr√ºne Funktion in Abbildung¬†4.18 wird neue, beim Modelltraining unbekannte Beobachtungen (\\(y_0\\)) vergleichsweise schlecht vorhersagen. In Abbildung¬†4.19 ist es umgekehrt.\n\n\n\n\nAbbildung¬†4.18: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren\n\n\nBetrachten wir im Gegensatz dazu Abbildung¬†4.19 aus James u.¬†a. (2021), die (in schwarz) eine hochgradig nichtlineare Funktion \\(f\\) zeigt. Entsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. Ein lineares Modell wird der Komplexit√§t von \\(f\\) nicht gerecht, Unteranpassung (underfitting) liegt vor.\n\n\nAbbildung¬†4.19: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#bias-varianz-abw√§gung",
    "href": "040-Statistisches-Lernen.html#bias-varianz-abw√§gung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.9 Bias-Varianz-Abw√§gung",
    "text": "4.9 Bias-Varianz-Abw√§gung\nDer Gesamtfehler \\(E\\) des Modells ist die Summe dreier Terme:\n\\[E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon\\]\nDabei meint \\(\\epsilon\\) den nicht reduzierbaren Fehler, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).\nBias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. Abbildung¬†4.20 aus Sauer (2019).\n\n\nAbbildung¬†4.20: Abw√§ngung von Bias vs.¬†Varianz"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#vertiefung",
    "href": "040-Statistisches-Lernen.html#vertiefung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.10 Vertiefung",
    "text": "4.10 Vertiefung\n\nVerdienst einer deutschen Data Scientistin\nWeitere Fallstudie zum Thema Regression auf Kaggle\nCrashkurs Data Science (Coursera, Johns Hopkins University) mit ‚ÄòStar-Dozenten‚Äô\nArbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf\nWerfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise\nWiederholen Sie unser Vorgehen in der Fallstudie zu den Flugversp√§tungen"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#aufgaben",
    "href": "040-Statistisches-Lernen.html#aufgaben",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.11 Aufgaben:",
    "text": "4.11 Aufgaben:\n\nMachen Sie sich mit ‚ÄòKaggle‚Äô vertraut\nBearbeiten Sie die Fallstudie ‚ÄòTitaRnic‚Äô auf Kaggle\nMachen Sie sich mit dieser einfachen Fallstudie zur linearen Regression vertraut: The Movie Data Base Revenue (Kaggle)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#videos",
    "href": "040-Statistisches-Lernen.html#videos",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.12 Videos",
    "text": "4.12 Videos\n\nPrognose-Wettbewerbe bei Kaggle am Beispiel von The Movie Data Base Revenue\n\n\n\n\n\nBaumer, Benjamin S., Daniel T. Kaplan, und Nicholas J. Horton. 2017. Modern Data Science with R (Chapman & Hall/CRC Texts in Statistical Science). Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#footnotes",
    "href": "040-Statistisches-Lernen.html#footnotes",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "",
    "text": "ceteris paribus‚Ü©Ô∏é\ndata-generating process, DGP‚Ü©Ô∏é"
  },
  {
    "objectID": "050-R-Vertiefung.html#lernsteuerung",
    "href": "050-R-Vertiefung.html#lernsteuerung",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Literatur\n\nRhys, Kap. 2\nMODAR, Kap. 5\n\n5.1.2 Lernziele\n\nSie k√∂nnen Funktionen, in R schreiben.\nSie k√∂nnen Datens√§tze vom Lang- und Breit-Format wechseln.\nSie k√∂nnen Wiederholungsstrukturen wie Mapping-Funktionen anwenden.\nSie k√∂nnen eine dplyr-Funktion auf mehrere Spalten gleichzeitig anwenden.\n\n5.1.3 Vorbereitung\n\nLesen Sie die Literatur."
  },
  {
    "objectID": "050-R-Vertiefung.html#objekttypen-in-r",
    "href": "050-R-Vertiefung.html#objekttypen-in-r",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.2 Objekttypen in R",
    "text": "5.2 Objekttypen in R\nN√§heres zu Objekttypen findet sich in Sauer (2019), Kap. 5.2.\n\n5.2.1 √úberblick\nIn R ist praktisch alles ein Objekt.\n\nDefinition 5.1 (Objekt (Informatik)) Ein Objekt meint ein im Computerspeicher repr√§sentiertes Ding, etwa eine Tabelle.\\(\\square\\)\n\n\nBeispiel 5.1 (Beispiele f√ºr Objekte) Vektoren und Dataframes (Tibbles) sind die vielleicht g√§ngigsten Objektarten in R (vgl. Abbildung¬†5.1), aus Sauer (2019)).\\(\\square\\)\n\n\n\nAbbildung¬†5.1: Zentrale Objektarten in R\n\n\nEs gibt in R keine (Objekte f√ºr) Skalare (einzelne Zahlen). Stattdessen nutzt R Vektoren der L√§nge 1.\nEin n√ºtzliches Schema stammt aus Wickham und Grolemund (2016), s. Abbildung¬†5.2).\n\n\nAbbildung¬†5.2: Objektarten hierarchisch gegliedert\n\n\n\n5.2.2 Taxonomie\nUnter homogenen Objektiven verstehen wir Datenstrukturen, die nur eine Art von Daten (wie Text oder Ganze Zahlen) fassen. Sonstige Objekte nennen wir heterogen.\n\nHomogene Objekte\n\nVektoren\nMatrizen\n\n\nHeterogen\n\nListe\nDataframes (Tibbles)\n\n\n\n\n5.2.2.1 Vektoren\nVektoren sind insofern zentral in R, als dass die √ºbrigen Datenstrukturen auf ihnen aufbauen, vgl. Abbildung¬†5.3 aus Sauer (2019).\nReine (atomare) Vektoren in R sind eine geordnete Liste von Daten eines Typs.\n\n\nAbbildung¬†5.3: Vektoren stehen im Zentrum der Datenstrukturen in R\n\n\n\nein_vektor &lt;- c(1, 2, 3)\nnoch_ein_vektor &lt;- c(\"A\", \"B\", \"C\")\nlogischer_vektor &lt;- c(TRUE, FALSE, TRUE)\n\nMit str() kann man sich die Struktur eines Objektsausgeben lassen:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\nstr(noch_ein_vektor)\n##  chr [1:3] \"A\" \"B\" \"C\"\nstr(logischer_vektor)\n##  logi [1:3] TRUE FALSE TRUE\n\nVektoren k√∂nnen von folgenden Typen sein:\n\nKommazahlen ( double) genannt\nGanzzahlig (integer, auch mit L f√ºr Long abgek√ºrzt)\nText (¬¥character`, String)\nlogische Ausdr√ºcke (logical oder lgl) mit TRUE oder FALSE\n\n\nKommazahlen und Ganze Zahlen zusammen bilden den Typ numeric (numerisch) in R.\nDen Typ eines Vektors kann man mit typeof() ausgeben lassen:\n\ntypeof(ein_vektor)\n## [1] \"double\"\n\n\n5.2.2.2 Faktoren\n\nsex &lt;- factor(c(\"Mann\", \"Frau\", \"Frau\"))\n\nInteressant:\n\nstr(sex)\n##  Factor w/ 2 levels \"Frau\",\"Mann\": 2 1 1\n\nVertiefende Informationen findet sich in Wickham und Grolemund (2016).\n\n5.2.2.3 Listen\n\neine_liste &lt;- list(titel = \"Einf√ºhrung\",\n                   woche = 1,\n                   datum = c(\"2022-03-14\", \"2202-03-21\"),\n                   lernziele = c(\"dies\", \"jenes\", \"und noch mehr\"),\n                   lehre = c(TRUE, TRUE, TRUE)\n                   )\nstr(eine_liste)\n## List of 5\n##  $ titel    : chr \"Einf√ºhrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\n\n5.2.2.4 Tibbles\nF√ºr tibble() brauchen wir tidyverse:\n\nlibrary(tidyverse)\n\n\n\nstudentis &lt;-\n  tibble(\n    name = c(\"Anna\", \"Berta\"),\n    motivation = c(10, 20),\n    noten = c(1.3, 1.7)\n  )\nstr(studentis)\n## tibble [2 √ó 3] (S3: tbl_df/tbl/data.frame)\n##  $ name      : chr [1:2] \"Anna\" \"Berta\"\n##  $ motivation: num [1:2] 10 20\n##  $ noten     : num [1:2] 1.3 1.7\n\n\n5.2.3 Indizieren\nEinen Teil eines Objekts auszulesen, bezeichnen wir als Indizieren.\n\n5.2.3.1 Reine Vektoren\nZur Erinnerung:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\n\n\nein_vektor[1]\n## [1] 1\nein_vektor[c(1,2)]\n## [1] 1 2\n\nAber nicht so:\n\nein_vektor[1,2]\n## Error in ein_vektor[1, 2]: incorrect number of dimensions\n\nMan darf Vektoren auch wie Listen ansprechen, also eine doppelte Eckklammer zum Indizieren verwenden\n\nein_vektor[[2]]\n## [1] 2\n\nDer Grund ist, dass Listen auch Vektoren sind, nur eben ein besonderer Fall eines Vektors:\n\nis.vector(eine_liste)\n## [1] TRUE\n\nWas passiert, wenn man bei einem Vektor der L√§nge 3 das 4. Element indiziert?\n\nein_vektor[4]\n## [1] NA\n\nEin schn√∂des NA ist die Antwort. Das ist interessant: Wir bekommen keine Fehlermeldung, sondern den Hinweis, das angesprochene Element sei leer bzw. nicht verf√ºgbar.\nIn Sauer (2019), Kap. 5.3.1 findet man weitere Indizierungsm√∂glichkeiten f√ºr reine Vektoren.\n\n5.2.3.2 Listen\n\neine_liste %&gt;% str()\n## List of 5\n##  $ titel    : chr \"Einf√ºhrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\nListen k√∂nnen wie Vektoren, also mit [ ausgelesen werden. Dann wird eine Liste zur√ºckgegeben.\n\neine_liste[1]\n## $titel\n## [1] \"Einf√ºhrung\"\neine_liste[2]\n## $woche\n## [1] 1\n\nDas hat den technischen Hintergrund, dass Listen als eine bestimmte Art von Vektoren implementiert sind.\nMann kann auch die ‚Äúdoppelte Eckklammer‚Äù, [[ zum Auslesen verwenden; dann wird anstelle einer Liste die einfachere Struktur eines Vektors zur√ºckgegeben:\n\neine_liste[[1]]\n## [1] \"Einf√ºhrung\"\n\nMan k√∂nnte sagen, die ‚Äú√§u√üere Schicht‚Äù des Objekts, die Liste, wird abgesch√§lt, und man bekommnt die ‚Äúinnere‚Äù Schicht, den Vektor.\nMann die Elemente der Liste entweder mit ihrer Positionsnummer (1, 2, ‚Ä¶) oder, sofern vorhanden, ihren Namen ansprechen:\n\neine_liste[[\"titel\"]]\n## [1] \"Einf√ºhrung\"\n\nDann gibt es noch den Dollar-Operator, mit dem Mann benannte Elemente von Listen ansprechen kann:\n\neine_liste$titel\n## [1] \"Einf√ºhrung\"\n\nMan kann auch tiefer in eine Liste hinein indizieren. Sagen wir, uns interessiert das 4. Element der Liste eine_liste - und davon das erste Element.\nDas geht dann so:\n\neine_liste[[4]][[1]] \n## [1] \"dies\"\n\nEine einfachere Art des Indizierens von Listen bietet die Funktion pluck(), aus dem Paket purrr, das Hilfen f√ºr den Umgang mit Listen bietet.\n\npluck(eine_liste, 4)\n## [1] \"dies\"          \"jenes\"         \"und noch mehr\"\n\nUnd jetzt aus dem 4. Element das 1. Element:\n\npluck(eine_liste, 4, 1)\n## [1] \"dies\"\n\nProbieren Sie mal, aus einer Liste der L√§nge 5 das 6. Element auszulesen:\n\neine_liste %&gt;% length()\n## [1] 5\n\n\neine_liste[[6]]\n## Error in eine_liste[[6]]: subscript out of bounds\n\nUnser Versuch wird mit einer Fehlermeldung quittiert.\nSprechen wir die Liste wie einen (atomaren) Vektor an, bekommen wir hingegen ein NA bzw. ein NULL:\n\neine_liste[6]\n## $&lt;NA&gt;\n## NULL\n\n\n5.2.3.3 Tibbles\nTibbles lassen sich sowohl wie ein Vektor als auch wie eine Liste indizieren.\n\nstudentis[1]\n\n\n\n  \n\n\n\nDie Indizierung eines Tibbles mit der einfachen Eckklammer liefert einen Tibble zur√ºck.\n\nstudentis[\"name\"]\n\n\n\n  \n\n\n\nMit doppelter Eckklammer bekommt man, analog zur Liste, einen Vektor zur√ºck:\n\nstudentis[[\"name\"]]\n## [1] \"Anna\"  \"Berta\"\n\nBeim Dollar-Operator kommt auch eine Liste zur√ºck:\n\nstudentis$name\n## [1] \"Anna\"  \"Berta\"\n\n\n5.2.4 Weiterf√ºhrende Hinweise\n\n\nTutorial zum Themen Indizieren von Listen von Jenny BC.\n\n5.2.5 Indizieren mit dem Tidyverse\nNat√ºrlich kann man auch die Tidyverse-Verben zum Indizieren verwenden. Das bietet sich an, wenn zwei Bedingungen erf√ºllt sind:\n\nWenn man einen Tibble als Input und als Output hat\nWenn man nicht programmieren m√∂chte"
  },
  {
    "objectID": "050-R-Vertiefung.html#datens√§tze-von-lang-nach-breit-umformatieren",
    "href": "050-R-Vertiefung.html#datens√§tze-von-lang-nach-breit-umformatieren",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.3 Datens√§tze von lang nach breit umformatieren",
    "text": "5.3 Datens√§tze von lang nach breit umformatieren\nManchmal findet man Datens√§tze im sog. langen Format vor, manchmal im breiten.\nIn der Regel m√ºssen die Daten ‚Äútidy‚Äù sein, was meist dem langen Format entspricht, vgl. Abbildung¬†5.4 aus Sauer (2019).\n\n\nAbbildung¬†5.4: Von lang nach breit und zur√ºck\n\n\nIn einer neueren Version des Tidyverse werden diese beiden Befehle umbenannt bzw. erweitert, s. Abbildung¬†5.5.\n\n\ngather() -&gt; pivot_longer()\n\n\nspread() -&gt; pivot_wider()\n\n\n\n\nAbbildung¬†5.5: Von ‚Äúweit‚Äù zu ‚Äúbreit‚Äù und zur√ºck, eine Animation\n\n\nWeitere Informationen findet sich in Wickham und Grolemund (2016), in diesem Abschnitt, 12.3."
  },
  {
    "objectID": "050-R-Vertiefung.html#funktionen",
    "href": "050-R-Vertiefung.html#funktionen",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.4 Funktionen",
    "text": "5.4 Funktionen\nEine Funktion kann man sich als analog zu einer Variable vorstellen. Es ist ein Objekt, das nicht Daten, sondern Syntax beinhaltet, vgl. Abbildung¬†5.6 aus Sauer (2019).\n\n\nAbbildung¬†5.6: Sinnbild einer Funktion\n\n\n\nmittelwert &lt;- function(x){\n  \n  summe &lt;- sum(x, na.rm = TRUE)\n  mw &lt;- summe/length(x)\n  return(mw)\n  \n}\n\n\nmittelwert(c(1, 2, 3))\n## [1] 2\n\nWeitere Informationen finden sich in Kapitel 19 in Wickham und Grolemund (2016). Alternativ findet sich ein Abschnitt dazu (28.1) in Sauer (2019)."
  },
  {
    "objectID": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "href": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.5 Wiederholungen programmieren",
    "text": "5.5 Wiederholungen programmieren\nH√§ufig m√∂chte man eine Operation mehrfach ausf√ºhren. Ein Beispiel w√§re die Anzahl der fehlenden Werte pro Spalte auslesen. Nat√ºrlich kann man die Abfrage einfach h√§ufig tippen, nervt aber irgendwann. Daher braucht‚Äôs Strukturen, die Wiederholungen beschreiben.\nDaf√ºr gibt es verschiedene Ans√§tze.\n\n5.5.1 across()\n\nHandelt es sich um Spalten von Tibbles, dann bietet sich die Funktion across(.col, .fns) an. across wendet eine oder mehrere Funktionen (mit .fns bezeichnet) auf die Spalten .col an.\nDas erkl√§rt sich am besten mit einem Beispiel:\nNat√ºrlich h√§tte man in diesem Fall auch anders vorgehen k√∂nnen:\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = mean))\n\n\n\n  \n\n\n\nM√∂chte man der Funktion .fns Parameter √ºbergeben, so nutzt man diese Syntax (‚ÄúPurrr-Lambda‚Äù):\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = ~ mean(., na.rm = TRUE)))\n\n\n\n  \n\n\n\nHier findet sich ein guter √úberblick zu across().\n\n5.5.2 map()\n\nmap() ist eine Funktion aus dem R-Paket purrr und Teil des Tidyverse.\nmap(x, f) wenden die Funktion f auf jedes Element von x an. Ist x ein Tibble, so wird f demnach auf jede Spalte von x angewendet (‚Äúzugeordnet‚Äù, daher map), vgl. Abbildung¬†5.7 aus Sauer (2019).\n\n\nAbbildung¬†5.7: Sinnbild f√ºr map aus purrr\n\n\nHier ein Beispiel-Code:\n\ndata(mtcars)\n\nmtcars &lt;- mtcars %&gt;% select(1:3)  # nur die ersten 3 Spalten\n\nmap(mtcars, mean)\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\nM√∂chte man der gemappten Funktion Parameter √ºbergeben, nutzt man wieder die ‚ÄúKringel-Schreibweise‚Äù:\n\nmap(mtcars, ~ mean(., na.rm = TRUE))\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\n\n5.5.3 Weiterf√ºhrende Hinweise\nWeiteres zu map() findet sich z.B. in Wickham und Grolemund (2016), Kapitel 21.5 oder in Sauer (2019), Kap. 28.2.\nTutorial zu map() von Jenny BC."
  },
  {
    "objectID": "050-R-Vertiefung.html#listenspalten",
    "href": "050-R-Vertiefung.html#listenspalten",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.6 Listenspalten",
    "text": "5.6 Listenspalten\n\n5.6.1 Wozu Listenspalten?\nListenspalten sind immer dann sinnvoll, wenn eine einfache Tabelle nicht komplex genug f√ºr unsere Daten ist.\nZwei F√§lle stechen dabei ins Auge:\n\nUnsere Datenstruktur ist nicht rechteckig\nIn einer Zelle der Tabelle soll mehr als ein einzelner Wert stehen: vielleicht ein Vektor, eine Liste oder eine Tabelle\n\nDer erstere Fall (nicht reckeckig) lie√üe sich noch einfach l√∂sen, in dem man mit NA auff√ºllt.\nDer zweite Fall verlangt schlichtweg nach komplexeren Datenstrukturen.\nKap. 25.3 aus Wickham und Grolemund (2016) bietet einen guten Einstieg in das Konzept von Listenspalten (list-columns) in R.\n\n5.6.2 Beispiele f√ºr Listenspalten\n\n5.6.2.1 tidymodel\nWenn wir mit tidymodels arbeiten, werden wir mit Listenspalten zu tun haben. Daher ist es praktisch, sich schon mal damit zu besch√§ftigen.\nHier ein Beispiel f√ºr eine \\(v=3\\)-fache Kreuzvalidierung:\n\nlibrary(tidymodels)\nmtcars_cv &lt;-\n  vfold_cv(mtcars, v = 3)\n\nmtcars_cv\n\n\n\n  \n\n\n\nBetrachten wir das Objekt mtcars_cv n√§her. Die Musik spielt in der 1. Spalte.\nLesen wir den Inhalt der 1. Spalte, 1 Zeile aus (nennen wir das mal ‚ÄúPosition 1,1‚Äù):\n\npos11 &lt;- mtcars_cv[[1]][[1]]\npos11\n## &lt;Analysis/Assess/Total&gt;\n## &lt;21/11/32&gt;\n\nIn dieser Zelle findet sich eine Aufteilung des Komplettdatensatzes in den Analyseteil (Analysis sample) und den Assessmentteil (Assessment Sample).\nSchauen wir jetzt in dieses Objekt n√§her an. Das k√∂nnen wir mit str() tun. str() zeigt uns die Strktur eines Objekts.\n\nstr(pos11)\n## List of 4\n##  $ data  :'data.frame':  32 obs. of  3 variables:\n##   ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n##   ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n##   ..$ disp: num [1:32] 160 160 108 258 360 ...\n##  $ in_id : int [1:21] 1 2 3 4 6 7 9 10 11 12 ...\n##  $ out_id: logi NA\n##  $ id    : tibble [1 √ó 1] (S3: tbl_df/tbl/data.frame)\n##   ..$ id: chr \"Fold1\"\n##  - attr(*, \"class\")= chr [1:2] \"vfold_split\" \"rsplit\"\n\nOh! pos11 ist eine Liste, und zwar eine durchaus komplexe. Wir m√ºssen erkennen, dass in einer einzelnen Zelle dieses Dataframes viel mehr steht, als ein Skalar bzw. ein einzelnes, atomares Element.\nDamit handelt es sich bei Spalte 1 dieses Dataframes (mtcars_cv) also um eine Listenspalte.\n√úben wir uns noch etwas im Indizieren.\nSprechen wir in pos11 das erste Element an (data) und davon das erste Element:\n\npos11[[\"data\"]][[1]]\n##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n## [31] 15.0 21.4\n\nWir haben hier die doppelten Eckklammern benutzt, um den ‚Äúeigentlichen‚Äù oder ‚Äúinneren‚Äù Vektor zu bekommen, nicht die ‚Äúau√üen‚Äù herumgewickelte Liste. Zur Erinnerung: Ein Dataframe ist ein Spezialfall einer Liste, also auch eine Liste, nur eine mit bestimmten Eigenschaften.\nZum Vergleich indizieren wir mal mit einer einfachen Eckklammer:\n\npos11[[\"data\"]][1] %&gt;% \n  head()\n\n\n\n  \n\n\n\nMit pluck() bekommen wir das gleiche Ergebnis, nur etwas komfortabler, da wir keine Eckklammern tippen m√ºssen:\n\npluck(pos11, \"data\", 1, 1)\n## [1] 21\n\nWie man sieht, k√∂nnen wir beliebig tief in das Objekt hineinindizieren.\n\n5.6.3 Programmieren mit dem Tidyverse\nDas Programmieren mit dem Tidyvers ist nicht ganz einfach und hier nicht n√§her ausgef√ºhrt. Eine Einf√ºhrung findet sich z.B.\n\nTidyeval in f√ºnf Minuten (Video)\nIn Kapiteln 17-21 in Advanced R, 2nd Ed\n\nEin √úberblicksdiagramm findet sich hier Quelle."
  },
  {
    "objectID": "050-R-Vertiefung.html#r-ist-schwierig",
    "href": "050-R-Vertiefung.html#r-ist-schwierig",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.7 R ist schwierig",
    "text": "5.7 R ist schwierig\nManche behaupten, R sei ein Inferno.\nZum Gl√ºck gibt es auch aufmunternde Stimmen:\n\npraise::praise()\n## [1] \"You are luminous!\"\n\nHat jemand einen guten Rat f√ºr uns? Vielleicht ist der h√§ufigste Rat, dass man die Dokumentation lesen solle."
  },
  {
    "objectID": "050-R-Vertiefung.html#aufgaben",
    "href": "050-R-Vertiefung.html#aufgaben",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\n\nFallstudie Flugversp√§tungen\nFallstudie Getreideernte"
  },
  {
    "objectID": "050-R-Vertiefung.html#vertiefung",
    "href": "050-R-Vertiefung.html#vertiefung",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\n\nFunktionale Programmierung mit R\nLernen Sie Wiederholungsstrukturen mit ggplot\n\n\n\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nWickham, Hadley, und Garrett Grolemund. 2016. R for Data Science: Visualize, Model, Transform, Tidy, and Import Data. O‚ÄôReilly Media. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "060-tidymodels.html#lernsteuerung",
    "href": "060-tidymodels.html#lernsteuerung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\n\nSie sind in der Lage, Regressionsmodelle mit dem tidymodels-Ansatz zu spezifizieren.\nSie k√∂nnen Begriffe des statistischen Lernens in das Vokabular von tidymodels √ºbersetzen."
  },
  {
    "objectID": "060-tidymodels.html#vorbereitung",
    "href": "060-tidymodels.html#vorbereitung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.2 Vorbereitung",
    "text": "6.2 Vorbereitung\n\nLesen Sie TMWR, Kapitel 1\n\nLesen Sie √ºbrige Literatur zu diesem Thema: TMWR, Kap. 1, 5, 6, 7, 8, 9\n\n\n6.2.1 Ben√∂tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ntidymodels ist ein Metapaket: Ein (R-)Paket, das mehrere andere Paket startet und uns damit das Leben einfacher macht. Eine Liste der R-Pakete, die durch tidymodels gestartet werden, findet sich hier. Probieren Sie auch mal ?tidymodels.\nEine Liste aller Pakete, die in Tidymodels benutzt werden, die dependencies, kann man sich so ausgeben lassen:\n\npkg_deps(x = \"tidymodels\", recursive = FALSE)"
  },
  {
    "objectID": "060-tidymodels.html#daten",
    "href": "060-tidymodels.html#daten",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.3 Daten",
    "text": "6.3 Daten\nDieser Abschnitt bezieht sich auf Kapitel 4 in Silge und Kuhn (2022).\nWir benutzen den Datensatz zu Immobilienpreise aus dem Ames County in Iowa, USA, gelegen im Zentrum des Landes.\n\ndata(ames)  # Daten wurden √ºber tidymodels mit geladen\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price))\n\nHier wurde die AV log-transformiert. Das hat zwei (wichtige) Effekte:\n\nDie Verteilung ist symmetrischer, n√§her an der Normalverteilung. Damit gibt es mehr Daten im Hauptbereich des Ranges von Sale_Price, was die Vorhersagen stabiler machen d√ºrfte.\nLogarithmiert man die Y-Variable, so kommt dies einem multiplikativen Modell gleich, s. auch hier."
  },
  {
    "objectID": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "href": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.4 Train- vs Test-Datensatz aufteilen",
    "text": "6.4 Train- vs Test-Datensatz aufteilen\nDieser Abschnitt bezieht sich auf Kapitel 5 in Silge und Kuhn (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nDas Aufteilen in Train- und Test-Datensatz ist einer der wesentlichen Grunds√§tze im maschinellen Lernen. Das Ziel ist, Overfitting abzuwenden. Im Train-Datensatz werden alle Modelle berechnet. Der Test-Datensatz wird nur einmal verwendet, und zwar zur √úberpr√ºfung der Modellg√ºte.\n\n\n\n\nEine Faustregel ist es, 70-80% der Daten in das Train-Sample und die √ºbrigen 20-30% in das Test-Sample zu stecken, s. Abbildung¬†6.1\n\n\n\n\nAbbildung¬†6.1: 80-20-Aufteilung der Daten in Train- bzw. Test-Sample\n\n\n\n\nPraktisch funktioniert das in Silge und Kuhn (2022) wie folgt.\nWir laden die Daten und erstellen einen Index, der jeder Beobachtung die Zuteilung zu Train- bzw. zum Test-Datensatz zuweist.\nDas kann, mit tidymodels so aussehen:\n\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\n\ninitial_split() speichert f√ºr sp√§tere komfortable Verwendung auch die Daten. Aber eben auch der Index, der bestimmt, welche Beobachtung im Train-Set landet:\n\names_split$in_id %&gt;% head(n = 10)\n##  [1]  2 28 30 31 32 33 35 78 79 83\nlength(ames_split$in_id)\n## [1] 2342\n\nPraktisch ist auch, dass die AV-Verteilung in beiden Datens√§tzen √§hnlich gehalten wird (Stratifizierung), das besorgt das Argument strata.\nDie eigentlich Aufteilung in die zwei Datens√§tze geht dann so:\n\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)"
  },
  {
    "objectID": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "href": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.5 Grundlagen der Modellierung mit tidymodels",
    "text": "6.5 Grundlagen der Modellierung mit tidymodels\nDieser Abschnitt bezieht sich auf Kapitel 6 in Silge und Kuhn (2022).\ntidymodels ist eine Sammlung mehrerer, zusammengeh√∂riger Pakete, eben zum Thema statistische Modellieren.\nDas kann man analog zur Sammlung tidyverse verstehen, zu der z.B. das R-Paket dplyr geh√∂rt.\nDas R-Paket innerhalb von tidymodels, das zum ‚ÄúFitten‚Äù von Modellen zust√§ndig ist, hei√üt parsnip.\nEine Liste der verf√ºgbaren Modelltypen, Modellimplementierungen und Modellparameter, die in Parsnip aktuell unterst√ºtzt werden, findet sich hier.\n\n6.5.1 Modelle spezifizieren\nEin (statistisches) Modell wird in Tidymodels mit drei Elementen spezifiziert, vgl. Abbildung¬†6.2.\n\n\n\nAbbildung¬†6.2: Definition eines Models in tidymodels\n\n\n\nDie Definition eines Modells in tidymodels folgt diesen Ideen:\n\nDas Modell sollte unabh√§ngig von den Daten spezifiziert sein\nDas Modell sollte unabh√§ngig von den Variablen (AV, UVs) spezifiziert sein\nDas Modell sollte unabh√§ngig von etwaiger Vorverarbeitung (z.B. z-Transformation) spezifiziert sein\n\nDa bei einer linearen Regression nur der Modus ‚ÄúRegression‚Äù m√∂glich ist, muss der Modus in diesem Fall nicht angegeben werden. Tidymodels erkennt das automatisch.\n\nlm_model &lt;-   \n  linear_reg() %&gt;%   # Algorithmus, Modelltyp\n  set_engine(\"lm\")  # Implementierung\n  # Modus hier nicht n√∂tig, da lineare Modelle immer numerisch klassifizieren\n\n\n6.5.2 Modelle berechnen\nNach Rhys (2020) ist ein Modell sogar erst ein Modell, wenn die Koeffizienten berechnet sind. Tidymodels kennt diese Unterscheidung nicht. Stattdessen spricht man in Tidymodels von einem ‚Äúgefitteten‚Äù Modell, sobald es berechnet ist. √Ñhnlich fancy k√∂nnte man von einem ‚Äúinstantiierten‚Äù Modell sprechen.\nF√ºr das Beispiel der einfachen linearen Regression hei√üt das, das Modell ist gefittet, sobald die Steigung und der Achsenabschnitt (sowie die Residualstreuung) berechnet sind.\n\nlm_form_fit &lt;- \n  lm_model %&gt;% \n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)\n\n\n6.5.3 Vorhersagen\nIm maschinellen Lernen ist man prim√§r an den Vorhersagen interessiert, h√§ufig nur an Punktsch√§tzungen. Schauen wir uns also zun√§chst diese an.\nVorhersagen bekommt man recht einfach mit der predict() Methode von tidymodels1:\n\npredict(lm_form_fit, new_data = ames_test) %&gt;% \n  head()\n\n\n\n  \n\n\n\nDie Syntax zum Vorhersagen lautet also: predict(modell, daten_zum_vorhersagen).\n\n6.5.4 Vorhersagen im Train-Datensatz\nVorhersagen im Train-Datensatz machen kaum Sinn, da sie nicht gegen Overfitting gesch√ºtzt sind und daher deutlich zu optimistisch sein k√∂nnen.\nBei einer linearen Regression ist diese Gefahr nicht so hoch, aber bei anderen, flexibleren Modellen, ist diese Gefahr absurd gro√ü.\n\n6.5.5 Modellkoeffizienten im Train-Datensatz\nGibt man den Namen des Modellobjekts ein, so wird ein √úberblick an relevanten Modellergebnissen am Bildschirm gedruckt:\n\nlm_form_fit\n## parsnip model object\n## \n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\nInnerhalb des Ergebnisobjekts findet sich eine Liste namens fit, in der die Koeffizienten (der ‚ÄúFit‚Äù) abgelegt sind:\n\nlm_form_fit %&gt;% pluck(\"fit\")\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\nZum Herausholen dieser Infos kann man auch alternativ die Funktion extract_fit_engine() verwenden:\n\nlm_fit &lt;-\n  lm_form_fit %&gt;% \n  extract_fit_engine()\n\nlm_fit\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\n\n\n\n\n\n\nHinweis\n\n\n\nM√∂chten Sie wissen, was sich in lm_form_fit alles verbirgt, bietet sich die Funktion str an. Alternativ k√∂nnen Sie in RStudio unter Environment das Objekt ‚Äúaufklappen‚Äù.\n\n\nDas extrahierte Objekt ist, in diesem Fall, das typische lm() Objekt. Entsprechend kann man daruaf coef() oder summary() anwenden.\n\ncoef(lm_fit)\n## (Intercept)   Longitude    Latitude \n## -311.510950   -2.109107    2.836443\nsummary(lm_fit)\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.02571 -0.09581 -0.01513  0.09817  0.57768 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -311.5110    14.5929  -21.35   &lt;2e-16 ***\n## Longitude     -2.1091     0.1303  -16.18   &lt;2e-16 ***\n## Latitude       2.8364     0.1800   15.75   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1613 on 2339 degrees of freedom\n## Multiple R-squared:  0.1738, Adjusted R-squared:  0.1731 \n## F-statistic: 246.1 on 2 and 2339 DF,  p-value: &lt; 2.2e-16\n\nSchicker sind die Pendant-Befehle aus broom, die jeweils einen Tibble zu√ºckliefern:\n\nlibrary(broom)\ntidy(lm_fit) # Koeffizienten\n\n\n\n  \n\n\nglance(lm_fit) # Modellg√ºte\n\n\n\n  \n\n\n\n\nlibrary(easystats)\nparameters(lm_form_fit)\n\n\n\n  \n\n\nr2(lm_form_fit)\n## # R2 for Linear Regression\n##        R2: 0.174\n##   adj. R2: 0.173\nmae(lm_form_fit)\n## [1] 0.122687\n\n\n6.5.6 Parsnip RStudio add-in\nMit dem Add-in von Parsnip kann man sich eine Modellspezifikation per Klick ausgeben lassen. Nett!\n\nparsnip_addin()"
  },
  {
    "objectID": "060-tidymodels.html#workflows",
    "href": "060-tidymodels.html#workflows",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.6 Workflows",
    "text": "6.6 Workflows\nDieser Abschnitt bezieht sich auf Kapitel 7 in Silge und Kuhn (2022).\n\n6.6.1 Konzept des Workflows in Tidymodels\n\n\n\nDefinition eines Models in tidymodels\n\n\n\n6.6.2 Einfaches Beispiel\nWir initialisieren einen Workflow, verzichten auf Vorverarbeitung und f√ºgen ein Modell hinzu:\n\nlm_workflow &lt;- \n  workflow() %&gt;%  # init\n  add_model(lm_model) %&gt;%   # Modell hinzuf√ºgen\n  add_formula(Sale_Price ~ Longitude + Latitude)  # Modellformel hinzuf√ºgen\n\nWerfen wir einen Blick in das Workflow-Objekt:\n\nlm_workflow\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Sale_Price ~ Longitude + Latitude\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nWie man sieht, geh√∂rt die Modellformel (y ~ x) zur Vorverarbeitung aus Sicht von Tidymodels.\nWas war nochmal im Objekt lm_model enthalten?\n\nlm_model\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nJetzt k√∂nnen wir das Modell berechnen (fitten):\n\nlm_fit &lt;- \n  lm_workflow %&gt;%\n  fit(ames_train)\n\nNat√ºrlich kann man synonym auch schreiben:\n\nlm_fit &lt;- fit(lm_wflow, ames_train)\n\nSchauen wir uns das Ergebnis an:\n\nlm_fit\n## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Sale_Price ~ Longitude + Latitude\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\n\n6.6.3 Vorhersage mit einem Workflow\nDie Vorhersage mit einem Tidymodels-Workflow ist einerseits komfortabel, da man einfach sagen kann:\n‚ÄúNimm die richtigen Koeffizienten des Modells aus dem Train-Set und wende sie auf das Test-Sample an. Berechne mir die Vorhersagen und die Modellg√ºte.‚Äù\nSo sieht das aus:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nAlso, last_fit k√ºmmert sich um Folgendes:\n\nBerechne Modell im (kompletten) Train-Sample\nSage Daten im Test-Sample vorher\nBerechne Modellg√ºte im Test-Sample\n\nEs wird ein recht komplexes Objekt zur√ºckgeliefert, das man erst mal durchschauen muss.\nWie man sieht, gibt es mehrere Listenspalten in final_lm_res. Besonders interessant erscheinen nat√ºrlich die Listenspalten .metrics und .predictions.\nSchauen wir uns die Vorhersagen an. Diese finden sich im resultierenden Objekt von last_fit, zusammen mit anderen Informationen wie MOdellg√ºte. Die .predictions sind selber ein Tibble, wo in der ersten Spalte die Vorhersagen stehen.\n\nlm_preds &lt;- final_lm_res %&gt;% pluck(\".predictions\", 1)\n\nEs gibt auch eine Funktion, die obige Zeile vereinfacht (also synonym ist):\n\nlm_preds &lt;- collect_predictions(final_lm_res)\nlm_preds %&gt;% slice_head(n = 5)\n\n\n\n  \n\n\n\n\n6.6.4 Modellg√ºte\nDieser Abschnitt bezieht sich auf Kapitel 9 in Silge und Kuhn (2022).\nDie Vorhersagen bilden die Basis f√ºr die Modellg√ºte (‚ÄúMetriken‚Äù), die schon fertig berechnet im Objekt final_lm_res liegen und mit collect_metrics herausgenommen werden k√∂nnen:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\n\nAlternativ kommt man mit pluck(final_lm_res, \".metrics\") an die gleichen Informationen.\n\n\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\nrmse\nstandard\n1.60 √ó 10‚àí1\n\nPreprocessor1_Model1\n\n\nrsq\nstandard\n1.67 √ó 10‚àí1\n\nPreprocessor1_Model1\n\n\n\n\n\n\nMan kann auch angeben, welche Metriken der Modellg√ºte man bekommen m√∂chte:\n\names_metrics &lt;- metric_set(rmse, rsq)\n\names_metrics(data = lm_preds, \n             truth = Sale_Price, \n             estimate = .pred)\n\n\n6.6.5 Vorhersage von Hand\nMan kann sich die Metriken auch von Hand ausgeben lassen, wenn man direktere Kontrolle haben m√∂chte als mit last_fit und collect_metrics.\n\names_test_small &lt;- ames_test %&gt;% slice(1:5)\npredict(lm_form_fit, new_data = ames_test_small)\n\n\n\n  \n\n\n\nJetzt binden wir die Spalten zusammen, also die ‚ÄúWahrheit‚Äù (\\(y\\), die beobachteten, tats√§chlichen Y-Werte) und die Vorhersagen (\\(\\hat{y}\\)):\n\names_test_small2 &lt;- \n  ames_test_small %&gt;% \n  select(Sale_Price) %&gt;% \n  bind_cols(predict(lm_form_fit, ames_test_small)) %&gt;% \n  # Add 95% prediction intervals to the results:\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) \n\n\nrsq(ames_test_small2, \n   truth = Sale_Price,\n   estimate = .pred\n   )\n\n\n\n  \n\n\n\nAndere Koeffizienten der Modellg√ºte k√∂nnen mit rmse oder mae abgerufen werden."
  },
  {
    "objectID": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "href": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.7 Rezepte zur Vorverarbeitung",
    "text": "6.7 Rezepte zur Vorverarbeitung\nDieser Abschnitt bezieht sich auf Kapitel 8 in Silge und Kuhn (2022).\n\n6.7.1 Was ist Rezept und wozu ist es gut?\nSo k√∂nnte ein typischer Aufruf von lm() aussehen:\n\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, \n   data = ames)\n\nNeben dem Fitten des Modells besorgt die Formel-Schreibweise noch einige zus√§tzliche n√ºtzliche Vorarbeitung:\n\nDefinition von AV und AV\nLog-Transformation von Gr_Liv_Area\n\nTransformation der nominalen Variablen in Dummy-Variablen\n\nDas ist sch√∂n und n√ºtzlich, hat aber auch Nachteile:\n\nDas Modell wird nicht nur spezifiziert, sondern auch gleich berechnet. Das ist unpraktisch, weil man die Modellformel vielleicht in anderen Modell wiederverwenden m√∂chte. Au√üerdem kann das Berechnen lange dauern.\nDie Schritte sind ineinander vermengt, so dass man nicht einfach und √ºbersichtlich die einzelnen Schritte bearbeiten kann.\n\nPraktischer w√§re also, die Schritte der Vorverarbeitung zu ent-flechten. Das geht mit einem ‚ÄúRezept‚Äù aus Tidymodels:\n\nsimple_ames &lt;- \n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) %&gt;%\n  step_log(Gr_Liv_Area, base = 10) %&gt;% \n  step_dummy(all_nominal_predictors())\nsimple_ames\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          4\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Rezept berechnet kein Modell. Es macht nichts au√üer die Vorverarbeitung des Modells zu spezifizieren (inklusive der Modellformel).\n\n\n\n6.7.2 Workflows mit Rezepten\nJetzt definieren wir den Workflow nicht nur mit einer Modellformel, sondern mit einem Rezept:\n\nlm_workflow &lt;-\n  workflow() %&gt;% \n  add_model(lm_model) %&gt;% \n  add_recipe(simple_ames)\n\nSonst hat sich nichts ge√§ndert.\nWie vorher, k√∂nnen wir jetzt das Modell berechnen und uns im Test-Set die Vorhersagen berechnen lassen:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nHier ist die Modellg√ºte:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\nlm_metrics\n\n\n\n  \n\n\n\n\n6.7.3 Spaltenrollen\nEine praktische Funktion ist es, bestimmte Spalten nicht als Pr√§diktor, sondern als ID-Variable zu nutzen. Das kann man in Tidymodels komfortabel wie folgt angeben:\n\names_recipe &lt;-\n  simple_ames %&gt;% \n  update_role(Neighborhood, new_role = \"id\")\n\names_recipe\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##         id          1\n##    outcome          1\n##  predictor          3\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()\n\n\n6.7.4 Fazit\nMehr zu Rezepten findet sich hier. Ein √úberblick zu allen Schritten der Vorverarbeitung findet sich hier."
  },
  {
    "objectID": "060-tidymodels.html#aufgaben",
    "href": "060-tidymodels.html#aufgaben",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\n\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\n\n\n\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "060-tidymodels.html#footnotes",
    "href": "060-tidymodels.html#footnotes",
    "title": "\n6¬† tidymodels\n",
    "section": "",
    "text": "im Gegensatz zum predict() von lm mit Unterstrich bei new_data, also nicht newdata.‚Ü©Ô∏é"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baumer, Benjamin S., Daniel T. Kaplan, and Nicholas J. Horton. 2017.\nModern Data Science with r (Chapman & Hall/CRC\nTexts in Statistical Science). Boca Raton, Florida: Chapman;\nHall/CRC.\n\n\nHvitfeldt, Emil. 2022. ISLR Tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nr. Second edition. Springer Texts in Statistics. New York:\nSpringer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with r, the Tidyverse, and\nMlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse Mit r: Daten Einlesen,\nAufbereiten, Visualisieren Und Modellieren. 1. Auflage 2019.\nFOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, and Max Kuhn. 2022. Tidy Modeling with\nR. https://www.tmwr.org/.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87.\nhttps://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, and Melissa Lee. 2022. Data\nScience: An Introduction. First edition. Statistics. Boca Raton:\nCRC Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data Science:\nVisualize, Model, Transform, Tidy, and Import Data. O‚ÄôReilly Media.\nhttps://r4ds.had.co.nz/index.html."
  }
]