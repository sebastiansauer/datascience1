[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "",
    "text": "1 Zu diesem Buch\nQuelle: ImageFlip"
  },
  {
    "objectID": "index.html#was-r√§t-meister-yoda",
    "href": "index.html#was-r√§t-meister-yoda",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.1 Was r√§t Meister Yoda?",
    "text": "1.1 Was r√§t Meister Yoda?\nMeister Yoda r√§t: Lesen Sie die Hinweise (Abbildung¬†1.1).\n\n\nAbbildung¬†1.1: Lesen Sie die folgenden Hinweise im eigenen Interesse\n\n\n\nQuelle: made at imageflip"
  },
  {
    "objectID": "index.html#zitation",
    "href": "index.html#zitation",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.2 Zitation",
    "text": "1.2 Zitation\nNutzen Sie diese DOI, um dieses Buch zu zitieren:"
  },
  {
    "objectID": "index.html#technische-details",
    "href": "index.html#technische-details",
    "title": "Grundlagen der Prognosemodellierung üîÆüß∞",
    "section": "\n1.3 Technische Details",
    "text": "1.3 Technische Details\n\nDiese Version des Buches wurde erstellt am: 2023-03-13 14:21:16\nDie URL zu diesem Buch lautet https://sebastiansauer.github.io/datascience1/ und ist bei GitHub Pages gehostet.\nDen Quellcode finden Sie in diesem Github-Repo.\nSie haben Feedback, Fehlerhinweise oder W√ºnsche zur Weiterentwicklung? Am besten stellen Sie hier einen Issue ein.\nDieses Projekt steht unter der MIT-Lizenz.\nDieses Buch wurde in RStudio mit Hilfe von bookdown geschrieben.\nDiese Version des Buches wurde mit der R-Version R version 4.2.1 (2022-06-23) und den folgenden Paketen erstellt:\n\n\n\n\n\npackage\nversion\nsource\n\n\n\nbookdown\n0.32\nCRAN (R 4.2.0)\n\n\nbroom\n1.0.3\nCRAN (R 4.2.0)\n\n\ncorrr\nNA\nNA\n\n\ndials\n1.1.0\nCRAN (R 4.2.0)\n\n\ndownlit\n0.4.2\nCRAN (R 4.2.0)\n\n\ndplyr\n1.1.0\nCRAN (R 4.2.0)\n\n\nggplot2\n3.4.1\nCRAN (R 4.2.0)\n\n\nglmnet\n4.1-6\nCRAN (R 4.2.0)\n\n\ninfer\n1.0.4\nCRAN (R 4.2.0)\n\n\nISLR\nNA\nNA\n\n\nkknn\n1.3.1\nCRAN (R 4.2.0)\n\n\nklaR\n1.7-1\nCRAN (R 4.2.0)\n\n\nMASS\n7.3-58.2\nCRAN (R 4.2.0)\n\n\nmodeldata\n1.0.1\nCRAN (R 4.2.0)\n\n\nparsnip\n1.0.3\nCRAN (R 4.2.0)\n\n\npatchwork\n1.1.2\nCRAN (R 4.2.0)\n\n\npurrr\n1.0.1\nCRAN (R 4.2.0)\n\n\nrandomForest\n4.7-1.1\nCRAN (R 4.2.0)\n\n\nranger\n0.14.1\nCRAN (R 4.2.0)\n\n\nreadr\n2.1.4\nCRAN (R 4.2.0)\n\n\nrsample\n1.1.1\nCRAN (R 4.2.0)\n\n\nrstatix\n0.7.2\nCRAN (R 4.2.0)\n\n\ntibble\n3.1.8\nCRAN (R 4.2.0)\n\n\ntidymodels\n1.0.0\nCRAN (R 4.2.0)\n\n\ntidyr\n1.3.0\nCRAN (R 4.2.0)\n\n\ntidyverse\n1.3.2\nCRAN (R 4.2.0)\n\n\ntune\n1.0.1\nCRAN (R 4.2.0)\n\n\nvip\n0.3.2\nCRAN (R 4.2.0)\n\n\nworkflows\n1.1.2\nCRAN (R 4.2.0)\n\n\nworkflowsets\n1.0.0\nCRAN (R 4.2.0)\n\n\nxgboost\n1.6.0.1\nCRAN (R 4.2.0)\n\n\nyardstick\n1.1.0\nCRAN (R 4.2.0)"
  },
  {
    "objectID": "010-Hinweise.html#ihr-lernerfolg",
    "href": "010-Hinweise.html#ihr-lernerfolg",
    "title": "Lernhilfen",
    "section": "\n2.1 Ihr Lernerfolg",
    "text": "2.1 Ihr Lernerfolg\n\n2.1.1 Was Sie hier lernen und wozu das gut ist\nAlle Welt spricht von Big Data, aber ohne die Analyse sind die gro√üen Daten nur gro√ües Rauschen. Was letztlich interessiert, sind die Erkenntnisse, die Einblicke, nicht die Daten an sich. Dabei ist es egal, ob die Daten gro√ü oder klein sind. Nat√ºrlich erlauben die heutigen Datenmengen im Verbund mit leistungsf√§higen Rechnern und neuen Analysemethoden ein Verst√§ndnis, das vor Kurzem noch nicht m√∂glich war. Und wir stehen erst am Anfang dieser Entwicklung. Vielleicht handelt es sich bei diesem Feld um eines der dynamischsten Fachgebiete der heutigen Zeit. Sie sind dabei: Sie lernen einiges Handwerkszeugs des ‚ÄúDatenwissenschaftlers‚Äù. Wir konzentrieren uns auf das vielleicht bekannteste Teilgebiet: Ereignisse vorhersagen auf Basis von hoch strukturierten Daten und geeigneter Algorithmen und Verfahren. Nach diesem Kurs sollten Sie in der Lage sein, typisches Gebabbel des Fachgebiet mit L√§ssigkeit mitzumachen. Ach ja, und mit einigem Erfolg Vorhersagemodelle entwickeln.\n\n2.1.2 Lernziele\n\n\n\n\n\n\nWichtig\n\n\n\nKurz gesagt: Sie lernen die Grundlagen von Data Science.\\(\\square\\)\n\n\nNach diesem Kurs sollten Sie\n\ngrundlegende Konzepte des statistischen Lernens verstehen und mit R anwenden k√∂nnen\ng√§ngige Prognose-Algorithmen kennen, in Grundz√ºgen verstehen und mit R anwenden k√∂nnen\ndie G√ºte und Grenze von Prognosemodellen einsch√§tzen k√∂nnen\n\n2.1.3 √úberblick\nAbb. Abbildung¬†2.1 gibt einen √úberblick √ºber den Verlauf und die Inhalte des Buches. Das Diagramm hilft Ihnen zu verorten, wo welches Thema im Gesamtzusammenhang steht.\n\n\n\n\nflowchart LR\n  subgraph R[Rahmen]\n    direction LR\n    subgraph V[Grundlagen]\n      direction TB\n      E[R] --- Um[Statistisches&lt;br&gt;Lernen]\n      Um --- tm[tidymodels]\n    end\n    subgraph M[Lernalgorithmen]\n      direction TB\n      M1[Regression] --- Vis[Baeume]\n      Vis --- U[Regularisierung]\n      U --- G[...]\n    end\n    subgraph N[Anwendung]\n      direction TB\n      D[Fallstudien]\n    end\n  V --&gt; M\n  M --&gt; N\n  end\n\n\nAbbildung¬†2.1: Ein ‚ÄòFahrplan‚Äô als ‚ÄòBig Picture‚Äô dieses Buches\n\n\n\n\n\n2.1.4 Modulzeitplan\n\n\n\n\n\n\n\n\n\n\n\n\n\nNr\nThema\nDatum\nKommentar\n\n\n\n1\nStatistisches Lernen\n13.3. - 19.3.\nLehrbeginn ist am Mi., 15.3.23\n\n\n2\nStatistisches Lernen\n20.3. - 26.3.\nNA\n\n\n3\nR, zweiter Blick\n27.3. - 2.4.\nNA\n\n\n4\nR, zweiter Blick\n3.4. - 9.4\nKarwoche (kein Unterricht am Do. und Fr.)\n\n\n5\ntidymodels\n10.4. - 16.4.\nOsterwoche (kein Unterricht am Mo. und Di.)\n\n\n6\nknn\n17.4. - 23.4.\nNA\n\n\n7\nResampling und Tuning\n24.4. - 30.4.\nNA\n\n\n8\nLogistische Regression\n1.5. - 7.5.\nMaifeiertag (kein Unterricht am Mo.)\n\n\n9\nEntscheidungsb√§ume\n8.5. - 14.5.\nNA\n\n\n10\nBaumbasierte Modelle\n15.5. - 21.5.\nNA\n\n\n11\n-\n22.5. - 28.5.\nBlockwocke - kein regul√§rer Unterricht\n\n\n12\nRegularisierung\n29.6. - 4.6.\nPfingstwoche (kein Unterricht am Mo. und Di.)\n\n\n13\nRegularisierung\n5.6. - 11.6.\nFronleichnam (kein Unterricht am Do. und Fr.)\n\n\n14\nFallstudien bei Kaggle\n12.6. - 18.6.\nNA\n\n\n15\nDimensionsreduktion\n19.6. - 25.6.\nNA\n\n\n16\nDer rote Faden\n26.6. - 2.7.\nLetzter Lehrtag ist Fr., 30.6.\n\n\n\n\n\n\n\n2.1.5 Voraussetzungen\nUm von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen:\n\ngrundlegende Kenntnisse im Umgang mit R, m√∂glichst auch mit dem tidyverse\ngrundlegende Kenntnisse der deskriptiven Statistik\ngrundlegende Kenntnis der Regressionsanalyse"
  },
  {
    "objectID": "010-Hinweise.html#lernhilfen",
    "href": "010-Hinweise.html#lernhilfen",
    "title": "Lernhilfen",
    "section": "\n2.2 Lernhilfen",
    "text": "2.2 Lernhilfen\n\n2.2.1 PDF-Version\nUm eine PDF-Version eines Kapitels zu erhalten, k√∂nnen Sie im Browser die Druckfunktion nutzen (Strg-P). W√§hlen Sie dort ‚ÄúPDF‚Äù als Ziel.\n\n2.2.2 Videos\nAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buchs. Besonders diese Playlist passt zu den Inhalten dieses Buchs.\n\n2.2.3 Software\nInstallieren Sie R und seine Freunde. F√ºr die Bayes-Inferenz brauchen Sie1 zus√§tzliche Software, was leider etwas Zusatzaufwand erfordert. Lesen Sie hier die Hinweise dazu. Installieren Sie die folgende R-Pakete2:\n\ntidyverse\neasystats\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\n\nR Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.\n\n\n\n2.2.4 Online-Unterst√ºtzung\nDieser Kurs kann in Pr√§senz und Online angeboten werden. Wenn Sie die Wahl haben, empfehle ich die Teilnahme in Pr√§senz, da der Lernerfolg h√∂her ist. Online ist es meist schwieriger, sich zu konzentrieren. Aber auch online ist es m√∂glich, den Stoff gut zu lernen, s. Abbildung¬†2.2.\n\n\nAbbildung¬†2.2: We believe in you! Image Credit: Allison Horst\n\n\nBitte beachten Sie, dass bei einer Teilnahme in Pr√§senz eine aktive Mitarbeit erwartet wird. Hingegen ist bei einer Online-Teilnahme keine/kaum aktive Mitarbeit m√∂glich.\nHier finden Sie einige Werkzeuge, die das Online-Zusammenarbeiten vereinfachen:\n\n\nFrag-Jetzt-Raum zum anonymen Fragen stellen w√§hrend des Unterrichts. Der Keycode wird Ihnen bei Bedarf vom Dozenten bereitgestellt.\n\nPadlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeitr√§gen. Die Zugangsdaten stellt Ihnen der Dozent bereit.\nNutzen Sie das vom Dozenten bereitgestelle Forum, um Fragen zu stellen und Fragen zu beantworten.\n\n2.2.5 Lerntipps\n\n\n\n\n\n\nHinweis\n\n\n\nStetige Mitarbeit - auch und gerade au√üerhalb des Unterrichts - ist der Schl√ºssel zum Pr√ºfungserfolg.\n\n\n\n\nLerngruppe: Treten Sie einer Lerngruppe bei.\n\nTutorium: Besuchen Sie ein Tutorium, falls eines angeboten wird.\n\nVor- und Nachbereitung: Bereiten Sie den Unterricht vor und nach.\n\nSelbsttest: Testen Sie sich mit Flashcards (Karteikarten mit Vor- und R√ºckseite). Wenn Sie alle Aufgaben dieses Kurses aus dem FF beherrschen, sollte die Pr√ºfung kein Problem sein.\n\n√úbungen: Bearbeiten Sie alle √úbungsaufgaben gewissenhaft.\nPortal Datenwerk: Gehen Sie die Aufgaben auf dem Portal Datenwerk durch (soweit relevant).\n\nFallstudien: Schauen Sie sich meine Fallstudiensammlungen an: https://sebastiansauer-academic.netlify.app/courseware/casestudies/\n\nLehrkraft ansprechen: Sprechen Sie die Lehrkraft an, wenn Sie Fragen haben. Haben Sie keine Scheu! Bitte lesen Sie aber vorab die Hinweise, um Redundanz zu vermeiden.\n\n2.2.6 Selbstlernkontrolle\nF√ºr jedes Kapitel sind (am Kapitelende) Aufgaben eingestellt, jeweils mit L√∂sung. Ein Teil dieser Aufgaben hat eine kurze, eindeutige L√∂sung (z.B. ‚Äú42‚Äù oder ‚ÄúAntwort C‚Äù); ein (kleiner) Teil der Aufgaben verlangen komplexere Antworten (z.B. ‚ÄúWelche Arten von Prioris gibt es bei stan_glm()?). Nutzen Sie die Fragen mit eindeutiger, kurzer L√∂sung um sich selber zu pr√ºfen. Nutzen Sie die Fragen mit komplexerer, l√§ngerer L√∂sung, um ein Themengebiet tiefer zu erarbeiten.\n\n\n\n\n\n\nHinweis\n\n\n\nFortw√§hrendes Feedback zu Ihrem Lernfortschritt ist wichtig, damit Sie Ihre Lernbem√ºhungen steuern k√∂nnen. Bearbeiten Sie daher die bereitgestellten Arbeiten ernsthaft.\n\n\n\n2.2.7 Lernen lernen\nHier sind einige Quellen (Literatur), die Ihnen helfen sollen, das Lernen (noch besser) zu lernen:\n\nEssentielle Tipps f√ºr Bachelor-Studierende der Psychologie\nKonzentriert arbeiten: Regeln f√ºr eine Welt voller Ablenkungen\nWie man ein Buch liest\nErsti-Hilfe: 112 Tipps f√ºr Studienanf√§nger - erfolgreich studieren ab der ersten Vorlesung\nVon der K√ºrze des Lebens\nBlog ‚ÄúStudienscheiss‚Äù"
  },
  {
    "objectID": "010-Hinweise.html#literatur",
    "href": "010-Hinweise.html#literatur",
    "title": "Lernhilfen",
    "section": "\n2.3 Literatur",
    "text": "2.3 Literatur\nZentrale Kursliteratur f√ºr die theoretischen Konzepte ist Rhys (2020). Bitte pr√ºfen Sie, ob das Buch in einer Bibliothek verf√ºgbar ist. Die praktische Umsetzung in R basiert auf Silge und Kuhn (2022) (dem ‚ÄúTidymodels-Konzept‚Äù); das Buch ist frei online verf√ºgbar.\nEine gute Erg√§nzung ist das Lehrbuch von Timbers, Campbell, und Lee (2022), welches grundlegende Data-Science-Konzepte erl√§utert und mit tidymodels umsetzt.\nJames u.¬†a. (2021) haben ein weithin renommiertes und sehr bekanntes Buch verfasst. Es ist allerdings etwas anspruchsvoller aus Rhys (2020), daher steht es nicht im Fokus dieses Kurses, aber einige Schwenker zu Inhalten von James u.¬†a. (2021) gibt es. Schauen Sie mal rein, das Buch ist gut!\nIn einigen Punkten ist weiterhin Sauer (2019) hilfreich; das Buch ist √ºber SpringerLink in Ihrer Hochschul-Bibliothek verf√ºgbar. Eine gute Erg√§nzung ist das ‚ÄúLab-Buch‚Äù von Hvitfeldt (2022). In dem Buch wird das Lehrbuch James u.¬†a. (2021) in Tidymodels-Konzepte √ºbersetzt; durchaus nett!"
  },
  {
    "objectID": "010-Hinweise.html#faq",
    "href": "010-Hinweise.html#faq",
    "title": "Lernhilfen",
    "section": "\n2.4 FAQ",
    "text": "2.4 FAQ\n\n\nFolien\n\nFrage: Gibt es ein Folienskript?\nAntwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zug√§ngliche Literatur gibt, dort gibt es ein Skript.\n\n\n\nEnglisch\n\nIst die Literatur auf Englisch?\nJa. Allerdings ist die Literatur gut zug√§nglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca in Wissenschaft und Wirtschaft. Ein solides Verst√§ndnis englischer (geschriebener) Sprache ist f√ºr eine gute Ausbildung unerl√§sslich. Zu dem sollte die Kursliteratur fachlich passende und gute B√ºcher umfassen; oft sind das englische Titel.\n\n\n\nAnstrengend\n\nIst der Kurs sehr anstrengend, aufw√§ndig?\nDer Kurs hat ein mittleres Anspruchsniveau.\n\n\n\nMathe\n\nMuss man ein Mathe-Crack sein, um eine gute Note zu erreichen?\nNein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur an, sie werden wenig Mathe darin finden.\n\n\n\nPr√ºfungsliteratur\n\nWelche Literatur ist pr√ºfungsrelevant?\nPr√ºfungsrelevant im engeren Sinne ist das Skript sowie alles, was im Unterricht behandelt wurde.\n\n\n\nPr√ºfung\n\nWie sieht die Pr√ºfung aus?\nDie Pr√ºfung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, in der reines Wissen abgefragt wird.\n\n\n\nNur R?\n\nWird nur R in dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig.\nIn der Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. In einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit einger√§umt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen.\n\n\n\n\n\n\n\nHvitfeldt, Emil. 2022. ISLR tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, und Melissa Lee. 2022. Data science: an introduction. First edition. Statistics. Boca Raton: CRC Press."
  },
  {
    "objectID": "010-Hinweise.html#footnotes",
    "href": "010-Hinweise.html#footnotes",
    "title": "Lernhilfen",
    "section": "",
    "text": "nicht gleich zu Beginn, aber nach 2-3 Wochen‚Ü©Ô∏é\nfalls Sie die Pakete schon installiert haben, k√∂nnten Sie mal in RStudio auf ‚Äúupdate.packages‚Äù klicken‚Ü©Ô∏é"
  },
  {
    "objectID": "030-Pruefung.html#pr√ºfungleistung",
    "href": "030-Pruefung.html#pr√ºfungleistung",
    "title": "3¬† Pr√ºfung",
    "section": "3.1 Pr√ºfungleistung",
    "text": "3.1 Pr√ºfungleistung\nDie Pr√ºfungsleistung besteht aus einem Prognosewettbewerb.\n\nGegenstand dieser Pr√ºfungsform ist eine Projektarbeit."
  },
  {
    "objectID": "030-Pruefung.html#tldr-zusammenfassung",
    "href": "030-Pruefung.html#tldr-zusammenfassung",
    "title": "3¬† Pr√ºfung",
    "section": "3.2 tl;dr: Zusammenfassung",
    "text": "3.2 tl;dr: Zusammenfassung\nVorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. Wenn Sie den DAX-Stand von morgen genau vorhersagen k√∂nnen, rufen Sie mich bitte sofort an. Genau das ist Ihre Aufgabe in dieser Pr√ºfungsleistung: Sie sollen Werte vorhersagen.\nEtwas konkreter: Stellen Sie sich ein paar Studentis vor. Von allen wissen Sie, wie lange die Person f√ºr die Statistikklausur gelernt hat. Au√üerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. Und Sie wissen die Note jeder Person in der Statistikklausur. Auf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die Pr√ºfung in Statistik schreiben muss will: ‚ÄúSag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?‚Äù. Mit Hilfe Ihrer Analyse k√∂nnen Sie diese Frage (und andere) beantworten. Nat√ºrlich k√∂nnten Sie es sich leicht machen und antworten: ‚ÄúMei, der Notendurchschnitt war beim letzten Mal 2.7. Also ist 2.7 kein ganz doofer Tipp f√ºr deine Note.‚Äù Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, wenn man es geschickt anstellt. Da hilft Ihnen die Statistik (doch, wirklich).\nKurz gesagt gehen Sie so vor: Importieren Sie die Daten in R, starten Sie die n√∂tigen R-Pakete und schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. Dann nehmen Sie die vielversprechendsten Pr√§diktoren in ein Regressionsmodell und schauen sich an, wie gut die Vorhersage ist. Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. Je genauer Ihre Vorhersage, desto besser ist Ihr Pr√ºfungsergebnis."
  },
  {
    "objectID": "030-Pruefung.html#vorhersage",
    "href": "030-Pruefung.html#vorhersage",
    "title": "3¬† Pr√ºfung",
    "section": "3.3 Vorhersage",
    "text": "3.3 Vorhersage\nNeben der erkl√§renden, r√ºckw√§rtsgerichteten Modellierung spielt insbesondere in der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle: Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. f√ºr neue Kunden auf Basis von soziodemographischen Daten den Kundenwert ‚Äì m√∂glichst genau ‚Äì zu prognostizieren. Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden, d.h. inklusive des f√ºr diese Kunden bekannten Kundenwertes.\nIhnen werden zwei Teildatenmengen zur Verf√ºgung gestellt: Zum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet.\n\nBei den Trainingsdaten (Train-Sample) liegen sowohl die erkl√§renden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor. Auf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) gesch√§tzt. Es ist also die Variable \\(y\\) vorherszusagen.\nDieses gesch√§tzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(\\x_0\\), f√ºr die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({x}_0)\\) berechnet. Der unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.\n\nLiegt zu einem noch sp√§teren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, so kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden, d.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden.\nIn der praktischen Anwendung k√∂nnen zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben):\n\ndie Trainingsphase, d.h., die Phase f√ºr die sowohl erkl√§rende (\\(x\\)) als auch die erkl√§rte Variable (\\(y\\)) bekannt sind. Hier wird das Modell gesch√§tzt (gelernt): \\(\\hat{f}(x)\\). Daf√ºr wird der Trainingsdatensatz genutzt.\nIn der folgenden Anwendungsphase sind nur die erkl√§renden Variablen (\\(x_0\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.\nEvt. gibt es sp√§ter noch die Evaluierungsphase, f√ºr die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, so dass die Vorhersageg√ºte des Modells √ºberpr√ºft werden kann.\n\nIm Computer kann man dieses Anwendungsszenario simulieren: man teilt die Datenmenge zuf√§llig in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((x,y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((x_0)\\)) auf: Die Modellierung erfolgt auf den Trainingsdaten. Das Modell wird angewendet auf die Testdaten (Anwendungsdaten). Da man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden."
  },
  {
    "objectID": "030-Pruefung.html#hauptziel-genaue-prognose",
    "href": "030-Pruefung.html#hauptziel-genaue-prognose",
    "title": "3¬† Pr√ºfung",
    "section": "3.4 Hauptziel: Genaue Prognose",
    "text": "3.4 Hauptziel: Genaue Prognose\nIhre Aufgabe ist: Spielen Sie den Data-Scientist! Konstruieren Sie ein Modell auf Basis der Trainingsdaten \\((x,y\\)) und sagen Sie f√ºr die Testdaten (\\(x_0\\)) die Zielvariable m√∂glichst genau voraus (\\(\\hat{y}_0\\)).\nIhr(e) Dozent*in kennt den Wert der Zielvariable (\\(y_0\\)). Sie nicht.\nVon zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser, das weniger Vorhersagefehler aufweist (im Test-Datensatz), also genauer vorhersagt. Kurz gesagt: Genauer ist besser."
  },
  {
    "objectID": "030-Pruefung.html#einzureichende-dateien",
    "href": "030-Pruefung.html#einzureichende-dateien",
    "title": "3¬† Pr√ºfung",
    "section": "3.5 Einzureichende Dateien",
    "text": "3.5 Einzureichende Dateien\n\nFolgende* Dateiarten* sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, qmd-, Rmd-Notebook oder Rmd-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.qmd."
  },
  {
    "objectID": "030-Pruefung.html#zum-aufbau-ihrer-prognosedatei-im-csv-format",
    "href": "030-Pruefung.html#zum-aufbau-ihrer-prognosedatei-im-csv-format",
    "title": "3¬† Pr√ºfung",
    "section": "3.6 Zum Aufbau Ihrer Prognosedatei im CSV-Format",
    "text": "3.6 Zum Aufbau Ihrer Prognosedatei im CSV-Format\n\nDie CSV-Datei muss aus genau zwei Spalten mit exakt folgenden Spaltennamen bestehen:\n\n\nid: Den ID-Wert jedes vorhergesagten Wertes\npred: Der vorhergesagte Wert.\n\n\nUmlaute sind zu ersetzen (also S√º√ü wird Suess etc.).\nDie CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).\nDie CSV-Datei muss genau die Anzahl an Zeilen aufweisen, die der Zeilenl√§nge im Test-Datensatz entspricht.\nPr√ºfen Sie, dass Ihre CSV-Datei sich problemlos lesen l√§sst. Falls keine (funktionst√ºchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Pr√ºfung nicht bestanden. Tipp: √ñffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vern√ºnftig aussieht. Achtung: √ñffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, der CSV-Dateien verf√§lschen kann auch ohne dass man die Datei speichert.\nFolgende Dateiarten sind einzureichen:\n\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, Rmd-, qmd- oder Rmd-Notebook-Datei)\n\nWeitere Dateien sind nicht einzureichen.\nKomprimieren Sie die Dateien nicht (z.B. via zip).\nDer Name jeder eingereichten Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd."
  },
  {
    "objectID": "030-Pruefung.html#gliederung-ihrer-analyse",
    "href": "030-Pruefung.html#gliederung-ihrer-analyse",
    "title": "3¬† Pr√ºfung",
    "section": "3.7 Gliederung Ihrer Analyse",
    "text": "3.7 Gliederung Ihrer Analyse\nIhr Analysedokument stellt alle Ihre Schritte vor, die Sie im Rahmen der Bearbeitung der Pr√ºfungsaufgabe unternommen haben, zumindest was die Analyse der Daten betrifft.\nDas Dokument mischt drei Textarten: R-Syntax, R-Ausgaben sowie Prosa (Ihre Erkl√§rung zu Ihrer Analyse). Alle drei Aspekte sind gleicherma√üen wichtig f√ºr diese Analyse.\nWenn Sie das Dokument als R-Markdown-Datei (qmd- oder Rmd-Datei) anlegen, m√ºssen Sie R-Code in einem ‚ÄúR-Chunk‚Äù auszeichnen. Prosa wird in Rmd-Datei als Standard gesehen, sie brauchen ihn nicht extra auszuzeichnen (f√ºr R-Notebook-Dateien gilt das Gleiche). In R-Skript-Dateien ist es umgekehrt: Sie m√ºssen R-Code nicht extra auszeichnen, da in R-Skripten R als ‚ÄúStandard-Text‚Äù gesehen wird. Hingegen m√ºssen Sie Prosa als Kommentar einf√ºgen. Es bleibt Ihnen √ºberlassen, f√ºr welche Variante (R-, Rmd- oder R-Notebook) Sie sich entscheiden. Keine Option wird als besser oder schlechter gewertet (vermutlich ist Rmd f√ºr Sie am einfachsten).\nSie k√∂nnen Ihr Analysedokument z.B. so gliedern:\n\nForschungsfrage und Hintergrund (Beschreiben Sie kurz, worum es geht)\nVorbereitung (Pakete laden, Daten importieren, etc.)\nExplorative Datenanalyse (Untersuchen Sie den Datensatz nach Auff√§lligkeiten, die Sie dann beim Modellieren nutzen)\nModelle (z.B. via lm(av ~ uv))\nVorhersagen (Vorhersage der Test-Daten anhand des besten Vorhersagemodells und Einreichen)\n\nDie Gliederung ist kein Muss; andere Gliederung sind auch m√∂glich. Entscheidend ist die fachliche Angemessenheit.\n\n3.7.1 Abschnitt Forschungsfrage und Hintergrund\nIn diesem Abschnitt passiert noch keine Statistik bzw. keine Analyse. Stattdessen stellen Sie in ‚Äúnormaler Sprache‚Äù, also ohne intensiven Gebrauch vom (statistischem) Fachvokabular dar, was Ziel und was Hintergrund der Analyse ist. Sie k√∂nnen als Ziel bzw. Hintergrund den formalen Aspekt der Pr√ºfung anf√ºhren, wichtiger sind aber inhaltliche bzw. fachliche √úberlegungen: Worum geht es in der Analyse? Warum ist die Frage wichtig? Was wird untersucht? Anhand welcher Methodik wird die Frage untersucht?\n\n\n3.7.2 Vorbereitung\nIn diesem Abschnitt Ihres Analysedokuments f√ºhren Sie die technische Vorbereitung durch. Das betrifft vor allem das Importieren der Daten und das Starten aller R-Pakete, die in der Analyse verwendet werden.\nZum Importieren der Daten gehen Sie bitte so vor: Legen Sie f√ºr diese Analyse ein Projekt in Rstudio an. Speichern Sie in diesem Ordner (auf der Wurzelebene, nicht in Unterverzeichnissen) die zu analyiserenden Daten. √Ñndern Sie nicht den Dateinamen der Daten. Importieren Sie die Daten auf folgende Weise: d_train &lt;- read_csv(\"d_train.csv) bzw. d_test &lt;- read_csv(\"d_test.csv\"). Auf diese Weise ist die Reproduzierbarkeit Ihrer Analyse sichergestellt.\n\n\n3.7.3 Explorative Datenanalyse\nDie explorative Datenanalyse (EDA) meint sowohl die deskriptive Statistik als auch die Datenvisualisierung. Typische Schritte sind: das Bearbeiten (oder Entfernen) von Extremwerten und fehlenden Werten, die Untersuchung von Verteilungsformen oder das Suchen nach Mustern (Korrelationen, Gruppenunterschieden). Ein n√ºtzliches Ergebnis ist z.B. zu erkennen, welche Variablen sich als Pr√§diktoren eignen (f√ºr den n√§chsten Abschnitt der Modellierung). Ziel ist, dass Sie den folgenden Schritt vorbereiten, also Schritte unternehmen, damit Sie die AV m√∂glichst gut vorhersagen k√∂nnen.\n\n\n3.7.4 Modellierung\nIn diesem Schritt berechnen Sie Prognosemodelle. Das sind oft lineare Modelle, also etwa lm(av ~ uv). Es empfiehlt sich, mehrere Modelle zu berechnen und zu schauen, welches dieser Kandidaten am besten ist. Die G√ºte eines Prognosemodells bemisst sich letztlich nur an der Pr√§zision der Vorhersage neuer Daten, also des Test-Datensatzes. Wie gut Ihre Vorhersagen also wirklich sind, erfahren Sie erst mit der Notenbekanntgabe. Allerdings k√∂nnen Sie die Trainingsdaten nutzen, um die G√ºte Ihrere Modell abzusch√§tzen.\n\n\n3.7.5 Vorhersagen\nSchlie√ülich entscheiden Sie sich f√ºr einen Modellkandidaten. Diesen Modellkandidaten nehmen Sie her, um die (Ihenn unbekannten) Werte der AV (Zielvariablen) vorherzusagen. Diese Vorhersagen - zusammen mit der ID f√ºr jede Vorhersagen - speichern Sie als (regul√§re) CSV-Datei ab und reichen Sie als Ihre Pr√ºfungsleistung ein, zusammen mit Ihrer Analysedatei."
  },
  {
    "objectID": "030-Pruefung.html#tipps",
    "href": "030-Pruefung.html#tipps",
    "title": "3¬† Pr√ºfung",
    "section": "3.8 Tipps",
    "text": "3.8 Tipps\n\n3.8.1 Tipps f√ºr eine gute Prognose\n\nSchauen Sie in die Literatur.\nEvtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausrei√üern) helfen.\n√úberlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierf√ºr gibt es Algorithmen und R-Funktionen.\nVermeiden Sie √úber-Anpassung (Overfitting).\nVermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgef√ºllt.\nArbeiten Sie die bereitgestellten Fallstudien durch. Wenn Sie mehr tun m√∂chten, finden Sie im Internet eine F√ºlle von weiteren Fallstudien.\n\n\n\n3.8.2 Tipps zur Datenverarbeitung\n\nEin ‚Äúdeutsches‚Äù Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets k√∂nnen dies allerdings.\n\n\n\n3.8.3 Tipps zum Aufbau des Analyseskripts\n\nZu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.\nZu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (nicht von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Pr√ºfer, nicht lauff√§hig ist).\n\n\n\n3.8.4 Sonstiges\n\nLegen Sie regelm√§√üig Sicherheitskopien Ihrer Arbeit an (ggf. auf einem anderen Datentr√§ger).\nAchten Sie darauf, dass Sie nicht durcheinander kommen, in welcher Datei der aktuelle Stand Ihrer Arbeit liegt."
  },
  {
    "objectID": "030-Pruefung.html#bewertung",
    "href": "030-Pruefung.html#bewertung",
    "title": "3¬† Pr√ºfung",
    "section": "3.9 Bewertung",
    "text": "3.9 Bewertung\n\n3.9.1 Kriterien\n\nEs gibt drei Bewertungskriterien:\n\nFormalia: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, √úbersichtlichkeit der Analyse.\nMethode: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.\nInhalt: Vorhersageg√ºte.\n\nDas zentrale Bewertungskriterium ist Inhalt; die √ºbrigen beiden Kriterien flie√üen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein.\nDie quantitative Datenanalyse in Durchf√ºhrung und Interpretation ist der Schwerpunkt dieser Arbeit. Zuf√§lliges identisches Vorgehen, z.B. im R Code, ist sehr unwahrscheinlich und kann als Plagiat bewertet werden.\nDie Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.\nEs werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.\nEs werden keine Hinweise vergeben, stattdessen gibt es einen √úberblick an typischen Fehlern.\nEs wird keine Musterl√∂sugn ver√∂ffentlicht, um nachfolgende Kohorten nicht zu bevorteilen bzw. die aktuelle Kohorte nicht zu benachteiligen.\n\n\n\n3.9.2 Kennzahl der Modellg√ºte\nDie G√ºte der Vorhersage wird anhand des mittleren Absolutfehlers (mae) bemessen:\n\\[\\text{mae} = \\frac{1}{n} \\sum_{i=1}^n|(y_i - \\hat{y}_i)|\\]\n\n\n3.9.3 Notenstufen\nZur Vorhersageg√ºte: Die Vorhersageg√ºte eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\).\nIhre Bewertung erfolgt entsprechend Ihrer Vorhersageg√ºte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als \\(2,0\\)!\n\n\n3.9.4 Bewertungsprozess\nDer Gutachter legt im Nachgang der Pr√ºfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellg√ºte offen. Au√üerdem werden die vorherzusagenden Daten ver√∂ffentlicht sowie die Grenzwerte f√ºr jede Notenstufe. Auf dieser Basis ist es allen Teilnehmis m√∂glich, die Korrektheit Ihrer Note zu √ºberpr√ºfen."
  },
  {
    "objectID": "030-Pruefung.html#hinweise",
    "href": "030-Pruefung.html#hinweise",
    "title": "3¬† Pr√ºfung",
    "section": "3.10 Hinweise",
    "text": "3.10 Hinweise\nSie haben freie Methodenwahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie k√∂nnen aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen.\nEine Einf√ºhrung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling with R.2. Die B√ºcher beinhalten jeweils Beispiele und Anwendung mit R.\nAuch ist es Ihnen √ºberlassen, welche Variablen Sie zur Modellierung heranziehen ‚Äì und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausrei√üer bereinigen o.√Ñ.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchf√ºhren, auch auf den Testdaten (Anwendungsdaten) durchzuf√ºhren.\nHinweise zur Modellwahl usw. gibt es auch in erw√§hnter Literatur, aber auch in vielen B√ºchern zum Thema Data-Science.\nAlles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent sein. Im √úbrigen lautet die Aufgabe: Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine sch√∂ne Antwort, trifft die Wirklichkeit aber leider nicht immer. Eine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangsl√§ufig eine gute Vorhersage (Test-Set)."
  },
  {
    "objectID": "030-Pruefung.html#formalia",
    "href": "030-Pruefung.html#formalia",
    "title": "3¬† Pr√ºfung",
    "section": "3.11 Formalia",
    "text": "3.11 Formalia\n\nEs sind nur Einzelarbeiten zul√§ssig.\nIn der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in bereitgestellten Datensatz genutzt werden.\nAlle Analyseschritte bzw. alle Ver√§nderungen an den Daten m√ºssen im (eingereichten) Analyseskript nachvollziehbar aufgef√ºhrt sein. Das Analyseskript ist als R-Skript, qmd-Datei, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie k√∂nnen die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).\nDas Analyseskript muss grunds√§tzlich funktionst√ºchtig f√ºr den Pr√ºfer sein: Alle Befehle m√ºssen ohne Fehlermeldung durchlaufen. Ausnahmen: a) Installation fehlender Pakete, b) Daten sollen aus der Wurzelebene des Projektordners importiert werden..\nEs d√ºrfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzul√§ssig.\nNichtbeachtung der f√ºr dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug f√ºhren.\nDer Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.\nEs muss keine Literatur zitiert werden.\nEin ausgedrucktes Exemplar muss nicht abgegeben werden.\nW√§hrend der Pr√ºfungsphase werden keine inhaltlichen Fragen (‚Äúwie macht man nochmal eine Log-Transformation?‚Äù) und keine technischen Fragen (‚Äúwie installiert man nochmal ein R-Paket?‚Äù) beantwortet."
  },
  {
    "objectID": "030-Pruefung.html#ich-brauche-hilfe",
    "href": "030-Pruefung.html#ich-brauche-hilfe",
    "title": "3¬† Pr√ºfung",
    "section": "3.12 Ich brauche Hilfe!",
    "text": "3.12 Ich brauche Hilfe!\n\n3.12.1 Wo finde ich Beispiele und Vorlagen?\nIm Rahmen des Unterrichts wurden mehrere Fallstudien erarbeitet bzw. bereitgestellt, diese dienen Ihnen als ideale Vorlage.\nEine Beispiel-Modellierung finden Sie in der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd. Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen k√∂nnen, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt.\nIm Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen k√∂nnen.\n\n\n3.12.2 Probepr√ºfung f√ºr den Prognosewettbewerb\nJa, hier. In diesem Ordner liegen die Dokumente, die Sie f√ºr die echte Pr√ºfung auch bekommen:\n\nTrain-Datensatz\nTest-Datensatz\nHinweise zur vorherzusagenden Variablen\n\n\n\n3.12.3 Materialsammlung\nIn diesem Ordner finden Sie eine Materialsammlung zum Prognosewettbewerb.\n\n\n3.12.4 Videos\nDiese Playlist beinhaltet Videos, die die Rahmenbedingungen der Pr√ºfungsleistung vorstellt."
  },
  {
    "objectID": "030-Pruefung.html#plagiatskontrolle",
    "href": "030-Pruefung.html#plagiatskontrolle",
    "title": "3¬† Pr√ºfung",
    "section": "3.13 Plagiatskontrolle",
    "text": "3.13 Plagiatskontrolle\nDie eingereichten Arbeiten k√∂nnen automatisiert auf Plagiate √ºberpr√ºft werden. Gibt es substanzielle √úberschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungen√ºgend bewertet oder es folgt eine Abwertung der Note."
  },
  {
    "objectID": "030-Pruefung.html#footnotes",
    "href": "030-Pruefung.html#footnotes",
    "title": "3¬† Pr√ºfung",
    "section": "",
    "text": "https://link.springer.com/book/10.1007/978-3-658-21587-3‚Ü©Ô∏é\nhttps://www.tmwr.org/‚Ü©Ô∏é"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#lernsteuerung",
    "href": "040-Statistisches-Lernen.html#lernsteuerung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.1 Lernsteuerung",
    "text": "4.1 Lernsteuerung\n\n4.1.1 Vorbereitung\n\nLesen Sie die Hinweise zum Modul.\nInstallieren (oder Updaten) Sie die f√ºr dieses Modul angegeben Software. Lesen Sie die Literatur.\n\n4.1.2 Lernziele\n\nSie k√∂nnen erl√§utern, was man unter statistischem Lernen versteht. Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann. Sie kennen verschiedenen Arten von statistischem Lernen und k√∂nnen Algorithmen zu diesen Arten zuordnen.\n\n4.1.3 Literatur\n\nRhys, Kap. 1\nevtl. Sauer, Kap. 15\n\n4.1.4 Hinweise\n\nBitte beachten Sie die Hinweise zum Pr√§senzunterricht und der Streamingoption.\nBitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) l√§uft.\n\n4.1.5 R-Pakete\nBen√∂tigte R-Pakete f√ºr dieses Kapitel:\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-data-science",
    "href": "040-Statistisches-Lernen.html#was-ist-data-science",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.2 Was ist Data Science?",
    "text": "4.2 Was ist Data Science?\nEs gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, und Horton (2017) definieren Data Science wie folgt (S. 4):\n\n\n\n\n\n\nHinweis\n\n\n\nThe science of extracting meaningful information from data.\\(\\square\\)\n\n\nAuf der anderen Seite entgegen viele Statistiker: ‚ÄúHey, das machen wir doch schon immer!‚Äù.\nEine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (‚ÄúDom√§ne‚Äù), die sozusagen den Empf√§nger bzw. die Kunden oder den Rahmen stellt. Dieser ‚ÄúDreiklang‚Äù ist in folgendem Venn-Diagramm dargestellt."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "href": "040-Statistisches-Lernen.html#was-ist-machine-learning",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.3 Was ist Machine Learning?",
    "text": "4.3 Was ist Machine Learning?\n\nDefinition 4.1 Maschinelles Lernen (ML), oft auch (synonym) als statistisches Lernen (statistical learning) bezeichnet, ist ein Teilgebiet der k√ºnstlichen Intelligenz (KI; artificial intelligence, AI) (Rhys 2020). ML wird auch als data-based bezeichnet in Abgrenzung von rule-based, was auch als ‚Äúklassische KI‚Äù bezeichnet wird, vgl. Abbildung¬†4.1.\n\n\n\n\n\nflowchart LR\n  subgraph KI[K√ºnstliche Intelligenz KI]\n    rb[rule based]\n    db[data based]\n  end   \n\n\nAbbildung¬†4.1: KI und Maschinelles Lernen\n\n\n\n\nIn beiden F√§llen finden Algorithmen Verwendung.\n\nDefinition 4.2 (Algorithmus) Algorithmen sind nichts anderes als genaue Schritt-f√ºr-Schritt-Anleitungen, um etwas zu erledigen.\\(\\square\\)\n\n\nBeispiel 4.1 Ein Kochrezept ist ein klassisches Beispiel f√ºr einen Algorithmus.\\(\\square\\)\n\nHier findet sich ein Beispiel f√ºr einen einfachen Additionsalgorithmus.\nEs gibt viele ML-Algorithmen, vgl. Abbildung¬†4.2.\n\n\n\n\nflowchart LR\n  subgraph KI[KI]\n    subgraph ML[ML]\n      A[Regression]\n      B[Neuronale Netze]\n      C[weitere]\n    end\n  end\n\n\nAbbildung¬†4.2: ML-Matroschka\n\n\n\n\n\n4.3.1 Rule-based\nKlassische (√§ltere) KI implementiert Regeln ‚Äúhartverdrahtet‚Äù in ein Computersystem. Nutzer f√ºttern Daten in dieses System. Das System leitet dann daraus Antworten ab.\nRegeln kann man prototypisch mit Wenn-Dann-Abfragen darstellen:\n\nlernzeit &lt;- c(0, 10, 10, 20)\nschlauer_nebensitzer &lt;- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] &gt; 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}\n## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\n\nSicherlich k√∂nnte man das schlauer programmieren, vielleicht so:\n\nd &lt;- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %&gt;% \n  mutate(bestanden = ifelse(lernzeit &gt; 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))\n\n\n\n  \n\n\n\n\n4.3.2 Data-based\nML hat zum Ziel, Regeln aus den Daten zu lernen. Man f√ºttert Daten und Antworten in das System, das System gibt Regeln zur√ºck.\nJames u.¬†a. (2021) definieren ML so: Nehmen wir an, wir haben die abh√§ngige Variable \\(Y\\) und \\(p\\) Pr√§diktoren, \\(X_1,X_2, \\ldots, X_p\\). Weiter nehmen wir an, die Beziehung zwischen \\(Y\\) und \\(X = (X_1, X_2, \\ldots, X_p)\\) kann durch eine Funktion \\(f\\) beschrieben werden. Das kann man so darstellen:\n\\[Y = f(X) + \\epsilon\\]\nML kann man auffassen als eine Menge an Verfahren, um \\(f\\) zu sch√§tzen.\nEin Beispiel ist in Abb. Abbildung¬†4.3 gezeigt (James u.¬†a. 2021).\n\n\nAbbildung¬†4.3: Vorhersage des Einkommens durch Ausbildungsjahre\n\n\nNat√ºrlich kann \\(X\\) mehr als eine Variable beinhalten, vgl. Abbildung¬†4.4) (James u.¬†a. 2021).\n\n\nAbbildung¬†4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren\n\n\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gef√ºttert und liefern Antworten. ML-Systeme werden mit Daten und Antworten gef√ºttert und liefern Regeln zur√ºck, s. Abbildung¬†4.5.\n\n\n\n\nflowchart LR\n  subgraph rb[rule-based]\n  D[Daten] --&gt;A[Antworten]\n  R[Regeln] --&gt;A\n  end\n  subgraph db[data-based]\n  D2[Daten] --&gt; R2[Regeln]\n  A2[Antworten] --&gt; R2\n  end\n\n\nAbbildung¬†4.5: Vergleich von klassischer KI (rule-based) und ML (data-based)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "href": "040-Statistisches-Lernen.html#modell-vs.-algorithmus",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.4 Modell vs.¬†Algorithmus",
    "text": "4.4 Modell vs.¬†Algorithmus\n\n4.4.1 Modell\nEin Modell, s. Abb. Abbildung¬†4.6) (Spurzem 2017)!\n\n\nAbbildung¬†4.6: Ein Modell-Auto\n\n\nWie man sieht, ist ein Modell eine vereinfachte Repr√§sentation eines Gegenstands.\nDer Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. Abbildung¬†4.7).\n\n\nAbbildung¬†4.7: Gegenstand und Modell\n\n\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln, die aus den Daten gelernt wurden.\n\n4.4.2 Beispiel f√ºr einen ML-Algorithmus\nUnter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren, anhand dessen die Beziehung zwischen \\(X\\) und \\(Y\\) ‚Äúgelernt‚Äù wird. Bei Rhys (2020) (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:\nBeispiel eines Regressionsalgorithmus\n\nSetze Gerade in die Daten mit \\(b_0 = \\hat{y}, b_1 = 0\\)\n\nBerechne \\(MSS = \\sum (y_i - \\hat{y_i})^2\\)\n\n‚ÄúDrehe‚Äù die Gerade ein bisschen, d.h. erh√∂he \\(b_1^{neu} = b_1^{alt} + 0.1\\)\n\nWiederhole 2-3 solange, bis \\(MSS &lt; \\text{Zielwert}\\)\n\n\nDiesen Algorithmus kann man ‚Äúvon Hand‚Äù z.B. mit dieser App durchspielen."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#taxonomie",
    "href": "040-Statistisches-Lernen.html#taxonomie",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.5 Taxonomie",
    "text": "4.5 Taxonomie\nMethoden des maschinellen Lernens lassen sich verschiedentlich gliedern. Eine typische Gliederung unterscheidet in supervidierte (geleitete) und nicht-supervidierte (ungeleitete) Algorithmen, s. Abb. Abbildung¬†4.8).\n\n\n\n\nflowchart LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --&gt; SL\n  ML --&gt; NSL\n  SL --&gt; Re\n  SL --&gt; Class\n  NSL --&gt; DimRed\n  NSL --&gt; Clust\n\n\n\nAbbildung¬†4.8: Taxonomie der Arten des maschinellen Lernens\n\n\n\n\n\n4.5.1 Geleitetes Lernen\nDie zwei Phasen des geleiteten Lernens sind in Abb. Abbildung¬†4.9) dargestellt.\n\n\n\n\nflowchart TD\n  subgraph A[Lernphase]\n    B[Daten mit Antwort] --&gt; C[Geleiteter Algorithmus]\n    C --&gt; D[Modell]\n  end\n  subgraph E[Vorhersagephase]\n    H[Neue Daten ohne Antwort] --&gt; F[Modell]\n    F --&gt; G[Antworten]\n  end\n  A--&gt;E\n\n\nAbbildung¬†4.9: Geleitetes Lernen geschieht in zwei Phasen\n\n\n\n\n\n4.5.1.1 Regression: Numerische Vorhersage\n\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n\n\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden G√ºtekoeffizienten gemessen:\n\nMean Squared Error (Mittlerer Quadratfehler):\n\n\\[MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\]\n\nMean Absolute Error (Mittlerer Absolutfehler):\n\n\\[MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|\\]\n\nWir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzusch√§tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.\n\n\n4.5.1.2 Klassifikation: Nominale Vorhersage\n\n\nBei einer Klassifikation wird nicht eine Zahl, sondern eine Klasse vorhergesagt\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit folgendem G√ºtekoeffizienten gemessen:\n\nMittlerer Klassifikationfehler \\(e\\):\n\n\\[e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) \\]\nDabei ist \\(I\\) eine Indikatorfunktion, die 1 zur√ºckliefert, wenn tats√§chlicher Wert und vorhergesagter Wert identisch sind.\n\n4.5.2 Ungeleitetes Lernen\nDie zwei Phasen des ungeleiteten Lernens sind in Abbildung¬†4.10 dargestellt.\n\n\n\n\nflowchart LR\n  subgraph X[Lernphase]\n    A[Daten ohne Antwort] --&gt; B[Ungeleiteter Algorithmus]\n    B --&gt; C[Modell]\n  end\n  subgraph D[Vorhersagephase]\n    E[Neue Daten, ohne Antwort] --&gt; C2[Modell]\n    C2 --&gt; F[Zuordnung zu den Regeln des Modells]\n  end  \n  X---&gt;D\n\n\nAbbildung¬†4.10: Die zwei Phasen des un√ºberwachten Lernens\n\n\n\n\nUngeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. Abbildung¬†4.11):\n\nFallreduzierendes Modellieren (Clustering)\nDimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\n\n\n\nAbbildung¬†4.11: Zwei Arten des ungeleitete Modellieren"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#ziele-des-ml",
    "href": "040-Statistisches-Lernen.html#ziele-des-ml",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.6 Ziele des ML",
    "text": "4.6 Ziele des ML\nMan kann vier Ziele des ML unterscheiden, s. Abbildung¬†4.12.\n\n\n\n\nflowchart TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[Erkl√§rung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --&gt; V\n  ML --&gt; E\n  ML --&gt; B\n  ML --&gt; DimRed\n\n\nAbbildung¬†4.12: Ziele des maschinellen Lernens\n\n\n\n\nVorhersage bezieht sich auf die Sch√§tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit). Erkl√§rung meint die kausale Analyse von Zusammenh√§ngen. Beschreibung ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken. Dimensionsreduktion ist ein Oberbegriff f√ºr Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s\nWie ‚Äúgut‚Äù ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellg√ºte oder model fit. Je schlechter die Modellg√ºte, desto h√∂her der Modellfehler, vgl. Abbildung¬†4.13.\n\n\nAbbildung¬†4.13: Wenig (links) vs.¬†viel (rechts) Vorhersagefehler\n\n\nDie Modellg√ºte eines Modells ist v.a. relevant f√ºr neue Beobachtungen, an denen das Modell nicht trainiert wurde."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#√ºber--vs.-unteranpassung",
    "href": "040-Statistisches-Lernen.html#√ºber--vs.-unteranpassung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.7 √úber- vs.¬†Unteranpassung",
    "text": "4.7 √úber- vs.¬†Unteranpassung\n\nDefinition 4.3 (Overfitting) Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als ‚Äúbare M√ºnze‚Äù, also f√§lschlich als Signal. Solche Modelle haben zu viel Varianz in ihren Vorhersagen.\\(\\square\\)\n\n\nDefinition 4.4 (Underfitting) Ein Modell ist zu simpel (ungenau, grobk√∂rnig) - es unterschl√§gt Nuancen des tats√§chlichen Musters. Solche Modelle haben zu viel Verzerrung (Bias) in ihren Vorhersagen.\\(\\square\\)\n\nWelches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. Abbildung¬†4.14), vgl. (Sauer 2019), Kap. 15?\n\n\n\n\nAbbildung¬†4.14: Over- vs.¬†Underfitting\n\n\n\n\nWelches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?\nModell D zeigt sehr gute Beschreibung (‚ÄúRetrodiktion‚Äù) der Werte, anhand derer das Modell trainiert wurde (‚ÄúTrainingsstichprobe‚Äù). Wird es aber ‚Äúehrlich‚Äù getestet, d.h. anhand neuer Daten (‚ÄúTest-Stichprobe‚Äù), wird es vermutlich nicht so gut abschneiden.\nEs gilt, ein Modell mit ‚Äúmittlerer‚Äù Komplexit√§t zu finden, um √úber- und Unteranpassung in Grenzen zu halten. Leider ist es nicht m√∂glich, vorab zu sagen, was der richtige, ‚Äúmittlere‚Äù Wert an Komplexit√§t eines Modells ist, vgl. Abbildung¬†4.15 aus (Sauer 2019).\n\n\nAbbildung¬†4.15: Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte: Gute Balance von Bias und Pr√§zision\n\n\n\n4.7.1 Do-it-yourself Under-/Overfitting\nErkunden wir die Effekte von Under- und Overfitting an einem einfachen, simulierten Datenbeispiel:\n\nd &lt;- tibble(\n  x = -2:2,\n  y = c(-1, -.5, 0, 0.1, 2)\n)\n\nJetzt ‚Äúfitten‚Äù wir eine zunehmend komplexe Funktion in diese Daten. Als Funktion w√§hlen wir ein Polynom von Grad 1 bis 4.\n\nEin Polynom 1. Grades ist eine lineare Funktion: \\(y \\sim x¬π\\).\nEin Polynom 2. Grades ist eine quadratische Funktion: \\(y \\sim x¬≤ + x\\)\n\nEin Polynom \\(n\\). Grades ist eine Funktion der Form \\(y \\sim x^n + x^{n-1} + x^{n-2} + \\ldots + x\\)\n\n\nPolynome werden flexibler (mehr ‚ÄúT√§ler‚Äù und ‚ÄúGipfel‚Äù haben), je h√∂her ihr Grad ist. Daher stellt sich die Frage, welcher Grad der ‚Äúrichtige‚Äù ist. Leider wissen wir in der Praxis nicht, welche Funktion die Natur ausgew√§hlt hat. Daher w√§re eine L√∂sung, die Funktion auszuw√§hlen, welche die Daten am besten erkl√§rt.\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE)\n\n\n\n\n\n(a) Grad 1\n\n\n\n\n\n\n(b) Grad 2\n\n\n\n\n\n\n\n\n(c) Grad 3\n\n\n\n\n\n\n(d) Grad 4\n\n\n\n\nAbbildung¬†4.16: Polynome vom Grad 1-4\n\n\n\nWie man sieht, wird der Modellfehler immer kleiner, der ‚ÄúFit‚Äù zunehmens besser.\nDas kann man sich nat√ºrlich auch pr√§ziser berechnen lassen.\n\nlm1 &lt;- lm(y ~ poly(x, 1), data = d)\nlm2 &lt;- lm(y ~ poly(x, 2), data = d)\nlm3 &lt;- lm(y ~ poly(x, 3), data = d)\nlm4 &lt;- lm(y ~ poly(x, 4), data = d)\n\nresults &lt;-\n  tibble(r2_lm1 = r2(lm1)$R2,\n         r2_lm2 = r2(lm2)$R2,\n         r2_lm3 = r2(lm3)$R2,\n         r2_lm4 = r2(lm4)$R2)\n\nresults\n\n\n\n  \n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nJe komplexer das Modell, desto besser der Fit1 in dem Modell, in das Modell berechnet wurde.\n\n\nAber wie gut werden die Vorhersagen f√ºr neue Daten sein?\nSagen wir, in Wirklichkeit ist der datengenerierende Prozess2 (DGP) eine einfache lineare Funktion, plus etwas Rauschen (Fehler, \\(\\epsilon\\)):\n\\(y \\sim x + \\epsilon\\)\nSagen wir, das Rauschen ist normalverteilt mit Streuung 0.5.\nSimulieren wir uns jetzt ein paar neue Daten, die aus dieser Funktion resultieren.\n\nd1 &lt;- tibble(\n  x = -2:2,\n  e = rnorm(n = 5, mean = 0, sd = .5), \n  y = x,  # \"wahrer\" Wert\n  y_hat = y + e  # beobachteter Wert mit Rauschen\n)\n\nd1\n\n\n\n  \n\n\n\n\nDefinition 4.5 (Train- und Test-Datensatz) Den Datensatz, in dem man ein Modell berechnet (‚Äúfittet‚Äù), nennt man auch Train-Datensatz. Einen anderen Datensatz, den man nutzt, um die G√ºte des Modells zu √ºberpr√ºfen, nennt man Test-Datensatz\n\nDamit wir eine stabilere Datenbasis haben, simulieren wir aber pro X-Wert (-2, -1, 0, 1, 2) nicht nur einen Wert, sondern, sagen wir, 10:\n\nd2 &lt;- \n  tibble(\n    x = rep(-2:2, times = 10),\n    e = rnorm(n = 50, mean = 0, sd = .5),  # Rauschen, Fehlerterm\n    y_hat = x,  # \"wahrer\" Wert\n    y = x + e  # beobachteter Wert mit Rauschen\n  )\n\nd2\n\n\n\n  \n\n\n\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE) +\n  geom_point(data = d2, color = \"blue\") \n\n\n\nAbbildung¬†4.17: In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut\n\n\n\n\nJetzt sieht das R-Quadrat schon nicht mehr so gut aus, s. Abbildung¬†4.17. Berechnen wir mal das R-Quadrat:\n\nrsq(data = d2, truth = y, estimate = y_hat)\n\n\n\n  \n\n\n\n\n√úbungsaufgabe 4.1 (Overfitting) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine einfache lineare Funktion sein (Polynom 1. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)\n\n\n√úbungsaufgabe 4.2 (Overfitting 2) Simulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine Polynomfunktion sein (Polynom 2. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.\\(\\square\\)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#no-free-lunch",
    "href": "040-Statistisches-Lernen.html#no-free-lunch",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.8 No free lunch",
    "text": "4.8 No free lunch\n\n\nYoda meint: Es gibt nicht ‚Äúdas‚Äù beste Modell\n\n\nQuelle: ImgFlip Meme Generator\nWenn \\(f\\) (die Beziehung zwischen \\(Y\\) und \\(X\\), auch datengenerierender Prozess genannt) linear oder fast linear ist, dann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. @ref(fig:2-10) aus James u.¬†a. (2021), dort zeigt die schwarze Linie den ‚Äúwahren Zusammenhang‚Äù, also \\(f\\) an. In orange sieht man ein lineares Modell, in gr√ºn ein hoch komplexes Modell, das sich in einer ‚Äúwackligen‚Äù Funktion - also mit hoher Varianz - niederschl√§gt. Das gr√ºne Modell k√∂nnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \\(y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon\\). Das lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias. Daher ist es f√ºr dieses \\(f\\) gut passend. Die gr√ºne Funktion zeigt dagegen √úberanpassung (overfitting), also viel Modellfehler (f√ºr eine Test-Stichprobe).\n\n\n\n\n\n\nVorsicht\n\n\n\nDie gr√ºne Funktion in Abbildung¬†4.18 wird neue, beim Modelltraining unbekannte Beobachtungen (\\(y_0\\)) vergleichsweise schlecht vorhersagen. In Abbildung¬†4.19 ist es umgekehrt.\n\n\n\n\nAbbildung¬†4.18: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren\n\n\nBetrachten wir im Gegensatz dazu Abbildung¬†4.19 aus James u.¬†a. (2021), die (in schwarz) eine hochgradig nichtlineare Funktion \\(f\\) zeigt. Entsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. Ein lineares Modell wird der Komplexit√§t von \\(f\\) nicht gerecht, Unteranpassung (underfitting) liegt vor.\n\n\nAbbildung¬†4.19: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#bias-varianz-abw√§gung",
    "href": "040-Statistisches-Lernen.html#bias-varianz-abw√§gung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.9 Bias-Varianz-Abw√§gung",
    "text": "4.9 Bias-Varianz-Abw√§gung\nDer Gesamtfehler \\(E\\) des Modells ist die Summe dreier Terme:\n\\[E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon\\]\nDabei meint \\(\\epsilon\\) den nicht reduzierbaren Fehler, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).\nBias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. Abbildung¬†4.20 aus Sauer (2019).\n\n\nAbbildung¬†4.20: Abw√§ngung von Bias vs.¬†Varianz"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#vertiefung",
    "href": "040-Statistisches-Lernen.html#vertiefung",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.10 Vertiefung",
    "text": "4.10 Vertiefung\n\nVerdienst einer deutschen Data Scientistin\nWeitere Fallstudie zum Thema Regression auf Kaggle\nCrashkurs Data Science (Coursera, Johns Hopkins University) mit ‚ÄòStar-Dozenten‚Äô\nArbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf\nWerfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise\nWiederholen Sie unser Vorgehen in der Fallstudie zu den Flugversp√§tungen"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#aufgaben",
    "href": "040-Statistisches-Lernen.html#aufgaben",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.11 Aufgaben:",
    "text": "4.11 Aufgaben:\n\nMachen Sie sich mit ‚ÄòKaggle‚Äô vertraut\nBearbeiten Sie die Fallstudie ‚ÄòTitaRnic‚Äô auf Kaggle\nMachen Sie sich mit dieser einfachen Fallstudie zur linearen Regression vertraut: The Movie Data Base Revenue (Kaggle)"
  },
  {
    "objectID": "040-Statistisches-Lernen.html#videos",
    "href": "040-Statistisches-Lernen.html#videos",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "\n4.12 Videos",
    "text": "4.12 Videos\n\nPrognose-Wettbewerbe bei Kaggle am Beispiel von The Movie Data Base Revenue\n\n\n\n\n\nBaumer, Benjamin S., Daniel T. Kaplan, und Nicholas J. Horton. 2017. Modern Data Science with R (Chapman & Hall/CRC Texts in Statistical Science). Boca Raton, Florida: Chapman; Hall/CRC.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87. https://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG."
  },
  {
    "objectID": "040-Statistisches-Lernen.html#footnotes",
    "href": "040-Statistisches-Lernen.html#footnotes",
    "title": "\n4¬† Statistisches Lernen\n",
    "section": "",
    "text": "ceteris paribus‚Ü©Ô∏é\ndata-generating process, DGP‚Ü©Ô∏é"
  },
  {
    "objectID": "050-R-Vertiefung.html#lernsteuerung",
    "href": "050-R-Vertiefung.html#lernsteuerung",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.1 Lernsteuerung",
    "text": "5.1 Lernsteuerung\n\n5.1.1 Literatur\n\nRhys, Kap. 2\nMODAR, Kap. 5\n\n5.1.2 Lernziele\n\nSie k√∂nnen Funktionen, in R schreiben.\nSie k√∂nnen Datens√§tze vom Lang- und Breit-Format wechseln.\nSie k√∂nnen Wiederholungsstrukturen wie Mapping-Funktionen anwenden.\nSie k√∂nnen eine dplyr-Funktion auf mehrere Spalten gleichzeitig anwenden.\n\n5.1.3 Vorbereitung\n\nLesen Sie die Literatur."
  },
  {
    "objectID": "050-R-Vertiefung.html#objekttypen-in-r",
    "href": "050-R-Vertiefung.html#objekttypen-in-r",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.2 Objekttypen in R",
    "text": "5.2 Objekttypen in R\nN√§heres zu Objekttypen findet sich in Sauer (2019), Kap. 5.2.\n\n5.2.1 √úberblick\nIn R ist praktisch alles ein Objekt.\n\nDefinition 5.1 (Objekt (Informatik)) Ein Objekt meint ein im Computerspeicher repr√§sentiertes Ding, etwa eine Tabelle.\\(\\square\\)\n\n\nBeispiel 5.1 (Beispiele f√ºr Objekte) Vektoren und Dataframes (Tibbles) sind die vielleicht g√§ngigsten Objektarten in R (vgl. Abbildung¬†5.1), aus Sauer (2019)).\\(\\square\\)\n\n\n\nAbbildung¬†5.1: Zentrale Objektarten in R\n\n\nEs gibt in R keine (Objekte f√ºr) Skalare (einzelne Zahlen). Stattdessen nutzt R Vektoren der L√§nge 1.\nEin n√ºtzliches Schema stammt aus Wickham und Grolemund (2016), s. Abbildung¬†5.2).\n\n\nAbbildung¬†5.2: Objektarten hierarchisch gegliedert\n\n\n\n5.2.2 Taxonomie\nUnter homogenen Objektiven verstehen wir Datenstrukturen, die nur eine Art von Daten (wie Text oder Ganze Zahlen) fassen. Sonstige Objekte nennen wir heterogen.\n\nHomogene Objekte\n\nVektoren\nMatrizen\n\n\nHeterogen\n\nListe\nDataframes (Tibbles)\n\n\n\n\n5.2.2.1 Vektoren\nVektoren sind insofern zentral in R, als dass die √ºbrigen Datenstrukturen auf ihnen aufbauen, vgl. Abbildung¬†5.3 aus Sauer (2019).\nReine (atomare) Vektoren in R sind eine geordnete Liste von Daten eines Typs.\n\n\nAbbildung¬†5.3: Vektoren stehen im Zentrum der Datenstrukturen in R\n\n\n\nein_vektor &lt;- c(1, 2, 3)\nnoch_ein_vektor &lt;- c(\"A\", \"B\", \"C\")\nlogischer_vektor &lt;- c(TRUE, FALSE, TRUE)\n\nMit str() kann man sich die Struktur eines Objektsausgeben lassen:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\nstr(noch_ein_vektor)\n##  chr [1:3] \"A\" \"B\" \"C\"\nstr(logischer_vektor)\n##  logi [1:3] TRUE FALSE TRUE\n\nVektoren k√∂nnen von folgenden Typen sein:\n\nKommazahlen ( double) genannt\nGanzzahlig (integer, auch mit L f√ºr Long abgek√ºrzt)\nText (¬¥character`, String)\nlogische Ausdr√ºcke (logical oder lgl) mit TRUE oder FALSE\n\n\nKommazahlen und Ganze Zahlen zusammen bilden den Typ numeric (numerisch) in R.\nDen Typ eines Vektors kann man mit typeof() ausgeben lassen:\n\ntypeof(ein_vektor)\n## [1] \"double\"\n\n\n5.2.2.2 Faktoren\n\nsex &lt;- factor(c(\"Mann\", \"Frau\", \"Frau\"))\n\nInteressant:\n\nstr(sex)\n##  Factor w/ 2 levels \"Frau\",\"Mann\": 2 1 1\n\nVertiefende Informationen findet sich in Wickham und Grolemund (2016).\n\n5.2.2.3 Listen\n\neine_liste &lt;- list(titel = \"Einf√ºhrung\",\n                   woche = 1,\n                   datum = c(\"2022-03-14\", \"2202-03-21\"),\n                   lernziele = c(\"dies\", \"jenes\", \"und noch mehr\"),\n                   lehre = c(TRUE, TRUE, TRUE)\n                   )\nstr(eine_liste)\n## List of 5\n##  $ titel    : chr \"Einf√ºhrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\n\n5.2.2.4 Tibbles\nF√ºr tibble() brauchen wir tidyverse:\n\nlibrary(tidyverse)\n\n\n\nstudentis &lt;-\n  tibble(\n    name = c(\"Anna\", \"Berta\"),\n    motivation = c(10, 20),\n    noten = c(1.3, 1.7)\n  )\nstr(studentis)\n## tibble [2 √ó 3] (S3: tbl_df/tbl/data.frame)\n##  $ name      : chr [1:2] \"Anna\" \"Berta\"\n##  $ motivation: num [1:2] 10 20\n##  $ noten     : num [1:2] 1.3 1.7\n\n\n5.2.3 Indizieren\nEinen Teil eines Objekts auszulesen, bezeichnen wir als Indizieren.\n\n5.2.3.1 Reine Vektoren\nZur Erinnerung:\n\nstr(ein_vektor)\n##  num [1:3] 1 2 3\n\n\nein_vektor[1]\n## [1] 1\nein_vektor[c(1,2)]\n## [1] 1 2\n\nAber nicht so:\n\nein_vektor[1,2]\n## Error in ein_vektor[1, 2]: incorrect number of dimensions\n\nMan darf Vektoren auch wie Listen ansprechen, also eine doppelte Eckklammer zum Indizieren verwenden\n\nein_vektor[[2]]\n## [1] 2\n\nDer Grund ist, dass Listen auch Vektoren sind, nur eben ein besonderer Fall eines Vektors:\n\nis.vector(eine_liste)\n## [1] TRUE\n\nWas passiert, wenn man bei einem Vektor der L√§nge 3 das 4. Element indiziert?\n\nein_vektor[4]\n## [1] NA\n\nEin schn√∂des NA ist die Antwort. Das ist interessant: Wir bekommen keine Fehlermeldung, sondern den Hinweis, das angesprochene Element sei leer bzw. nicht verf√ºgbar.\nIn Sauer (2019), Kap. 5.3.1 findet man weitere Indizierungsm√∂glichkeiten f√ºr reine Vektoren.\n\n5.2.3.2 Listen\n\neine_liste %&gt;% str()\n## List of 5\n##  $ titel    : chr \"Einf√ºhrung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\n\nListen k√∂nnen wie Vektoren, also mit [ ausgelesen werden. Dann wird eine Liste zur√ºckgegeben.\n\neine_liste[1]\n## $titel\n## [1] \"Einf√ºhrung\"\neine_liste[2]\n## $woche\n## [1] 1\n\nDas hat den technischen Hintergrund, dass Listen als eine bestimmte Art von Vektoren implementiert sind.\nMann kann auch die ‚Äúdoppelte Eckklammer‚Äù, [[ zum Auslesen verwenden; dann wird anstelle einer Liste die einfachere Struktur eines Vektors zur√ºckgegeben:\n\neine_liste[[1]]\n## [1] \"Einf√ºhrung\"\n\nMan k√∂nnte sagen, die ‚Äú√§u√üere Schicht‚Äù des Objekts, die Liste, wird abgesch√§lt, und man bekommnt die ‚Äúinnere‚Äù Schicht, den Vektor.\nMann die Elemente der Liste entweder mit ihrer Positionsnummer (1, 2, ‚Ä¶) oder, sofern vorhanden, ihren Namen ansprechen:\n\neine_liste[[\"titel\"]]\n## [1] \"Einf√ºhrung\"\n\nDann gibt es noch den Dollar-Operator, mit dem Mann benannte Elemente von Listen ansprechen kann:\n\neine_liste$titel\n## [1] \"Einf√ºhrung\"\n\nMan kann auch tiefer in eine Liste hinein indizieren. Sagen wir, uns interessiert das 4. Element der Liste eine_liste - und davon das erste Element.\nDas geht dann so:\n\neine_liste[[4]][[1]] \n## [1] \"dies\"\n\nEine einfachere Art des Indizierens von Listen bietet die Funktion pluck(), aus dem Paket purrr, das Hilfen f√ºr den Umgang mit Listen bietet.\n\npluck(eine_liste, 4)\n## [1] \"dies\"          \"jenes\"         \"und noch mehr\"\n\nUnd jetzt aus dem 4. Element das 1. Element:\n\npluck(eine_liste, 4, 1)\n## [1] \"dies\"\n\nProbieren Sie mal, aus einer Liste der L√§nge 5 das 6. Element auszulesen:\n\neine_liste %&gt;% length()\n## [1] 5\n\n\neine_liste[[6]]\n## Error in eine_liste[[6]]: subscript out of bounds\n\nUnser Versuch wird mit einer Fehlermeldung quittiert.\nSprechen wir die Liste wie einen (atomaren) Vektor an, bekommen wir hingegen ein NA bzw. ein NULL:\n\neine_liste[6]\n## $&lt;NA&gt;\n## NULL\n\n\n5.2.3.3 Tibbles\nTibbles lassen sich sowohl wie ein Vektor als auch wie eine Liste indizieren.\n\nstudentis[1]\n\n\n\n  \n\n\n\nDie Indizierung eines Tibbles mit der einfachen Eckklammer liefert einen Tibble zur√ºck.\n\nstudentis[\"name\"]\n\n\n\n  \n\n\n\nMit doppelter Eckklammer bekommt man, analog zur Liste, einen Vektor zur√ºck:\n\nstudentis[[\"name\"]]\n## [1] \"Anna\"  \"Berta\"\n\nBeim Dollar-Operator kommt auch eine Liste zur√ºck:\n\nstudentis$name\n## [1] \"Anna\"  \"Berta\"\n\n\n5.2.4 Weiterf√ºhrende Hinweise\n\n\nTutorial zum Themen Indizieren von Listen von Jenny BC.\n\n5.2.5 Indizieren mit dem Tidyverse\nNat√ºrlich kann man auch die Tidyverse-Verben zum Indizieren verwenden. Das bietet sich an, wenn zwei Bedingungen erf√ºllt sind:\n\nWenn man einen Tibble als Input und als Output hat\nWenn man nicht programmieren m√∂chte"
  },
  {
    "objectID": "050-R-Vertiefung.html#datens√§tze-von-lang-nach-breit-umformatieren",
    "href": "050-R-Vertiefung.html#datens√§tze-von-lang-nach-breit-umformatieren",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.3 Datens√§tze von lang nach breit umformatieren",
    "text": "5.3 Datens√§tze von lang nach breit umformatieren\nManchmal findet man Datens√§tze im sog. langen Format vor, manchmal im breiten.\nIn der Regel m√ºssen die Daten ‚Äútidy‚Äù sein, was meist dem langen Format entspricht, vgl. Abbildung¬†5.4 aus Sauer (2019).\n\n\nAbbildung¬†5.4: Von lang nach breit und zur√ºck\n\n\nIn einer neueren Version des Tidyverse werden diese beiden Befehle umbenannt bzw. erweitert, s. Abbildung¬†5.5.\n\n\ngather() -&gt; pivot_longer()\n\n\nspread() -&gt; pivot_wider()\n\n\n\n\nAbbildung¬†5.5: Von ‚Äúweit‚Äù zu ‚Äúbreit‚Äù und zur√ºck, eine Animation\n\n\nWeitere Informationen findet sich in Wickham und Grolemund (2016), in diesem Abschnitt, 12.3."
  },
  {
    "objectID": "050-R-Vertiefung.html#funktionen",
    "href": "050-R-Vertiefung.html#funktionen",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.4 Funktionen",
    "text": "5.4 Funktionen\nEine Funktion kann man sich als analog zu einer Variable vorstellen. Es ist ein Objekt, das nicht Daten, sondern Syntax beinhaltet, vgl. Abbildung¬†5.6 aus Sauer (2019).\n\n\nAbbildung¬†5.6: Sinnbild einer Funktion\n\n\n\nmittelwert &lt;- function(x){\n  \n  summe &lt;- sum(x, na.rm = TRUE)\n  mw &lt;- summe/length(x)\n  return(mw)\n  \n}\n\n\nmittelwert(c(1, 2, 3))\n## [1] 2\n\nWeitere Informationen finden sich in Kapitel 19 in Wickham und Grolemund (2016). Alternativ findet sich ein Abschnitt dazu (28.1) in Sauer (2019)."
  },
  {
    "objectID": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "href": "050-R-Vertiefung.html#wiederholungen-programmieren",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.5 Wiederholungen programmieren",
    "text": "5.5 Wiederholungen programmieren\nH√§ufig m√∂chte man eine Operation mehrfach ausf√ºhren. Ein Beispiel w√§re die Anzahl der fehlenden Werte pro Spalte auslesen. Nat√ºrlich kann man die Abfrage einfach h√§ufig tippen, nervt aber irgendwann. Daher braucht‚Äôs Strukturen, die Wiederholungen beschreiben.\nDaf√ºr gibt es verschiedene Ans√§tze.\n\n5.5.1 across()\n\nHandelt es sich um Spalten von Tibbles, dann bietet sich die Funktion across(.col, .fns) an. across wendet eine oder mehrere Funktionen (mit .fns bezeichnet) auf die Spalten .col an.\nDas erkl√§rt sich am besten mit einem Beispiel:\nNat√ºrlich h√§tte man in diesem Fall auch anders vorgehen k√∂nnen:\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = mean))\n\n\n\n  \n\n\n\nM√∂chte man der Funktion .fns Parameter √ºbergeben, so nutzt man diese Syntax (‚ÄúPurrr-Lambda‚Äù):\n\nmtcars %&gt;% \n  summarise(across(.cols = everything(),\n                   .fns = ~ mean(., na.rm = TRUE)))\n\n\n\n  \n\n\n\nHier findet sich ein guter √úberblick zu across().\n\n5.5.2 map()\n\nmap() ist eine Funktion aus dem R-Paket purrr und Teil des Tidyverse.\nmap(x, f) wenden die Funktion f auf jedes Element von x an. Ist x ein Tibble, so wird f demnach auf jede Spalte von x angewendet (‚Äúzugeordnet‚Äù, daher map), vgl. Abbildung¬†5.7 aus Sauer (2019).\n\n\nAbbildung¬†5.7: Sinnbild f√ºr map aus purrr\n\n\nHier ein Beispiel-Code:\n\ndata(mtcars)\n\nmtcars &lt;- mtcars %&gt;% select(1:3)  # nur die ersten 3 Spalten\n\nmap(mtcars, mean)\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\nM√∂chte man der gemappten Funktion Parameter √ºbergeben, nutzt man wieder die ‚ÄúKringel-Schreibweise‚Äù:\n\nmap(mtcars, ~ mean(., na.rm = TRUE))\n## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n\n\n5.5.3 Weiterf√ºhrende Hinweise\nWeiteres zu map() findet sich z.B. in Wickham und Grolemund (2016), Kapitel 21.5 oder in Sauer (2019), Kap. 28.2.\nTutorial zu map() von Jenny BC."
  },
  {
    "objectID": "050-R-Vertiefung.html#listenspalten",
    "href": "050-R-Vertiefung.html#listenspalten",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.6 Listenspalten",
    "text": "5.6 Listenspalten\n\n5.6.1 Wozu Listenspalten?\nListenspalten sind immer dann sinnvoll, wenn eine einfache Tabelle nicht komplex genug f√ºr unsere Daten ist.\nZwei F√§lle stechen dabei ins Auge:\n\nUnsere Datenstruktur ist nicht rechteckig\nIn einer Zelle der Tabelle soll mehr als ein einzelner Wert stehen: vielleicht ein Vektor, eine Liste oder eine Tabelle\n\nDer erstere Fall (nicht reckeckig) lie√üe sich noch einfach l√∂sen, in dem man mit NA auff√ºllt.\nDer zweite Fall verlangt schlichtweg nach komplexeren Datenstrukturen.\nKap. 25.3 aus Wickham und Grolemund (2016) bietet einen guten Einstieg in das Konzept von Listenspalten (list-columns) in R.\n\n5.6.2 Beispiele f√ºr Listenspalten\n\n5.6.2.1 tidymodel\nWenn wir mit tidymodels arbeiten, werden wir mit Listenspalten zu tun haben. Daher ist es praktisch, sich schon mal damit zu besch√§ftigen.\nHier ein Beispiel f√ºr eine \\(v=3\\)-fache Kreuzvalidierung:\n\nlibrary(tidymodels)\nmtcars_cv &lt;-\n  vfold_cv(mtcars, v = 3)\n\nmtcars_cv\n\n\n\n  \n\n\n\nBetrachten wir das Objekt mtcars_cv n√§her. Die Musik spielt in der 1. Spalte.\nLesen wir den Inhalt der 1. Spalte, 1 Zeile aus (nennen wir das mal ‚ÄúPosition 1,1‚Äù):\n\npos11 &lt;- mtcars_cv[[1]][[1]]\npos11\n## &lt;Analysis/Assess/Total&gt;\n## &lt;21/11/32&gt;\n\nIn dieser Zelle findet sich eine Aufteilung des Komplettdatensatzes in den Analyseteil (Analysis sample) und den Assessmentteil (Assessment Sample).\nSchauen wir jetzt in dieses Objekt n√§her an. Das k√∂nnen wir mit str() tun. str() zeigt uns die Strktur eines Objekts.\n\nstr(pos11)\n## List of 4\n##  $ data  :'data.frame':  32 obs. of  3 variables:\n##   ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n##   ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n##   ..$ disp: num [1:32] 160 160 108 258 360 ...\n##  $ in_id : int [1:21] 1 2 3 4 6 7 9 10 11 12 ...\n##  $ out_id: logi NA\n##  $ id    : tibble [1 √ó 1] (S3: tbl_df/tbl/data.frame)\n##   ..$ id: chr \"Fold1\"\n##  - attr(*, \"class\")= chr [1:2] \"vfold_split\" \"rsplit\"\n\nOh! pos11 ist eine Liste, und zwar eine durchaus komplexe. Wir m√ºssen erkennen, dass in einer einzelnen Zelle dieses Dataframes viel mehr steht, als ein Skalar bzw. ein einzelnes, atomares Element.\nDamit handelt es sich bei Spalte 1 dieses Dataframes (mtcars_cv) also um eine Listenspalte.\n√úben wir uns noch etwas im Indizieren.\nSprechen wir in pos11 das erste Element an (data) und davon das erste Element:\n\npos11[[\"data\"]][[1]]\n##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n## [31] 15.0 21.4\n\nWir haben hier die doppelten Eckklammern benutzt, um den ‚Äúeigentlichen‚Äù oder ‚Äúinneren‚Äù Vektor zu bekommen, nicht die ‚Äúau√üen‚Äù herumgewickelte Liste. Zur Erinnerung: Ein Dataframe ist ein Spezialfall einer Liste, also auch eine Liste, nur eine mit bestimmten Eigenschaften.\nZum Vergleich indizieren wir mal mit einer einfachen Eckklammer:\n\npos11[[\"data\"]][1] %&gt;% \n  head()\n\n\n\n  \n\n\n\nMit pluck() bekommen wir das gleiche Ergebnis, nur etwas komfortabler, da wir keine Eckklammern tippen m√ºssen:\n\npluck(pos11, \"data\", 1, 1)\n## [1] 21\n\nWie man sieht, k√∂nnen wir beliebig tief in das Objekt hineinindizieren.\n\n5.6.3 Programmieren mit dem Tidyverse\nDas Programmieren mit dem Tidyvers ist nicht ganz einfach und hier nicht n√§her ausgef√ºhrt. Eine Einf√ºhrung findet sich z.B.\n\nTidyeval in f√ºnf Minuten (Video)\nIn Kapiteln 17-21 in Advanced R, 2nd Ed\n\nEin √úberblicksdiagramm findet sich hier Quelle."
  },
  {
    "objectID": "050-R-Vertiefung.html#r-ist-schwierig",
    "href": "050-R-Vertiefung.html#r-ist-schwierig",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.7 R ist schwierig",
    "text": "5.7 R ist schwierig\nManche behaupten, R sei ein Inferno.\nZum Gl√ºck gibt es auch aufmunternde Stimmen:\n\npraise::praise()\n## [1] \"You are luminous!\"\n\nHat jemand einen guten Rat f√ºr uns? Vielleicht ist der h√§ufigste Rat, dass man die Dokumentation lesen solle."
  },
  {
    "objectID": "050-R-Vertiefung.html#aufgaben",
    "href": "050-R-Vertiefung.html#aufgaben",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.8 Aufgaben",
    "text": "5.8 Aufgaben\n\nFallstudie Flugversp√§tungen\nFallstudie Getreideernte"
  },
  {
    "objectID": "050-R-Vertiefung.html#vertiefung",
    "href": "050-R-Vertiefung.html#vertiefung",
    "title": "\n5¬† R, zweiter Blick\n",
    "section": "\n5.9 Vertiefung",
    "text": "5.9 Vertiefung\n\nFunktionale Programmierung mit R\nLernen Sie Wiederholungsstrukturen mit ggplot\n\n\n\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nWickham, Hadley, und Garrett Grolemund. 2016. R for Data Science: Visualize, Model, Transform, Tidy, and Import Data. O‚ÄôReilly Media. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "060-tidymodels.html#lernsteuerung",
    "href": "060-tidymodels.html#lernsteuerung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.1 Lernsteuerung",
    "text": "6.1 Lernsteuerung\n\n6.1.1 Lernziele\n\nSie sind in der Lage, Regressionsmodelle mit dem tidymodels-Ansatz zu spezifizieren.\nSie k√∂nnen Begriffe des statistischen Lernens in das Vokabular von tidymodels √ºbersetzen."
  },
  {
    "objectID": "060-tidymodels.html#vorbereitung",
    "href": "060-tidymodels.html#vorbereitung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.2 Vorbereitung",
    "text": "6.2 Vorbereitung\n\nLesen Sie TMWR, Kapitel 1\n\nLesen Sie √ºbrige Literatur zu diesem Thema: TMWR, Kap. 1, 5, 6, 7, 8, 9\n\n\n6.2.1 Ben√∂tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ntidymodels ist ein Metapaket: Ein (R-)Paket, das mehrere andere Paket startet und uns damit das Leben einfacher macht. Eine Liste der R-Pakete, die durch tidymodels gestartet werden, findet sich hier. Probieren Sie auch mal ?tidymodels.\nEine Liste aller Pakete, die in Tidymodels benutzt werden, die dependencies, kann man sich so ausgeben lassen:\n\npkg_deps(x = \"tidymodels\", recursive = FALSE)"
  },
  {
    "objectID": "060-tidymodels.html#daten",
    "href": "060-tidymodels.html#daten",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.3 Daten",
    "text": "6.3 Daten\nDieser Abschnitt bezieht sich auf Kapitel 4 in Silge und Kuhn (2022).\nWir benutzen den Datensatz zu Immobilienpreise aus dem Ames County in Iowa, USA, gelegen im Zentrum des Landes.\n\ndata(ames)  # Daten wurden √ºber tidymodels mit geladen\names &lt;- \n  ames %&gt;% \n  mutate(Sale_Price = log10(Sale_Price))\n\nHier wurde die AV log-transformiert. Das hat zwei (wichtige) Effekte:\n\nDie Verteilung ist symmetrischer, n√§her an der Normalverteilung. Damit gibt es mehr Daten im Hauptbereich des Ranges von Sale_Price, was die Vorhersagen stabiler machen d√ºrfte.\nLogarithmiert man die Y-Variable, so kommt dies einem multiplikativen Modell gleich, s. auch hier."
  },
  {
    "objectID": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "href": "060-tidymodels.html#train--vs-test-datensatz-aufteilen",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.4 Train- vs Test-Datensatz aufteilen",
    "text": "6.4 Train- vs Test-Datensatz aufteilen\nDieser Abschnitt bezieht sich auf Kapitel 5 in Silge und Kuhn (2022).\n\n\n\n\n\n\nHinweis\n\n\n\nDas Aufteilen in Train- und Test-Datensatz ist einer der wesentlichen Grunds√§tze im maschinellen Lernen. Das Ziel ist, Overfitting abzuwenden. Im Train-Datensatz werden alle Modelle berechnet. Der Test-Datensatz wird nur einmal verwendet, und zwar zur √úberpr√ºfung der Modellg√ºte.\n\n\n\n\nEine Faustregel ist es, 70-80% der Daten in das Train-Sample und die √ºbrigen 20-30% in das Test-Sample zu stecken, s. Abbildung¬†6.1\n\n\n\n\npie title Train-Test-Aufteilung\n    \"Train\" : 80\n    \"Test\" : 19\n    \"The Unkown God\": 1\n\n\nAbbildung¬†6.1: 80-20-Aufteilung der Daten in Train- bzw. Test-Sample\n\n\n\n\nPraktisch funktioniert das in Silge und Kuhn (2022) wie folgt.\nWir laden die Daten und erstellen einen Index, der jeder Beobachtung die Zuteilung zu Train- bzw. zum Test-Datensatz zuweist.\nDas kann, mit tidymodels so aussehen:\n\names_split &lt;- initial_split(ames, prop = 0.80, strata = Sale_Price)\n\ninitial_split() speichert f√ºr sp√§tere komfortable Verwendung auch die Daten. Aber eben auch der Index, der bestimmt, welche Beobachtung im Train-Set landet:\n\names_split$in_id %&gt;% head(n = 10)\n##  [1]  2 27 28 30 31 32 35 79 84 89\nlength(ames_split$in_id)\n## [1] 2342\n\nPraktisch ist auch, dass die AV-Verteilung in beiden Datens√§tzen √§hnlich gehalten wird (Stratifizierung), das besorgt das Argument strata.\nDie eigentlich Aufteilung in die zwei Datens√§tze geht dann so:\n\names_train &lt;- training(ames_split)\names_test  &lt;-  testing(ames_split)"
  },
  {
    "objectID": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "href": "060-tidymodels.html#grundlagen-der-modellierung-mit-tidymodels",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.5 Grundlagen der Modellierung mit tidymodels",
    "text": "6.5 Grundlagen der Modellierung mit tidymodels\nDieser Abschnitt bezieht sich auf Kapitel 6 in Silge und Kuhn (2022).\ntidymodels ist eine Sammlung mehrerer, zusammengeh√∂riger Pakete, eben zum Thema statistische Modellieren.\nDas kann man analog zur Sammlung tidyverse verstehen, zu der z.B. das R-Paket dplyr geh√∂rt.\nDas R-Paket innerhalb von tidymodels, das zum ‚ÄúFitten‚Äù von Modellen zust√§ndig ist, hei√üt parsnip.\nEine Liste der verf√ºgbaren Modelltypen, Modellimplementierungen und Modellparameter, die in Parsnip aktuell unterst√ºtzt werden, findet sich hier.\n\n6.5.1 Modelle spezifizieren\nEin (statistisches) Modell wird in Tidymodels mit drei Elementen spezifiziert, vgl. Abbildung¬†6.2.\n\n\n\n\nflowchart LR\n   \n  \n\n  subgraph Modus\n  r2[regresssion]\n  classification\n  end\n  \n  subgraph Implementierung\n  lm\n  stan_glm\n  div2[...]\n  end\n  \n  subgraph Algorithmus\n  R[Regression]\n  NN[Neuronale Netze]\n  div[...]\n  end \n  \n\n\n\nAbbildung¬†6.2: Definition eines Models in tidymodels\n\n\n\n\nDie Definition eines Modells in tidymodels folgt diesen Ideen:\n\nDas Modell sollte unabh√§ngig von den Daten spezifiziert sein\nDas Modell sollte unabh√§ngig von den Variablen (AV, UVs) spezifiziert sein\nDas Modell sollte unabh√§ngig von etwaiger Vorverarbeitung (z.B. z-Transformation) spezifiziert sein\n\nDa bei einer linearen Regression nur der Modus ‚ÄúRegression‚Äù m√∂glich ist, muss der Modus in diesem Fall nicht angegeben werden. Tidymodels erkennt das automatisch.\n\nlm_model &lt;-   \n  linear_reg() %&gt;%   # Algorithmus, Modelltyp\n  set_engine(\"lm\")  # Implementierung\n  # Modus hier nicht n√∂tig, da lineare Modelle immer numerisch klassifizieren\n\n\n6.5.2 Modelle berechnen\nNach Rhys (2020) ist ein Modell sogar erst ein Modell, wenn die Koeffizienten berechnet sind. Tidymodels kennt diese Unterscheidung nicht. Stattdessen spricht man in Tidymodels von einem ‚Äúgefitteten‚Äù Modell, sobald es berechnet ist. √Ñhnlich fancy k√∂nnte man von einem ‚Äúinstantiierten‚Äù Modell sprechen.\nF√ºr das Beispiel der einfachen linearen Regression hei√üt das, das Modell ist gefittet, sobald die Steigung und der Achsenabschnitt (sowie die Residualstreuung) berechnet sind.\n\nlm_form_fit &lt;- \n  lm_model %&gt;% \n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)\n\n\n6.5.3 Vorhersagen\nIm maschinellen Lernen ist man prim√§r an den Vorhersagen interessiert, h√§ufig nur an Punktsch√§tzungen. Schauen wir uns also zun√§chst diese an.\nVorhersagen bekommt man recht einfach mit der predict() Methode von tidymodels1:\n\npredict(lm_form_fit, new_data = ames_test) %&gt;% \n  head()\n\n\n\n  \n\n\n\nDie Syntax zum Vorhersagen lautet also: predict(modell, daten_zum_vorhersagen).\n\n6.5.4 Vorhersagen im Train-Datensatz\nVorhersagen im Train-Datensatz machen kaum Sinn, da sie nicht gegen Overfitting gesch√ºtzt sind und daher deutlich zu optimistisch sein k√∂nnen.\nBei einer linearen Regression ist diese Gefahr nicht so hoch, aber bei anderen, flexibleren Modellen, ist diese Gefahr absurd gro√ü.\n\n6.5.5 Modellkoeffizienten im Train-Datensatz\nGibt man den Namen des Modellobjekts ein, so wird ein √úberblick an relevanten Modellergebnissen am Bildschirm gedruckt:\n\nlm_form_fit\n## parsnip model object\n## \n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\nInnerhalb des Ergebnisobjekts findet sich eine Liste namens fit, in der die Koeffizienten (der ‚ÄúFit‚Äù) abgelegt sind:\n\nlm_form_fit %&gt;% pluck(\"fit\")\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\nZum Herausholen dieser Infos kann man auch alternativ die Funktion extract_fit_engine() verwenden:\n\nlm_fit &lt;-\n  lm_form_fit %&gt;% \n  extract_fit_engine()\n\nlm_fit\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\n\n\n\n\n\n\nHinweis\n\n\n\nM√∂chten Sie wissen, was sich in lm_form_fit alles verbirgt, bietet sich die Funktion str an. Alternativ k√∂nnen Sie in RStudio unter Environment das Objekt ‚Äúaufklappen‚Äù.\n\n\nDas extrahierte Objekt ist, in diesem Fall, das typische lm() Objekt. Entsprechend kann man daruaf coef() oder summary() anwenden.\n\ncoef(lm_fit)\n## (Intercept)   Longitude    Latitude \n## -311.510950   -2.109107    2.836443\nsummary(lm_fit)\n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.02571 -0.09581 -0.01513  0.09817  0.57768 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(&gt;|t|)    \n## (Intercept) -311.5110    14.5929  -21.35   &lt;2e-16 ***\n## Longitude     -2.1091     0.1303  -16.18   &lt;2e-16 ***\n## Latitude       2.8364     0.1800   15.75   &lt;2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1613 on 2339 degrees of freedom\n## Multiple R-squared:  0.1738, Adjusted R-squared:  0.1731 \n## F-statistic: 246.1 on 2 and 2339 DF,  p-value: &lt; 2.2e-16\n\nSchicker sind die Pendant-Befehle aus broom, die jeweils einen Tibble zu√ºckliefern:\n\nlibrary(broom)\ntidy(lm_fit) # Koeffizienten\n\n\n\n  \n\n\nglance(lm_fit) # Modellg√ºte\n\n\n\n  \n\n\n\nEine weitere Alternative sind die Befehle zur Modell-Performance von easystats¬¥^[Paketperformance`]:\n\nlibrary(easystats)\nparameters(lm_form_fit)\n\n\n\n  \n\n\nr2(lm_form_fit)\n## # R2 for Linear Regression\n##        R2: 0.174\n##   adj. R2: 0.173\nmae(lm_form_fit)\n## [1] 0.122687\n\n\n6.5.6 Parsnip RStudio add-in\nMit dem Add-in von Parsnip kann man sich eine Modellspezifikation per Klick ausgeben lassen. Nett!\n\nparsnip_addin()"
  },
  {
    "objectID": "060-tidymodels.html#workflows",
    "href": "060-tidymodels.html#workflows",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.6 Workflows",
    "text": "6.6 Workflows\nDieser Abschnitt bezieht sich auf Kapitel 7 in Silge und Kuhn (2022).\n\n6.6.1 Konzept des Workflows in Tidymodels\n\n\n\nDefinition eines Models in tidymodels\n\n\n\n6.6.2 Einfaches Beispiel\nWir initialisieren einen Workflow, verzichten auf Vorverarbeitung und f√ºgen ein Modell hinzu:\n\nlm_workflow &lt;- \n  workflow() %&gt;%  # init\n  add_model(lm_model) %&gt;%   # Modell hinzuf√ºgen\n  add_formula(Sale_Price ~ Longitude + Latitude)  # Modellformel hinzuf√ºgen\n\nWerfen wir einen Blick in das Workflow-Objekt:\n\nlm_workflow\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Sale_Price ~ Longitude + Latitude\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nWie man sieht, geh√∂rt die Modellformel (y ~ x) zur Vorverarbeitung aus Sicht von Tidymodels.\nWas war nochmal im Objekt lm_model enthalten?\n\nlm_model\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n\nJetzt k√∂nnen wir das Modell berechnen (fitten):\n\nlm_fit &lt;- \n  lm_workflow %&gt;%\n  fit(ames_train)\n\nNat√ºrlich kann man synonym auch schreiben:\n\nlm_fit &lt;- fit(lm_wflow, ames_train)\n\nSchauen wir uns das Ergebnis an:\n\nlm_fit\n## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Sale_Price ~ Longitude + Latitude\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -311.511       -2.109        2.836\n\n\n6.6.3 Vorhersage mit einem Workflow\nDie Vorhersage mit einem Tidymodels-Workflow ist einerseits komfortabel, da man einfach sagen kann:\n‚ÄúNimm die richtigen Koeffizienten des Modells aus dem Train-Set und wende sie auf das Test-Sample an. Berechne mir die Vorhersagen und die Modellg√ºte.‚Äù\nSo sieht das aus:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nAlso, last_fit k√ºmmert sich um Folgendes:\n\nBerechne Modell im (kompletten) Train-Sample\nSage Daten im Test-Sample vorher\nBerechne Modellg√ºte im Test-Sample\n\nEs wird ein recht komplexes Objekt zur√ºckgeliefert, das man erst mal durchschauen muss.\nWie man sieht, gibt es mehrere Listenspalten in final_lm_res. Besonders interessant erscheinen nat√ºrlich die Listenspalten .metrics und .predictions.\nSchauen wir uns die Vorhersagen an. Diese finden sich im resultierenden Objekt von last_fit, zusammen mit anderen Informationen wie MOdellg√ºte. Die .predictions sind selber ein Tibble, wo in der ersten Spalte die Vorhersagen stehen.\n\nlm_preds &lt;- final_lm_res %&gt;% pluck(\".predictions\", 1)\n\nEs gibt auch eine Funktion, die obige Zeile vereinfacht (also synonym ist):\n\nlm_preds &lt;- collect_predictions(final_lm_res)\nlm_preds %&gt;% slice_head(n = 5)\n\n\n\n  \n\n\n\n\n6.6.4 Modellg√ºte\nDieser Abschnitt bezieht sich auf Kapitel 9 in Silge und Kuhn (2022).\nDie Vorhersagen bilden die Basis f√ºr die Modellg√ºte (‚ÄúMetriken‚Äù), die schon fertig berechnet im Objekt final_lm_res liegen und mit collect_metrics herausgenommen werden k√∂nnen:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\n\nAlternativ kommt man mit pluck(final_lm_res, \".metrics\") an die gleichen Informationen.\n\n\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\nrmse\nstandard\n1.62 √ó 10‚àí1\n\nPreprocessor1_Model1\n\n\nrsq\nstandard\n1.44 √ó 10‚àí1\n\nPreprocessor1_Model1\n\n\n\n\n\n\nMan kann auch angeben, welche Metriken der Modellg√ºte man bekommen m√∂chte:\n\names_metrics &lt;- metric_set(rmse, rsq)\n\names_metrics(data = lm_preds, \n             truth = Sale_Price, \n             estimate = .pred)\n\n\n6.6.5 Vorhersage von Hand\nMan kann sich die Metriken auch von Hand ausgeben lassen, wenn man direktere Kontrolle haben m√∂chte als mit last_fit und collect_metrics.\n\names_test_small &lt;- ames_test %&gt;% slice(1:5)\npredict(lm_form_fit, new_data = ames_test_small)\n\n\n\n  \n\n\n\nJetzt binden wir die Spalten zusammen, also die ‚ÄúWahrheit‚Äù (\\(y\\), die beobachteten, tats√§chlichen Y-Werte) und die Vorhersagen (\\(\\hat{y}\\)):\n\names_test_small2 &lt;- \n  ames_test_small %&gt;% \n  select(Sale_Price) %&gt;% \n  bind_cols(predict(lm_form_fit, ames_test_small)) %&gt;% \n  # Add 95% prediction intervals to the results:\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) \n\n\nrsq(ames_test_small2, \n   truth = Sale_Price,\n   estimate = .pred\n   )\n\n\n\n  \n\n\n\nAndere Koeffizienten der Modellg√ºte k√∂nnen mit rmse oder mae2 abgerufen werden."
  },
  {
    "objectID": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "href": "060-tidymodels.html#rezepte-zur-vorverarbeitung",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.7 Rezepte zur Vorverarbeitung",
    "text": "6.7 Rezepte zur Vorverarbeitung\nDieser Abschnitt bezieht sich auf Kapitel 8 in Silge und Kuhn (2022).\n\n6.7.1 Was ist Rezept und wozu ist es gut?\nSo k√∂nnte ein typischer Aufruf von lm() aussehen:\n\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, \n   data = ames)\n\nNeben dem Fitten des Modells besorgt die Formel-Schreibweise noch einige zus√§tzliche n√ºtzliche Vorarbeitung:\n\nDefinition von AV und AV\nLog-Transformation von Gr_Liv_Area\n\nTransformation der nominalen Variablen in Dummy-Variablen\n\nDas ist sch√∂n und n√ºtzlich, hat aber auch Nachteile:\n\nDas Modell wird nicht nur spezifiziert, sondern auch gleich berechnet. Das ist unpraktisch, weil man die Modellformel vielleicht in anderen Modell wiederverwenden m√∂chte. Au√üerdem kann das Berechnen lange dauern.\nDie Schritte sind ineinander vermengt, so dass man nicht einfach und √ºbersichtlich die einzelnen Schritte bearbeiten kann.\n\nPraktischer w√§re also, die Schritte der Vorverarbeitung zu ent-flechten. Das geht mit einem ‚ÄúRezept‚Äù aus Tidymodels:\n\nsimple_ames &lt;- \n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) %&gt;%\n  step_log(Gr_Liv_Area, base = 10) %&gt;% \n  step_dummy(all_nominal_predictors())\nsimple_ames\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          4\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()\n\n\n\n\n\n\n\nHinweis\n\n\n\nEin Rezept berechnet kein Modell. Es macht nichts au√üer die Vorverarbeitung des Modells zu spezifizieren (inklusive der Modellformel).\n\n\n\n6.7.2 Workflows mit Rezepten\nJetzt definieren wir den Workflow nicht nur mit einer Modellformel, sondern mit einem Rezept:\n\nlm_workflow &lt;-\n  workflow() %&gt;% \n  add_model(lm_model) %&gt;% \n  add_recipe(simple_ames)\n\nSonst hat sich nichts ge√§ndert.\nWie vorher, k√∂nnen wir jetzt das Modell berechnen und uns im Test-Set die Vorhersagen berechnen lassen:\n\nfinal_lm_res &lt;- last_fit(lm_workflow, ames_split)\nfinal_lm_res\n\n\n\n  \n\n\n\nHier ist die Modellg√ºte:\n\nlm_metrics &lt;- collect_metrics(final_lm_res)\nlm_metrics\n\n\n\n  \n\n\n\n\n6.7.3 Spaltenrollen\nEine praktische Funktion ist es, bestimmte Spalten nicht als Pr√§diktor, sondern als ID-Variable zu nutzen. Das kann man in Tidymodels komfortabel wie folgt angeben:\n\names_recipe &lt;-\n  simple_ames %&gt;% \n  update_role(Neighborhood, new_role = \"id\")\n\names_recipe\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##         id          1\n##    outcome          1\n##  predictor          3\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()\n\n\n6.7.4 Fazit\nMehr zu Rezepten findet sich hier. Ein √úberblick zu allen Schritten der Vorverarbeitung findet sich hier."
  },
  {
    "objectID": "060-tidymodels.html#aufgaben",
    "href": "060-tidymodels.html#aufgaben",
    "title": "\n6¬† tidymodels\n",
    "section": "\n6.8 Aufgaben",
    "text": "6.8 Aufgaben\n\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\n\n\n\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "060-tidymodels.html#footnotes",
    "href": "060-tidymodels.html#footnotes",
    "title": "\n6¬† tidymodels\n",
    "section": "",
    "text": "im Gegensatz zum predict() von lm mit Unterstrich bei new_data, also nicht newdata.‚Ü©Ô∏é\nAchtung: Die Funktion mae gibt es sowohl in tidymodels auch in easystats, hier kann es zu Konflikten kommen.‚Ü©Ô∏é"
  },
  {
    "objectID": "070-knn.html#lernsteuerung",
    "href": "070-knn.html#lernsteuerung",
    "title": "\n7¬† kNN\n",
    "section": "\n7.1 Lernsteuerung",
    "text": "7.1 Lernsteuerung\n\n7.1.1 √úberblick\nIn diesem Kapitel geht es um das Verfahren KNN, K-N√§chste-Nachbarn (\\(k\\) nearest neighbors).\n\n7.1.2 Lernziele\n\n‚ÄúSie sind in der Lage, einfache Klassifikationsmodelle zu spezifizieren mit tidymodels‚Äù\n‚ÄúSie k√∂nnen den knn-Algorithmus erl√§utern‚Äù\n‚ÄúSie k√∂nnen den knn-Algorithmus in tidymodels anwenden‚Äù\n‚ÄúSie k√∂nnen die G√ºtemetriken von Klassifikationsmodellen einsch√§tzen‚Äù\n\n7.1.3 Literatur\n\n‚ÄúRhys, Kap. 3‚Äù\n‚ÄúTimbers et al., Kap. 5‚Äù"
  },
  {
    "objectID": "070-knn.html#ben√∂tigte-r-pakete",
    "href": "070-knn.html#ben√∂tigte-r-pakete",
    "title": "\n7¬† kNN\n",
    "section": "\n7.2 Ben√∂tigte R-Pakete",
    "text": "7.2 Ben√∂tigte R-Pakete\n\nlibrary(tidymodels)\n#library(tidyverse)"
  },
  {
    "objectID": "070-knn.html#intuitive-erkl√§rung",
    "href": "070-knn.html#intuitive-erkl√§rung",
    "title": "\n7¬† kNN\n",
    "section": "\n7.3 Intuitive Erkl√§rung",
    "text": "7.3 Intuitive Erkl√§rung\nK-N√§chste-Nachbarn (\\(k\\) nearest neighbors, kNN) ist ein einfacher Algorithmus des maschinellen Lernens, der sowohl f√ºr Klassifikation als auch f√ºr numerische Vorhersage (Regression) genutzt werden kann. Wir werden kNN als Beispiel f√ºr eine Klassifikation betrachten.\nBetrachen wir ein einf√ºhrendes Beispiel von Rhys (2020), f√ºr das es eine Online-Quelle gibt. Stellen Sie sich vor, wir laufen durch englische Landschaft, vielleicht die Grafschaft Kent, und sehen ein kleines Tier durch das Gras huschen. Eine Schlange?! In England gibt es (laut Rhys (2020)) nur eine giftige Schlange, die Otter (Adder). Eine andere Schlange, die Grass Snake ist nicht giftig, und dann kommt noch der Slow Worm in Frage, der gar nicht zur Familie der Schlangen geh√∂rt. Prim√§r interessiert uns die Frage, haben wir jetzt eine Otter gesehen? Oder was f√ºr ein Tier war es?\nZum Gl√ºck wissen wir einiges √ºber Schlangen bzw. schlangen√§hnliche Tiere Englands. N√§mlich k√∂nnen wir die betreffenden Tierarten in Gr√∂√üe und Aggressivit√§t einsch√§tzen, das ist in Abbildung Abbildung¬†7.1 dargestellt.\n\n\n\n\nAbbildung¬†7.1: Haben wir gerade eine Otter gesehen?\n\n\n\n\nDer Algorithmus von kNN sieht einfach gesagt vor, dass wir schauen, welcher Tierarten Tiere mit √§hnlicher Aggressivit√§t und Gr√∂√üe angeh√∂ren. Die Tierart die bei diesen ‚ÄúNachbarn‚Äù hinsichtlich √Ñhnlichkeit relevanter Merkmale am h√§ufigsten vertreten ist, ordnen wir die bisher unklassifizierte Beobachtung zu.\nEtwas zugespitzt:\n\nWenn es quakt wie eine Ente ü¶Ü, l√§uft wie eine Ente ü¶Üund aussieht wie eine Ente ü¶Ü, dann ist es eine Ente ü¶Ü.\n\nDie Anzahl \\(k\\) der n√§chsten Nachbarn k√∂nnen wir frei w√§hlen; der Wert wird nicht vom Algorithmuss bestimmt. Solche vom Nutzi zu bestimmenden Gr√∂√üen nennt man auch Tuningparameter."
  },
  {
    "objectID": "070-knn.html#krebsdiagnostik",
    "href": "070-knn.html#krebsdiagnostik",
    "title": "\n7¬† kNN\n",
    "section": "\n7.4 Krebsdiagnostik",
    "text": "7.4 Krebsdiagnostik\nBetrachten wir ein Beispiel von Timbers, Campbell, und Lee (2022), das hier frei eingesehen werden kann.\nDie Daten sind so zu beziehen:\n\ndata_url &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv\"\ncancer &lt;- read.csv(data_url)\n\nIn diesem Beispiel versuchen wir Tumore der Brust zu klassifizieren, ob sie einen schweren Verlauf (maligne, engl. malignant) oder einen weniger schweren Verlauf (benigne, engl. benign) erwarten lassen. Der Datensatz ist hier n√§her erl√§utert.\nWie in Abbildung¬†7.2 ersichtlich, steht eine Tumordiagnose (malignant vs.¬†benign) in Abh√§ngigkeit von Umfang (engl. perimeter) und Konkavit√§t, die ‚ÄúGekr√ºmmtheit nach innen‚Äù.\n\n\n\n\nAbbildung¬†7.2: Streudiagramm zur Einsch√§tzung von Tumordiagnosen\n\n\n\n\nIn diesem Code-Beispiel wird die seit R 4.1.0 verf√ºgbare R-native Pfeife verwendet. Wichtig ist vielleicht vor allem, dass diese Funktion nicht l√§uft auf R-Versionen vor 4.1.0. Einige Unterschiede zur seit l√§ngerem bekannten Magrittr-Pfeife sind hier erl√§utert.\nWichtig ist, dass die Merkmale standardisiert sind, also eine identische Skalierung aufweisen, da sonst das Merkmal mit kleinerer Skala weniger in die Berechnung der N√§he (bzw. Abstand) eingeht.\nF√ºr einen neuen, bisher unklassifizierten Fall suchen nur nun nach einer Diagnose, also nach der am besten passenden Diagnose (maligne oder benigne), s. Abbildung¬†7.3, wieder aus Timbers, Campbell, und Lee (2022). Ihr Quellcode f√ºr dieses Diagramm (und das ganze Kapitel) findet sich hier.\n\n\n\n\nAbbildung¬†7.3: Ein neuer Fall, bisher unklassifiziert\n\n\n\n\nWir k√∂nnen zun√§chst den (im euklidischen Koordinatensystem) n√§chst gelegenen Fall (der ‚Äún√§chste Nachbar‚Äù) betrachten, und vereinbaren, dass wir dessen Klasse als Sch√§tzwert f√ºr den unklassiffizierten Fall √ºbernehmen, s. Abbildung¬†7.4.\n\n\nAbbildung¬†7.4: Ein n√§chster Nachbar\n\n\nBetrachten wir einen anderen zu klassifizierenden Fall, s. Abbildung¬†7.5. Ob hier die Klassifikation von ‚Äúbenign‚Äù korrekt ist? Wom√∂glich nicht, denn viele andere Nachbarn, die etwas weiter weg gelegen sind, geh√∂ren zur anderen Diagnose, malign.\n\n\n\n\nAbbildung¬†7.5: Tr√ºgt der n√§chste Nachbar?\n\n\n\n\nUm die Vorhersage zu verbessern, k√∂nnen wir nicht nur den n√§chstgelegenen Nachbarn betrachten, sondern die \\(k\\) n√§chstgelegenen, z.B. \\(k=3\\), s. Abb Abbildung¬†7.6.\n\n\n\n\nAbbildung¬†7.6: kNN mit k=3\n\n\n\n\nDie Entscheidungsregel ist dann einfach eine Mehrheitsentscheidung: Wir klassifizieren den neuen Fall entsprechend der Mehrheit in den \\(k\\) n√§chst gelegenen Nachbarn."
  },
  {
    "objectID": "070-knn.html#berechnung-der-n√§he",
    "href": "070-knn.html#berechnung-der-n√§he",
    "title": "\n7¬† kNN\n",
    "section": "\n7.5 Berechnung der N√§he",
    "text": "7.5 Berechnung der N√§he\nEs gibt verschiedenen Algorithmen, um die N√§he bzw. Distanz der Nachbarn zum zu klassifizieren Fall zu berechnen.\nEine gebr√§uchliche Methode ist der euklidische Abstand, der mit Pythagoras berechnet werden kann, s. Abbildung¬†7.7 aus Sauer (2019).\n\n\n\n\nAbbildung¬†7.7: Euklidischer Abstand wird mit der Regel von Pythagoras berechnet\n\n\n\n\nWie war das noch mal?\n\\[c^2 = a^2 + b^2\\]\nIm Beispiel oben also:\n\\(c^2 = 3^2 + 4^2 = 5^2\\)\nDamit gilt: \\(c = \\sqrt{c^2} = \\sqrt{5^2}=5\\).\nIm 2D-Raum ist das so einfach, dass man das (fast) mit blo√üem Augenschein entscheiden kann. In mehr als 2 Dimensionen wird es aber schwierig f√ºr das Auge, wie ein Beispiel aus Timbers, Campbell, und Lee (2022) zeigt.\nAllerdings kann man den guten alten Pythagoras auch auf Dreiecke mit mehr als zwei Dimensionen anwenden, s. Abbildung¬†7.8 aus Sauer (2019), Kap. 21.1.2.\n\n\n\n\n\n(a) Pythagoras mit mehr als zwei Dimensionen\n\n\n\n\n\n\n(b) Pythagoras mit mehr als zwei Dimensionen\n\n\n\n\nAbbildung¬†7.8: Pythagoras in der Ebene (links) und in 3D (rechts)‚Äù\n\n\nBleiben wir beim Beispiel von Anna und Berta und nehmen wir eine dritte Variable hinzu (Statistikliebe). Sagen wir, der Unterschied in dieser dritten Variable zwischen Anna und Berta betrage 2.\nEs gilt:\n\\[\n\\begin{aligned}\ne^2 &= c^2 + d^2 \\\\\ne^2 &= 5^2 + 2^2 \\\\\ne^2 &= 25 + 4\\\\\ne &= \\sqrt{29} \\approx 5.4\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "070-knn.html#knn-mit-tidymodels",
    "href": "070-knn.html#knn-mit-tidymodels",
    "title": "\n7¬† kNN\n",
    "section": "\n7.6 kNN mit Tidymodels",
    "text": "7.6 kNN mit Tidymodels\n\n7.6.1 Analog zu Timbers et al.\nEine Anwendung von kNN mit Tidymodels ist in Timbers, Campbell, und Lee (2022), Kap. 5.6, hier beschrieben.\nDie Daten aus Timbers, Campbell, und Lee (2022) finden sich in diesem Github-Repo-\nDie (z-transformierten) Daten zur Tumorklassifikation k√∂nnen hier bezogen werden.\n\ndata_url &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv\"\ncancer &lt;- read_csv(data_url)\n\nTimbers, Campbell, und Lee (2022) verwenden in Kap. 5 auch noch nicht standardisierte Daten, unscales_wdbc.csv, die hier als CSV-Datei heruntergeladen werden k√∂nnen.\n\ncancer_unscales_path &lt;- \"https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv\"\n\nunscaled_cancer &lt;- read_csv(cancer_unscales_path) |&gt;\n  mutate(Class = as_factor(Class)) |&gt;\n  select(Class, Area, Smoothness)\nunscaled_cancer\n\n\n\n  \n\n\n\n\n7.6.2 Rezept definieren\n\nuc_recipe &lt;- recipe(Class ~ ., data = unscaled_cancer)\nprint(uc_recipe)\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          2\n\nUnd jetzt die z-Transformation:\n\nuc_recipe &lt;- \n  uc_recipe |&gt;\n  step_scale(all_predictors()) |&gt;\n  step_center(all_predictors())\n\nDie Schritte prep() und bake() sparen wir uns, da fit() und predict() das f√ºr uns besorgen.\n\n7.6.3 Modell definieren\n\nknn_spec &lt;- nearest_neighbor(weight_func = \"rectangular\", neighbors = 5) |&gt;\n  set_engine(\"kknn\") |&gt;\n  set_mode(\"classification\")\nknn_spec\n## K-Nearest Neighbor Model Specification (classification)\n## \n## Main Arguments:\n##   neighbors = 5\n##   weight_func = rectangular\n## \n## Computational engine: kknn\n\n\n7.6.4 Workflow definieren\n\nknn_fit &lt;- workflow() |&gt;\n  add_recipe(uc_recipe) |&gt;\n  add_model(knn_spec) |&gt;\n  fit(data = unscaled_cancer)\n\nknn_fit\n## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 2 Recipe Steps\n## \n## ‚Ä¢ step_scale()\n## ‚Ä¢ step_center()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## Call:\n## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5,     data, 5), kernel = ~\"rectangular\")\n## \n## Type of response variable: nominal\n## Minimal misclassification: 0.1107206\n## Best kernel: rectangular\n## Best k: 5\n\n\n7.6.5 Vorhersagen\n\nnew_observation &lt;- tibble(Area = c(500, 1500), Smoothness = c(0.075, 0.1))\nprediction &lt;- predict(knn_fit, new_observation)\n\nprediction"
  },
  {
    "objectID": "070-knn.html#mit-train-test-aufteilung",
    "href": "070-knn.html#mit-train-test-aufteilung",
    "title": "\n7¬† kNN\n",
    "section": "\n7.7 Mit Train-Test-Aufteilung",
    "text": "7.7 Mit Train-Test-Aufteilung\nIm Kapitel 5 greifen Timbers, Campbell, und Lee (2022) die Aufteilung in Train- vs.¬†Test-Sample noch nicht auf (aber in Kapitel 6).\nDa in diesem Kurs diese Aufteilung aber schon besprochen wurde, soll dies hier auch dargestellt werden.\n\ncancer_split &lt;- initial_split(cancer, prop = 0.75, strata = Class)\ncancer_train &lt;- training(cancer_split)\ncancer_test &lt;- testing(cancer_split) \n\n\n7.7.1 Rezept definieren\n\ncancer_recipe &lt;- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |&gt;\n  step_scale(all_predictors()) |&gt;\n  step_center(all_predictors())\n\n\n7.7.2 Modell definieren\n\nknn_spec &lt;- nearest_neighbor(weight_func = \"rectangular\", neighbors = 3) |&gt;\n  set_engine(\"kknn\") |&gt;\n  set_mode(\"classification\")\n\n\n7.7.3 Workflow definieren\n\nknn_fit &lt;- workflow() |&gt;\n  add_recipe(cancer_recipe) |&gt;\n  add_model(knn_spec) |&gt;\n  fit(data = cancer_train)\n\nknn_fit\n## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 2 Recipe Steps\n## \n## ‚Ä¢ step_scale()\n## ‚Ä¢ step_center()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## Call:\n## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(3,     data, 5), kernel = ~\"rectangular\")\n## \n## Type of response variable: nominal\n## Minimal misclassification: 0.1220657\n## Best kernel: rectangular\n## Best k: 3\n\n\n7.7.4 Vorhersagen\nIm Gegensatz zu Timbers, Campbell, und Lee (2022) verwenden wir hier last_fit() und collect_metrics(), da wir dies bereits eingef√ºhrt haben und k√ºnftig darauf aufbauen werden.\n\ncancer_test_fit &lt;- last_fit(knn_fit, cancer_split)\n\ncancer_test_fit\n\n\n\n  \n\n\n\n\n7.7.5 Modellg√ºte\n\ncancer_test_fit %&gt;% collect_metrics()\n\n\n\n  \n\n\n\nDie eigentlichen Predictions stecken in der Listenspalte .predictions im Fit-Objekt:\n\nnames(cancer_test_fit)\n## [1] \"splits\"       \"id\"           \".metrics\"     \".notes\"       \".predictions\"\n## [6] \".workflow\"\n\nGenau genommen ist .predictions eine Spalte, in der in jeder Zeile (und damit Zelle) eine Tabelle (Tibble) steht. Wir haben nur eine Zeile und wollen das erste Element dieser Spalte herausziehen, die Vorhersagen (Wahrscheinlichkeit) f√ºr begigne Struktur ($; die Spalte hei√üt √ºbrigens .pred_B). Au√üerdem brauchen wir die tats√§chlichen Diagnosen, \\(y\\), die ‚Äúwohnen‚Äù in der Spalte mit Namen Class. Da hilft pluck().\n\ncancer_test_fit %&gt;%  \n  pluck(\".predictions\", 1) %&gt;% str()\n## tibble [143 √ó 6] (S3: tbl_df/tbl/data.frame)\n##  $ .pred_B    : num [1:143] 0 0 0 0 0 ...\n##  $ .pred_M    : num [1:143] 1 1 1 1 1 ...\n##  $ .row       : int [1:143] 1 3 5 15 25 31 33 36 37 38 ...\n##  $ .pred_class: Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 2 2 2 1 2 1 ...\n##  $ Class      : Factor w/ 2 levels \"B\",\"M\": 2 2 2 2 2 2 2 2 2 1 ...\n##  $ .config    : chr [1:143] \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" \"Preprocessor1_Model1\" ...\n\n\ncancer_test_predictions &lt;- \ncancer_test_fit %&gt;% \n  pluck(\".predictions\", 1)\n\nconfusion &lt;- cancer_test_predictions |&gt;\n             conf_mat(truth = Class, estimate = .pred_class)\n\nconfusion\n##           Truth\n## Prediction  B  M\n##          B 85  9\n##          M  5 44\n\n\n7.7.6 Visualisierung\n\nautoplot(confusion, type = \"mosaic\")\n\n\n\nautoplot(confusion, type = \"heatmap\") +\n  labs(x = \"Beobachtung\",\n       y = \"Vorhersage\",\n       title = \"Konfusionsmatrix\")"
  },
  {
    "objectID": "070-knn.html#kennzahlen-der-klassifikation",
    "href": "070-knn.html#kennzahlen-der-klassifikation",
    "title": "\n7¬† kNN\n",
    "section": "\n7.8 Kennzahlen der Klassifikation",
    "text": "7.8 Kennzahlen der Klassifikation\nIn Sauer (2019), Kap. 19.6, findet sich einige Erkl√§rung zu Kennzahlen der Klassifikationsg√ºte.\nEin Test kann vier verschiedenen Ergebnisse haben:\n\n\n\n\n\n\nVier Arten von Ergebnissen von Klassifikationen\n\nWahrheit\nAls negativ (-) vorhergesagt\nAls positiv (+) vorhergesagt\nSumme\n\n\n\nIn Wahrheit negativ (-)\nRichtig negativ (RN)\nFalsch positiv (FP)\nN\n\n\nIn Wahrheit positiv (+)\nFalsch negativ (FN)\nRichtig positiv (RN)\nP\n\n\nSumme\nN*\nP*\nN+P\n\n\n\n\n\n\nEs gibt eine verwirrende Vielfalt von Kennzahlen, um die G√ºte einer Klassifikation einzusch√§tzen. Hier sind einige davon:\n\n\n\n\n\n\nGel√§ufige Kennwerte der Klassifikation.\nF: Falsch. R: Richtig. P: Positiv. N: Negativ\nName\nDefinition\nSynonyme\nFP-Rate\nFP/N\nAlphafehler, Typ-1-Fehler, 1-Spezifit√§t, Fehlalarm\nRP-Rate\nRP/N\nPower, Sensitivit√§t, 1-Betafehler, Recall\nFN-Rate\nFN/N\nFehlender Alarm, Befafehler\nRN-Rate\nRN/N\nSpezifit√§t, 1-Alphafehler\nPos. Vorhersagewert\nRP/P*\nPr√§zision, Relevanz\nNeg. Vorhersagewert\nRN/N*\nSegreganz\nRichtigkeit\n(RP+RN)/(N+P)\nKorrektklassifikationsrate, Gesamtgenauigkeit"
  },
  {
    "objectID": "070-knn.html#krebstest-beispiel",
    "href": "070-knn.html#krebstest-beispiel",
    "title": "\n7¬† kNN\n",
    "section": "\n7.9 Krebstest-Beispiel",
    "text": "7.9 Krebstest-Beispiel\nBetrachten wir Daten eines fiktiven Krebstest, aber realistischen Daten.\n\n## # A tibble: 1 √ó 7\n##   format width height colorspace matte filesize density\n##   &lt;chr&gt;  &lt;int&gt;  &lt;int&gt; &lt;chr&gt;      &lt;lgl&gt;    &lt;int&gt; &lt;chr&gt;  \n## 1 PNG      500    429 sRGB       TRUE     40643 72x72\n\n\n\n\nWie gut ist dieser Test? Berechnen wir einige Kennzahlen.\nDa die Funktionen zur Klassifikation stets einen Faktor wollen, wandeln wir die relevanten Spalten zuerst in einen Faktor um (aktuell sind es numerische Spalten).\n\nkrebstest &lt;-\n  krebstest  %&gt;% \n  mutate(Krebs = factor(Krebs),\n         Test = factor(Test))\n\nGesamtgenauigkeit:\n\naccuracy(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nSensitivit√§t:\n\nsens(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nSpezifit√§t:\n\nyardstick::spec(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nKappa:\n\nyardstick::kap(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nPositiver Vorhersagewert:\n\nppv(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nNegativer Vorhersagewert:\n\nnpv(krebstest, truth = Krebs, estimate = Test)\n\n\n\n  \n\n\n\nW√§hrend Sensitivit√§t und Spezitivit√§t sehr hoch sind, ist die der negative Vorhersagewert sehr gering:\nWenn man einen positiven Test erh√§lt, ist die Wahrscheinlichkeit, in Wahrheit krank zu sein gering, zum Gl√ºck!"
  },
  {
    "objectID": "070-knn.html#aufgaben",
    "href": "070-knn.html#aufgaben",
    "title": "\n7¬† kNN\n",
    "section": "\n7.10 Aufgaben",
    "text": "7.10 Aufgaben\n\nArbeiten Sie sich so gut als m√∂glich durch diese Analyse zum Verlauf von Covid-F√§llen\n\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu Vulkanausbr√ºchen\nFallstudie Himalaya\n\n\n\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, und Melissa Lee. 2022. Data science: an introduction. First edition. Statistics. Boca Raton: CRC Press."
  },
  {
    "objectID": "080-Resampling-Tuning.html#lernsteuerung",
    "href": "080-Resampling-Tuning.html#lernsteuerung",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.1 Lernsteuerung",
    "text": "8.1 Lernsteuerung\n\n8.1.1 Lernziele\n\nSie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.\nSie k√∂nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.\n\n8.1.2 Vorbereitung\n\nLesen Sie die Literatur.\n\n8.1.3 Literatur\n\nRhys, Kap. 3\nTMWR, Kap. 10, 12\n\n8.1.4 Ben√∂tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tune)  #  wird nicht autaomtisch mit tidymodels gestartet"
  },
  {
    "objectID": "080-Resampling-Tuning.html#√ºberblick",
    "href": "080-Resampling-Tuning.html#√ºberblick",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.2 √úberblick",
    "text": "8.2 √úberblick\nDer Standardablauf des maschinellen Lernens ist in Abbildung¬†8.1 dargestellt. Eine alternative, hilfreich Abbildung findet sich hier in Kap. 10.2 in Silge und Kuhn (2022).\n\n\n\n\nflowchart TD\n   \nGesamtdatensatz --&gt; Split[In Train- und Test aufteilen]\nsubgraph Fit[F√ºr jeden Modellkandidaten i]\n  subgraph Kand[Modellkandidat i]\n  F[Fitte im Train-S] --&gt; T[Teste im Assessment-S]\n  end\nend\nSplit --&gt; Fit\nFit --&gt; Best[Bestimmte besten Kandidaten]\nBest --&gt; lastFit[Fitte ihn im ganzen Train-S]\nlastFit --&gt; test[Teste im Tes-S]\n\n\nAbbildung¬†8.1: Standardablauf des maschinellen Lernens mit Tuning und Resampling"
  },
  {
    "objectID": "080-Resampling-Tuning.html#tidymodels",
    "href": "080-Resampling-Tuning.html#tidymodels",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.3 tidymodels",
    "text": "8.3 tidymodels\n\n8.3.1 Datensatz aufteilen\n\ndata(ames)\n\nset.seed(4595)\ndata_split &lt;- initial_split(ames, strata = \"Sale_Price\")\n\names_train &lt;- training(data_split)\names_test &lt;- testing(data_split)\n\n\n8.3.2 Rezept, Modell und Workflow definieren\nIn gewohnter Weise definieren wir den Workflow mit einem kNN-Modell.\n\names_rec &lt;-\n  recipe(Sale_Price ~ ., data = ames_train) %&gt;%\n  step_log(Sale_Price, base = 10) %&gt;%\n  step_other(Neighborhood, threshold = .1)  %&gt;%\n  step_dummy(all_nominal()) %&gt;%\n  step_zv(all_predictors()) \n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n  ) %&gt;%\n  set_engine(\"kknn\")\n\names_wflow &lt;-\n  workflow() %&gt;%\n  add_recipe(ames_rec) %&gt;%\n  add_model(knn_model)\n\nDas kNN-Modell ist noch nicht berechnet, es ist nur ein ‚ÄúRezept‚Äù erstellt:\n\nknn_model\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Computational engine: kknn\n\n\names_wflow\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 4 Recipe Steps\n## \n## ‚Ä¢ step_log()\n## ‚Ä¢ step_other()\n## ‚Ä¢ step_dummy()\n## ‚Ä¢ step_zv()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Computational engine: kknn"
  },
  {
    "objectID": "080-Resampling-Tuning.html#resampling",
    "href": "080-Resampling-Tuning.html#resampling",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.4 Resampling",
    "text": "8.4 Resampling\nVergleichen Sie die drei F√§lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:\n\nWir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe ‚Äúvorher‚Äù. Wir finden eine Gesamtgenauigkeit von 80%.\nWir fitten ein Klassifikationsmodell in einem Teil der urspr√ºnglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der urspr√ºnglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.\nWir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der F√§lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.\n\nWelchen der drei F√§lle finden Sie am sinnvollsten? Warum?"
  },
  {
    "objectID": "080-Resampling-Tuning.html#illustration-des-resampling",
    "href": "080-Resampling-Tuning.html#illustration-des-resampling",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.5 Illustration des Resampling",
    "text": "8.5 Illustration des Resampling\nResampling stellt einen Oberbegriff dar; Kreuzvalidierung ist ein Unterbegriff dazu. Es gibt noch andere Arten des Resampling, etwa Bootstrapping oder Leave-One-Out-Cross-Validation (LOOCV).\nIm Folgenden ist nur die Kreuzvalidierung dargestellt, da es eines der wichtigsten und vielleicht das Wichtigste ist. In vielen Quellen finden sich Erl√§uterungen anderer Verfahren dargestellt, etwa in Silge und Kuhn (2022), James u.¬†a. (2021) oder Rhys (2020).\n\n8.5.1 Einfache v-fache Kreuzvalidierung\nAbbildung¬†8.2 illustriert die zuf√§llige Aufteilung von \\(n=10\\) F√§llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe. Man spricht von Kreuzvalidierung (cross validation, CV).\nIn diesem Fall wurden 70% der (\\(n=10\\)) F√§lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe); ein willk√ºrlicher, aber nicht un√ºblicher Anteil. Diese Aufteilung wurde \\(v=3\\) Mal vorgenommen, es resultieren drei ‚ÄúResampling-Stichproben‚Äù, die manchmal auch als ‚ÄúFaltungen‚Äù bezeichnet werden.\n\n\n\n\nAbbildung¬†8.2: Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt\n\n\n\n\nSauer (2019) stellt das Resampling so dar (S. 259), s. Abbildung¬†8.3.\n\n\n\n\nAbbildung¬†8.3: Kreuzvalidierung, Aufteilung in Train- vs.¬†Testsample\n\n\n\n\nDer Gesamtfehler der Vorhersage wird als Mittelwerte der Vorhersagefehler in den einzelnen Faltungen berechnet.\nWarum ist die Vorhersage besser, wenn man mehrere Faltungen, mehrere Sch√§tzungen f√ºr \\(y\\) also, vornimmt?\nDer Grund ist das Gesetz der gro√üen Zahl, nachdem sich eine Sch√§tzung in Mittelwert und Variabilit√§t stabilisiert mit steigendem Stichprobenumfang, dem wahren Mittelwert also pr√§ziser sch√§tzt. Bei Normalverteilungen klappt das gut, bei randlastigen Verteilungen leider nicht mehr (Taleb 2019).\nH√§ufig werden \\(v=10\\) Faltungen verwendet, was sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.\n\n8.5.2 Wiederholte Kreuzvalidierung\nDie \\(r\\)-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (n√§mlich \\(r=4\\) mal), Sauer (2019) stellt das Resampling so dar (S. 259), s. Abbildung¬†8.4.\n\n\n\n\nAbbildung¬†8.4: Wiederholte Kreuzvalidierung\n\n\n\n\nDie wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.\nSilge und Kuhn (2022) zeigen die Verringerung des Sch√§tzfehlers als Funktion der \\(r\\) Wiederholungen dar, s. Abbildung¬†8.5.\n\n\n\n\nAbbildung¬†8.5: Reduktion des Sch√§tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung\n\n\n\n\nWarum ist die Wiederholung der Kreuzvalidierung n√ºtzlich?\nDie Kreuvalidierung liefert einen Sch√§tzwert der Modellparameter, die wahren Modellparameter werden also anhand einer Stichprobe von \\(n=1\\) gesch√§tzt. Mit h√∂herem Stichprobenumfang kann diese Sch√§tzung nat√ºrlich pr√§zisiert werden.\nDa jede Stichprobenverteilung bei \\(n \\rightarrow \\infty\\) normalverteilt ist - ein zentrales Theorem der Statistik, der Zentrale Grenzwertsatz (Central Limit Theorem) - kann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem \\(n\\) ebenfalls ann√§hernd normalverteilt1. Dann sind die Quantile bekannt und man kann die Streuung der Sch√§tzers, \\({\\sigma }_{\\bar {x}}\\), z.B. f√ºr den Mittelwert, einfach sch√§tzen:\n\\[{\\displaystyle {\\sigma }_{\\bar {x}}\\ ={\\frac {\\sigma }{\\sqrt {n}}}}\\]\n\n8.5.3 Resampling passiert im Train-Sample\nWichtig zu beachten ist, dass die Resampling nur im Train-Sample stattfindet. Das Test-Sample bleibt unanger√ºhrt. Dieser Sachverhalt ist in Abbildung¬†8.6, aus Silge und Kuhn (2022), illustriert.\n\n\n\n\nAbbildung¬†8.6: Resampling im Train-, nicht im Test-Sample\n\n\n\n\nWie in Abbildung¬†8.6 dargestellt, wird das Modell im Analyse-Sample berechnet (gefittet), und im Assessment-Sample auf Modellg√ºte hin √ºberpr√ºft.\nDie letztliche Modellg√ºte ist dann die Zusammenfassung (Mittelwert) der einzelnen Resamples.\n\n8.5.4 Andere Illustrationen\nEs gibt eine Reihe vergleichbarer Illustrationen in anderen B√ºchern:\n\nTimbers, Campbell & Lee, 2022, Kap. 6\nSilge & Kuhn, 2022, 10.1\nSilge & Kuhn, 2022, 10.2\nSilge & Kuhn, 2022, 10.3\nJames, Witten, hastie & Tishirani, 2021, 5.3"
  },
  {
    "objectID": "080-Resampling-Tuning.html#gesetz-der-gro√üen-zahl",
    "href": "080-Resampling-Tuning.html#gesetz-der-gro√üen-zahl",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.6 Gesetz der gro√üen Zahl",
    "text": "8.6 Gesetz der gro√üen Zahl\nNach dem Gesetz der gro√üen Zahl (Law of Large Numbers) sollte sich der Mittelwert einer gro√üen Stichprobe dem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess) sehr nahe kommen.\n\\[\\displaystyle \\lim _{n\\to \\infty }\\sum _{i=1}^{n}{\\frac {X_{i}}{n}}={\\overline {X}}\\]\nDavid Salazar visualisiert das folgenderma√üen in diesem Post seines lesenswerten Blogs, s. Abbildung¬†8.7).\n\n# source: https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/\nsamples &lt;- 1000\n\nthin &lt;- rnorm(samples, sd = 20)\n\ncumulative_mean &lt;- function(numbers) {\n    x &lt;- seq(1, length(numbers))\n    cum_mean &lt;- cumsum(numbers)/x \n    cum_mean\n}\n\nthin_cum_mean &lt;- cumulative_mean(thin)\n\nthin_cum_mean %&gt;%\n  tibble(running_mean = .) %&gt;% \n  add_rownames(var = 'number_samples') %&gt;% \n  mutate(number_samples = as.double(number_samples)) %&gt;% \n  arrange(number_samples) %&gt;% \n  ggplot(aes(x = number_samples, y = running_mean)) +\n    geom_line(color = 'dodgerblue4') +\n    geom_hline(yintercept = 0, linetype = 2, color = 'red') +\n  hrbrthemes::theme_ipsum_rc(grid = 'Y') +\n  scale_x_continuous(labels = scales::comma) +\n  labs(x = \"Stichprobengr√∂√üe\",\n       title = \"Gesetz der gro√üen Zahl\", \n       subtitle = \"Kumulierter Mittelwert aus einer Normalverteilung mit sd=20\")\n\n\n\nAbbildung¬†8.7: Gesetz der gro√üen Zahl\n\n\n\n\nWie man sieht, n√§hert sich der empirische Mittelwert (also in der Stichprobe) immer mehr dem theoretischen Mittelwert, 0, an.\nAchtung: Bei randlastigen Verteilungen darf man dieses sch√∂ne, wohlerzogene Verhalten nicht erwarten (Taleb 2019)."
  },
  {
    "objectID": "080-Resampling-Tuning.html#√ºber--und-unteranpassung-an-einem-beispiel",
    "href": "080-Resampling-Tuning.html#√ºber--und-unteranpassung-an-einem-beispiel",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.7 √úber- und Unteranpassung an einem Beispiel",
    "text": "8.7 √úber- und Unteranpassung an einem Beispiel\n\n\n\n\nAbbildung¬†8.8: Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die ‚Äòwahre Funktion‚Äô, der datengenerierende Prozess ist im Teil A dargestellt\n\n\n\n\nAbbildung¬†8.8 zeigt:\n\nTeil A: Die ‚Äòwahre Funktion‚Äô, \\(f\\), die die Daten erzeugt. Man spricht auch von der ‚Äúdatengenerierenden Funktion‚Äù. Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das hei√üt nicht, dass die wahre Funktion die Daten perfekt erkl√§rt, schlie√ülich kann die Funktion zwar wahr, aber unvollst√§ndig sein oder unsere Messinstrumente sind nicht perfekt pr√§zise.\nTeil B: Die Daten, erzeugt aus A plus etwas zuf√§lliges Fehler (Rauschen).\nTeil C: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\nTeil D: Ein zu komplexes Modell: √úberanpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\nTeil E: Ein Modell mittlerer Komplexit√§t. Keine √úberanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein."
  },
  {
    "objectID": "080-Resampling-Tuning.html#cv-in-tidymodels",
    "href": "080-Resampling-Tuning.html#cv-in-tidymodels",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.8 CV in tidymodels",
    "text": "8.8 CV in tidymodels\n\n8.8.1 CV definieren\nSo kann man eine einfache v-fache Kreuzvalidierung in Tidymodels auszeichnen:\n\nset.seed(2453)\names_folds &lt;- vfold_cv(ames_train, strata = \"Sale_Price\")\names_folds\n\n\n\n  \n\n\n\nWerfen wir einen Blick in die Spalte splits, erste Zeile:\n\names_folds %&gt;% pluck(1, 1)\n## &lt;Analysis/Assess/Total&gt;\n## &lt;1976/221/2197&gt;\n\nM√∂chte man die Defaults vpn vfold_cv wissen, schaut man in der Hilfe nach: ?vfold_cv:\nvfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)\nProbieren wir \\(v=5\\) und \\(r=2\\):\n\names_folds_rep &lt;- vfold_cv(ames_train, \n                           strata = \"Sale_Price\", \n                           v = 5,\n                           repeats = 2)\names_folds_rep\n\n\n\n  \n\n\n\n\n8.8.2 Resamples fitten\nHat unser Computer mehrere Rechenkerne, dann k√∂nnen wir diese nutzen und die Berechnungen beschleunigen. Im Standard wird sonst nur ein Kern verwendet.\n\nmycores &lt;- parallel::detectCores(logical = FALSE)\nmycores\n## [1] 4\n\nAuf Unix/MacOC-Systemen kann man dann die Anzahl der parallen Kerne so einstellen2:\n\nlibrary(doMC)\nregisterDoMC(cores = mycores)\n\nSo, und jetzt fitten wir die Resamples und trachten die Modellg√ºte in den Resamples:\n\names_resamples_fit &lt;- \n  ames_wflow %&gt;% \n  fit_resamples(ames_folds)\n\n ames_resamples_fit %&gt;%\n  collect_metrics()\n\n\n\n  \n\n\n\nNat√ºrlich interessiert uns prim√§r die Modellg√ºte im Test-Sample:\n\nfinal_ames &lt;-\n  last_fit(ames_wflow, data_split)\n\n\nfinal_ames %&gt;% \n  collect_metrics()"
  },
  {
    "objectID": "080-Resampling-Tuning.html#tuning",
    "href": "080-Resampling-Tuning.html#tuning",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.9 Tuning",
    "text": "8.9 Tuning\n\n8.9.1 Tuning auszeichnen\nIn der Modellspezifikation des Modells k√∂nnen wir mit tune() auszeichnen, welche Parameter wir tunen m√∂chten. Wir k√∂nenn\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) %&gt;%\n  set_engine(\"kknn\")\n\nWir k√∂nnen dem Tuningparameter auch einen Namen (ID/Laben) geben, z.B. ‚ÄúK‚Äù:\n\nknn_model &lt;-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\")\n  ) %&gt;%\n  set_engine(\"kknn\")\n\n\n8.9.2 Grid Search vs.¬†Iterative Search\nIm K-N√§chste-Nachbarn-Modell ist der vorhergesagt Wert, \\(\\hat{y}\\) f√ºr eine neue Beobachtung \\(x_0\\) wie folgt definiert:\n\\[\n\\hat y = \\frac{1}{K}\\sum_{\\ell = 1}^K x_\\ell^*,\n\\]\nwobei \\(K\\) die Anzahl der zu ber√ºcksichtigen n√§chsten Nachbarn darstellt und \\(x_\\ell^*\\) die Werte dieser ber√ºcksichtiggten Nachbarn.\nDie Wahl von \\(K\\) hat einen gewaltigen Einfluss auf die Vorhersagen und damit auf die Vorhersageg√ºte. Allerdings wird \\(K\\) nicht vom Modell gesch√§tzt. Es liegt an den Nutzi, diesen Wert zu w√§hlen.\nParameter dieser Art (die von den Nutzi zu bestimmen sind, nicht vom Algorithmus), nennt man Tuningparameter.\nAbbildung Abbildung¬†8.9 aus Silge und Kuhn (2022) stellt exemplarisch dar, welchen gro√üen Einfluss die Wahl des Werts eines Tuningparameters auf die Vorhersagen eines Modells haben.\n\n\n\n\nAbbildung¬†8.9: Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter\n\n\n\n\nAber wie w√§hlt man ‚Äúgute‚Äù Werte der Tuningparater? Zwei Ans√§tze, grob gesprochen, bieten sich an.\n\nGrid Search: Probiere viele Werte aus und schaue, welcher der beste ist. Dabei musst du hoffen, dass du die Werte erwischt, die nicht nur im Train-, sondern auch im Test-Sample gut funktionieren werden.\nIterative Search: Wenn du einen Wert eines Tuningparameters hast, nutze diesen, um intelligenter einen neuen Wert eines Tuningparameters zu finden.\n\nDer Unterschied beider Ans√§tze ist in Silge und Kuhn (2022) wie in Abbildung¬†8.10 dargestellt.\n\n\n\n\nAbbildung¬†8.10: Links: Grid Search. Rechts: Iterative Search2\n\n\n\n\nIn tidymodels kann man mit tune() angeben, dass man einen bestimmten Parameter tunen m√∂chte. tidymodels f√ºhrt das dann ohne weiteres Federlesens f√ºr uns durch."
  },
  {
    "objectID": "080-Resampling-Tuning.html#tuning-mit-tidymodels",
    "href": "080-Resampling-Tuning.html#tuning-mit-tidymodels",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.10 Tuning mit Tidymodels",
    "text": "8.10 Tuning mit Tidymodels\n\n8.10.0.1 Tuningparameter betrachten\nM√∂chte man wissen, welche und wie viele Tuningparameter tidymodels in einem Modell ber√ºcksichtigt, kann man extract_parameter_set_dials() aufrufen:\n\nextract_parameter_set_dials(knn_model)\n\n\n\n  \n\n\n\nDie Ausgabe informiert uns, dass es nur einen Tuningparameter gibt in diesem Modell und dass der Name (Label, ID) des Tuningparameters ‚ÄúK‚Äù ist. Au√üerdem sollen die Anzahl der Nachbarn getunt werden. Der Tuningparameter ist numerisch; das sieht man an nparam[+].\nSchauen wir uns mal an, auf welchen Wertebereich tidymodels den Parameter \\(K\\) begrenzt hat:\n\nknn_model %&gt;% \n  extract_parameter_dials(\"K\")\n## # Nearest Neighbors (quantitative)\n## Range: [1, 15]\n\nAktualisieren wir mal unseren Workflow entsprechend:\n\names_wflow &lt;-\n  ames_wflow %&gt;% \n  update_model(knn_model)\n\nWir k√∂nnen auch Einfluss nehmen und angeben, dass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll (f√ºr den Tuningparameter neighbors):\n\names_set &lt;-\n  extract_parameter_set_dials(ames_wflow) %&gt;%\n  update(K = neighbors(c(1, 50)))\n\names_set\n\n\n\n  \n\n\n\n\n8.10.1 Datenabh√§ngige Tuningparameter\nManche Tuningparameter kann man nur bestimmen, wenn man den Datensatz kennt. So ist die Anzahl der Pr√§diktoren, mtry in einem Random-Forest-Modell sinnvollerweise als Funktion der Pr√§diktorenzahl zu w√§hlen. Der Workflow kennt aber den Datensatz nicht. Daher muss der Workflow noch ‚Äúfinalisiert‚Äù oder ‚Äúaktualisiert‚Äù werden, um den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen.\nWenn wir im Rezept aber z.B. die Anzahl der Pr√§diktoren ver√§ndert haben, m√∂chten wir die Grenzen des Wertebereichs f√ºr mtry (oder andere Tuningparameter) vielleicht nicht h√§ndisch, ‚Äúhartverdrahtet‚Äù selber bestimmen, sondern lieber den Computer anweisen, und sinngem√§√ü sagen: ‚ÄúWarte mal mit der Bestimmung der Werte der Tuningparameter, bis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir, dass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch √§ndern musst. Und tu das dann auch.‚Äù Dazu sp√§ter mehr.\n\names_set &lt;-\n  workflow() %&gt;% \n  add_model(knn_model) %&gt;% \n  add_recipe(ames_rec) %&gt;% \n  extract_parameter_set_dials() %&gt;% \n  finalize(ames_train)\n\n\n8.10.2 Modelle mit Tuning berechnen\nNachdem wir die Tuningwerte bestimmt haben, k√∂nnen wir jetzt das Modell berechnen: F√ºr jeden Wert des Tuningparameters wird ein Modell berechnet:\n\names_grid_search &lt;-\n  tune_grid(\n    ames_wflow,\n    resamples = ames_folds\n  )\names_grid_search\n\n\n\n  \n\n\n\nIm Default berechnet tiymodels 10 Kandidatenmodelle.\nDie Spalte .metrics beinhaltet die Modellg√ºte f√ºr jedes Kandidatenmodell.\n\names_grid_search %&gt;% \n  collect_metrics()\n\n\n\n  \n\n\n\nDas k√∂nnen wir uns einfach visualisieren lassen:\n\nautoplot(ames_grid_search)\n\n\n\n\nAuf Basis dieser Ergebnisse k√∂nnte es Sinn machen, noch gr√∂√üere Werte f√ºr \\(K\\) zu √ºberpr√ºfen.\n\n8.10.3 Vorhersage im Test-Sample\nWelches Modellkandidat war jetzt am besten?\n\nshow_best(ames_grid_search)\n\n\n\n  \n\n\n\nW√§hlen wir jetzt mal das beste Modell aus (im Sinne des Optimierungskriteriusms):\n\nselect_best(ames_grid_search)\n\n\n\n  \n\n\n\nOk, notieren wir uns die Kombination der Tuningparameterwerte im besten Kandiatenmodell. In diesem Fall hat das Modull nur einen Tuningparameter:\n\names_knn_best_params &lt;-\n  tibble(K = 15)\n\nUnser Workflow wei√ü noch nicht, welche Tuningparameterwerte am besten sind:\n\names_wflow\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 4 Recipe Steps\n## \n## ‚Ä¢ step_log()\n## ‚Ä¢ step_other()\n## ‚Ä¢ step_dummy()\n## ‚Ä¢ step_zv()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = tune(\"K\")\n## \n## Computational engine: kknn\n\nneighbors = tune(\"K\") sagt uns, dass er diesen Parameter tunen will. Das haben wir jetzt ja erledigt. Wir wollen f√ºr das Test-Sample nur noch einen Wert, eben aus dem besten Kandidatenmodell, verwenden:\n\names_final_wflow &lt;-\n  ames_wflow %&gt;% \n  finalize_workflow(ames_knn_best_params)\n\names_final_wflow\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 4 Recipe Steps\n## \n## ‚Ä¢ step_log()\n## ‚Ä¢ step_other()\n## ‚Ä¢ step_dummy()\n## ‚Ä¢ step_zv()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = 15\n## \n## Computational engine: kknn\n\nWie man sieht, steht im Workflow nichts mehr von Tuningparameter.\nWir k√∂nnen jetzt das ganze Train-Sample fitten, also das Modell auf das ganze Train-Sample anwenden - nicht nur auf ein Analysis-Sample. Und mit den dann resultierenden Modellkoeffizienten sagen wir das TestSample vorher:\n\nfinal_ames_knn_fit &lt;-\n  last_fit(ames_final_wflow, data_split)\n\nfinal_ames_knn_fit\n\n\n\n  \n\n\n\nHolen wir uns die Modellg√ºte:\n\ncollect_metrics(final_ames_knn_fit)"
  },
  {
    "objectID": "080-Resampling-Tuning.html#aufgaben",
    "href": "080-Resampling-Tuning.html#aufgaben",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.11 Aufgaben",
    "text": "8.11 Aufgaben\n\nArbeiten Sie sich so gut als m√∂glich durch diese Analyse zum Verlauf von Covid-F√§llen\n\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu Vulkanausbr√ºchen\nFallstudie Himalaya"
  },
  {
    "objectID": "080-Resampling-Tuning.html#vertiefung",
    "href": "080-Resampling-Tuning.html#vertiefung",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "\n8.12 Vertiefung",
    "text": "8.12 Vertiefung\nFields arranged by purity, xkcd 435\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse mit R: Daten einlesen, aufbereiten, visualisieren und modellieren. 1. Auflage 2019. FOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/.\n\n\nTaleb, Nassim Nicholas. 2019. The statistical consequences of fat tails, papers and commentaries. Monograph. https://nassimtaleb.org/2020/01/final-version-fat-tails/."
  },
  {
    "objectID": "080-Resampling-Tuning.html#footnotes",
    "href": "080-Resampling-Tuning.html#footnotes",
    "title": "\n8¬† Resampling und Tuning\n",
    "section": "",
    "text": "Das klappt bei randlastigen Verteilungen nicht‚Ü©Ô∏é\nIn Windows gibt es andere Wege.‚Ü©Ô∏é"
  },
  {
    "objectID": "090-glm.html#lernsteuerung",
    "href": "090-glm.html#lernsteuerung",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.1 Lernsteuerung",
    "text": "9.1 Lernsteuerung\n\n9.1.1 Vorbereitung\nFrischen Sie Ihr Wissen zur logistischen Regression auf bzw. machen Sie sich mit den Grundlagen des Verfahrens vertraut.\n\n9.1.2 Lernziele\nSie verstehen den Zusammenhang von linearen und logistischen Modellen Sie k√∂nnen die logistische Regression mit Methoden von tidymodels anwenden\n\n9.1.3 Literatur\nRhys, Kap. 4\n\n9.1.4 Ben√∂tigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\n\neasystats ist, wie Tidymodels und Tidyverse, ein Metapaket, ein R-Paket also, das mehrere Pakete verwaltet und startet. Hier findet sich mehr Info zu Easystats.\nEinen flotten Spruch bekommen wir von Easystats gratis dazu:\n\neasystats_zen()\n## [1] \"Patience you must have my young padawan.\""
  },
  {
    "objectID": "090-glm.html#intuitive-erkl√§rung",
    "href": "090-glm.html#intuitive-erkl√§rung",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.2 Intuitive Erkl√§rung",
    "text": "9.2 Intuitive Erkl√§rung\nDie logistische Reression ist ein Spezialfall des linearen Modells (lineare Regression), der f√ºr bin√§re (dichotom) AV eingesetzt wird (es gibt auch eine Variante f√ºr multinominale AV). Es k√∂nnen eine oder mehrere UV in eine logistische Regression einflie√üen, mit beliebigem Skalenniveau.\nBeispiele f√ºr Forschungsfragen, die mit der logistischen Regression modelliert werden sind:\n\nWelche Faktoren sind pr√§diktiv, um vorherzusagen, ob jemand einen Kredit zur√ºckzahlen kann oder nicht?\nHaben weibliche Passagiere aus der 1. Klasse eine h√∂here √úberlebenschance als andere Personen auf der Titanic?\nWelche Faktoren h√§ngen damit zusammen, ob ein Kunde eine Webseite verl√§sst, bevor er einen Kauf abschlie√üt?\n\nDer Name stammt von der logistischen Funktion, die man in der einfachsten Form so darstellen kann:\n\\[f(x) = \\frac{x}{1+e^{-x}}\\]\nDa die AV als dichotom modelliert wird, spricht man von einer Klassifikation.\nAllerdings ist das Modell reichhaltiger als eine blo√üe Klassifikation, die (im bin√§ren Fall) nur 1 Bit Information liefert: ‚Äúja‚Äù vs.¬†‚Äúnein‚Äù bzw. 0 vs.¬†1.\nDas Modell liefert n√§mlich nicht nur eine Klassifikation zur√ºck, sondern auch eine Indikation der St√§rke (epistemologisch) der Klassenzugeh√∂rigkeit.\nEinfach gesagt hei√üt das, dass die logistische Regression eine Wahrscheinlichkeit der Klassenzugeh√∂rigkeit zur√ºckliefert.\n\n\n\n\nflowchart LR\n  Daten --&gt; Modell --&gt; Wskt --&gt; Klasse\n\n\n\nAbbildung¬†9.1: Ablauf einer Klassifikation"
  },
  {
    "objectID": "090-glm.html#profil",
    "href": "090-glm.html#profil",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.3 Profil",
    "text": "9.3 Profil\nDas Profil des Modells kann man wie folgt charakterisieren, vgl. Tab. Tabelle¬†9.1.\n\n\n\n\n\n\n\nTabelle¬†9.1: Profil der logistischen Regression\n\nMerkmal\nLogistische Regression\n\n\n\nKlassifikation\nja\n\n\nRegression\nnein\n\n\nLerntyp\n√ºberwacht\n\n\nparametrisch\nja"
  },
  {
    "objectID": "090-glm.html#warum-nicht-die-lineare-regression-verwenden",
    "href": "090-glm.html#warum-nicht-die-lineare-regression-verwenden",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.4 Warum nicht die lineare Regression verwenden?",
    "text": "9.4 Warum nicht die lineare Regression verwenden?\nForschungsfrage: Kann man anhand des Spritverbrauchs vorhersagen, ob ein Auto eine Automatik- bzw. ein manuelle Schaltung hat? Anders gesagt: H√§ngen Spritverbrauch und Getriebeart, s. Abbildung¬†9.2? (Datensatz mtcars)\n\ndata(mtcars)\nd &lt;-\n  mtcars %&gt;% \n  mutate(mpg_z = standardize(mpg),\n         iv = mpg_z,\n         dv = am)\n\nm81 &lt;- lm(dv ~ iv, data = d)\ncoef(m81)\n## (Intercept)          iv \n##   0.4062500   0.2993109\n\n\n\n\n\nAbbildung¬†9.2: Klassifikation von am\n\n\n\n\n\\(Pr(\\text{am}=1|m91,\\text{mpg_z}=0) = 0.46\\): Die Wahrscheinlichkeit einer manuelle Schaltung, gegeben einem durchschnittlichen Verbrauch (und dem Modell m81) liegt bei knapp 50%.\n\n9.4.1 Lineare Modelle running wild\nWie gro√ü ist die Wahrscheinlichkeit f√ºr eine manuelle Schaltung ‚Ä¶\n\n‚Ä¶ bei mpg_z = -2?\n\n\npredict(m81, newdata = data.frame(iv = -2))\n##          1 \n## -0.1923719\n\n\\(Pr(\\hat{y})&lt;0\\) macht keinen Sinn. ‚ö°\n\n‚Ä¶ bei mpg_z = +2?\n\n\npredict(m81, newdata = data.frame(iv = +2))\n##        1 \n## 1.004872\n\n\\(Pr(\\hat{y})&gt;1\\) macht keinen Sinn. ‚ö°\nSchauen Sie sich mal die Vorhersage an f√ºr mpg_z=5 ü§Ø\n\n9.4.2 Wir m√ºssen die Regressionsgerade umbiegen\n‚Ä¶ wenn der vorhergesagte Wert eine Wahrscheinlichkeit, \\(p_i\\), ist, s. Abbildung¬†9.3.\n\n\n\n\nAbbildung¬†9.3: Wir biegen die Regressionsgeraden in eine S-Form\n\n\n\n\nDie schwarze Gerade verl√§sst den Wertebereich der Wahrscheinlichkeit. Die blaue Kurve, \\(\\mathcal{f}\\), bleibt im erlaubten Bereich, \\(Pr(y) \\in [0,1]\\). Wir m√ºssen also die linke oder die rechte Seite des linearen Modells transformieren: \\(p_i = f(\\alpha + \\beta \\cdot x)\\) bzw.:\n\\(f(p) = \\alpha + \\beta \\cdot x\\)\n\\(\\mathcal{f}\\) nennt man eine Link-Funktion.\n\n9.4.3 Verallgemeinerte lineare Modelle zur Rettung\nF√ºr metrische AV mit theoretisch unendlichen Grenzen des Wertebereichs haben wir bisher eine Normalverteilung verwendet:\n\\[y_i \\sim \\mathcal{N}(\\mu_i, \\sigma)\\]\nDann ist die Normalverteilung eine voraussetzungsarme Wahl (maximiert die Entropie).\nAber wenn die AV bin√§r ist bzw. H√§ufigkeiten modelliert, braucht man eine Variable die nur positive Werte zul√§sst.\nDiese Verallgemeinerung des linearen Modells bezeichnet man als verallgemeinertes lineares Modell (generalized linear model, GLM).\nIm Falle einer bin√§ren (bzw. dichotomen) AV liegt eine bestimmte Form des GLM vor, die man als logistische Regression bezeichnet."
  },
  {
    "objectID": "090-glm.html#der-logit-link",
    "href": "090-glm.html#der-logit-link",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.5 Der Logit-Link",
    "text": "9.5 Der Logit-Link\nDer Logit-Link wird auch \\(\\mathcal{L}\\), logit, Log-Odds oder Logit-Funktion genannt.\nEr ‚Äúbiegt‚Äù die lineare Funktion in die richtige Form.\nDer Logit-Link ordnet einen Parameter, der als Wahrscheinlichkeitsmasse definiert ist (und daher im Bereich von 0 bis 1 liegt), einem linearen Modell zu (das jeden beliebigen reellen Wert annehmen kann):\n\\[\n\\begin{align}\n    \\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{align}\n\\]\n\nDie Logit-Funktion \\(\\mathcal{L}\\) ist definiert als der (nat√ºrliche) Logarithmus des Verh√§ltnisses der Wahrscheinlichkeit zu Gegenwahrscheinlichkeit:\n\n\\[\\mathcal{L} = \\text{log} \\frac{p_i}{1-p_i}\\]\n\nDas Verh√§ltnis der Wahrscheinlichkeit zu Gegenwahrscheinlichkeit nennt man auch Odds.\nAlso:\n\n\\[\\mathcal{L} = \\text{log} \\frac{p_i}{1-p_i} = \\alpha + \\beta x_i\\]"
  },
  {
    "objectID": "090-glm.html#aber-warum",
    "href": "090-glm.html#aber-warum",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.6 Aber warum?",
    "text": "9.6 Aber warum?\nForschungsfrage: H√§ngt das √úberleben (statistisch) auf der Titanic vom Geschlecht ab?\nWie war eigentlich insgesamt, also ohne auf einen (oder mehrere) Pr√§diktoren zu bedingen, die √úberlebenswahrscheinlichkeit?\n\ndata(titanic_train, package = \"titanic\")\n\nm82 &lt;- lm(Survived ~ 1, data = titanic_train)\ncoef(m82)\n## (Intercept) \n##   0.3838384\n\nDie Wahrscheinlichkeit zu √úberleben \\(Pr(y=1)\\) lag bei einem guten Drittel (0.38).\nDas h√§tte man auch so ausrechnen:\n\ntitanic_train %&gt;% \n  count(Survived) %&gt;% \n   mutate(prop = n/sum(n))\n\n\n\n  \n\n\n\nAnders gesagt: \\(p(y=1) = \\frac{549}{549+342} \\approx 0.38\\)\n\n9.6.1 tidymodels, m83\nBerechnen wir jetzt ein lineares Modell f√ºr die AV Survived mit dem Geschlecht als P√§diktor:\n\nd &lt;-\n  titanic_train %&gt;% \n  filter(Fare &gt; 0) %&gt;% \n  mutate(iv = log(Fare),\n         dv = factor(Survived))\n\nDie Faktorstufen, genannt levels von Survived sind:\n\nlevels(d$dv)\n## [1] \"0\" \"1\"\n\nUnd zwar genau in dieser Reihenfolge."
  },
  {
    "objectID": "090-glm.html#lm83-glm",
    "href": "090-glm.html#lm83-glm",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.7 lm83, glm",
    "text": "9.7 lm83, glm\nDie klassische Methoden in R, ein logistisches Modell zu berechnen, ist mit der Funktion glm(). Tidymodels greift intern auf diese Funktion zur√ºck. Daher sind die Ergebnisse numerisch identisch.\n\nlm83 &lt;- glm(dv ~ iv, data = d, family = \"binomial\")\ncoef(lm83)\n## (Intercept)          iv \n##  -2.6827432   0.7479317\n\n\nAV: √úberleben (bin√§r/Faktor)\nUV: Ticketpreis\n\nMit easystats kann man sich model_parameter() einfach ausgeben lassen:\n\nlibrary(easystats)\n\n\nmodel_parameters(lm83)\n\n\n\n  \n\n\n\nUnd auch visualisieren lassen:\n\nplot(model_parameters(lm83))"
  },
  {
    "objectID": "090-glm.html#m83-tidymodels",
    "href": "090-glm.html#m83-tidymodels",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.8 m83, tidymodels",
    "text": "9.8 m83, tidymodels\nAchtung! Bei tidymodels muss bei einer Klassifikation die AV vom Type factor sein. Au√üerdem wird bei tidymodels, im Gegensatz zu (g)lm nicht die zweite, sondern die erste als Ereignis modelliert wird.\nDaher wechseln wir die referenzkategorie, wir ‚Äúre-leveln‚Äù, mit relevel():\n\nd2 &lt;-\n  d %&gt;% \n  mutate(dv = relevel(dv, ref = \"1\"))\n\nCheck:\n\nlevels(d2$dv)\n## [1] \"1\" \"0\"\n\nPasst.\nDie erste Stufe ist jetzt 1, also √úberleben.\nJetzt berechnen wir das Modell in gewohnter Weise mit tidymodels.\n\nm83_mod &lt;-\n  logistic_reg()\n\nm83_rec &lt;-\n  recipe(dv ~ iv, data = d2)\n\nm83_wf &lt;-\n  workflow() %&gt;% \n  add_model(m83_mod) %&gt;% \n  add_recipe(m83_rec)\n\nm83_fit &lt;-\n  fit(m83_wf, data = d2)\n\nHier sind die Koeffizienten, die kann man sich aus m83_fit herausziehen:\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n2.68\n0.26\n10.46\n0.00\n\n\niv\n‚àí0.75\n0.08\n‚àí9.13\n0.00\n\n\n\n\n\n## [1]  2.6827432 -0.7479317\n\n\n\n\n\n  \n\n\n\nDie Koeffizienten werden in Logits angegeben.\nIn Abbildung¬†9.4 ist das Modell und die Daten visualisiert.\n\n\n\n\nAbbildung¬†9.4: Modell m83 und die Titanic-Daten\n\n\n\n\nDefinieren wir als \\(y=1\\) das zu modellierende Ereignis, hier ‚Äú√úberleben auf der Titanic‚Äù (hat also √ºberlebt).\nWie wir oben schon gesehen haben, funktioniert die lineare Regression nicht einwandfrei bei bin√§ren (oder dichotomen) AV.\n\n9.8.1 Wahrscheinlichkeit in Odds\nProbieren wir Folgendes: Rechnen wir die Wahrscheinlichkeit zu √úberlegen f√ºr \\(y\\), kurz \\(p\\), in Odds (Chancen) um.\n\\(odds = \\frac{p}{1-p}\\)\nIn R:\n\nodds &lt;- 0.38 / 0.62\nodds\n## [1] 0.6129032\n\nBildlich gesprochen sagen die Odds: f√ºr 38 Menschen, die √ºberlebt haben, kommen (ca.) 62 Menschen, die nicht √ºberlebt haben, s. Abbildung¬†9.5.\n\n\n\n\nAbbildung¬†9.5: Odds: 38 zu 62\n\n\n\n\nPlotten wir die Odds als Funktion der UV, s. Abbildung¬†9.6.\n\n\n\n\nAbbildung¬†9.6: Odds als Funktion der UV\n\n\n\n\nWir sind noch nicht am Ziel; die Variable ist noch nicht ‚Äúrichtig gebogen‚Äù.\n\n9.8.2 Von Odds zu Log-Odds\nWenn wir jetzt den Logarithmus (der Odds) berechnen bekommen wir eine ‚Äúbrav gebogenen‚Äù Funktion, die Log-Odds, \\(\\mathcal{L}\\), als Funktion der UV, s. Abbildung¬†9.7.\n\\[\\mathcal{L} = log (odds) = log \\left(\\frac{p}{1-p}\\right)\\]\n\n\n\n\nAbbildung¬†9.7: Logit als Funktion der UV\n\n\n\n\nLinear!\nEs gilt also:\n\\[\\text {log-odds} = b_0 + b_1x\\]\nLog-Odds (Log-Odds) bezeichnet man auch als Logits."
  },
  {
    "objectID": "090-glm.html#inverser-logit",
    "href": "090-glm.html#inverser-logit",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.9 Inverser Logit",
    "text": "9.9 Inverser Logit\nUm nach \\(p\\) aufzul√∂sen, m√ºssen wir einige Algebra bem√ºhen:\n\\[\n\\begin{align}\n\\text{log} \\frac{p}{1-p} &= \\alpha + \\beta x & & \\text{Exponentieren}\\\\\n\\frac{p}{1-p} &= e^{\\alpha + \\beta x} \\\\\np_i &= e^{\\alpha + \\beta x_i} (1-p) & & \\text{Zur Vereinfachung: } x := e^{\\alpha + \\beta x_i} \\\\\np_i &= x (1-p) \\\\\n&= x - xp \\\\\np + px &= x \\\\\np(1+x) &= x \\\\\np &= \\frac{x} {1+x} & & \\text{L√∂sen wir x wieder auf.} \\\\\np &= \\frac{e^{\\alpha + \\beta x_i}}{1 + e^{\\alpha + \\beta x_i}} = \\mathcal{L}^{-1}\n\\end{align}\n\\]\nDiese Funktion nennt man auch inverser Logit, \\(\\text{logit}^{-1}, \\mathcal{L}^{-1}\\).\nZum Gl√ºck macht das alles die Rechenmaschine f√ºr uns üòÑ.\n\n9.9.1 Vom Logit zur Klasse\nPraktisch k√∂nnen wir uns die Logits und ihre zugeh√∂rige Wahrscheinlichkeit einfach ausgeben lassen mit R. Und die vorhergesagte Klasse (.pred_class) auch:\n\nd3 &lt;-\n  d2 %&gt;% \n  bind_cols(predict(m83_fit, new_data = d2, type = \"prob\")) %&gt;% \n  bind_cols(predict(m83_fit, new_data = d2)) %&gt;%  # Klasse\n  bind_cols(logits = predict(m83_fit, new_data = d2, type = \"raw\"))  # Logits\n  \nd3 %&gt;% \n  slice_head(n = 3) %&gt;% \n  select(Name, last_col())\n\n\n\n  \n\n\n\n\n9.9.2 Grenzwert wechseln\nIm Standard wird 50% als Grenzwert f√ºr die vorhergesagte Klasse \\(c\\) genommen:\n\nwenn \\(p &lt;= .5 \\rightarrow c = 0\\)\n\nwenn \\(p &gt; .5 \\rightarrow c = 1\\)\n\n\nMan kann aber den Grenzwert beliebig w√§hlen, um Kosten-Nutzen-Abw√§gungen zu optimieren; mehr dazu findet sich z.B. hier."
  },
  {
    "objectID": "090-glm.html#logit-und-inverser-logit",
    "href": "090-glm.html#logit-und-inverser-logit",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.10 Logit und Inverser Logit",
    "text": "9.10 Logit und Inverser Logit\n\n9.10.1 Logit\n\\((0,1) \\rightarrow (-\\infty, +\\infty)\\)\nAbbildung¬†9.8 zeigt die Ver√§nderung des Wertebereichs bei Umrechnung von Wahrscheinlichkeit zu Logit.\n\n\n\n\nAbbildung¬†9.8: Der Wertebereich der Wahrscheinlichkeit ist [0,1]; der Wertebereich des Logits [-Inf,+Inf].\n\n\n\n\nPraktisch, um Wahrscheinlichkeit zu modellieren.\n\\[p \\rightarrow \\fbox{logit} \\rightarrow \\alpha + \\beta x\\]\n\n9.10.2 Inv-Logit\nBeim Inversen Logit (Inv-Logit) ist es genau umgekehrt wie beim Logit. Abbildung¬†9.9 zeigt die Ver√§nderung des Wertebereichs des Inv-Logits.\n\\((-\\infty, +\\infty) \\rightarrow (0,1)\\)\n\n\n\n\nAbbildung¬†9.9: Ver√§nderung der Wertebereichs durch die Inv-Logit-Umrechnung\n\n\n\n\nPraktisch, um in Wahrscheinlichkeiten umzurechnen.\n\\[p \\leftarrow \\fbox{inv-logit} \\leftarrow \\alpha + \\beta x\\]"
  },
  {
    "objectID": "090-glm.html#logistische-regression-im-√ºberblick",
    "href": "090-glm.html#logistische-regression-im-√ºberblick",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.11 Logistische Regression im √úberblick",
    "text": "9.11 Logistische Regression im √úberblick\n\nEine Regression mit binomial verteilter AV und Logit-Link nennt man logistische Regression.\n\nMan verwendet die logistische Regression um binomial verteilte AV zu modellieren, z.B.\n\nWie hoch ist die Wahrscheinlichkeit, dass ein Kunde das Produkt kauft?\nWie hoch ist die Wahrscheinlichkeit, dass ein Mitarbeiter k√ºndigt?\nWie hoch ist die Wahrscheinlichkeit, die Klausur zu bestehen?\n\n\nDie logistische Regression ist eine normale, lineare Regression f√ºr den Logit von \\(Pr(y=1)\\), wobei \\(y\\) (AV) binomialvereteilt mit \\(n=1\\) angenommen wird:\n\n\\[\n\\begin{align}\ny_i &\\sim \\mathcal{B}(1, p_i) \\\\\n\\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{align}\n\\]\n\nDa es sich um eine normale, lineare Regression handelt, sind alle bekannten Methoden und Techniken der linearen Regression zul√§ssig.\nDa Logits nicht einfach zu interpretieren sind, rechnet man nach der Berechnung des Modells den Logit h√§ufig in Wahrscheinlichkeiten um.\n\n\n9.11.1 Die Koeffizienten sind schwer zu interpretieren\nPuhhh, s. Abbildung¬†9.10\n\n\n\n\nAbbildung¬†9.10: Die Koeffizienten der logistischen Regression sind nicht normal - im additiven Sinne - zu interpretieren.\n\n\n\n\n\nIn der logistischen Regression gilt nicht mehr, dass eine konstante Ver√§nderung in der UV mit einer konstanten Ver√§nderung in der AV einhergeht.\nStattdessen geht eine konstante Ver√§nderung in der UV mit einer konstanten Ver√§nderung im Logit der AV einher.\nBeim logistischen Modell hier gilt, dass in der N√§he von \\(x=0\\) die gr√∂√üte Ver√§nderung in \\(p\\) von statten geht; je weiter weg von \\(x=0\\), desto geringer ist die Ver√§nderung in \\(p\\).\n\n9.11.2 Logits vs.¬†Wahrscheinlichkeiten\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\nlogit\np\n\n\n\n‚àí10.00\n0.00\n\n\n‚àí3.00\n0.05\n\n\n‚àí2.00\n0.12\n\n\n‚àí1.00\n0.27\n\n\n‚àí0.50\n0.38\n\n\n‚àí0.25\n0.44\n\n\n0.00\n0.50\n\n\n0.25\n0.56\n\n\n0.50\n0.62\n\n\n1.00\n0.73\n\n\n2.00\n0.88\n\n\n3.00\n0.95\n\n\n10.00\n1.00"
  },
  {
    "objectID": "090-glm.html#aufgaben",
    "href": "090-glm.html#aufgaben",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.12 Aufgaben",
    "text": "9.12 Aufgaben\n\nFallstudien zu Studiengeb√ºhren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF"
  },
  {
    "objectID": "090-glm.html#vertiefung",
    "href": "090-glm.html#vertiefung",
    "title": "\n9¬† Logistische Regression\n",
    "section": "\n9.13 Vertiefung",
    "text": "9.13 Vertiefung\nFallstudie Diabetes mit logististischer Regression"
  },
  {
    "objectID": "100-baeume.html#lernsteuerung",
    "href": "100-baeume.html#lernsteuerung",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.1 Lernsteuerung",
    "text": "10.1 Lernsteuerung\n\n10.1.1 Lernziele\n\n‚ÄúSie k√∂nnen den rpart-Algorithmus erkl√§ren‚Äù\n‚ÄúSie wissen, wie man Overfitting bei Entscheidungsb√§ume begrenzen kann‚Äù\n‚ÄúSie k√∂nnen Entscheidungsb√§ume in R berechnen‚Äù Literatur:\n‚ÄúRhys, Kap. 7‚Äù\n\n10.1.2 Vorbereitung\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\nlibrary(titanic)  # Datensatzt Titanic\n#library(rpart)  # Berechnung von Entscheidungsb√§umen\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\nlibrary(readr)  # rds"
  },
  {
    "objectID": "100-baeume.html#entscheidungb√§ume",
    "href": "100-baeume.html#entscheidungb√§ume",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.2 Entscheidungb√§ume",
    "text": "10.2 Entscheidungb√§ume\n\n10.2.1 Anatomie eines Baumes\nEin Baum üå≥ hat (u.a.):\n\nWurzel\nBl√§tter\n√Ñste\n\nIn einem Entscheidungsbaum ist die Terminologie √§hnlich, s. Abbildung¬†10.1. Allgemein gesagt, kann ein Entscheidungsbaum in einem baum√§hnlichen Graphen visualisiert werden. Dort gibt es Knoten, die durch Kanten verbunden sind, wobei zu einem Knoten genau ein Kanten f√ºhrt.\nEin Beispiel f√ºr einen einfachen Baum sowie die zugeh√∂rige rekursive Partionierung ist in Abbildung¬†10.1 dargestellt; man erkennt \\(R=3\\) Regionen bzw. Bl√§tter (James u.¬†a. 2021).\n\n\n\n\n\n(a) Ein einfacher Baum\n\n\n\n\n\n\n(b) Die rekursiven, rechteckigen Partionierungen eines Baumes\n\n\n\n\nAbbildung¬†10.1: Einfaches Beispiel f√ºr einen Baum sowie der zugeh√∂rigen rekursiven Partionierung\n\n\nIn Abbildung¬†10.1 wird der Knoten an der Spitze auch als Wurzel(knoten) bezeichnet. Von diesem Knoten entspringen alle Pfade. Ein Pfad ist die geordnete Menge der Pfade mit ihren Knoten ausgehend von der Wurzel bis zu einem Blatt. Knoten, aus denen kein Kanten mehr wegf√ºhrt (‚ÄúEndknoten‚Äù) werden als Bl√§tter bezeichnet. Von einem Knoten gehen zwei Kanten aus (oder gar keine). Knoten, von denen zwei Kanten ausgehen, spiegeln eine Bedingung (Pr√ºfung) wider, im Sinne einer Aussage, die mit ja oder nein beantwortet werden kann. Die Anzahl der Knoten eines Pfads entsprechen den Ebenen bzw. der Tiefe des Baumes. Von der obersten Ebene (Wurzelknoten) kann man die \\(e\\) Ebenen aufsteigend durchnummerieren, beginnend bei 1: \\(1,2,\\ldots,e\\).\n\n10.2.2 B√§ume als Regelmaschinen rekursiver Partionierung\nEin Baum kann man als eine Menge von Regeln, im Sinne von Wenn-dann-sonst-Aussagen, sehen:\nWenn Pr√§diktor A = 1 ist dann\n|  Wenn Pr√§diktor B = 0 ist dann p = 10%\n|  sonst p = 30%\nsonst p = 50%\nIn diesem Fall, zwei Pr√§diktoren, ist der Pr√§diktorenraum in drei Regionen unterteilt: Der Baum hat drei Bl√§tter.\nF√ºr ?fig-tree1 ergibt sich eine komplexere Aufteilung, s. auch Abbildung¬†10.2.\n\n\n\n\nBeispiel f√ºr einen Entscheidungsbaum\n\n\n\n\nKleine Lesehilfe f√ºr ?fig-tree1:\n\nF√ºr jeden Knoten steht in der ersten Zeile der vorhergesagte Wert, z.B. 0 im Wurzelknoten\ndarunter steht der Anteil (die Wahrscheinlichkeit) f√ºr die in diesem Knoten vorhergesagte Kategorie (0 oder 1)\ndarunter (3. Zeile) steht der Anteil der F√§lle (am Gesamt-Datensatz) in diesem Knoten, z.B. 100%\n\n\n\n\n\n\nAbbildung¬†10.2: Partionierung in Rechtecke durch Entscheidungsb√§ume\n\n\n\n\nWie der Algorithmus oben zeigt, wird der Pr√§diktorraum wiederholt (rekursiv) aufgeteilt, und zwar in Rechtecke,s. Abbildung¬†10.2. Man nennt (eine Implementierung) dieses Algorithmus auch rpart.\nDas Regelwerk zum Baum aus ?fig-tree1 sieht so aus:\n\n## parsnip model object\n## \n## n= 891 \n## \n## node), split, n, loss, yval, (yprob)\n##       * denotes terminal node\n## \n##   1) root 891 342 0 (0.61616162 0.38383838)  \n##     2) Pclass&gt;=2.5 491 119 0 (0.75763747 0.24236253)  \n##       4) Age&gt;=6.5 461 102 0 (0.77874187 0.22125813) *\n##       5) Age&lt; 6.5 30  13 1 (0.43333333 0.56666667) *\n##     3) Pclass&lt; 2.5 400 177 1 (0.44250000 0.55750000)  \n##       6) Age&gt;=17.5 365 174 1 (0.47671233 0.52328767)  \n##        12) Pclass&gt;=1.5 161  66 0 (0.59006211 0.40993789) *\n##        13) Pclass&lt; 1.5 204  79 1 (0.38725490 0.61274510)  \n##          26) Age&gt;=44.5 67  32 0 (0.52238806 0.47761194)  \n##            52) Age&gt;=60.5 14   3 0 (0.78571429 0.21428571) *\n##            53) Age&lt; 60.5 53  24 1 (0.45283019 0.54716981)  \n##             106) Age&lt; 47.5 13   3 0 (0.76923077 0.23076923) *\n##             107) Age&gt;=47.5 40  14 1 (0.35000000 0.65000000) *\n##          27) Age&lt; 44.5 137  44 1 (0.32116788 0.67883212) *\n##       7) Age&lt; 17.5 35   3 1 (0.08571429 0.91428571) *\n\nKleine Lesehilfe: Ander Wurzel root des Baumes, Knoten 1)haben wir 891 F√§lle, von denen 342 nicht unserer Vorhersage yval entsprechen, also loss sind, das ist ein Anteil, (yprob) von 0.38. Unsere Vorhersage ist 0, da das die Mehrheit in diesem Knoten ist, dieser Anteil betr√§gt ca. 61%. In der Klammer stehen also die Wahrscheinlichkeiten f√ºr alle Auspr√§gungen von Y:, 0 und 1, in diesem Fall. Entsprechendes gilt f√ºr jeden weiteren Knoten.\nEin kurzer Check der H√§ufigkeit am Wurzelknoten:\n\ncount(titanic_train, Survived)\n\n\n\n  \n\n\n\nSolche Entscheidungsb√§ume zu erstellen, ist nichts neues. Man kann sie mit einer einfachen Checkliste oder Entscheidungssystem vergleichen. Der Unterschied zu Entscheidungsb√§umen im maschinellen Lernen ist nur, dass die Regeln aus den Daten gelernt werden, man muss sie nicht vorab kennen.\nNoch ein Beispiel ist in Abbildung¬†10.3 gezeigt (James u.¬†a. 2021): Oben links zeigt eine unm√∂gliche Partionierung (f√ºr einen Entscheidungsbaum). Oben rechts zeigt die Regionen, die sich durch den Entscheidungsbaum unten links ergeben. Untenrechts ist der Baum in 3D dargestellt.\n\n\n\n\nAbbildung¬†10.3: Ein weiteres Beispiel zur Darstellung von Entscheidungsb√§umen"
  },
  {
    "objectID": "100-baeume.html#klassifikation",
    "href": "100-baeume.html#klassifikation",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.3 Klassifikation",
    "text": "10.3 Klassifikation\nB√§ume k√∂nnen f√ºr Zwecke der Klassifikation (nominal skalierte AV) oder Regression (numerische AV) verwendet werden. Betrachten wir zun√§chst die bin√§re Klassifikation, also f√ºr eine zweistufige (nominalskalierte) AV. Das Ziel des Entscheidungsmodel-Algorithmus ist es, zu Bl√§ttern zu kommen, die m√∂glichst ‚Äúsortenrein‚Äù sind, sich also m√∂glichst klar f√ºr eine (der beiden) Klassen \\(A\\) oder \\(B\\) aussprechen. Nach dem Motto: ‚ÄúWenn Pr√§diktor 1 kleiner \\(x\\) und wenn Pr√§diktor 2 gleich \\(y\\), dann handelt es sich beim vorliegenden Fall ziemlich sicher um Klasse \\(A\\).‚Äù\n\nJe homogener die Verteilung der AV pro Blatt, desto genauer die Vorhersagen.\n\nUnsere Vorhersage in einem Blatt entspricht der Merheit bzw. der h√§ufigsten Kategorie in diesem Blatt.\n\n10.3.1 Gini als Optimierungskriterium\nEs gibt mehrere Kennzahlen, die zur Optimierung bzw. zur Entscheidung zum Aufbau des Entscheidungsbaum herangezogen werden. Zwei √ºbliche sind der Gini-Koeffizient und die Entropie. Bei Kennzahlen sind Ma√ü f√ºr die Homogenit√§t oder ‚ÄúSortenreinheit‚Äù (vs.¬†Heterogenit√§t, engl. auch impurity).\nDen Algorithmus zur Erzeugung des Baumes kann man so darstellen:\nWiederhole f√ºr jede Ebenes\n|  pr√ºfe f√ºr alle Pr√§diktoren alle m√∂glichen Bedingungen\n|  w√§hle denjenigen Pr√§diktor mit derjenigen Bedingung, der die Homogenit√§t maximiert\nsolange bis Abbruchkriterium erreicht ist.\nEin Bedingung k√∂nnte sein Age &gt;= 18 oder Years &lt; 4.5.\nEs kommen mehrere Abbruchkriterium in Frage:\n\nEine Mindestanzahl von Beobachtungen pro Knoten wird unterschritten (minsplit)\nDie maximale Anzahl an Ebenen ist erreicht (maxdepth)\nDie minimale Zahl an Beobachtungen eines Blatts wird unterschritten (minbucket)\n\nDer Gini-Koeffizient ist im Fall einer UV mit zwei Stufen, \\(c_A\\) und \\(c_B\\), so definiert:\n\\[G = 1 - \\left(p(c_A)^2 + (1-p(c_A))^2\\right)\\]\nDer Algorithmus ist ‚Äúgierig‚Äù (greedy): Optimiert werden lokal optimale Aufteilungen, auch wenn das bei sp√§teren Aufteilungen im Baum dann insgesamt zu geringerer Homogenit√§t f√ºhrt.\nDie Entropie ist definiert als\n\\[D = - \\sum_{k=1}^K p_k \\cdot log(p_k),\\]\nwobei \\(K\\) die Anzahl der Kategorien indiziert.\nGini-Koeffizient und Entropie kommen oft zu √§hnlichen numerischen Ergebnissen, so dass wir uns im Folgenden auf den Gini-Koeffizienten konzentieren werden.\n\nBeispiel\nVergleichen wir drei Bedingungen mit jeweils \\(n=20\\) F√§llen, die zu unterschiedlich homogenen Knoten f√ºhren:\n\n10/10\n15/5\n19/1\n\nWas ist jeweils der Wert des Gini-Koeffizienten?\n\nG1 &lt;- 1 - ((10/20)^2 + (10/20)^2)\nG1\n## [1] 0.5\n\nG2 &lt;- 1 - ((15/20)^2 + (5/20)^2)\nG2\n## [1] 0.375\n\nG3 &lt;- 1 - ((19/20)^2 + (1/20)^2)\nG3\n## [1] 0.095\n\nWie man sieht, sinkt der Wert des Gini-Koeffizienten (‚ÄúG-Wert‚Äù), je homogener die Verteilung ist. Maximal heterogen (‚Äúgemischt‚Äù) ist die Verteilung, wenn alle Werte gleich oft vorkommen, in diesem Fall also 50%/50%.\n\nNeben dem G-Wert f√ºr einzelne Knoten kann man den G-Wert f√ºr eine Aufteilung (‚ÄúSplit‚Äù) berechnen, also die Fraeg beantworten, ob die Aufteilung eines Knoten in zwei zu mehr Homogenit√§t f√ºhrt. Der G-Wert einer Aufteilung ist die gewichtete Summe der G-Werte der beiden Knoten (links, \\(l\\) und rechts, \\(r\\)):\n\\[G_{split} = p(l) G_{l} + p(r) G_r\\]\nDer Gewinn (gain) an Homogenit√§t ist dann die Differenz des G-Werts der kleineren Ebene und der Aufteilung:\n\\[G_{gain} = G - G_{split}\\]\nDer Algorithmus kann auch bei UV mit mehr als zwei, also \\(K\\) Stufen, \\(c_1, c_2, \\ldots, c_K\\) verwendet werden:\n\\[G= 1- \\sum_{k=1}^K p(c_k)^2\\]\n\n10.3.2 Metrische Pr√§diktoren\nAu√üerdem ist es m√∂glich, Bedingung bei metrischen UV auf ihre Homogenit√§t hin zu bewerten, also Aufteilungen der Art Years &lt; 4.5 zu t√§tigen. Dazu muss man einen Wert identifieren, bei dem man auftrennt.\nDas geht in etwa so:\nSortiere die Werte eines Pr√§diktors (aufsteigend)\nF√ºr jedes Paar an aufeinanderfolgenden Werten berechne den G-Wert\nFinde das Paar mit dem h√∂chsten G-Wert aus allen Paaren\nNimm den Mittelwert der beiden Werte dieses Paares: Das ist der Aufteilungswert\nAbbildung Abbildung¬†10.4 stellt dieses Vorgehen schematisch dar (Rhys 2020).\n\nknitr::include_graphics(\"img/fig7-5_alt.jpeg\")\n\n\n\nAbbildung¬†10.4: Aufteilungswert bei metrischen Pr√§diktoren"
  },
  {
    "objectID": "100-baeume.html#regressionb√§ume",
    "href": "100-baeume.html#regressionb√§ume",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.4 Regressionb√§ume",
    "text": "10.4 Regressionb√§ume\nBei Regressionsb√§umen wird nicht ein Homogenit√§tsma√ü wie der Gini-Koeffizient als Optimierungskriterium herangezogen, sondern die RSS (Residual Sum of Squares) bietet sich an.\nDie \\(J\\) Regionen (Partionierungen) des Pr√§diktorraums \\(R_1, R_2, \\ldots, R_J\\) m√ºssen so gew√§hlt werden, dass RSS minimal ist:\n\\[RSS = \\sum^J_{j=1}\\sum_{i\\in R_j}(u_i - \\hat{y}_{R_j})^2,\\]\nwobei \\(\\hat{y}\\) der (vom Baum) vorhergesagte Wert ist f√ºr die \\(j\\)-te Region."
  },
  {
    "objectID": "100-baeume.html#baum-beschneiden",
    "href": "100-baeume.html#baum-beschneiden",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.5 Baum beschneiden",
    "text": "10.5 Baum beschneiden\nEin Problem mit Entscheidungsb√§umen ist, dass ein zu komplexer Baum, ‚Äúzu ver√§stelt‚Äù sozusagen, in hohem Ma√üe Overfitting ausgesetzt ist: Bei h√∂heren Ebenen im Baum ist die Anzahl der Beobachtungen zwangsl√§ufig klein, was bedeutet, dass viel Rauschen gefittet wird.\nUm das Overfitting zu vermeiden, gibt es zwei auf der Hand liegende Ma√ünahmen:\n\nDen Baum nicht so gro√ü werden lassen\nDen Baum ‚Äúzur√ºckschneiden‚Äù\n\nDie 1. Ma√ünahme beruht auf dem Festlegen einer maximalen Zahl an Ebenen (maxdepth) oder einer minimalen Zahl an F√§llen pro Knoten (minsplit) oder im Blatt (minbucket).\nDie 2. Ma√ünahme, das Zur√ºckschneiden (pruning) des Baumes hat als Idee, einen ‚ÄúTeilbaum‚Äù \\(T\\) zu finden, der so klein wie m√∂glich ist, aber so gut wie m√∂glich pr√§zise Vorhersagen erlaubt. Dazu belegen wir die RSS eines Teilbaums (subtree) mit einem Strafterm \\(s = \\alpha |T|\\), wobei \\(|T|\\) die Anzahl der Bl√§tter des Baums entspricht. \\(\\alpha\\) ist ein Tuningparameter, also ein Wert, der nicht vom Modell berechnet wird, sondern von uns gesetzt werden muss - zumeist durch schlichtes Ausprobieren. \\(\\alpha\\) w√§gt ab zwischen Komplexit√§t und Fit (geringe RSS). Wenn \\(\\alpha=0\\) haben wir eine normalen, unbeschnittenen Baum \\(T_0\\). Je gr√∂√üer \\(\\alpha\\) wird, desto h√∂her wird der ‚ÄúPreis‚Äù f√ºr viele Bl√§tter, also f√ºr Komplexit√§t und der Baum wird kleiner. Dieses Vorgehen nennt man auch cost complexity pruning. Daher nennt man den zugeh√∂rigen Tuningparameter auch Cost Complexity \\(C_p\\)."
  },
  {
    "objectID": "100-baeume.html#das-rechteck-schl√§gt-zur√ºck",
    "href": "100-baeume.html#das-rechteck-schl√§gt-zur√ºck",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.6 Das Rechteck schl√§gt zur√ºck",
    "text": "10.6 Das Rechteck schl√§gt zur√ºck\nEntscheidungsb√§ume zeichnen sich durch rechtecke (rekursive) Partionierungen des Pr√§diktorenraums aus. Lineare Modelle durch eine einfache lineare Partionierung (wenn man Klassifizieren m√∂chte), Abbildung¬†10.5 verdeutlicht diesen Unterschied (James u.¬†a. 2021).\n\n\n\n\nAbbildung¬†10.5: Rechteckige vs.¬†lineare Partionierung\n\n\n\n\nJetzt kann sich fragen: Welches Vorgehen ist besser - das rechteckige oder das lineare Partionierungen. Da gibt es eine klare Antwort: Es kommt drauf an. Wie Abbildung¬†10.5 gibt es Datenlagen, in denen das eine Vorgehen zu homogenerer Klassifikation f√ºhrt und Situationen, in denen das andere Vorgehen besser ist, vgl. Abbildung¬†10.6.\n\n\n\n\nAbbildung¬†10.6: Free Lunch?"
  },
  {
    "objectID": "100-baeume.html#tidymodels",
    "href": "100-baeume.html#tidymodels",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.7 Tidymodels",
    "text": "10.7 Tidymodels\nProbieren wir den Algorithmus Entscheidungsb√§ume an einem einfachen Beispiel in R mit Tidymodels aus.\nDie Aufgabe sei, Spritverbrauch (m√∂glichst exakt) vorherzusagen.\nEin √§hnliches Beispiel, mit analogem Vorgehen, findet sich in dieser Fallstude.\n\n10.7.1 Initiale Datenaufteilung\n\nlibrary(tidymodels)\n\n\ndata(\"mtcars\")\n\nset.seed(42)  # Reproduzierbarkeit\nd_split &lt;- initial_split(mtcars, strata = mpg)\n## Warning: The number of observations in each quantile is below the recommended threshold of 20.\n## ‚Ä¢ Stratification will use 1 breaks instead.\n## Warning: Too little data to stratify.\n## ‚Ä¢ Resampling will be unstratified.\n\nd_train &lt;- training(d_split)\nd_test &lt;- testing(d_split)\n\nDie Warnung zeigt uns, dass der Datensatz sehr klein ist; stimmt. Ignorieren wir hier einfach.\nWie man auf der Hilfeseite der Funktion sieht, wird per Voreinstellung 3/1 aufgeteilt, also 75% in das Train-Sample, 25% der Daten ins Test-Sample.\nBei \\(n=32\\) finden also 8 Autos ihren Weg ins Test-Sample und die √ºbrigen 24 ins Train-Sample. Bei der kleinen Zahl k√∂nnte man sich (berechtigterweise) fragen, ob es Sinn macht, die sp√§rlichen Daten noch mit einem Test-Sample weiter zu dezimieren. Der Einwand ist nicht unberechtigt, allerdings zieht der Verzicht auf ein Test-Sample andere Probleme, Overfitting namentlich, nach sich.\n\n10.7.2 Kreuzvalidierung definieren\n\nd_cv &lt;- vfold_cv(d_train, strata = mpg, repeats = 5, v = 5) \nd_cv\n\n\n\n  \n\n\n\nDie Defaults (Voreinstellungen) der Funktion vfold_cv() k√∂nnen, wie immer, auf der Hilfeseite der Funktion nachgelesen werden.\nDa die Stichprobe sehr klein ist, bietet es sich an, eine kleine Zahl an Faltungen (folds) zu w√§hlen. Bei 10 Faltungen beinhaltete eine Stichprobe gerade 10% der F√§lle in Train-Sample, also etwa ‚Ä¶ 2!\nZur Erinnerung: Je gr√∂√üer die Anzahl der Repeats, desto genauer sch√§tzen wir die Modellg√ºte.\n\n10.7.3 Rezept definieren\nHier ein einfaches Rezept:\n\nrecipe1 &lt;-\n  recipe(mpg ~ ., data = d_train) %&gt;% \n  step_impute_knn() %&gt;% \n  step_normalize() %&gt;% \n  step_dummy() %&gt;% \n  step_other(threshold = .1)\n\n\n10.7.4 Modell definieren\n\ntree_model &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) %&gt;% \n  set_engine(\"rpart\") %&gt;% \n  set_mode(\"regression\")\n  \n\nWenn Sie sich fragen, woher Sie die Optionen f√ºr die Tuningparameter wissen sollen: Schauen Sie mal in die Hilfeseite des Pakets {{dials}}; das Paket ist Teil von Tidymodels.\nDie Berechnung des Modells l√§uft √ºber das Paket {{rpart}}, was wir durch set_engine() festgelegt haben.\nDer Parameter Cost Complexity, \\(C_p\\) oder manchmal auch mit \\(\\alpha\\) bezeichnet, hat einen typischen Wertebereich von \\(10^{-10}\\) bis \\(10^{-1}\\):\n\ncost_complexity()\n## Cost-Complexity Parameter (quantitative)\n## Transformer: log-10 [1e-100, Inf]\n## Range (transformed scale): [-10, -1]\n\nHier ist der Wert in Log-Einheiten angegeben. Wenn Sie sich fragen, woher Sie das bittesch√∂n wissen sollen: Naja, es steht auf der Hilfeseite üòÑ.\nUnser Modell ist also so definiert:\n\ntree_model\n## Decision Tree Model Specification (regression)\n## \n## Main Arguments:\n##   cost_complexity = tune()\n##   tree_depth = tune()\n##   min_n = tune()\n## \n## Computational engine: rpart\n\nMit tune() weist man den betreffenden Parameter als ‚Äúzu tunen‚Äù aus - gute Werte sollen durch Ausprobieren w√§hrend des Berechnens bestimmt werden. Genauer gesagt soll das Modell f√ºr jeden Wert (oder jede Kombination an Werten von Tuningparametern) berechnet werden.\nEine Kombination an Tuningparameter-Werten, die ein Modell spezifizieren, sozusagen erst ‚Äúfertig definieren‚Äù, nennen wir einen Modellkandidaten.\nDefinieren wir also eine Tabelle (grid) mit Werten, die ausprobiert, ‚Äúgetuned‚Äù werden sollen. Wir haben oben dre Tuningparameter bestimmt. Sagen wir, wir h√§tten gerne jeweils 5 Werte pro Parameter.\n\ntree_grid &lt;-\n  grid_regular(\n    cost_complexity(),\n    tree_depth(),\n    min_n(),\n    levels = 4\n  )\n\nF√ºr jeden Parameter sind Wertebereiche definiert; dieser Wertebereich wird gleichm√§√üig (daher grid regular) aufgeteilt; die Anzahl der verschiedenen Werte pro Parameter wird druch levels gegeben.\nMehr dazu findet sich auf der Hilfeseite zu grid_regular().\nWenn man die alle miteinander durchprobiert, entstehen \\(4^3\\) Kombinationen, also Modellkandidaten.\nAllgemeiner gesagt sind das bei \\(n\\) Tuningparametern mit jeweils \\(m\\) verschiedenen Werten \\(m^n\\) M√∂glichkeiten, spricht Modellkandidaten. Um diesen Faktor erh√∂ht sich die Rechenzeit im Vergleich zu einem Modell ohne Tuning. Man sieht gleich, dass die Rechenzeit schnell unangenehm lang werden kann.\nEntsprechend hat unsere Tabelle diese Zahl an Zeilen. Jede Zeile definiert einen Modellkandidaten, also eine Berechnung des Modells.\n\ndim(tree_grid)\n## [1] 64  3\n\n\nhead(tree_grid)\n\n\n\n  \n\n\n\nMan beachte, dass au√üer Definitionen bisher nichts passiert ist ‚Äì vor allem haben wir noch nichts berechnet. Sie scharren mit den Hufen? Wollen endlich loslegen? Also gut.\n\n10.7.5 Workflow definieren\nFast vergessen: Wir brauchen noch einen Workflow.\n\ntree_wf &lt;-\n  workflow() %&gt;% \n  add_model(tree_model) %&gt;% \n  add_recipe(recipe1)\n\n\n10.7.6 Modell tunen und berechnen\nAchtung: Das Modell zu berechnen kann etwas dauern. Es kann daher Sinn machen, das Modell abzuspeichern, so dass Sie beim erneuten Durchlaufen nicht nochmal berechnen m√ºssen, sondern einfach von der Festplatte laden k√∂nnen; das setzt nat√ºrlich voraus, dass sich am Modell nichts ge√§ndert hat.\n\ndoParallel::registerDoParallel()  # mehrere Kerne parallel nutzen\n\nset.seed(42)\ntic()  # Stoppuhr an\ntrees_tuned &lt;-\n  tune_grid(\n    object = tree_wf,\n    grid = tree_grid,\n    resamples = d_cv\n  )\ntoc()  # Stoppuhr aus\n\nEs bietet sich vielleicht in dem Fall an, das Ergebnis-Objekt als R Data serialized (rds) abzuspeichern:\n\nwrite_rds(trees_tuned, \"objects/trees1.rds\")\n\nBzw. so wieder aus der RDS-Datei zu importieren:\n\ntrees_tuned &lt;- read_rds(\"objects/trees1.rds\")\n\n\n\n\n\n\n\nHinweis\n\n\n\nDas Zwischenspeichern von Modellobjekten ist praktisch, weil es Rechenzeit spart. Allerdings hat es auch Nachteile: Wenn Sie Ihre Modellspezifikation √§ndern, m√ºssen Sie auch Ihr gespeichertes Modell aktualisieren. Das vergisst man leicht. Dann hat man falsche Ergebnisse und man wird nicht durch eine Fehlermeldung gewarnt.\n\n\nHier oder hier kann man einiges zum Unterschied einer RDS-Datei vs.¬†einer ‚Äúnormalen‚Äù R-Data-Datei nachlesen. Wenn man m√∂chte üòâ.\n\ntrees_tuned\n\n\n\n  \n\n\n\nDie Warnhinweise kann man sich so ausgeben lassen:\n\ncollect_notes(trees_tuned)\n\n\n\n  \n\n\n\nWie gesagt, in diesem Fall war die Stichprobengr√∂√üe sehr klein.\n\n10.7.7 Modellg√ºte evaluieren\n\ncollect_metrics(trees_tuned)\n\n\n\n  \n\n\n\nPraktischerweise gibt es eine Autoplot-Funktion, um die besten Modellparameter auszulesen:\n\nautoplot(trees_tuned)\n\n\n\n\n\n10.7.8 Bestes Modell ausw√§hlen\nAus allen Modellkandidaten w√§hlen wir jetzt das beste Modell aus:\n\nselect_best(trees_tuned)\n\n\n\n  \n\n\n\nMit diesem besten Kandidaten definieren wir jetzt das ‚Äúfinale‚Äù Modell, wir ‚Äúfinalisieren‚Äù das Modell mit den besten Modellparametern:\n\ntree_final &lt;-\n  finalize_model(tree_model, parameters = select_best(trees_tuned))\n\ntree_final\n## Decision Tree Model Specification (regression)\n## \n## Main Arguments:\n##   cost_complexity = 1e-04\n##   tree_depth = 5\n##   min_n = 2\n## \n## Computational engine: rpart\n\nHier ist, unser finaler Baum üå≥.\nSchlie√ülich updaten wir mit dem finalen Baum noch den Workflow:\n\nfinal_wf &lt;-\n  tree_wf %&gt;% \n  update_model(tree_final)\n\n\n10.7.9 Final Fit\nJetzt fitten wir dieses Modell auf das ganze Train-Sample und predicten auf das Test-Sample:\n\ntree_fit_final &lt;-\n  final_wf %&gt;% \n  last_fit(d_split)\n\ntree_fit_final\n\n\n\n  \n\n\n\n\ncollect_metrics(tree_fit_final)\n\n\n\n  \n\n\n\nVoil√†: Die Modellg√ºte f√ºr das Test-Sample: Im Schnitt liegen wir ca. 4 Meilen daneben mit unseren Vorhersagen, wenn wir RMSE mal so locker interpretieren wollen.\nIn der Regel ist √ºbrigens RMSE interessanter als R-Quadrat, da R-Quadrat die G√ºte eines Korrelationsmusters vorhersagt, aber RMSE die Pr√§zision der Vorhersage, also sozusagen die K√ºrze der Fehlerbalken.\n\n10.7.10 Nur zum Spa√ü: Vergleich mit linearem Modell\nEin einfaches lineares Modell, was h√§tte das jetzt wohl f√ºr eine Modellg√ºte?\n\nlm_model &lt;-\n  linear_reg()\n\n\nlm_wf &lt;-\n  workflow() %&gt;% \n  add_model(lm_model) %&gt;% \n  add_recipe(recipe1)\n\n\ntic()\nlm_fit &lt;-\n  fit_resamples(\n    lm_wf,\n    resamples = d_cv\n  )\ntoc()\n## 10.873 sec elapsed\n\n\ncollect_metrics(lm_fit)\n\n\n\n  \n\n\n\n\nlm_fit_final &lt;- \n  last_fit(lm_wf, d_split)\n\nWie pr√§zise ist die Vorhersage im Test-Sample?\n\ncollect_metrics(lm_fit_final)\n\n\n\n  \n\n\n\nDas lineare Modell schneidet etwas (deutlich?) schlechter ab als das einfache Baummodell.\nMan beachte, dass die Modellg√ºte im Train-Samle h√∂her ist als im Test-Sample (Overfitting)."
  },
  {
    "objectID": "100-baeume.html#vertiefung",
    "href": "100-baeume.html#vertiefung",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.8 Vertiefung",
    "text": "10.8 Vertiefung\n\nVisualisierung des ML-Ablaufs am Beispiel des Entscheidungsbaums, Teil 1\nVisualisierung des ML-Ablaufs am Beispiel des Entscheidungsbaums, Teil 2"
  },
  {
    "objectID": "100-baeume.html#aufgaben",
    "href": "100-baeume.html#aufgaben",
    "title": "\n10¬† Entscheidungsb√§ume\n",
    "section": "\n10.9 Aufgaben",
    "text": "10.9 Aufgaben\n\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications."
  },
  {
    "objectID": "110-ensemble.html#lernsteuerung",
    "href": "110-ensemble.html#lernsteuerung",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.1 Lernsteuerung",
    "text": "11.1 Lernsteuerung\n\n11.1.1 Lernziele\n\nSie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest\nSie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann\nSie k√∂nnen diese Verfahren in R berechnen\n\n11.1.2 Literatur\n\nRhys, Kap. 8"
  },
  {
    "objectID": "110-ensemble.html#vorbereitung",
    "href": "110-ensemble.html#vorbereitung",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.2 Vorbereitung",
    "text": "11.2 Vorbereitung\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung\nlibrary(vip)  # Variable importance plot\nlibrary(readr)  # read_rds"
  },
  {
    "objectID": "110-ensemble.html#hinweise-zur-literatur",
    "href": "110-ensemble.html#hinweise-zur-literatur",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.3 Hinweise zur Literatur",
    "text": "11.3 Hinweise zur Literatur\nDie folgenden Ausf√ºhrungen basieren prim√§r auf Rhys (2020), aber auch auf James u.¬†a. (2021) und (weniger) Kuhn und Johnson (2013)."
  },
  {
    "objectID": "110-ensemble.html#wir-brauchen-einen-wald",
    "href": "110-ensemble.html#wir-brauchen-einen-wald",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.4 Wir brauchen einen Wald",
    "text": "11.4 Wir brauchen einen Wald\nEin Pluspunkt von Entscheidungsb√§umen ist ihre gute Interpretierbarkeit. Man k√∂nnte behaupten, dass B√§ume eine typische Art des menschlichen Entscheidungsverhalten nachahmen: ‚ÄúWenn A, dann tue B, ansonsten tue C‚Äù (etc.). Allerdings: Einzelne Entscheidungsb√§ume haben oft keine so gute Prognosegenauigkeit. Der oder zumindest ein Grund ist, dass sie (zwar wenig Bias aber) viel Varianz aufweisen. Das sieht man z.B. daran, dass die Vorhersagegenauigkeit stark schwankt, w√§hlt man eine andere Aufteilung von Train- vs.¬†Test-Sample. Anders gesagt: B√§ume overfitten ziemlich schnell. Und obwohl das No-Free-Lunch-Theorem zu den Grundfesten des maschinellen Lernens (oder zu allem wissenschaftlichen Wissen) geh√∂rt, kann man festhalten, dass sog. Ensemble-Lernen fast immer besser sind als einzelne Baummodelle. Kurz gesagt: Wir brauchen einen Wald: üå≥üå≥üå≥.1"
  },
  {
    "objectID": "110-ensemble.html#was-ist-ein-ensemble-lerner",
    "href": "110-ensemble.html#was-ist-ein-ensemble-lerner",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.5 Was ist ein Ensemble-Lerner?",
    "text": "11.5 Was ist ein Ensemble-Lerner?\nEnsemble-Lerner kombinieren mehrere schwache Lerner zu einem starken Lerner. Das Paradebeispiel sind baumbasierte Modelle; darauf wird sich die folgende Ausf√ºhrung auch begrenzen. Aber theoretisch kann man jede Art von Lerner kombinieren. Bei numerischer Pr√§diktion wird bei Ensemble-Lerner zumeist der Mittelwert als Optmierungskriterium herangezogen; bei Klassifikation (nominaler Pr√§diktion) hingegen die modale Klasse (also die h√§ufigste). Warum hilft es, mehrere Modelle (Lerner) zu einem zu aggregieren? Die Antwort lautet, dass die Streuung der Mittelwerte sinkt, wenn die Stichprobengr√∂√üe steigt. Zieht man Stichproben der Gr√∂√üe 1, werden die Mittelwerte stark variieren, aber bei gr√∂√üeren Stichproben (z.B. Gr√∂√üe 100) deutlich weniger2. Die Streuung der Mittelwerte in den Stichproben nennt man bekanntlich Standardefehler (se). Den se des Mittelwerts (\\(se_M\\)) f√ºr eine normalverteilte Variable \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\) gilt: \\(se_{M} = \\sigma / \\sqrt(n)\\), wobei \\(\\sigma\\) die SD der Verteilung und \\(\\mu\\) den Erwartungswert (‚ÄúMittelwert‚Äù) meint, und \\(n\\) ist die Stichprobengr√∂√üe.\n\n\n\n\n\n\nHinweis\n\n\n\nJe gr√∂√üer die Stichprobe, desto kleiner die Varianz des Sch√§tzers (ceteris paribus). Anders gesagt: Gr√∂√üere Stichproben sch√§tzen genauer als kleine Stichproben.\n\n\nAus diesem Grund bietet es sich an, schwache Lerner mit viel Varianz zu kombinieren, da die Varianz so verringert wird."
  },
  {
    "objectID": "110-ensemble.html#bagging",
    "href": "110-ensemble.html#bagging",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.6 Bagging",
    "text": "11.6 Bagging\n\n11.6.1 Bootstrapping\nDas erste baumbasierte Modell, was vorgestellt werden soll, basiert auf sog. Bootstrapping, ein Standardverfahren in der Statistik (James u.¬†a. 2021).\nBootstrapping ist eine Nachahmung f√ºr folgende Idee: H√§tte man viele Stichproben aus der relevanten Verteilung, so k√∂nnte man z.B. die Genauigkeit eines Modells \\(\\hat{f}_{\\bar{X}}\\) zur Sch√§tzung des Erwartungswertes \\(\\mu\\) einfach dadurch bestimmen, indem man se berechnet, also die Streuung der Mitterwerte \\(\\bar{X}\\) berechnet. Au√üerdem gilt, dass die Pr√§zision der Sch√§tzung des Erwartungswerts steigt mit steigendem Stichprobenumfang \\(n\\). Wir k√∂nnten also f√ºr jede der \\(B\\) Stichproben, \\(b=1,\\ldots, B\\), ein (Baum-)Modell berechnen, \\(\\hat{f}^b\\), und dann deren Vorhersagen aggregieren (zum Mittelwert oder Modalwert). Das kann man formal so darstellen (James u.¬†a. 2021):\n\\[\\hat{f}_{\\bar{X}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^b\\]\nMit diesem Vorgehen kann die Varianz des Modells \\(\\hat{f}_{\\bar{X}}\\) verringert werden; die Vorhersagegenauigkeit steigt.\nLeider haben wir in der Regel nicht viele (\\(B\\)) Datens√§tze.\nDaher ‚Äúbauen‚Äù wir uns aus dem einzelnen Datensatz, der uns zur Verf√ºgung steht, viele Datens√§tze. Das h√∂rt sich nach ‚Äútoo good to be true‚Äù an3 Weil es sich unglaubw√ºrdig anh√∂rt, nennt man das entsprechende Verfahren (gleich kommt es!) auch ‚ÄúM√ºnchhausen-Methode‚Äù, nach dem ber√ºhmten L√ºbgenbaron. Die Amerikaner ziehen sich √ºbrigens nicht am Schopf aus dem Sumpf, sondern mit den Stiefelschlaufen (die Cowboys wieder), daher spricht man im Amerikanischen auch von der ‚ÄúBoostrapping-Methode‚Äù.\nDiese ‚ÄúPseudo-Stichproben‚Äù oder ‚ÄúBootstrapping-Stichproben‚Äù sind aber recht einfach zu gewinnen.. Gegeben sei Stichprobe der Gr√∂√üe \\(n\\):\n\nZiehe mit Zur√ºcklegen (ZmZ) aus der Stichprobe \\(n\\) Beobachtungen\nFertig ist die Bootstrapping-Stichprobe.\n\nAbbildung¬†11.1 verdeutlicht das Prinzip des ZMZ, d.h. des Bootstrappings. Wie man sieht, sind die Bootstrap-Stichproben (rechts) vom gleichen Umfang \\(n\\) wie die Originalstichprobe (links). Allerdins kommen nicht alle F√§lle (in der Regel) in den ‚ÄúBoostrap-Beutel‚Äù (in bag), sondern einige F√§lle werden oft mehrfach gezogen, so dass einige F√§lle nicht gezogen werden (out of bag).\n\n\n\n\nAbbildung¬†11.1: Bootstrapping: Der Topf links symbolisiert die Original-Stichprobe, aus der wir hier mehrere ZMZ-Stichproben ziehen (Rechts), dargestellt mit ‚Äòin bag‚Äô\n\n\n\n\nMan kann zeigen, dass ca. 2/3 der F√§lle gezogen werden, bzw. ca. 1/3 nicht gezogen werden. Die nicht gezogenen F√§lle nennt man auch out of bag (OOB).\nF√ºr die Entwicklung des Bootstrapping wurde der Autor, Bradley Efron, im Jahr 2018 mit dem internationalen Preis f√ºr Statistik ausgezeichnet;\n\n‚ÄúWhile statistics offers no magic pill for quantitative scientific investigations, the bootstrap is the best statistical pain reliever ever produced,‚Äù says Xiao-Li Meng, Whipple V. N. Jones Professor of Statistics at Harvard University.‚Äú"
  },
  {
    "objectID": "110-ensemble.html#bagging-algorithmus",
    "href": "110-ensemble.html#bagging-algorithmus",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.7 Bagging-Algorithmus",
    "text": "11.7 Bagging-Algorithmus\nBagging, die Kurzform f√ºr Bootstrap-Aggregation ist wenig mehr als die Umsetzung des Boostrappings.\nDer Algorithmus von Bagging kann so beschrieben werden:\n\nW√§hle \\(B\\), die Anzahl der Boostrap-Stichproben und damit auch Anzahl der Submodelle (Lerner)\nZiehe \\(B\\) Boostrap-Stichproben\nBerechne das Modell \\(\\hat{f}^{*b}\\) f√ºr jede der \\(B\\) Stichproben (typischerweise ein einfacher Baum)\nSchicke die Test-Daten durch jedes Sub-Modell\nAggregiere ihre Vorhersage zu einem Wert (Modus bzw. Mittelwert) pro Fall aus dem Test-Sample, zu \\(\\hat{f}_{\\text{bag}}\\)\n\n\nAnders gesagt:\n\\[\\hat{f}_{\\text{bag}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^{*b}\\]\nDer Bagging-Algorithmus ist in Abbildung Abbildung¬†11.2 dargestellt.\n\n\n\n\nflowchart LR\n  D[Datensatz] --&gt; B1[Baum 1] --&gt; M[Modus als Vorhersagewert]\n  D--&gt;B2[Baum 2] --&gt; M\n  D--&gt;B3[Baum ...]---&gt;M\n  D--&gt;B4[Baum B]---&gt;M\n\n\nAbbildung¬†11.2: Bagging schematisch illustriert\n\n\n\n\nDie Anzahl der B√§ume (allgemeiner: Submodelle) \\(B\\) ist h√§ufig im oberen drei- oder niedrigem vierstelligen Bereich, z.B. \\(B=1000\\). Eine gute Nachricht ist, dass Bagging nicht √ºberanpasst, wenn \\(B\\) gro√ü wird.\n\n11.7.1 Variablenrelevanz\nMan kann die Relevanz der Pr√§diktoren in einem Bagging-Modell auf mehrere Arten sch√§tzen. Ein Weg (bei numerischer Pr√§diktion) ist, dass man die RSS-Verringerung, die durch Aufteilung anhand eines Pr√§diktors erzeugt wird, mittelt √ºber alle beteiligten B√§ume (Modelle). Bei Klassifikation kann man die analog die Reduktion des Gini-Wertes √ºber alle B√§ume mitteln und als Sch√§tzwert f√ºr die Relevanz des Pr√§diktors heranziehen.\n\n11.7.2 Out-of-Bag-Vorhersagen\nDa nicht alle F√§lle der Stichprobe in das Modell einflie√üen (sondern nur ca. 2/3), kann der Rest der F√§lle zur Vorhersage genutzt werden. Bagging erzeugt sozusagen innerhalb der Stichprobe selbst√§ndig ein Train- und ein Test-Sample. Man spricht von Out-of-Bag-Sch√§tzung (OOB-Sch√§tzung). Der OOB-Fehler (z.B. MSE bei numerischen Modellen und Genauigkeit bei nominalen) ist eine valide Sch√§tzung des typischen Test-Sample-Fehlers.\nHat man aber Tuningparameter, so wird man dennoch auf die typische Train-Test-Aufteilung zur√ºckgreifen, um Overfitting durch das Ausprobieren der Tuning-Kandidaten zu vermeiden (was sonst zu Zufallstreffern f√ºhren w√ºrde bei gen√ºgend vielen Modellkandidaten)."
  },
  {
    "objectID": "110-ensemble.html#random-forests",
    "href": "110-ensemble.html#random-forests",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.8 Random Forests",
    "text": "11.8 Random Forests\nRandom Forests (‚ÄúZufallsw√§lder‚Äù) sind eine Weiterentwicklung von Bagging-Modellen. Sie sind Bagging-Modelle, aber haben noch ein Ass im √Ñrmel: Und zwar wird an jedem Slit (Astgabel, Aufteilung) nur eine Zufallsauswahl an \\(m\\) Pr√§diktoren ber√ºcksichtigt. Das h√∂rt sich verr√ºckt an: ‚ÄúWie, mit weniger Pr√§diktoren soll eine bessere Vorhersage erreicht werden?!‚Äù Ja, genau so ist es! Nehmen Sie an, es gibt im Datensatz einen sehr starken und ein paar mittelstarke Pr√§diktoren; der Rest der Pr√§diktoren ist wenig relevant. Wenn Sie jetzt viele ‚Äúgebootstrapte‚Äù4 ziehen, werden diese B√§ume sehr √§hnlich sein: Der st√§rkste Pr√§diktor steht vermutlich immer ob an der Wurzel, dann kommen die mittelstarken Pr√§diktoren. Jeder zus√§tzliche Baum tr√§gt dann wenig neue Information bei. Anders gesagt: Die Vorhersagen der B√§ume sind dann sehr √§hnlich bzw. hoch korreliert. Bildet man den Mittelwert von hoch korrelierten Variablen, verringert sich leider die Varianzu nur wenig im Vergleich zu nicht oder gering korrelierten Variablen (James u.¬†a. 2021). Dadurch dass Random Forests nur \\(m\\) der \\(p\\) Pr√§diktoren pro Split zulassen, werden die B√§ume unterschiedlicher. Wir ‚Äúdekorrelieren‚Äù die B√§ume. Bildet man den Mittelwert von gering(er) korrelierten Variablen, so ist die Varianzreduktion h√∂her - und die Vohersage genauer. L√§sst man pro Split \\(m=p\\) Pr√§diktoren zu, so gleicht Bagging dem Random Forest. Die Anzahl \\(m\\) der erlaubten Pr√§diktoren werden als Zufallstichprobe aus den \\(p\\) Pr√§diktoren des Datensatzes gezogen (ohne Zur√ºcklegen). \\(m\\) ist ein Tuningparameter; \\(m=\\sqrt(p)\\) ist ein beliebter Startwert. In den meisten Implementationen wird \\(m\\) mit mtry bezeichnet (so auch in Tidymodels).\nDer Random-Forest-Algorithmus ist in Abbildung¬†11.3 illustriert.\n\n\n\nAbbildung¬†11.3: Zufallsw√§lder durch Ziehen mit Zur√ºcklegen (zmz) und Ziehen ohne Zur√ºcklegen (ZoZ)\n\n\n\nAbbildung¬†11.4 vergleicht die Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen aus James u.¬†a. (2021). In diesem Fall ist die Vorhersageg√ºte deutlich unter der OOB-G√ºte; laut James u.¬†a. (2021) ist dies hier ‚ÄúZufall‚Äù.\n\n\n\n\nAbbildung¬†11.4: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen\n\n\n\n\nDen Effekt von \\(m\\) (Anzahl der Pr√§diktoren pro Split) ist in Abbildung¬†11.5 dargestellt (James u.¬†a. 2021). Man erkennt, dass der Zusatznutzen an zus√§tzlichen B√§umen, \\(B\\), sich abschw√§cht. \\(m=\\sqrt{p}\\) schneidet wie erwartet am besten ab.\n\n\n\n\nAbbildung¬†11.5: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen"
  },
  {
    "objectID": "110-ensemble.html#boosting",
    "href": "110-ensemble.html#boosting",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.9 Boosting",
    "text": "11.9 Boosting\nIm Unterschied zu Bagging und Random-Forest-Modellen wird beim Boosting der ‚ÄúWald‚Äù sequenziell entwickelt, nicht gleichzeitig wie bei den anderen vorgestellten ‚ÄúWald-Modellen‚Äù. Die zwei bekanntesten Implementierungen bzw. Algorithmus-Varianten sind AdaBoost und XGBoost. Gerade XGBoost hat den Ruf, hervorragende Vorhersagen zu leisten. Auf Kaggle gewinnt nach einigen Berichten oft XGBoost. Nur neuronale Netze schneiden besser ab. Random-Forest-Modelle kommen nach diesem Bereich auf Platz 3. Allerdings ben√∂tigen neuronale Netzen oft riesige Stichprobengr√∂√üen und bei spielen ihre Nuanciertheit vor allem bei komplexen Daten wie Bildern oder Sprache aus. F√ºr ‚Äúrechteckige‚Äù Daten (also aus einfachen, normalen Tabellen) wird ein baumbasiertes Modell oft besser abschneiden.\nDie Idee des Boosting ist es, anschaulich gesprochen, aus Fehlern zu lernen: Fitte einen Baum, schau welche F√§lle er schlecht vorhergesagt hat, konzentriere dich beim n√§chsten Baum auf diese F√§lle und so weiter.\nWie andere Ensemble-Methoden auch kann Boosting theoretisch f√ºr beliebige Algorithmen eingesetzt werden. Es macht aber Sinn, Boosting bei ‚Äúschwachen Lernern‚Äù einzusetzen. Typisches Beispiel ist ein einfacher Baum; ‚Äúeinfach‚Äù soll hei√üen, der Baum hat nur wenig Gabeln oder vielleicht sogar nur eine einzige. Dann spricht man von einem Stumpf, was intuitiv gut passt.\n\n11.9.1 AdaBoost\nDer AdaBoost-Algorithmus funktioniert, einfach dargestellt, wie folgt. Zuerst hat jeder Fall \\(i\\) im Datensatz des gleiche Gewicht. Die erste (und alle weiteren) Stichprobe werden per Bootstrapping aus dem Datensatz gezogen. Dabei ist die Wahrscheinlichkeit, gezogen zu werden, proportional zum Gewicht des Falles, \\(w_i\\). Da im ersten Durchgang die Gewichte identisch sind, haben zun√§chst alle F√§lle die gleiche Wahrscheinlichkeit, in das Bootstrap-Sample gezogen zu werden. Die B√§ume bei AdaBoost sind eigentlich nur ‚ÄúSt√ºmpfe‚Äù: Sie bestehen aus einem einzelnen Split, s. Abbildung¬†11.6.\n\n\n\n\nflowchart LR\n  root --&gt; leaf1\n  root --&gt; leaf2\n\n\nAbbildung¬†11.6: Ein Baumstumpf bei AdaBoost\n\n\n\n\nNach Berechnung des Baumes und der Vorhersagen werden die richtig klassifizierten F√§lle heruntergewichtet und die falsch klassifizierten F√§lle hoch gewichtet, also st√§rker gewichtet (bleiben wir aus Gr√ºnden der Einfachheit zun√§chst bei der Klassifikation). Dieses Vorgehen folgt dem Gedanken, dass man sich seine Fehler genauer anschauen muss, die falsch klassifizierten F√§lle sozusagen mehr Aufmerksamkeit bed√ºrfen. Das n√§chste (zweite) Modell zieht ein weiteres Bootstrap-Sample. Jetzt sind allerdings die Gewichte schon angepasst, so dass mehr F√§lle, die im vorherigen Modell falsch klassifiziert wurden, in den neuen (zweiten) Baum gezogen werden. Das neue Modell hat also bessere Chancen, die Aspekte, die das Vorg√§nger-Modell √ºbersah zu korrigieren bzw. zu lernen. Jetzt haben wir zwei Modelle. Die k√∂nnen wir aggregieren, genau wie beim Bagging: Der Modus der Vorhersage √ºber alle (beide) B√§ume hinwig ist dann die Vorhersage f√ºr einen bestimmten Fall (‚ÄúFall‚Äù und ‚ÄúBeobachtung‚Äù sind stets synonym f√ºr \\(y_i\\) zu verstehen). So wiederholt sich das Vorgehen f√ºr \\(B\\) B√§ume: Die Gewichte werden angepasst, das neue Modell wird berechnet, alle Modelle machen ihre Vorhersagen, per Mehrheitsbeschluss - mit gewichteten Modellen - wird die Vorhersage bestimmt pro Fall. Irgendwann erreichen wir die vorab definierte Maximalzahl an B√§umen, \\(B\\), und das Modell kommt zu einem Ende.\nDa das Modell die Fehler seiner Vorg√§nger reduziert, wird der Bias im Gesamtmodell verringert. Da wir gleichzeitig auch Bagging vornehmen, wird aber die Varianz auch verringert. Klingt schon wieder (fast) nach Too-Good-to-be-True!\nDas Gewicht \\(w_i^b\\) des \\(i\\)ten Falls im \\(b\\)ten Modell von \\(B\\) berechnet sich wie folgt (Rhys 2020):\n\\[ w_i^b = \\begin{cases}\nw_i^{b-1} \\cdot e^{-\\text{model weight}} \\qquad \\text{wenn korrekt klassifiziert} \\\\\nw_i^{b-1} \\cdot e^{\\text{model weight}} \\qquad \\text{wenn inkorrekt klassifiziert} \\\\\n\\end{cases}\\]\nDas Modellgewicht \\(mw\\) berechnet sich dabei so (Rhys 2020):\n\\[mw_b = 0.5 \\cdot log\\left( \\frac{1-p(\\text{inkorrect})}{p(\\text{korrekt})} \\right) \\propto \\mathcal{L(p)} \\]\n\\(p(\\cdot)\\) ist der Anteil (Wahrscheinlichkeit) einer Vorhersage.\nDas Modellgewicht ist ein Faktor, der schlechtere Modelle bestraft. Das folgt dem Gedanken, dass schlechteren Modellen weniger Geh√∂rt geschenkt werden soll, aber schlecht klassifizierten F√§llen mehr Geh√∂r.\nDas Vorgehen von AdaBoost ist in Abbildung¬†11.7 illustriert.\n\n\n\nAbbildung¬†11.7: AdaBoost illustriert\n\n\n\n\n11.9.2 XGBoost\nXGBoost ist ein Gradientenverfahren, eine Methode also, die die Richtung des parziellen Ableitungskoeffizienten als Optimierungskriterium heranzieht. XGBoost ist √§hnlich zu AdaBoost, nur dass Residuen modelliert werden, nicht \\(y\\). Die Vorhersagefehler von \\(\\hat{f}^b\\) werden die Zielvariable von \\(\\hat{f}^{b+1}\\). Ein Residuum ist der Vorhersagefehler, bei metrischen Modellen etwa RMSE, oder schlicht \\(r_i = y_i - \\hat{y}_i\\). Details finden sich z.B. hier, dem Original XGBoost-Paper (Chen und Guestrin 2016).\nDie hohe Vorhersageg√ºte von Boosting-Modellen ist exemplarisch in Abbildung¬†11.8 dargestellt (James u.¬†a. 2021, 358ff). Allerdings verwenden die Autoren Friedmans (2001) Gradient Boosting Machine, eine weitere Variante des Boosting .\n\n\n\n\nAbbildung¬†11.8: Vorhersageg√ºte von Boosting und Random Forest"
  },
  {
    "objectID": "110-ensemble.html#tidymodels",
    "href": "110-ensemble.html#tidymodels",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.10 Tidymodels",
    "text": "11.10 Tidymodels\n\n11.10.1 Datensatz Churn\nWir betrachten einen Datensatz zur Kundenabwanderung (Churn) aus dieser Quelle.\n\nknitr::opts_chunk$set(echo = TRUE)\n\nDie Daten habe ich von dieser Quelle heruntergeladen.\n\nchurn_df &lt;- read_rds('data/churn_data.rds')\n\nEin Blick in die Daten, s. Tabelle¬†11.1\n\nchurn_df %&gt;% \n  head() %&gt;% \n  gt::gt()\n\n\n\n\n\n\nTabelle¬†11.1: Churn-Datensatz\n\ncanceled_service\nenrollment_discount\nspouse_partner\ndependents\nphone_service\ninternet_service\nonline_security\nonline_backup\ndevice_protection\ntech_support\nstreaming_tv\nstreaming_movies\ncontract\npaperless_bill\npayment_method\nmonths_with_company\nmonthly_charges\nlate_payments\n\n\n\nyes\nno\nno\nno\nmultiple_lines\nfiber_optic\nyes\nyes\nyes\nno\nno\nno\none_year\nno\ncredit_card\n30\n51.01440\n3\n\n\nyes\nno\nyes\nyes\nmultiple_lines\nfiber_optic\nno\nyes\nyes\nyes\nyes\nno\ntwo_year\nyes\nelectronic_check\n39\n80.42466\n4\n\n\nyes\nyes\nno\nno\nsingle_line\nfiber_optic\nno\nno\nno\nno\nyes\nyes\nmonth_to_month\nyes\nmailed_check\n1\n75.88737\n3\n\n\nyes\nno\nyes\nyes\nsingle_line\nfiber_optic\nyes\nno\nno\nno\nyes\nno\ntwo_year\nno\ncredit_card\n29\n81.96467\n3\n\n\nyes\nyes\nno\nno\nsingle_line\ndigital\nno\nno\nno\nno\nyes\nyes\nmonth_to_month\nyes\nbank_draft\n9\n101.34257\n5\n\n\nyes\nno\nyes\nno\nsingle_line\nfiber_optic\nyes\nyes\nno\nyes\nyes\nyes\nmonth_to_month\nno\nmailed_check\n14\n72.01285\n4\n\n\n\n\n\n\n\n\n\n11.10.2 Data Splitting und CV\nDas Kreuzvalidieren (CV) fassen wir auch unter diesen Punkt.\n\nchurn_split &lt;- initial_split(churn_df, prop = 0.75, \n                             strata = canceled_service)\n\nchurn_training &lt;- churn_split %&gt;% training()\n\nchurn_test &lt;- churn_split %&gt;% testing()\n\nchurn_folds &lt;- vfold_cv(churn_training, v = 5)\n\n\n11.10.3 Feature Engineering\nHier definieren wir zwei Rezepte. Gleichzeitig ver√§ndern wir die Pr√§diktoren (normalisieren, dummysieren, ‚Ä¶). Das nennt man auch Feature Engineering.\n\nchurn_recipe1 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% \n                       step_normalize(all_numeric(), -all_outcomes()) %&gt;% \n                       step_dummy(all_nominal(), -all_outcomes())\n\nchurn_recipe2 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% \n                       step_YeoJohnson(all_numeric(), -all_outcomes()) %&gt;% \n                       step_normalize(all_numeric(), -all_outcomes()) %&gt;% \n                       step_dummy(all_nominal(), -all_outcomes())\n\nstep_YeoJohnson() reduziert Schiefe in der Verteilung.\n\n11.10.4 Modelle\n\ntree_model &lt;- decision_tree(cost_complexity = tune(),\n                            tree_depth = tune(),\n                            min_n = tune()) %&gt;% \n              set_engine('rpart') %&gt;% \n              set_mode('classification')\n\nrf_model &lt;- rand_forest(mtry = tune(),\n                        trees = tune(),\n                        min_n = tune()) %&gt;% \n            set_engine('ranger') %&gt;% \n            set_mode('classification')\n\n\nboost_model &lt;- boost_tree(mtry = tune(),\n                        min_n = tune(),\n                        trees = tune()) %&gt;% \n  set_engine(\"xgboost\", nthreads = parallel::detectCores()) %&gt;% \n  set_mode(\"classification\")\n\n\nglm_model &lt;- logistic_reg()\n\n\n11.10.5 Workflows\nWir definieren ein Workflow-Set:\n\npreproc &lt;- list(rec1 = churn_recipe1, rec2 = churn_recipe2)\nmodels &lt;- list(tree1 = tree_model, rf1 = rf_model, boost1 = boost_model, glm1 = glm_model)\n \n \nall_workflows &lt;- workflow_set(preproc, models)\n\nInfos zu workflow_set bekommt man wie gewohnt mit ?workflow_set.\nIm Standard werden alle Rezepte und Modelle miteinander kombiniert (cross = TRUE), also preproc * models Modelle gefittet.\n\n11.10.6 Modelle berechnen mit Tuning, einzeln\nWir k√∂nnten jetzt jedes Modell einzeln tunen, wenn wir wollen.\n\n11.10.6.1 Baum\n\ntree_wf &lt;-\n  workflow() %&gt;% \n  add_model(tree_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\ntree_fit &lt;-\n  tree_wf %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, yardstick::spec)\n    )\ntoc()\n## 20.261 sec elapsed\n\nIm Standard werden 10 Modellkandidaten getuned.\n\ntree_fit\n\n\n\n  \n\n\n\nSchauen wir uns das Objekt etwas n√§her an:\n\ntree_fit$.metrics[[1]]\n\n\n\n  \n\n\n\n30 Zeilen: 3 G√ºtemetriken (Sens, Spec, ROC AUC) mit je 10 Werten (Submodellen), gibt 30 Koeffizienten.\nF√ºr jeden der 5 Faltungen haben wir also 10 Submodelle.\nWelches Modell ist das beste?\n\nshow_best(tree_fit)\n\n\n\n  \n\n\n\nAha, das sind die f√ºnf besten Modelle, bzw. ihre Tuningparameter, ihre mittlere G√ºte zusammen mit dem Standardfehler.\n\nautoplot(tree_fit)\n\n\n\n\n\n11.10.6.2 RF\nWas f√ºr Tuningparameter hat den der Algorithmus bzw. seine Implementierung?\n\nshow_model_info(\"rand_forest\")\n## Information for `rand_forest`\n##  modes: unknown, classification, regression, censored regression \n## \n##  engines: \n##    classification: randomForest, ranger¬π, spark\n##    regression:     randomForest, ranger¬π, spark\n## \n## ¬πThe model can use case weights.\n## \n##  arguments: \n##    ranger:       \n##       mtry  --&gt; mtry\n##       trees --&gt; num.trees\n##       min_n --&gt; min.node.size\n##    randomForest: \n##       mtry  --&gt; mtry\n##       trees --&gt; ntree\n##       min_n --&gt; nodesize\n##    spark:        \n##       mtry  --&gt; feature_subset_strategy\n##       trees --&gt; num_trees\n##       min_n --&gt; min_instances_per_node\n## \n##  fit modules:\n##          engine           mode\n##          ranger classification\n##          ranger     regression\n##    randomForest classification\n##    randomForest     regression\n##           spark classification\n##           spark     regression\n## \n##  prediction modules:\n##              mode       engine                    methods\n##    classification randomForest           class, prob, raw\n##    classification       ranger class, conf_int, prob, raw\n##    classification        spark                class, prob\n##        regression randomForest               numeric, raw\n##        regression       ranger     conf_int, numeric, raw\n##        regression        spark                    numeric\n\nDa die Berechnung einiges an Zeit braucht, kann man das (schon fr√ºher einmal berechnete) Ergebnisobjekt von der Festplatte lesen (sofern es existiert). Ansonsten berechnet man neu:\n\nif (file.exists(\"objects/rf_fit1.rds\")){\n  rf_fit1 &lt;- read_rds(\"objects/rf_fit1.rds\")\n} else {\nrf_wf1 &lt;-\n  workflow() %&gt;% \n  add_model(rf_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\nrf_fit1 &lt;-\n  rf_wf1 %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, spec)\n    )\ntoc()\n}\n\nSo kann man das berechnete Objekt abspeichern auf Festplatte, um k√ºnftig Zeit zu sparen5:\n\nwrite_rds(rf_fit1, file = \"objects/rf_fit1.rds\")\n\n\nrf_fit1\n\n\n\n  \n\n\n\n\nshow_best(rf_fit1)\n\n\n\n  \n\n\n\n\n11.10.6.3 XGBoost\n\nboost_wf1 &lt;-\n  workflow() %&gt;% \n  add_model(boost_model) %&gt;% \n  add_recipe(churn_recipe1)\n\n\ntic()\nboost_fit1 &lt;-\n  boost_wf1 %&gt;% \n  tune_grid(\n    resamples = churn_folds,\n    metrics =  metric_set(roc_auc, sens, spec)\n    )\ntoc()\n\nWieder auf Festplatte speichern:\n\nwrite_rds(boost_fit1, file = \"objects/boost_fit1.rds\")\n\nUnd so weiter.\n\n11.10.7 Workflow-Set tunen\n\nif (file.exists(\"objects/churn_model_set.rds\")) {\n  churn_model_set &lt;- read_rds(\"objects/churn_model_set.rds\")\n} else {\n  tic()\n  churn_model_set &lt;-\n    all_workflows %&gt;% \n    workflow_map(\n      resamples = churn_folds,\n      grid = 20,\n      metrics = metric_set(roc_auc),\n      seed = 42,  # reproducibility\n      verbose = TRUE)\n  toc()\n}\n\nDa die Berechnung schon etwas Zeit braucht, macht es Sinn, das Modell (bzw. das Ergebnisobjekt) auf Festplatte zu speichern:\n\nwrite_rds(churn_model_set, file = \"objects/churn_model_set.rds\")\n\nAchtung Dieser Schritt ist gef√§hrlich: Wenn Sie Ihr Rezept und Fit-Objekt √§ndenr, kriegt das Ihre Festplatte nicht unbedingt mit. Sie k√∂nnten also unbemerkt mit dem alten Objekt von Ihrer Festplatte weiterarbeiten, ohne durch eine Fehlermeldung gewarnt zu werden.\nEntsprechend kann man das Modellobjekt wieder importieren, wenn einmal abgespeichert:\n\nchurn_model_set &lt;- read_rds(file = \"objects/churn_model_set.rds\")\n\n\n11.10.8 Ergebnisse im Train-Sest\nHier ist die Rangfolge der Modelle, geordnet nach mittlerem ROC AUC:\n\nrank_results(churn_model_set, rank_metric = \"roc_auc\")\n\n\n\n  \n\n\n\n\nautoplot(churn_model_set, metric = \"roc_auc\")\n\n\n\n\n\n11.10.9 Bestes Modell\nUnd hier nur der beste Kandidat pro Algorithmus:\n\nautoplot(churn_model_set, metric = \"roc_auc\", select_best = \"TRUE\") +\n  geom_text(aes(y = mean - .01, label = wflow_id), angle = 90, hjust = 1) +\n  theme(legend.position = \"none\") +\n  lims(y = c(0.85, 1))\n\n\n\n\nBoosting hat - knapp - am besten abgeschnitten. Allerdings sind Random Forest und die schlichte, einfache logistische Regression auch fast genau so gut. Das w√§re ein Grund f√ºr das einfachste Modell, das GLM, zu votieren. Zumal die Interpretierbarkeit am besten ist. Alternativ k√∂nnte man sich f√ºr das Boosting-Modell aussprechen.\nMan kann sich das beste Submodell auch von Tidymodels bestimmen lassen. Das scheint aber (noch) nicht f√ºr ein Workflow-Set zu funktionieren, sondern nur f√ºr das Ergebnisobjekt von tune_grid.\n\nselect_best(churn_model_set, metric = \"roc_auc\")\n## Error in `select_best()`:\n## ! No `select_best()` exists for this type of object.\n\nrf_fit1 haben wir mit tune_grid() berechnet; mit diesem Modell kann select_best() arbeiten:\n\nselect_best(rf_fit1)\n\n\n\n  \n\n\n\nAber wir k√∂nnen uns h√§ndisch behelfen.\nSchauen wir uns mal die Metriken (Vorhersageg√ºte) an:\n\nchurn_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean)\n\n\n\n  \n\n\n\nrec1_boost1 scheint das beste Modell zu sein.\n\nbest_model_params &lt;-\nextract_workflow_set_result(churn_model_set, \"rec1_boost1\") %&gt;% \n  select_best()\n\nbest_model_params\n\n\n\n  \n\n\n\n\n11.10.10 Finalisisieren\nWir entscheiden uns mal f√ºr das Boosting-Modell, rec1_boost1. Diesen Workflow, in finalisierter Form, brauchen wir f√ºr den ‚Äúfinal Fit‚Äù. Finalisierte Form hei√üt:\n\nSchritt 1: Nimm den passenden Workflow, hier rec1 und boost1; das hatte uns oben rank_results() verraten.\nSchritt 2: Update (Finalisiere) ihn mit den besten Tuningparameter-Werten\n\n\n# Schritt 1:\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_boost1\")\n\nbest_wf\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 2 Recipe Steps\n## \n## ‚Ä¢ step_normalize()\n## ‚Ä¢ step_dummy()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Boosted Tree Model Specification (classification)\n## \n## Main Arguments:\n##   mtry = tune()\n##   trees = tune()\n##   min_n = tune()\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\nJetzt finalisieren wir den Workflow, d.h. wir setzen die Parameterwerte des besten Submodells ein:\n\n# Schritt 2:\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 2 Recipe Steps\n## \n## ‚Ä¢ step_normalize()\n## ‚Ä¢ step_dummy()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Boosted Tree Model Specification (classification)\n## \n## Main Arguments:\n##   mtry = 6\n##   trees = 80\n##   min_n = 21\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\n\n11.10.11 Last Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  last_fit(churn_split)\n\nfit_final\n\n\n\n  \n\n\n\n\ncollect_metrics(fit_final)\n\n\n\n  \n\n\n\n\n11.10.12 Variablenrelevanz\nUm die Variablenrelevanz zu plotten, m√ºssen wir aus dem Tidymodels-Ergebnisobjekt das eigentliche Ergebnisobjekt herausziehen, von der R-Funktion, die die eigentliche Berechnung durchf√ºhrt, das w√§re glm() bei einer logistischen Regression oder xgboost::xgb.train() bei XGBoost:\n\nfit_final %&gt;% \n  extract_fit_parsnip()\n## parsnip model object\n## \n## ##### xgb.Booster\n## raw: 99.9 Kb \n## call:\n##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n##     colsample_bytree = 1, colsample_bynode = 0.285714285714286, \n##     min_child_weight = 21L, subsample = 1), data = x$data, nrounds = 80L, \n##     watchlist = x$watchlist, verbose = 0, nthreads = 8L, nthread = 1, \n##     objective = \"binary:logistic\")\n## params (as set within xgb.train):\n##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.285714285714286\", min_child_weight = \"21\", subsample = \"1\", nthreads = \"8\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\n## xgb.attributes:\n##   niter\n## callbacks:\n##   cb.evaluation.log()\n## # of features: 21 \n## niter: 80\n## nfeatures : 21 \n## evaluation_log:\n##     iter training_logloss\n##        1        0.5634598\n##        2        0.4799218\n## ---                      \n##       79        0.1875497\n##       80        0.1872028\n\nDieses Objekt √ºbergeben wir dann an vip:\n\nfit_final %&gt;% \n  extract_fit_parsnip() %&gt;% \n  vip()\n\n\n\n\n\n11.10.13 ROC-Curve\nEine ROC-Kurve berechnet Sensitivit√§t und Spezifit√§t aus den Vorhersagen, bzw. aus dem Vergleich von Vorhersagen und wahrem Wert (d.h. der beobachtete Wert).\nZiehen wir also zuerst die Vorhersagen heraus:\n\nfit_final %&gt;% \n  collect_predictions()\n\n\n\n  \n\n\n\nPraktischerweise werden die ‚Äúwahren Werte‚Äù (also die beobachtaten Werte), canceled_service, ausch angegeben.\nDann berechnen wir die roc_curve und autoplotten sie, s. Abbildung¬†11.9.\n\nfit_final %&gt;% \n  collect_predictions() %&gt;% \n  roc_curve(canceled_service, .pred_yes) %&gt;% \n  autoplot()\n\n\n\nAbbildung¬†11.9: Die ROC-Kurve f√ºr unser Model"
  },
  {
    "objectID": "110-ensemble.html#aufgaben",
    "href": "110-ensemble.html#aufgaben",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.11 Aufgaben",
    "text": "11.11 Aufgaben\n\nAufgaben zu Tidymodels, PDF\nAufgaben zu Tidymodels, HTML"
  },
  {
    "objectID": "110-ensemble.html#vertiefung",
    "href": "110-ensemble.html#vertiefung",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.12 Vertiefung",
    "text": "11.12 Vertiefung\nNutzen Sie StackOverflow als Forum f√ºr Ihre Fragen - Hier ein Beispiel zu einer Fehlermeldung, die mir Kopfzerbrechen bereitete"
  },
  {
    "objectID": "110-ensemble.html#fallstudien",
    "href": "110-ensemble.html#fallstudien",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "\n11.13 Fallstudien",
    "text": "11.13 Fallstudien\n\n‚ÄúFallstudie Vulkanausbr√ºche‚Äù\n‚ÄúFallstudie Brettspiele mit XGBoost‚Äù\n‚ÄúEinfache Durchf√ºhrung eines Modellierung mit XGBoost‚Äù\n‚ÄúFallstudie Oregon Schools‚Äù\n‚ÄúFallstudie Churn‚Äù\n‚ÄúFallstudie Ikea‚Äù\n‚ÄúFallstudie Wasserquellen in Sierra Leone‚Äù\n‚ÄúFallstudie B√§ume in San Francisco‚Äù\n‚ÄúFallstudie Vulkanausbr√ºche‚Äù\n‚ÄúFallstudie Brettspiele mit XGBoost‚Äù\n\n\n\n\n\nChen, Tianqi, und Carlos Guestrin. 2016. ‚ÄûXGBoost: A Scalable Tree Boosting System‚Äú. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785‚Äì94. KDD ‚Äô16. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/2939672.2939785.\n\n\nFriedman, J. 2001. ‚ÄûGreedy function approximation: A gradient boosting machine.‚Äú https://doi.org/10.1214/AOS/1013203451.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, und Kjell Johnson. 2013. Applied predictive modeling. Bd. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications."
  },
  {
    "objectID": "110-ensemble.html#footnotes",
    "href": "110-ensemble.html#footnotes",
    "title": "\n11¬† Ensemble Lerner\n",
    "section": "",
    "text": "√úbrigens geh√∂rt zu den weiteren Vorteilen von B√§umen, dass sie die Temperatur absenken; zu Zeiten von Hitzewellen k√∂nnte das praktisch sein. Ansonsten erzeugen sie aber nur Luft und haben auch sonst kaum erkennbaren Nutzen. B√§ume stellen zum Beispiel nie WLAN bereit.‚Ü©Ô∏é\nbei Fat-Tails-Variablen muss man diese Aussage einschr√§nken‚Ü©Ô∏é\nWenn es einen No-Free-Lunch-Satz gibt, m√ºsste es auch einen Too-Good-to-be-True-Satz geben, den wir hiermit postulieren.‚Ü©Ô∏é\nSchlimmes Denglisch‚Ü©Ô∏é\nAber Vorsicht, dass man nicht vergisst, diese Objekte zu aktualisieren.‚Ü©Ô∏é"
  },
  {
    "objectID": "120-regularisierte-modelle.html#lernsteuerung",
    "href": "120-regularisierte-modelle.html#lernsteuerung",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.1 Lernsteuerung",
    "text": "12.1 Lernsteuerung\n\n12.1.1 Lernziele\n\n‚ÄúSie k√∂nnen Algorithmen f√ºr regularisierte lineare Modell erkl√§ren, d.h. Lasso- und Ridge-Regression‚Äù\n‚ÄúSie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann‚Äù\n‚ÄúSie k√∂nnen diese Verfahren in R berechnen‚Äù\n\n12.1.2 Literatur\n\n‚ÄúRhys, Kap. 11‚Äù\n\n12.1.3 Hinweise\n‚ÄúRhys und ISLR sind eine gute Quelle zum Einstieg in das Thema.\n\n12.1.4 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\nlibrary(tidymodels)\nlibrary(tictoc)  # Zeitmessung"
  },
  {
    "objectID": "120-regularisierte-modelle.html#regularisierung",
    "href": "120-regularisierte-modelle.html#regularisierung",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.2 Regularisierung",
    "text": "12.2 Regularisierung\n\n12.2.1 Was ist Regularisierung?\nRegularisieren verweist auf ‚Äúregul√§r‚Äù; laut Duden bedeutet das Wort so viel wie ‚Äúden Regeln, Bestimmungen, Vorschriften entsprechend; vorschriftsm√§√üig, ordnungsgem√§√ü, richtig‚Äù oder ‚Äú√ºblich‚Äù.\nIm Englischen spricht man auch von ‚Äúpenalized models‚Äù, ‚Äúbestrafte Modell‚Äù und von ‚Äúshrinkage‚Äù, von ‚ÄúSchrumpfung‚Äù im Zusammenhang mit dieer Art von Modellen.\nRegularisierung ist ein Meta-Algorithmus, also ein Verfahren, was als zweiter Schritt ‚Äúauf‚Äù verschiedene Modelle angewendet werden kann - zumeist aber auf lineare Modelle, worauf wir uns im Folgenden konzentrieren.\nDas Ziel von Regularisierung ist es, Overfitting zu vermeiden, in dem die Komplexit√§t eines Modells reduziert wird. Der Effekt von Regularisierung ist, dass die Varianz der Modelle verringert wird und damit das Overfitting. Der Preis ist, dass der Bias erh√∂ht wird, aber oft geht die Rechnung auf, dass der Gewinn gr√∂√üer ist als der Verlust.\nIm Kontext von linearen Modellen bedeutet das, dass die Koeffizienten (\\(\\beta\\)s) im Betrag verringert werden durch Regularisierung, also in Richtung Null ‚Äúgeschrumpft‚Äù werden.\nDem liegt die Idee zugrunde, dass extreme Werte in den Koeffizienten vermutlich nicht ‚Äúecht‚Äù, sondern durch Rauschen f√§lschlich vorgegaukelt werden.\nDie bekanntesten Vertreter dieser Modellart sind Ridge Regression, \\(L2\\), das Lasso, \\(L1\\), sowie Elastic Net.\n\n12.2.2 √Ñhnliche Verfahren\nEin √§hnliches Ziel wie der Regulaisierung liegt dem Pruning zugrunde, dem nachtr√§glichen Beschneiden von Entscheidungsb√§umen. In beiden F√§llen wird die Komplexit√§t des Modells verringert, und damit die Varianz auf Kosten eines m√∂glichen Anstiegs der Verzerrung (Bias) des Modells. Unterm Strich hofft man, dass der Gewinn die Kosten √ºbersteigt und somit der Fit im Test-Sample besser wird.\nEine Andere Art der Regularisierung wird durch die Verwendung von Bayes-Modellen erreicht: Setzt man einen konservativen Prior, etwa mit Mittelwert Null und kleiner Streuung, so werden die Posteriori-Koeffizienten gegen Null hin geschrumpft werden.\nMit Mehrebenen-Modellen (Multi Level Models) l√§sst sich ein √§hnlicher Effekt erreichen.\n\n12.2.3 Normale Regression (OLS)\nMan kann sich fragen, warum sollte man an der normalen Least-Square-Regression (OLS: Ordinary Least Square) weiter herumbasteln wollen, schlie√ülich garantiert das Gauss-Markov-Theorem, dass eine lineare Regression den besten linearen unverzerrten Sch√§tzwert (BLUE, best linear unbiased estimator) stellt, vorausgesetzt die Voraussetzungen der Regression sind erf√ºllt.\nJa, die Sch√§tzwerte (Vorhersagen) der Regression sind BLUE, sch√§tzen also den wahren Wert korrekt und maximal pr√§zise. Das gilt (nat√ºrlich) nur, wenn die Voraussetzungen der Regression erf√ºllt sind, also vor allem, dass die Beziehung auch linear-additiv ist.\nZur Erinnerung, mit OLS minimiert man man den quadrierten Fehler, \\(RSS\\), Residual Sum of Square:\n\\[RSS = \\sum_{i=1}^n \\left(y_i - \\beta_0 - \\sum_{j=1}^p \\beta_j x_{ij} \\right)\\]\nMan sucht also diejenigen Koeffizientenwerte \\(\\beta\\) (Argumente der Loss-Funktion RSS), die RSS minimieren:\n\\[\\beta = \\underset {\\beta}{\\operatorname {arg\\,min(RSS)}}\\]\nEs handelt sich hier um Sch√§tzwerte, die meist mit dem H√ºtchen \\(\\hat{\\beta}\\) ausgedr√ºckt werden, hier aber zur einfacheren Notation weggelassen sind.\nAbb. Abbildung¬†12.1 visualisiert die Optimierung mit OLS Quelle. An gleicher Stelle findet sich eine gute Darstellung zu den (mathematischen) Grundlagen der OLS-Regression.\n\n\nAbbildung¬†12.1: Visualisierung der Minimierung der RSS durch OLS\n\n\n√úbrigens nennt man Funktionen, die man minimiert mit Hilfe von Methoden des maschinellen Lernens mit dem Ziel die optimalen Koeffizienten (wie \\(\\beta\\)s) zu finden, auch Loss Functions (Kostenfunktion).\nDas Problem der Regression ist, dass die sch√∂ne Eigenschaft BLUE nur im Train-Sample, nicht (notwendig) im Test-Sample gilt."
  },
  {
    "objectID": "120-regularisierte-modelle.html#ridge-regression-l2",
    "href": "120-regularisierte-modelle.html#ridge-regression-l2",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.3 Ridge Regression, L2",
    "text": "12.3 Ridge Regression, L2\n\n12.3.1 Strafterm\nRidge Regression ist sehr √§hnlich zum OLS-Algorithmus, nur das ein ‚ÄúStrafterm aufgebrummt‚Äù wird, der \\(RSS\\) erh√∂ht.\nDer Gesamtterm, der optimiert wird, \\(L_{L2}\\) (Loss Level 2) ist also die Summe aus RSS und dem Strafterm:\n\\[L_{L2} = RSS + \\text{Strafterm}\\]\nDer Strafterm ist so aufgebaut, dass (im Absolutbetrag) gr√∂√üere Koeffizienten mehr zum Fehler beitragen, also eine Funktion der (quadrierten) Summe der Absolutwerte der Koeffizienten:\n\\[\\text{Strafterm} = \\lambda \\sum_{j=1}^p \\beta_j^2\\]\nMan nennt den L2-Strafterm auch L2-Norm1.\nDabei ist \\(\\lambda\\) (lambda) ein Tuningparameter, der bestimmt, wie stark die Bestrafung ausf√§llt. Den Wert von \\(\\lambda\\) lassen wir durch Tuning bestimmen, wobei \\(\\lambda \\in \\mathbb{R}^+\\setminus\\{0\\}\\). Es gilt: Je gr√∂√üer lambda, desto st√§rker die Schrumpfung der Koeffizienten gegen Null, da der gesamte zu minimierende Term, \\(L_{L2}\\) entsprechend durch lambda vergr√∂√üert wird.\nDer Begriff ‚ÄúL2‚Äù beschreibt dass es sich um eine quadrierte Normierung handelt.\nDer Begriff ‚ÄúNorm‚Äù stammt aus der Vektoralgebra. Die L2-Norm eines Vektors \\(||v||\\) mit \\(k\\) Elementen ist so definiert Quelle:\n\\[||v|| = \\left(|{v_1}|^2+ |{v_2}|^2+ |{v_i}|^2+ \\ldots + |{v_k}|^2 \\right)^{1/2} \\] wobei \\(|{v_i}|\\) den Absolutwert (Betrag) meint de Elements \\(v_i\\) meint. Im Falle von reellen Zahlen und Quadrierung braucht es hier die Absolutfunktion nicht.\nIm Falle von zwei Elementen vereinfacht sich obiger Ausdruck zu:\n\\[||v|| = \\sqrt{\\left({v_1}^2+ {v_2}^2\\right)} \\]\nDas ist nichts anderes als Pythagoras‚Äô Gesetz im euklidischen Raum.\nDer Effekt von \\(\\lambda \\sum_{j=1}^p \\beta_j^2\\) ist wie gesagt, dass die Koeffizienten in Richtung Null geschrumpft werden. Wenn \\(\\lambda = 0\\), resultiert OLS. Wenn \\(\\lambda \\rightarrow \\infty\\), werden alle Koeffizienten auf Null gesch√§tzt werden, Abb. Abbildung¬†12.2 verdeutlicht dies (James u.¬†a. 2021).\n\n\nAbbildung¬†12.2: Links: Regressionskoeffizienten als Funktion von lambda. Rechts: L2-Norm der Ridge-Regression im Verh√§ltnis zur OLS-Regression\n\n\n\n12.3.2 Standardisierung\nDie Straftermformel sagt uns, dass die Ridge-Regression abh√§ngig von der Skalierung der Pr√§diktoren ist. Daher sollten die Pr√§diktoren vor der Ridge-Regression zun√§chst auf \\(sd=1\\) standardisiert werden. Da wir \\(\\beta_0\\) nicht schrumpfen wollen, sondern nur die Koeffizienten der Pr√§diktoren bietet es sich an, die Pr√§diktoren dazu noch zu zentieren. Kurz: Die z-Transformation bietet sich als Vorverarbeitung zur Ridge-Regression an."
  },
  {
    "objectID": "120-regularisierte-modelle.html#lasso-l1",
    "href": "120-regularisierte-modelle.html#lasso-l1",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.4 Lasso, L1",
    "text": "12.4 Lasso, L1\n\n12.4.1 Strafterm\nDer Strafterm in der ‚ÄúLasso-Variante‚Äù der regularisierten Regression lautet so:\n\\[\\text{Strafterm} = \\lambda \\sum_{j=1}^p |\\beta_j|,\\]\nist also analog zur Ridge-Regression konzipiert.\nGenau wie bei der L2-Norm-Regularisierung ist ein ‚Äúguter‚Äù Wert von lambda entscheidend. Dieser Wert wird, wie bei der Ridge-Regression, durch Tuning bestimmt.\nDer Unterschied ist, dass die L1-Norm (Absolutwerte) und nicht die L2-Norm (Quadratwerte) verwendet werden.\nDie L1-Norm eines Vektors ist definiert durch \\(||\\beta||_1 = \\sum|\\beta_j|\\).\n\n12.4.2 Variablenselektion\nGenau wie die Ridge-Regression f√ºhrt ein h√∂here lambda-Wert zu einer Regularisierung (Schrumpfung) der Koeffizienten. Im Unterschied zur Ridge-Regression hat das Lasso die Eigenschaft, einzelne Parameter auf exakt Null zu schrumpfen und damit faktisch als Pr√§diktor auszuschlie√üen. Anders gesagt hat das Lasso die praktische Eigenschaft, Variablenselektion zu erm√∂glichen.\nAbb. Abbildung¬†12.3 verdeutlicht den Effekt der Variablenselektion, vgl. James u.¬†a. (2021), Kap. 6.2. Die Ellipsen um \\(\\hat{beta}\\) herum nent man Kontourlinien. Alle Punkte einer Kontourlinie haben den gleiche RSS-Wert, stehen also f√ºr eine gleichwertige OLS-L√∂sung.\n\n\nAbbildung¬†12.3: lambda in der Lasso-Regression\n\n\nWarum erlaubt die L1-Norm Variablenselektion, die L2-Norm aber nicht? Abb. Abbildung¬†12.4 verdeutlicht den Unterschied zwischen L1- und L2-Norm. Es ist eine Regression mit zwei Pr√§diktoren, also den zwei Koeffizienten \\(\\beta1, \\beta_2\\) dargestellt.\n\n\nAbbildung¬†12.4: Verlauf des Strafterms bei der L1-Norm (links) und der L2-Norm (rechts)\n\n\nBetrachten wir zun√§chst das rechte Teilbild f√ºr die L2-Norm aus Abb. Abbildung¬†12.4, das in Abb. Abbildung¬†12.5 in den Fokus ger√ºckt wird (Rhys 2020).\n\n\nAbbildung¬†12.5: Verlauf des Strafterms bei der L1-Norm (links) und der L2-Norm (rechts)\n\n\nWenn lambda gleich Null ist, entspricht \\(L_{L2}\\) genau der OLS-L√∂sung. Vergr√∂√üert man lambda, so liegt \\(L_{L2}\\) dem Schnittpunkt des OLS-Kreises mit dem zugeh√∂rigen lambda-Kreis. Wie man sieht, f√ºhrt eine Erh√∂hung von lambda zu einer Reduktion der Absolutwerte von \\(\\beta_1\\) und \\(\\beta_2\\). Allerdings werden, wie man im Diagramm sieht, auch bei hohen lambda-Werten die Regressionskoeffizienten nicht exakt Null sein.\nWarum l√§sst die L2-Norm f√ºr bestimmte lambda-Werte den charakteristischen Kreis entstehen? Die Antwort ist, dass die L√∂sungen f√ºr \\(\\beta_1^2 + \\beta_2^2=1\\) (mit \\(\\lambda=1\\)) graphisch als Kreis dargestellt werden k√∂nnen.\nAnders ist die Situation bei der L1-Norm, dem Lasso, vgl. Abb. Abbildung¬†12.6.\n\n\nAbbildung¬†12.6: Verlauf des Strafterms bei der L1-Norm\n\n\nEine Erh√∂hung von $ f√ºhrt aufgrund der charakteristischen Kontourlinie zu einem Schnittpunkt (von OLS-L√∂sung und lambda-Wert), der - wenn lambda gro√ü genug ist, stets auf einer der beiden Achsen liegt, also zu einer Nullsetzung des Parameters f√ºhrt.\nDamit kann man argumentieren, dass das Lasso implizit davon ausgeht, dass einige Koeffizienten in Wirklichkeit exakt Null sind, die L2-Norm aber nicht."
  },
  {
    "objectID": "120-regularisierte-modelle.html#l1-vs.-l2",
    "href": "120-regularisierte-modelle.html#l1-vs.-l2",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.5 L1 vs.¬†L2",
    "text": "12.5 L1 vs.¬†L2\n\n12.5.1 Wer ist st√§rker?\nMan kann nicht sagen, dass die L1- oder die L2-Norm strikt besser sei. Es kommt auf den Datensatz an. Wenn man einen Datensatz hat, in dem es eingie wenige starke Pr√§diktoren gibt und viele sehr schwache (oder exakt irrelevante) Pr√§diktoren gibt, dann wird L1 tendenziell zu besseren Ergebnissen f√ºhren(James u.¬†a. 2021, 246). Das Lasso hat noch den Vorteil der Einfachheit, da weniger Pr√§diktoren im Modell verbleiben.\nRidge-Regression wird dann besser abschneiden (tendenziell), wenn die Pr√§diktoren etwa alle gleich stark sind.\n\n12.5.2 Elastic Net als Kompromiss\nDas Elastic Net (EN) ist ein Kompromiss zwischen L1- und L2-Norm. \\(\\lambda\\) wird auf einen Wert zwischen 1 und 2 eingestellt; auch hier wird der Wert f√ºr \\(\\lambda\\) wieder per Tuning gefunden.\n\\[L_{EN} = RSS + \\lambda\\left((1-\\alpha))\\cdot \\text{L2-Strafterm} + \\alpha \\cdot  \\text{L1-Strafterm}\\right)\\]\n\\(\\alpha\\) ist ein Tuningparameter, der einstellt, wie sehr wir uns Richtung L1- vs.¬†L2-Norm bewegen. Damit wird sozusagen die ‚ÄúMischung‚Äù eingestellt (von L1- vs.¬†L2).\nSpezialf√§lle:\n\nWenn \\(\\alpha=0\\) resultiert die Ridge-Regression (L1-Strafterm wird Null)\nWenn \\(\\alpha=1\\) resultiert die Lasso-Regression (L2-Strafterm wird Null)"
  },
  {
    "objectID": "120-regularisierte-modelle.html#aufgaben",
    "href": "120-regularisierte-modelle.html#aufgaben",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "\n12.6 Aufgaben",
    "text": "12.6 Aufgaben\n\n‚ÄúFallstudie Serie The Office‚Äù\n‚ÄúFallstudie NBER Papers‚Äù\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications."
  },
  {
    "objectID": "120-regularisierte-modelle.html#footnotes",
    "href": "120-regularisierte-modelle.html#footnotes",
    "title": "\n12¬† Regularisierte Modelle\n",
    "section": "",
    "text": "Streng genommen ist er eine Funktion der L2-Norm bzw. mit Lambda-Gewichtet und ohne die Wurzel, die zur Vektornorm geh√∂rt‚Ü©Ô∏é"
  },
  {
    "objectID": "130-kaggle.html#lernsteuerung",
    "href": "130-kaggle.html#lernsteuerung",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\n\nSie wissen, wie man einen Datensatz f√ºr einen Prognosewettbwerb bei Kaggle einreicht\nSie kennen einige Beispiele von Notebooks auf Kaggle (f√ºr die Sprache R)\nSie wissen, wie man ein Workflow-Set in Tidymodels berechnet\nSie wissen, dass Tidymodels im Rezept keine Transformationen im Test-Sample ber√ºcksichtigt und wie man damit umgeht\n\n13.1.2 Hinweise\n\nMachen Sie sich mit Kaggle vertraut. Als √úbungs-Wettbewerb dient uns TMDB Box-office Revenue (s. Aufgaben)\n\n13.1.3 R-Pakete\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen\nlibrary(lubridate)  # Datumsangaben\nlibrary(VIM)  # fehlende Werte\nlibrary(visdat)  # Datensatz visualisieren"
  },
  {
    "objectID": "130-kaggle.html#was-ist-kaggle",
    "href": "130-kaggle.html#was-ist-kaggle",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.2 Was ist Kaggle?",
    "text": "13.2 Was ist Kaggle?\n\nKaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n\nQuelle\nKaggle as AirBnB for Data Scientists?!"
  },
  {
    "objectID": "130-kaggle.html#fallstudie-tmdb",
    "href": "130-kaggle.html#fallstudie-tmdb",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.3 Fallstudie TMDB",
    "text": "13.3 Fallstudie TMDB\nWir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb.\nZiel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme.\n\n13.3.1 Aufgabe\nReichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Score!\n\n13.3.2 Hinweise\n\nSie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden.\nHalten Sie das Modell so einfach wie m√∂glich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere Schn√∂rkel.\nLogarithmieren Sie budget und revenue.\nMinimieren Sie die Vorverarbeitung (steps) so weit als m√∂glich.\nVerwenden Sie tidymodels.\nDie Zielgr√∂√üe ist revenue in Dollars; nicht in ‚ÄúLog-Dollars‚Äù. Sie m√ºssen also r√ºcktransformieren, wenn Sie revenue logarithmiert haben.\n\n13.3.3 Daten\nDie Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so:\n\nd_train_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv\"\nd_test_path &lt;- \"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv\"\n\nWir importieren die Daten von der Online-Quelle:\n\nd_train_raw &lt;- read_csv(d_train_path)\nd_test &lt;- read_csv(d_test_path)\n\nMal einen Blick werfen:\n\nglimpse(d_train_raw)\n## Rows: 3,000\n## Columns: 23\n## $ id                    &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1‚Ä¶\n## $ belongs_to_collection &lt;chr&gt; \"[{'id': 313576, 'name': 'Hot Tub Time Machine C‚Ä¶\n## $ budget                &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶\n## $ genres                &lt;chr&gt; \"[{'id': 35, 'name': 'Comedy'}]\", \"[{'id': 35, '‚Ä¶\n## $ homepage              &lt;chr&gt; NA, NA, \"http://sonyclassics.com/whiplash/\", \"ht‚Ä¶\n## $ imdb_id               &lt;chr&gt; \"tt2637294\", \"tt0368933\", \"tt2582802\", \"tt182148‚Ä¶\n## $ original_language     &lt;chr&gt; \"en\", \"en\", \"en\", \"hi\", \"ko\", \"en\", \"en\", \"en\", ‚Ä¶\n## $ original_title        &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n## $ overview              &lt;chr&gt; \"When Lou, who has become the \\\"father of the In‚Ä¶\n## $ popularity            &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶\n## $ poster_path           &lt;chr&gt; \"/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg\", \"/w9Z7A0GHEh‚Ä¶\n## $ production_companies  &lt;chr&gt; \"[{'name': 'Paramount Pictures', 'id': 4}, {'nam‚Ä¶\n## $ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'US', 'name': 'United States of‚Ä¶\n## $ release_date          &lt;chr&gt; \"2/20/15\", \"8/6/04\", \"10/10/14\", \"3/9/12\", \"2/5/‚Ä¶\n## $ runtime               &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶\n## $ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}]\", \"[{'‚Ä¶\n## $ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n## $ tagline               &lt;chr&gt; \"The Laws of Space and Time are About to be Viol‚Ä¶\n## $ title                 &lt;chr&gt; \"Hot Tub Time Machine 2\", \"The Princess Diaries ‚Ä¶\n## $ Keywords              &lt;chr&gt; \"[{'id': 4379, 'name': 'time travel'}, {'id': 96‚Ä¶\n## $ cast                  &lt;chr&gt; \"[{'cast_id': 4, 'character': 'Lou', 'credit_id'‚Ä¶\n## $ crew                  &lt;chr&gt; \"[{'credit_id': '59ac067c92514107af02c8c8', 'dep‚Ä¶\n## $ revenue               &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶\nglimpse(d_test)\n## Rows: 4,398\n## Columns: 22\n## $ id                    &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, ‚Ä¶\n## $ belongs_to_collection &lt;chr&gt; \"[{'id': 34055, 'name': 'Pok√©mon Collection', 'p‚Ä¶\n## $ budget                &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06‚Ä¶\n## $ genres                &lt;chr&gt; \"[{'id': 12, 'name': 'Adventure'}, {'id': 16, 'n‚Ä¶\n## $ homepage              &lt;chr&gt; \"http://www.pokemon.com/us/movies/movie-pokemon-‚Ä¶\n## $ imdb_id               &lt;chr&gt; \"tt1226251\", \"tt0051380\", \"tt0118556\", \"tt125595‚Ä¶\n## $ original_language     &lt;chr&gt; \"ja\", \"en\", \"en\", \"fr\", \"en\", \"en\", \"de\", \"en\", ‚Ä¶\n## $ original_title        &lt;chr&gt; \"„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§\", \"Attack of t‚Ä¶\n## $ overview              &lt;chr&gt; \"Ash and friends (this time accompanied by newco‚Ä¶\n## $ popularity            &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680‚Ä¶\n## $ poster_path           &lt;chr&gt; \"/tnftmLMemPLduW6MRyZE0ZUD19z.jpg\", \"/9MgBNBqlH1‚Ä¶\n## $ production_companies  &lt;chr&gt; NA, \"[{'name': 'Woolner Brothers Pictures Inc.',‚Ä¶\n## $ production_countries  &lt;chr&gt; \"[{'iso_3166_1': 'JP', 'name': 'Japan'}, {'iso_3‚Ä¶\n## $ release_date          &lt;chr&gt; \"7/14/07\", \"5/19/58\", \"5/23/97\", \"9/4/10\", \"2/11‚Ä¶\n## $ runtime               &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,‚Ä¶\n## $ spoken_languages      &lt;chr&gt; \"[{'iso_639_1': 'en', 'name': 'English'}, {'iso_‚Ä¶\n## $ status                &lt;chr&gt; \"Released\", \"Released\", \"Released\", \"Released\", ‚Ä¶\n## $ tagline               &lt;chr&gt; \"Somewhere Between Time & Space... A Legend Is B‚Ä¶\n## $ title                 &lt;chr&gt; \"Pok√©mon: The Rise of Darkrai\", \"Attack of the 5‚Ä¶\n## $ Keywords              &lt;chr&gt; \"[{'id': 11451, 'name': 'pok‚àö¬©mon'}, {'id': 1155‚Ä¶\n## $ cast                  &lt;chr&gt; \"[{'cast_id': 3, 'character': 'Tonio', 'credit_i‚Ä¶\n## $ crew                  &lt;chr&gt; \"[{'credit_id': '52fe44e7c3a368484e03d683', 'dep‚Ä¶\n\n\n13.3.4 Train-Set verschlanken\nDa wir aus Gr√ºnden der Einfachheit einige Spalten nicht ber√ºcksichtigen, entfernen wir diese Spalten, was die Gr√∂√üe des Datensatzes massiv reduziert.\n\nd_train &lt;-\n  d_train_raw %&gt;% \n  select(popularity, runtime, revenue, budget, release_date) \n\n\n13.3.5 Datensatz kennenlernen\n\nlibrary(visdat)\nvis_dat(d_train)\n\n\n\n\n\n13.3.6 Fehlende Werte pr√ºfen\nWelche Spalten haben viele fehlende Werte?\n\nvis_miss(d_train)\n\n\n\n\nMit VIM kann man einen Datensatz gut auf fehlende Werte hin untersuchen:\n\naggr(d_train)"
  },
  {
    "objectID": "130-kaggle.html#rezept",
    "href": "130-kaggle.html#rezept",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.4 Rezept",
    "text": "13.4 Rezept\n\n13.4.1 Rezept definieren\n\nrec1 &lt;-\n  recipe(revenue ~ ., data = d_train) %&gt;% \n  #update_role(all_predictors(), new_role = \"id\") %&gt;% \n  #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% \n  #update_role(revenue, new_role = \"outcome\") %&gt;% \n  step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% \n  step_log(budget) %&gt;% \n  step_mutate(release_date = mdy(release_date)) %&gt;% \n  step_date(release_date, features = c(\"year\", \"month\"), \nkeep_original_cols = FALSE) %&gt;% \n  step_impute_knn(all_predictors()) %&gt;% \n  step_dummy(all_nominal())\n\nrec1\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          4\n## \n## Operations:\n## \n## Variable mutation for if_else(budget &lt; 10, 10, budget)\n## Log transformation on budget\n## Variable mutation for mdy(release_date)\n## Date features from release_date\n## K-nearest neighbor imputation for all_predictors()\n## Dummy variables from all_nominal()\n\n\ntidy(rec1)\n\n\n\n  \n\n\n\n\n13.4.2 Check das Rezept\n\nprep(rec1, verbose = TRUE)\n## oper 1 step mutate [training] \n## oper 2 step log [training] \n## oper 3 step mutate [training] \n## oper 4 step date [training] \n## oper 5 step impute knn [training] \n## oper 6 step dummy [training] \n## The retained training set is ~ 0.37 Mb  in memory.\n## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          4\n## \n## Training data contained 3000 data points and 2 incomplete rows. \n## \n## Operations:\n## \n## Variable mutation for ~if_else(budget &lt; 10, 10, budget) [trained]\n## Log transformation on budget [trained]\n## Variable mutation for ~mdy(release_date) [trained]\n## Date features from release_date [trained]\n## K-nearest neighbor imputation for popularity, runtime, budget, release_date_year... [trained]\n## Dummy variables from release_date_month [trained]\n\n\nprep(rec1) %&gt;% \n  bake(new_data = NULL) \n\n\n\n  \n\n\n\nWir definieren eine Helper-Funktion:\n\nsum_isna &lt;- function(x) {sum(is.na(x))}\n\nUnd wenden diese auf jede Spalte an:\n\nprep(rec1) %&gt;% \n  bake(new_data = NULL) %&gt;%  \n  map_df(sum_isna)\n\n\n\n  \n\n\n\nKeine fehlenden Werte mehr in den Pr√§diktoren.\nNach fehlenden Werten k√∂nnte man z.B. auch so suchen:\n\ndatawizard::describe_distribution(d_train)\n\n\n\n  \n\n\n\nSo bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache.\n\n13.4.3 Check Test-Sample\nDas Test-Sample backen wir auch mal.\nWichtig: Wir preppen den Datensatz mit dem Train-Sample.\n\nbake(prep(rec1), new_data = d_test) %&gt;% \n  head()"
  },
  {
    "objectID": "130-kaggle.html#kreuzvalidierung",
    "href": "130-kaggle.html#kreuzvalidierung",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.5 Kreuzvalidierung",
    "text": "13.5 Kreuzvalidierung\n\ncv_scheme &lt;- vfold_cv(d_train,\n  v = 5, \n  repeats = 3)"
  },
  {
    "objectID": "130-kaggle.html#modelle",
    "href": "130-kaggle.html#modelle",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.6 Modelle",
    "text": "13.6 Modelle\n\n13.6.1 Baum\n\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\ntree_depth = tune(),\nmode = \"regression\")\n\n\n13.6.2 Random Forest\n\ndoParallel::registerDoParallel()\n\n\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"regression\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n\n13.6.3 XGBoost\n\nmod_boost &lt;- boost_tree(mtry = tune(),\nmin_n = tune(),\ntrees = tune()) %&gt;% \n  set_engine(\"xgboost\", nthreads = parallel::detectCores()) %&gt;% \n  set_mode(\"regression\")\n\n\n13.6.4 LM\n\nmod_lm &lt;-\n  linear_reg()"
  },
  {
    "objectID": "130-kaggle.html#workflows",
    "href": "130-kaggle.html#workflows",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.7 Workflows",
    "text": "13.7 Workflows\n\npreproc &lt;- list(rec1 = rec1)\nmodels &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm)\n \n \nall_workflows &lt;- workflow_set(preproc, models)"
  },
  {
    "objectID": "130-kaggle.html#fitten-und-tunen",
    "href": "130-kaggle.html#fitten-und-tunen",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.8 Fitten und tunen",
    "text": "13.8 Fitten und tunen\n\nif (file.exists(\"objects/tmdb_model_set.rds\")) {\n  tmdb_model_set &lt;- read_rds(\"objects/tmdb_model_set.rds\")\n} else {\n  tic()\n  tmdb_model_set &lt;-\nall_workflows %&gt;% \nworkflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n#  metrics = metric_set(rmse),\n  seed = 42,  # reproducibility\n  verbose = TRUE)\n  toc()\n}\n\nMan k√∂nnte sich das Ergebnisobjekt abspeichern, um k√ºnftig Rechenzeit zu sparen:\n\nwrite_rds(tmdb_model_set, \"objects/tmdb_model_set.rds\")\n\nAber Achtung: Wenn Sie vergessen, das Objekt auf der Festplatte zu aktualisieren, haben Sie eine zus√§tzliche Fehlerquelle. Gefahr im Verzug. Professioneller ist der Ansatz mit dem R-Paket target."
  },
  {
    "objectID": "130-kaggle.html#finalisieren",
    "href": "130-kaggle.html#finalisieren",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.9 Finalisieren",
    "text": "13.9 Finalisieren\n\n13.9.1 Welcher Algorithmus schneidet am besten ab?\nGenauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz.\n\ntune::autoplot(tmdb_model_set) +\n  theme(legend.position = \"bottom\")\n\n\n\n\nR-Quadrat ist nicht entscheidend; rmse ist wichtiger.\nDie Ergebnislage ist nicht ganz klar, aber einiges spricht f√ºr das Boosting-Modell, rec1_boost1.\n\ntmdb_model_set %&gt;% \n  collect_metrics() %&gt;% \n  arrange(-mean) %&gt;% \n  head(10)\n\n\n\n  \n\n\n\n\nbest_model_params &lt;-\nextract_workflow_set_result(tmdb_model_set, \"rec1_boost1\") %&gt;% \n  select_best()\n\nbest_model_params\n\n\n\n  \n\n\n\n\nbest_wf &lt;- \nall_workflows %&gt;% \n  extract_workflow(\"rec1_boost1\")\n\n#best_wf\n\n\nbest_wf_finalized &lt;- \n  best_wf %&gt;% \n  finalize_workflow(best_model_params)\n\nbest_wf_finalized\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 6 Recipe Steps\n## \n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_log()\n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_date()\n## ‚Ä¢ step_impute_knn()\n## ‚Ä¢ step_dummy()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Boosted Tree Model Specification (regression)\n## \n## Main Arguments:\n##   mtry = 6\n##   trees = 100\n##   min_n = 4\n## \n## Engine-Specific Arguments:\n##   nthreads = parallel::detectCores()\n## \n## Computational engine: xgboost\n\n\n13.9.2 Final Fit\n\nfit_final &lt;-\n  best_wf_finalized %&gt;% \n  fit(d_train)\n## [22:30:13] WARNING: amalgamation/../src/learner.cc:627: \n## Parameters: { \"nthreads\" } might not be used.\n## \n##   This could be a false alarm, with some parameters getting used by language bindings but\n##   then being mistakenly passed down to XGBoost core, or some parameter actually being used\n##   but getting flagged wrongly here. Please open an issue if you find any such cases.\n\nfit_final\n## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: boost_tree()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 6 Recipe Steps\n## \n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_log()\n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_date()\n## ‚Ä¢ step_impute_knn()\n## ‚Ä¢ step_dummy()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## ##### xgb.Booster\n## raw: 264.4 Kb \n## call:\n##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n##     colsample_bytree = 1, colsample_bynode = 0.4, min_child_weight = 4L, \n##     subsample = 1), data = x$data, nrounds = 100L, watchlist = x$watchlist, \n##     verbose = 0, nthreads = 8L, nthread = 1, objective = \"reg:squarederror\")\n## params (as set within xgb.train):\n##   eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"0.4\", min_child_weight = \"4\", subsample = \"1\", nthreads = \"8\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\n## xgb.attributes:\n##   niter\n## callbacks:\n##   cb.evaluation.log()\n## # of features: 15 \n## niter: 100\n## nfeatures : 15 \n## evaluation_log:\n##     iter training_rmse\n##        1     123099072\n##        2     102336979\n## ---                   \n##       99      27336836\n##      100      27000016\n\n\nd_test$revenue &lt;- NA\n\nfinal_preds &lt;- \n  fit_final %&gt;% \n  predict(new_data = d_test) %&gt;% \n  bind_cols(d_test)"
  },
  {
    "objectID": "130-kaggle.html#submission",
    "href": "130-kaggle.html#submission",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.10 Submission",
    "text": "13.10 Submission\n\n13.10.1 Submission vorbereiten\n\nsubmission_df &lt;-\n  final_preds %&gt;% \n  select(id, revenue = .pred)\n\nAbspeichern und einreichen:\n\nwrite_csv(submission_df, file = \"objects/submission.csv\")\n\nDiese CSV-Datei reichen wir dann bei Kagglei ein.\n\n13.10.2 Kaggle Score\nDiese Submission erzielte einen Score von 4.79227 (RMSLE)."
  },
  {
    "objectID": "130-kaggle.html#aufgaben",
    "href": "130-kaggle.html#aufgaben",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.11 Aufgaben",
    "text": "13.11 Aufgaben\n\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfache lineare Regression in Base-R, Anf√§ngerniveau, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB"
  },
  {
    "objectID": "130-kaggle.html#vertiefung",
    "href": "130-kaggle.html#vertiefung",
    "title": "\n13¬† Kaggle\n",
    "section": "\n13.12 Vertiefung",
    "text": "13.12 Vertiefung\n\nKaggle-Blog"
  },
  {
    "objectID": "140-faden.html#lernsteuerung",
    "href": "140-faden.html#lernsteuerung",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.1 Lernsteuerung",
    "text": "14.1 Lernsteuerung\n\n14.1.1 √úberblick\nMittlerweile haben wir einiges zum Thema Data Science bzw. maschinelles Lernen behandelt (und sie hoffentlich viel gelernt).\nDa ist es an der Zeit, einen Schritt zur√ºck zu treten, um sich einen √úberblick √ºber den gegangenen Weg zu verschaffen, den ber√ºhmten ‚Äúroten Faden‚Äù zu sehen, den zur√ºckgelegten Weg nachzuzeichnen in den groben Linien, um einen (klareren) √úberblick √ºber das Terrain zu bekommen.\nIn diesem Kapitel werden wir verschiedene ‚ÄúAussichtspfade‚Äù suchen, um im Bild zu bleiben, die uns einen √úberblick √ºber das Gel√§nde versprechen.\n\n14.1.2 Lernziele\n\nSie erarbeiten sich einen √úberblick √ºber den bisher gelernten Stoff bzw. verfeinern Ihren bestehenden √úberblick\n\n14.1.3 Literatur\n\nRhys im √úberblick"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-1-blick-vom-hohen-berg",
    "href": "140-faden.html#aussichtspunkt-1-blick-vom-hohen-berg",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.2 Aussichtspunkt 1: Blick vom hohen Berg",
    "text": "14.2 Aussichtspunkt 1: Blick vom hohen Berg\nUnd so zeigt sich ein ‚ÄúFlussbild‚Äù1 (Abbildung¬†14.1).\n\n\n\n\nflowchart LR\n  Vv[Vorverarbeitung] --&gt; W[Workflow]\n  MF[Modellformel] --&gt; W[Workflow]\n  Mo[Modell] --&gt; W[Workflow]\n  Al[Algorithmus] --&gt; Mo\n  Im[Implementierung] --&gt; Mo\n  Mod[Modus] --&gt; Mo\n  St[z.B. Standardisierung] --&gt; Vv\n  FW[z.B. Fehlende Werte] --&gt; Vv\n  W -- f√ºr jeden Workflow --&gt; Tuning\n  subgraph Tuning\nsubgraph Resampling\n  subgraph Fitten\n  end\nend\n  end\n  Tuning --&gt; bM[bester Modellkandidat]\n  bM --&gt; FT[Fitten auf ganz Train-Sample]\n  FT --&gt; PT[Predict auf Test-Sample]\n  PT --&gt;  MG[Modellg√ºte]\n  MG --&gt; num[numerisch]\n  MG --&gt; klas[klassifikatorisch]\n\n\n\nAbbildung¬†14.1: Ein Flussbild des maschinellen Lernens\n\n\n\n\nDer Reisef√ºhrer erz√§hlt uns zu diesem Bild folgende Geschichte:\n\n\nVideo-Geschichte"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-2-blick-in-den-hof-der-handwerker",
    "href": "140-faden.html#aussichtspunkt-2-blick-in-den-hof-der-handwerker",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.3 Aussichtspunkt 2: Blick in den Hof der Handwerker",
    "text": "14.3 Aussichtspunkt 2: Blick in den Hof der Handwerker\nWenn man auf einem hohen Berg gestanden ist, hat man zwar einen guten √úberblick √ºber das Land bekommen, aber das konkrete Tun bleibt auf solchen H√∂hen verborgen.\nM√∂chte man wissen, wie das gesch√§ftige Leben abl√§uft, muss man also den t√§tigen Menschen √ºber die Schulter schauen. Werfen wir also einen Blick in den ‚ÄúHof der Handwerker‚Äù, wo grundlegende Werkst√ºcke gefertigt werden, und wir jeden Handgriff aus der N√§he mitverfolgen k√∂nnen.\n\n14.3.1 Ein maximale einfaches Werkst√ºck mit Tidymodels\nWeniger blumig ausgedr√ºckt: Schauen wir uns ein maximal einfaches Beispiel an, wie man mit Tidymodels Vorhersagen t√§tigt. Genauer gesagt bearbeiten wir einen sehr einfachen Ansatz f√ºr einen Kaggle-Prognosewettbewerb.\n\n\n\n14.3.2 Ein immer noch recht einfaches Werkst√ºck mit Tidymodels\nDieses Beispiel ist nur wenig aufw√§ndiger als das vorherige."
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-3-der-nebelberg-quiz",
    "href": "140-faden.html#aussichtspunkt-3-der-nebelberg-quiz",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.4 Aussichtspunkt 3: Der Nebelberg (Quiz)",
    "text": "14.4 Aussichtspunkt 3: Der Nebelberg (Quiz)\nDa der ‚ÄúNebelberg‚Äù zumeist in Wolken verh√ºllt ist, muss man, wenn man ihn ersteigt und ins Land hinunterschaut, erraten, welche Teile zu sehen sind. Sozusagen eine Art Landschafts-Quiz.\nVoil√†, hier ist es, das Quiz zum maschinellen Lernen:\n\nLoading‚Ä¶"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-4-der-exerzitien-park",
    "href": "140-faden.html#aussichtspunkt-4-der-exerzitien-park",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.5 Aussichtspunkt 4: Der Exerzitien-Park",
    "text": "14.5 Aussichtspunkt 4: Der Exerzitien-Park\nWir stehen vor dem Eingang zu einem Park, in dem sich viele Menschen an merkw√ºrdigen √úbungen, Exerzitien, beflei√üigen. Vielleicht wollen Sie sich auch an einigen √úbungen abh√§rten? Bitte sch√∂n, lassen Sie sich nicht von mir aufhalten.\n\nYACSDA: Yet Another Case Study on Data Analysis\n‚Ä¶\nNUR EXPLORATIVE DATENANALYSE\n\nDatenjudo mit Pinguinen\nData-Wranglinng-Aufgaben zur Lebenserwartung\nAufgabe zur Datenvisualisierung des Diamantenpreises\nFallstudie Flugversp√§tungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten Flugversp√§tungen, Datensatz ‚Äònycflights13‚Äô\n\nNUR LINEARE MODELL\n\nBeispiel f√ºr Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel f√ºr Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel f√ºr Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von Flugversp√§tungen\nMovies\nFallstudie Einfache lineare Regression in Base-R, Anf√§ngerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\n\nYouTube-PLAYLISTS\n\nPlaylist YACSDAs\nPlaylist zur Pr√ºfungsleistung Prognosewettbewerb\nKaggle-Fallstudie TMDB: einfache lineare Regression\nPlaylist zum statistischen Modellieren\n\nMASCHINELLES LERNEN MIT TIDYMODELS\n\nExperimenting with machine learning in R with tidymodels and the Kaggle titanic dataset\nTutorial on tidymodels for Machine Learning\nClassification with Tidymodels, Workflows and Recipes\nA (mostly!) tidyverse tour of the Titanic\nPersonalised Medicine - EDA with tidy R\nTidy TitaRnic\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\nAnalyse zum Verlauf von Covid-F√§llen\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu Vulkanausbr√ºchen\nFallstudie Himalaya\nFallstudien zu Studiengeb√ºhren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\nEinfache Durchf√ºhrung eines Modellierung mit XGBoost\nFallstudie Oregon Schools\nFallstudie Churn\nFallstudie Ikea\nFallstudie Wasserquellen in Sierra Leone\nFallstudie B√§ume in San Francisco\nFallstudie Vulkanausbr√ºche\nFallstudie Brettspiele mit XGBoost\nFallstudie Serie The Office\nFallstudie NBER Papers\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Titanic mit Tidymodels bei Kaggle\nEinfache Fallstudie mit Tidymodels bei Kaggle"
  },
  {
    "objectID": "140-faden.html#aussichtspunkt-5-in-der-bibliothek",
    "href": "140-faden.html#aussichtspunkt-5-in-der-bibliothek",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.6 Aussichtspunkt 5: In der Bibliothek",
    "text": "14.6 Aussichtspunkt 5: In der Bibliothek\nEinen √úberblick √ºber eine Landschaft gewinnt man nicht nur von ausgesetzten Wegpunkten aus, sondern auch, manchmal, aus Schriftst√ºcken. Hier ist eine Auswahl an Literatur, die Grundlagen zu unserem Landstrich erl√§utert.\n\nRhys (2020)\nSilge und Kuhn (2022)\n\nEtwas weiter leiten uns diese Erz√§hler:\n\nJames u.¬†a. (2021)\nKuhn und Johnson (2013)"
  },
  {
    "objectID": "140-faden.html#krafttraining",
    "href": "140-faden.html#krafttraining",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.7 Krafttraining",
    "text": "14.7 Krafttraining\nUm die Aussicht genie√üen zu k√∂nnen, muss man manchmal ausgesetzte Pl√§tze in schwindelerregenden einigerma√üen steilen als H√ºgel erkennbaren H√∂hen erreichen‚Ä¶\nSportliche Leistungen erreicht nur, wer trainiert ist. Das ist im Land des Data Science nicht anders.\nHier ist eine Liste von √úbungen, die Ihre Datenkraft st√§hlen soll:\n\n\nLerngruppe: Den Wert einer Lerngruppe kann man kaum untersch√§tzen. Die Motivation, der Austausch, der Zwang seine Gedanken geordnet darzustellen, das wechselseitige Abfragen - diese Dinge machen eine Lerngruppe zu einem der wichtigsten Erfolgsgarant in Ihren Lernbem√ºhungen.\n\nExzerpte: Exzerpte, Zusammenfassungen also, sind n√∂tig, um von einer vermeintlichen ‚ÄúJaja, easy, versthe ich alles‚Äù Oberfl√§chen-Verarbeitung zu einem (ausgepr√§gterem) Tiefenverst√§ndnis vorzudringen.\n\nAufgaben: Manchmal stellt ein Dozent Aufgaben ein. Die Chance sollte man nutzen, denn zwar ist vieles in der Didaktikforschung noch unsicher, aber dass Aufgaben l√∂sen beim Lernen hilft, und zwar viel, ist eines der wenigen unstrittigen Erkenntnisse.\n\nFallstudien: √Ñhnliches wie Aufgaben, die oft kleinteilig-akademisch angelegt sind, hilft die gro√üe Schwester der schn√∂den Aufgabe, die Fallstudie, beim Vordringen in Verst√§ndnistiefen.\n\nLesen: Ja, Lesen ist voll Old School. Aber so was √Ñhnliches wie Updaten der Brain-Software. N√ºtzlich, weil die alte Software irgendwann nicht mehr supported wird.\n\nForum: Sie haben eine Frage, aber Sie k√∂nnen unm√∂glich ein paar Tage warten, bis Sie den Dozenten im Unterricht sprechen? Posten Sie die Frage in einem Forum! Vielleicht im Forum des Moduls oder aber in einem geeigneten Forum im Internet.\n\nYoutube: Zwar wettern Dozentis gerne √ºber die mangelnde Verarbeitungstiefe beim Fern schauen. Au√üerdem sind Lehrvideos didaktisch echt asbachuralt. Aber okay, manchmal und in √ºberschaubarer Dosis ist ein Lehrvideo eine n√ºtzliche Erg√§nzung zu den √ºbrigen Ma√ünahmen."
  },
  {
    "objectID": "140-faden.html#aufgaben",
    "href": "140-faden.html#aufgaben",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.8 Aufgaben",
    "text": "14.8 Aufgaben\n\nEinfache Random-Forest-Modellierung bei Kaggle (TMDB)\nEinfache Workflow-Set-Modellierung bei Kaggle (TMDB)\nBearbeiten Sie so viele Fallstudien der Fallstudiensammlung wie n√∂tig, um den Stoff fl√ºssig zu beherrschen"
  },
  {
    "objectID": "140-faden.html#vertiefung",
    "href": "140-faden.html#vertiefung",
    "title": "\n14¬† Der rote Faden\n",
    "section": "\n14.9 Vertiefung",
    "text": "14.9 Vertiefung\n\nMathematische Grundlagen k√∂nnen Sie z.B. hier vertiefen\nGute Fallstudie bei Kaggle f√ºr Regressionsprobleme: House Prices\nSie m√∂chten schnell ein Code-Schnipsel (√∂ffentlich sichtbar) teilen? Probieren Sie Github Gists aus\n\n\n\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An introduction to statistical learning: with applications in R. Second edition. Springer texts in statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, und Kjell Johnson. 2013. Applied predictive modeling. Bd. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with R, the tidyverse, and mlr. Shelter Island, NY: Manning publications.\n\n\nSilge, Julia, und Max Kuhn. 2022. Tidy Modeling with R. https://www.tmwr.org/."
  },
  {
    "objectID": "140-faden.html#footnotes",
    "href": "140-faden.html#footnotes",
    "title": "\n14¬† Der rote Faden\n",
    "section": "",
    "text": "Wem das Bild zu klein gezeichnet ist, der nehme entweder eine Lupe oder √∂ffne das Bild per Rechtsklick in einem neuen Tab.‚Ü©Ô∏é"
  },
  {
    "objectID": "150-fallstudien.html#lernsteuerung",
    "href": "150-fallstudien.html#lernsteuerung",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.1 Lernsteuerung",
    "text": "15.1 Lernsteuerung\n\n15.1.1 Lernziele\n\nSie k√∂nnen die Techniken des Maschinellen Lernens mit dem Tidymodels-Ansatz fl√ºssig anbringen.\n\n15.1.2 Literatur\n\nRhys, Kap. 12"
  },
  {
    "objectID": "150-fallstudien.html#fallstudien-zur-explorativen-datenanalyse",
    "href": "150-fallstudien.html#fallstudien-zur-explorativen-datenanalyse",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.2 Fallstudien zur explorativen Datenanalyse",
    "text": "15.2 Fallstudien zur explorativen Datenanalyse\n\nFALLSTUDIEN - NUR EXPLORATIVE DATENANALYSE\n\nDatenjudo mit Pinguinen\nData-Wranglinng-Aufgaben zur Lebenserwartung\nCase study: data vizualization on flight delays using tidyverse tools\nAufgabe zur Datenvisualisierung des Diamantenpreises\nFallstudie Flugversp√§tungen - EDA\nFallstudie zur EDA: Top-Gear\nFallstudie zur EDA: OECD-Wellbeing-Studie\nFallstudie zur EDA: Movie Rating\nFallstudie zur EDA: Women in Parliament\nFinde den Tag mit den meisten Flugversp√§tungen, Datensatz ‚Äònycflights13‚Äô\nCleaning and visualizing genomic data: a case study in tidy analysis\nTidyverse Case Study: Exploring the Billboard Charts\nAnalyse einiger RKI-Coronadaten: Eine reproduzierbare Fallstudie\nOpenCaseStudies - Health Expenditure\nOpen Case Studies: School Shootings in the United States - includes dashboards\nOpen Case Studies: Disparities in Youth Disconnection\nYACSDA Seitenspr√ºnge\nThe Open Case Study Search provides a nice collection of helpful case studies.\nifes@FOM Fallstudienseite"
  },
  {
    "objectID": "150-fallstudien.html#fallstudien-zu-linearen-modellen",
    "href": "150-fallstudien.html#fallstudien-zu-linearen-modellen",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.3 Fallstudien zu linearen Modellen",
    "text": "15.3 Fallstudien zu linearen Modellen\n\nFALLSTUDIEN - NUR LINEARE MODELLE\n\nBeispiel f√ºr Prognosemodellierung 1, grundlegender Anspruch, Video\nBeispiel f√ºr Ihre Prognosemodellierung 2, mittlerer Anspruch\nBeispiel f√ºr Ihre Prognosemodellierung 3, hoher Anspruch\nFallstudie: Modellierung von Flugversp√§tungen\nModelling movie successes: linear regression\nMovies\nFallstudie Einfache lineare Regression in Base-R, Anf√§ngerniveau, Kaggle-Competition TMDB\nFallstudie Sprit sparen\nFallstudie zum Beitrag verschiedener Werbeformate zum Umsatz; eine Fallstudie in Python, aber mit etwas Erfahrung wird man den Code einfach in R umsetzen k√∂nnen (wenn man nicht in Python schreiben will)\nPractical Linear Regression with R: A case study on diamond prices\nCase Study: Italian restaurants in NYC\nVorhersage-Modellierung des Preises von Diamanten\nModellierung Diamantenpreis 2"
  },
  {
    "objectID": "150-fallstudien.html#fallstudien-zum-maschinellen-lernen-mit-tidymodels",
    "href": "150-fallstudien.html#fallstudien-zum-maschinellen-lernen-mit-tidymodels",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.4 Fallstudien zum maschinellen Lernen mit Tidymodels",
    "text": "15.4 Fallstudien zum maschinellen Lernen mit Tidymodels\n\nFALLSTUDIEN - MASCHINELLES LERNEN MIT TIDYMODELS\n\nExperimenting with machine learning in R with tidymodels and the Kaggle titanic dataset\nTutorial on tidymodels for Machine Learning\nClassification with Tidymodels, Workflows and Recipes\nA (mostly!) tidyverse tour of the Titanic\nPersonalised Medicine - EDA with tidy R\nTidy TitaRnic\nFallstudie Seegurken\nSehr einfache Fallstudie zur Modellierung einer Regression mit tidymodels\nFallstudie zur linearen Regression mit Tidymodels\nAnalyse zum Verlauf von Covid-F√§llen\nFallstudie zur Modellierung einer logististischen Regression mit tidymodels\nFallstudie zu Vulkanausbr√ºchen\nFallstudie Himalaya\nFallstudien zu Studiengeb√ºhren\n1. Modell der Fallstudie Hotel Bookings\nAufgaben zur logistischen Regression, PDF\nFallstudie Oregon Schools\nFallstudie Windturbinen\nFallstudie Churn\nEinfache Durchf√ºhrung eines Modellierung mit XGBoost\nFallstudie Oregon Schools\nFallstudie Churn\nFallstudie Ikea\nFallstudie Wasserquellen in Sierra Leone\nFallstudie B√§ume in San Francisco\nFallstudie Vulkanausbr√ºche\nFallstudie Brettspiele mit XGBoost\nFallstudie Serie The Office\nFallstudie NBER Papers\nFallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB\nFallstudie Titanic mit Tidymodels bei Kaggle\nEinfache Fallstudie mit Tidymodels bei Kaggle\nExploring the Star Wars ‚ÄúPrequel Renaissance‚Äù Using tidymodels and workflowsets"
  },
  {
    "objectID": "150-fallstudien.html#vertiefung",
    "href": "150-fallstudien.html#vertiefung",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.5 Vertiefung",
    "text": "15.5 Vertiefung\n\nWie man eine Data-Science-Projekt strukturiert\nHausmeisterarbeit mit {{janitor}}"
  },
  {
    "objectID": "150-fallstudien.html#aufgaben",
    "href": "150-fallstudien.html#aufgaben",
    "title": "\n15¬† Fallstudien\n",
    "section": "\n15.6 Aufgaben",
    "text": "15.6 Aufgaben\n\nBearbeiten Sie eine Auswahl von Fallstudien Ihrer Wahl aus dieser Sammlung"
  },
  {
    "objectID": "160-e.html#lernsteuerung",
    "href": "160-e.html#lernsteuerung",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.1 Lernsteuerung",
    "text": "16.1 Lernsteuerung\n\n16.1.1 Lernziele\n\nSie wissen um die Bedeutung von e\nSie k√∂nnen die Zahl e herleiten\n\n16.1.2 Literatur\n\nKen Benoit: Lineare Regression mit logarithmischen Transformationen"
  },
  {
    "objectID": "160-e.html#vorbereitung",
    "href": "160-e.html#vorbereitung",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.2 Vorbereitung",
    "text": "16.2 Vorbereitung\nIn diesem Kapitel werden folgende R-Pakete ben√∂tigt:\n\nlibrary(tidyverse)\nlibrary(knitr)"
  },
  {
    "objectID": "160-e.html#staunen",
    "href": "160-e.html#staunen",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.3 Staunen",
    "text": "16.3 Staunen\nStaunen ist der Ursprung der Philosophie und damit des Denkens und damit vielleicht der Wissenschaft, wie es vielleicht recht treffend in diesem Cartoon von Doug Savage, 2014 dargestellt ist.\nStaunen r√ºhrt her vom Moment der Erkennens, dem Auftun von Verst√§ndnistiefe.\nUnd Tiefe des Verst√§ndnis findet sich vielleicht am deutlichsten in der Mathematik, meint XKCD."
  },
  {
    "objectID": "160-e.html#exponenzielles-wachstum",
    "href": "160-e.html#exponenzielles-wachstum",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.4 Exponenzielles Wachstum",
    "text": "16.4 Exponenzielles Wachstum\ne wie exponenzielles Wachstum: Wachstum mit konstantem Faktor.\nVerdoppeln ist eine wohl bekannte Art des exponenziellen Wachsens:\n\nEin Virus vermehrt sich w√§hrend der Zeitperiode \\(z\\) um den Faktor 2, verdoppelt seine Zahl also.\nDas Kapitel einer Anlage verdoppelt sich w√§hrend des Zeitraums \\(z\\).\nEine Population verdoppelt sich (w√§hrend eines Zeitraums \\(z\\)).\n\nVisualisieren wir uns einen exponenziellen Prozess, s. Abbildung¬†16.1.\n\nd1 &lt;-\n  tibble(z = 1:10,\n         y = 2^z)\n\nd1 %&gt;% \n  ggplot(aes(x = z, y = y)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\nAbbildung¬†16.1: Ein exponenzieller Wachstumsprozess\n\n\n\n\n‚ÄúVerdoppeln‚Äù meint das Gleiche wie ‚ÄúWachsen um 100%‚Äù: Faktor 2 entspricht also 100%.\nSagen wir, eine Population mit Startgr√∂√üe 1 verdoppelt sich drei Mal, Wachstum von 100% √ºber drei Perioden:\n\\(1 \\cdot 2^3 = 8\\)\nDanach ist die Population also 8 mal so gro√ü wie vorher.\nAllgemeiner k√∂nnen wir also schreiben\n\\(2^x = (1+ 100\\%)^x\\),\nwobei \\(x\\) die Anzahl der betrachteten Zeitperioden meint.\nWir k√∂nnen auf der Y-Achse auch die Anzahl der Verdopplungen auftragen, denn wir wissen ja, dass pro Zeitperiode eine Verdopplung dazu kommt, nach zwei Zeitperioden also zwei Verdopplungen, nach drei Zeitperioden drei Verdopplungen, nach vier Zeitperioden vier Verdopplungen ‚Ä¶\nNur sieht das Diagramm dann dr√∂ge aus, s. Abbildung¬†16.2. Diese Darstellung (Anzahl der Verdopplungsphasen) nennt man auch logarithmische Darstellung.\n\nd1a &lt;-\n  tibble(z = 1:10,\n         verdopplung = 1:10)\n\nd1a %&gt;% \n  ggplot(aes(x = z, y = verdopplung)) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = 1:10)\n\n\n\nAbbildung¬†16.2: Logarithmische Darstellung eines Wachstumsprozesses"
  },
  {
    "objectID": "160-e.html#sofortiges-wachstum",
    "href": "160-e.html#sofortiges-wachstum",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.5 Sofortiges Wachstum",
    "text": "16.5 Sofortiges Wachstum\nSagen wir, wir bringen ein Kapitel (in H√∂he von einer Geldeinheit) zur Bank. Die Bank bietet uns eine traumhafte Verzinsung (r wir Rate) von 100$ pro Jahr.\nUm den Zinzeszinseffekt auszunutzen, heben wir das Geld mehrfach unterj√§hrig ab, um es sofort wieder anzulegen, s. Abbildung¬†16.3.\n\nd2 &lt;-\n  tibble(\n    r = 1:20,\n    y = (1 + 1/r)^r\n  )\n\n\nd2 %&gt;% \n  ggplot() +\n  aes(x = r,\n      y = y) +\n  geom_point() +\n  geom_line()\n\n\n\nAbbildung¬†16.3: Wachstum wenn wir das Geld mehrfach unterj√§hrig abheben und neu einzahlen\n\n\n\n\nK√∂nnen wir mit dieser Methode unendlich viel Geld erzeugen? Tabelle¬†16.1 gibt eine Antwort.\n\nd2 &lt;-\n  tibble(x = 0:10,\n         r = 10^x,\n         y = (1 + 1/r)^r)\n\nd2 %&gt;% \n  kable(digits = 10)\n\n\n\nTabelle¬†16.1: Zinswachstum bei h√§ufiger Aus- und Einzahlung pro Jahr\n\nx\nr\ny\n\n\n\n0\n1e+00\n2.000000\n\n\n1\n1e+01\n2.593742\n\n\n2\n1e+02\n2.704814\n\n\n3\n1e+03\n2.716924\n\n\n4\n1e+04\n2.718146\n\n\n5\n1e+05\n2.718268\n\n\n6\n1e+06\n2.718280\n\n\n7\n1e+07\n2.718282\n\n\n8\n1e+08\n2.718282\n\n\n9\n1e+09\n2.718282\n\n\n10\n1e+10\n2.718282\n\n\n\n\n\n\nWenn \\(r\\) gegen unendlich geht:\n\\[w = e=\\lim _{n\\to \\infty }\\left(1+{\\frac {1}{r}}\\right)^{r}\\]\n\\(e\\) ist das maximale Wachstum, dass man mit sofortiger, stetiger Verzinsung erreichen kann."
  },
  {
    "objectID": "160-e.html#andere-wachstumsraten",
    "href": "160-e.html#andere-wachstumsraten",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.6 Andere Wachstumsraten",
    "text": "16.6 Andere Wachstumsraten\n50% Wachstum:\n\\[\\left(1+{\\frac {.50}{50}}\\right)^{50}=(1+0.01)^{50} \\approx 1.64\\]\nEtwas genauer:\n\n(1 + (.50/50))^50\n## [1] 1.644632\n\n50% Wachstum bedeutet also 50 Phasen mit je 1% Wachstum ‚Ä¶\nMoment, wenn wir 100% Wachstum so darstellen, also als 100 Wachstumsphasen mit je 1% Wachstum:\n\\[\\left(1+{\\frac {1.00}{100}}\\right)^{100}=(1+.01)^{100} \\approx e\\]\n\n(1 + (1.00/100))^100\n## [1] 2.704814"
  },
  {
    "objectID": "160-e.html#wachstum-mit-basis-e",
    "href": "160-e.html#wachstum-mit-basis-e",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.7 Wachstum mit Basis e",
    "text": "16.7 Wachstum mit Basis e\nZwei Perioden Wachstum mit sofortiger, stetiger Verzinsung (100%) erh√∂ht das Kapitel um den Faktor \\(e^2\\). Beginnt man mit dem Kapitel 1, so betr√§gt das Endkapitel (Wachstum):\n\\[w = e \\cdot e = e^2\\]\nW√§chst das Kapitel aber nur mit 50%, so gilt (f√ºr zwei Zeitperioden):\n\\[w= e^{0.5 \\cdot 2} = e^1\\]\nAllgemeiner:\nDas Wachstum \\(w\\) nach \\(t\\) Perioden und Wachstumsfaktor \\(r\\) betr√§gt e hoch dem Produkt von \\(r\\) und \\(z\\):\n\\[w=e^{r\\cdot t}\\]"
  },
  {
    "objectID": "160-e.html#logarithmus",
    "href": "160-e.html#logarithmus",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.8 Logarithmus",
    "text": "16.8 Logarithmus\nW√§chst eine Gr√∂√üe stetig (mit 100%) f√ºr \\(t\\) Zeitr√§ume, so ist der resultierende Wachstumswert \\(w = e^r\\). Der Logarithmus (zur Basis \\(e\\)) liefert den Exponenten, \\(r\\) zur√ºck.\nWachstum f√ºr zwei Perioden:\n\nw &lt;- exp(2)\nw\n## [1] 7.389056\n\nWie viele Perioden waren es noch mal?\n\nlog(w)\n## [1] 2\n\nWie lange dauert es, bis wir das Kapitel verdoppelt haben (stetige Verzinsung mit 100%)?\n\nlog(2)\n## [1] 0.6931472\n\nEs dauert ca. 0.7 Zeitperioden bis zur Verdopplung."
  },
  {
    "objectID": "160-e.html#regel-der-72",
    "href": "160-e.html#regel-der-72",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.9 Regel der 72",
    "text": "16.9 Regel der 72\nVon dieser Zahl her r√ºhrt die ‚ÄúRegel der 72‚Äù.\n72 l√§sst sich angenehm teilen (2,3,4,6,12, ‚Ä¶), besser als 69.31‚Ä¶"
  },
  {
    "objectID": "160-e.html#fazit",
    "href": "160-e.html#fazit",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.10 Fazit",
    "text": "16.10 Fazit\n\n\nWolfi tr√§umt"
  },
  {
    "objectID": "160-e.html#vertiefung",
    "href": "160-e.html#vertiefung",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.11 Vertiefung",
    "text": "16.11 Vertiefung\n\n‚ÄúIntuitive Erkl√§rung zu e‚Äù"
  },
  {
    "objectID": "160-e.html#aufgaben",
    "href": "160-e.html#aufgaben",
    "title": "\n16¬† Staunen mit e\n",
    "section": "\n16.12 Aufgaben",
    "text": "16.12 Aufgaben\n\n‚ÄúFallstudien-Sammlung TMDB‚Äù"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baumer, Benjamin S., Daniel T. Kaplan, and Nicholas J. Horton. 2017.\nModern Data Science with r (Chapman & Hall/CRC\nTexts in Statistical Science). Boca Raton, Florida: Chapman;\nHall/CRC.\n\n\nChen, Tianqi, and Carlos Guestrin. 2016. ‚ÄúXGBoost: A\nScalable Tree Boosting System.‚Äù In Proceedings of the 22nd\nACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, 785‚Äì94. KDD ‚Äô16.\nNew York, NY, USA: Association for Computing\nMachinery. https://doi.org/10.1145/2939672.2939785.\n\n\nFriedman, J. 2001. ‚ÄúGreedy Function Approximation: A Gradient\nBoosting Machine.‚Äù https://doi.org/10.1214/AOS/1013203451.\n\n\nHvitfeldt, Emil. 2022. ISLR Tidymodels Labs. https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nr. Second edition. Springer Texts in Statistics. New York:\nSpringer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive\nModeling. Vol. 26. Springer.\n\n\nRhys, Hefin. 2020. Machine Learning with r, the Tidyverse, and\nMlr. Shelter Island, NY: Manning publications.\n\n\nSauer, Sebastian. 2019. Moderne Datenanalyse Mit r: Daten Einlesen,\nAufbereiten, Visualisieren Und Modellieren. 1. Auflage 2019.\nFOM-Edition. Wiesbaden: Springer. https://www.springer.com/de/book/9783658215866.\n\n\nSilge, Julia, and Max Kuhn. 2022. Tidy Modeling with\nR. https://www.tmwr.org/.\n\n\nSpurzem, Lothar. 2017. VW 1303 von Wiking in 1:87.\nhttps://de.wikipedia.org/wiki/Modellautomobil#/media/File:Wiking-Modell_VW_1303_(um_1975).JPG.\n\n\nTaleb, Nassim Nicholas. 2019. The Statistical Consequences of Fat\nTails, Papers and Commentaries. Monograph. https://nassimtaleb.org/2020/01/final-version-fat-tails/.\n\n\nTimbers, Tiffany-Anne, Trevor Campbell, and Melissa Lee. 2022. Data\nScience: An Introduction. First edition. Statistics. Boca Raton:\nCRC Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data Science:\nVisualize, Model, Transform, Tidy, and Import Data. O‚ÄôReilly Media.\nhttps://r4ds.had.co.nz/index.html."
  }
]