# Kaggle







## Lernsteuerung


###  Lernziele

- Sie wissen, wie man einen Datensatz (eine "Submission") für einen Prognosewettbwerb bei Kaggle einreicht
- Sie kennen einige Beispiele von Notebooks auf Kaggle (für die Sprache R)
- Sie wissen, wie man ein Workflow-Set in Tidymodels berechnet
- Sie wissen, dass Tidymodels im Rezept keine Transformationen im Test-Sample berücksichtigt und wie man damit umgeht
 

###  Hinweise
- Machen Sie sich mit Kaggle vertraut. Als Übungs-Wettbewerb dient uns `TMDB Box-office Revenue` (s. Aufgaben)
  





### R-Pakete


In diesem Kapitel werden folgende R-Pakete benötigt:

```{r echo = TRUE}
library(tidyverse)
library(tidymodels)
library(tictoc)  # Rechenzeit messen
library(lubridate)  # Datumsangaben
library(VIM)  # fehlende Werte
library(visdat)  # Datensatz visualisieren
```


## Was ist Kaggle?


>Kaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.

[Quelle](https://en.wikipedia.org/wiki/Kaggle)


[Kaggle as AirBnB for Data Scientists?!](https://www.kaggle.com/getting-started/44916)


## Fallstudie TMDB

Wir bearbeiten hier die Fallstudie [TMDB Box Office Prediction - 
Can you predict a movie's worldwide box office revenue?](https://www.kaggle.com/competitions/tmdb-box-office-prediction/overview),
ein [Kaggle](https://www.kaggle.com/)-Prognosewettbewerb.

Ziel ist es, genaue Vorhersagen zu machen,
in diesem Fall für Filme.



### Aufgabe

Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score!


### Hinweise

- Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden.
- Halten Sie das Modell so einfach wie möglich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere Schnörkel.
- Logarithmieren Sie `budget` und `revenue`.
- Minimieren Sie die Vorverarbeitung (`steps`) so weit als möglich.
- Verwenden Sie `tidymodels`.
- Die Zielgröße ist `revenue` in Dollars; nicht in "Log-Dollars". Sie müssen also rücktransformieren,
wenn Sie `revenue` logarithmiert haben.



### Daten


```{r echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Die Daten können Sie von der Kaggle-Projektseite beziehen oder so:

```{r}
d_train_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv"
d_test_path <- "https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv"
```


Wir importieren die Daten von der Online-Quelle:

```{r}
d_train_raw <- read_csv(d_train_path)
d_test <- read_csv(d_test_path)
```


Mal einen Blick werfen:

```{r}
glimpse(d_train_raw)
glimpse(d_test)
```


### Train-Set verschlanken

Da wir aus Gründen der Einfachheit einige Spalten nicht berücksichtigen,
entfernen wir diese Spalten,
was die Größe des Datensatzes massiv reduziert.

```{r}
d_train <-
  d_train_raw %>% 
  select(popularity, runtime, revenue, budget, release_date) 
```








### Datensatz kennenlernen




```{r}
library(visdat)
vis_dat(d_train)
```


### Fehlende Werte prüfen

Welche Spalten haben viele fehlende Werte?


```{r}
vis_miss(d_train)
```


Mit `{VIM}` kann man einen Datensatz gut auf fehlende Werte hin untersuchen:

```{r}
aggr(d_train)
```


## Rezept

### Rezept definieren


```{r}
rec1 <-
  recipe(revenue ~ ., data = d_train) %>% 
  #update_role(all_predictors(), new_role = "id") %>% 
  #update_role(popularity, runtime, revenue, budget, original_language) %>% 
  #update_role(revenue, new_role = "outcome") %>% 
  step_mutate(budget = if_else(budget < 10, 10, budget)) %>% 
  step_log(budget) %>% 
  step_mutate(release_date = mdy(release_date)) %>% 
  step_date(release_date, features = c("year", "month"), 
keep_original_cols = FALSE) %>% 
  step_impute_knn(all_predictors()) %>% 
  step_dummy(all_nominal())

rec1
```

```{r}
tidy(rec1)
```



### Check das Rezept 


```{r}
prep(rec1, verbose = TRUE)
```



```{r}
prep(rec1) %>% 
  bake(new_data = NULL) 
```


Wir definieren eine Helper-Funktion:

```{r}
sum_isna <- function(x) {sum(is.na(x))}
```


Und wenden diese auf jede Spalte an:

```{r}
prep(rec1) %>% 
  bake(new_data = NULL) %>%  
  map_df(sum_isna)
```


Keine fehlenden Werte mehr *in den Prädiktoren*.

Nach fehlenden Werten könnte man z.B. auch so suchen:

```{r descr-distr}
datawizard::describe_distribution(d_train)
```


So bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache.

### Check Test-Sample

Das Test-Sample backen wir auch mal.

Wichtig: Wir preppen den Datensatz mit dem *Train-Sample*.

```{r}
bake(prep(rec1), new_data = d_test) %>% 
  head()
```




## Kreuzvalidierung


```{r cv-scheme}
cv_scheme <- vfold_cv(d_train,
  v = 5, 
  repeats = 3)
```


## Modelle

### Baum


```{r}
mod_tree <-
  decision_tree(cost_complexity = tune(),
tree_depth = tune(),
mode = "regression")
```



### Random Forest


```{r}
doParallel::registerDoParallel()
```


```{r rand-for-def}
mod_rf <-
  rand_forest(mtry = tune(),
  min_n = tune(),
  trees = 1000,
  mode = "regression") %>% 
  set_engine("ranger", num.threads = 4)
```



### XGBoost


```{r xgboost-def}
mod_boost <- boost_tree(mtry = tune(),
min_n = tune(),
trees = tune()) %>% 
  set_engine("xgboost", nthreads = parallel::detectCores()) %>% 
  set_mode("regression")
```


### LM


```{r}
mod_lm <-
  linear_reg()
```



## Workflows


```{r wfs}
preproc <- list(rec1 = rec1)
models <- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm)
 
 
all_workflows <- workflow_set(preproc, models)
```


## Fitten und tunen


```{r fit-the-whole-shebang}
if (file.exists("objects/tmdb_model_set.rds")) {
  tmdb_model_set <- read_rds("objects/tmdb_model_set.rds")
} else {
  tic()
  tmdb_model_set <-
all_workflows %>% 
workflow_map(
  resamples = cv_scheme,
  grid = 10,
#  metrics = metric_set(rmse),
  seed = 42,  # reproducibility
  verbose = TRUE)
  toc()
}
```


Man könnte sich das Ergebnisobjekt abspeichern, 
um künftig Rechenzeit zu sparen:

```{r eval = FALSE}
write_rds(tmdb_model_set, "objects/tmdb_model_set.rds")
```


*Aber Achtung:* Wenn Sie vergessen, das Objekt auf der Festplatte zu aktualisieren, haben Sie eine zusätzliche Fehlerquelle. 
Gefahr im Verzug.
Professioneller ist der Ansatz mit dem R-Paket [target](https://books.ropensci.org/targets/).



## Finalisieren


### Welcher Algorithmus schneidet am besten ab?

Genauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus,
sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus
ein spezifischer Datensatz.

```{r}
tune::autoplot(tmdb_model_set) +
  theme(legend.position = "bottom")
```

R-Quadrat ist nicht entscheidend; `rmse` ist wichtiger.

Die Ergebnislage ist nicht ganz klar, aber
einiges spricht für das Boosting-Modell, `rec1_boost1`.


```{r}
tmdb_model_set %>% 
  collect_metrics() %>% 
  arrange(-mean) %>% 
  head(10)
```


```{r}
best_model_params <-
extract_workflow_set_result(tmdb_model_set, "rec1_boost1") %>% 
  select_best()

best_model_params
```



```{r}
best_wf <- 
all_workflows %>% 
  extract_workflow("rec1_boost1")

#best_wf
```


```{r}
best_wf_finalized <- 
  best_wf %>% 
  finalize_workflow(best_model_params)

best_wf_finalized
```

### Final Fit


```{r}
fit_final <-
  best_wf_finalized %>% 
  fit(d_train)

fit_final
```




```{r}
d_test$revenue <- NA

final_preds <- 
  fit_final %>% 
  predict(new_data = d_test) %>% 
  bind_cols(d_test)
```


## Submission


### Submission vorbereiten

```{r}
submission_df <-
  final_preds %>% 
  select(id, revenue = .pred)
```


Abspeichern und einreichen:

```{r eval = FALSE}
write_csv(submission_df, file = "objects/submission.csv")
```

Diese CSV-Datei reichen wir dann bei Kagglei ein.


### Kaggle Score

Diese Submission erzielte einen Score von **4.79227** (RMSLE).


## Miniprojekt


Reichen Sie Ihre Vorhersagen für die [TMDB-Competition](https://www.kaggle.com/competitions/tmdb-box-office-prediction) bei Kaggle ein!

Stellen Sie auch (im Rahmen dieses Wettbewerbs) Ihre Syntax offen. 

Bereiten Sie sich vor, Ihre Analyse zu präsentieren.







## Aufgaben

Schauen Sie sich mal die Kategorie [tmdb](https://datenwerk.netlify.app/#category=tmdb) auf [Datenwerk](https://datenwerk.netlify.app/) an.

Alternativ bietet die Kategorie [tidymodels](https://datenwerk.netlify.app/#category=tidymodels) eine Sammlung von Aufgaben rund um das R-Paket Tidymodels; dort können Sie sich Aufgaben anpassen.



## Kaggle-Fallstudien 

- [Fallstudie Einfache lineare Regression mit Tidymodels, Kaggle-Competition TMDB](https://www.kaggle.com/ssauer/simple-linear-model-tidymodels)
- [Fallstudie Einfaches Random-Forest-Modell mit Tidymodels, Kaggle-Competition TMDB](https://www.kaggle.com/code/ssauer/simple-rf-tuned)
- [Fallstudie Einfache lineare Regression in Base-R, Anfängerniveau, Kaggle-Competition TMDB](https://www.kaggle.com/code/ssauer/tmdb-simple-regression-beginners)
- [Fallstudie Workflow-Set mit Tidymodels, Kaggle-Competition TMDB](https://www.kaggle.com/ssauer/tmdb-xgboost-tidymodels)


  
##  Vertiefung

- [Kaggle-Blog](https://medium.com/kaggle-blog)

