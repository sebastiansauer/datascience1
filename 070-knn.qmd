# kNN

## Lernsteuerung




### √úberblick

In diesem Kapitel geht es um das Verfahren *KNN*, *K-N√§chste-Nachbarn* ($k$ nearest neighbors).


###  Lernziele

- Sie sind in der Lage, einfache Klassifikationsmodelle zu spezifizieren mit tidymodels
- Sie k√∂nnen den knn-Algorithmus erl√§utern
- Sie k√∂nnen den knn-Algorithmus in tidymodels anwenden
- Sie k√∂nnen die G√ºtemetriken von Klassifikationsmodellen einsch√§tzen

###  Literatur

- Rhys, Kap. 3
- [Timbers et al., Kap. 5](https://datasciencebook.ca/classification.html#classification)


## Ben√∂tigte R-Pakete 


```{r}
library(tidymodels)
library(tidyverse)
```

```{r echo = FALSE, message=FALSE}
library(gt)
```



## Intuitive Erkl√§rung

*K-N√§chste-Nachbarn* ($k$ nearest neighbors, kNN) ist ein einfacher Algorithmus des maschinellen Lernens,
der sowohl f√ºr Klassifikation als auch f√ºr numerische Vorhersage (Regression) genutzt werden kann.
Wir werden kNN als Beispiel f√ºr eine Klassifikation betrachten.


Betrachen wir ein einf√ºhrendes Beispiel von @rhys, f√ºr das es eine [Online-Quelle](https://livebook.manning.com/book/machine-learning-for-mortals-mere-and-otherwise/chapter-3/22) gibt.
Stellen Sie sich vor, wir laufen durch englische Landschaft,
vielleicht die Grafschaft Kent, und sehen ein kleines Tier durch das Gras huschen.
Eine Schlange?!
In England gibt es (laut @rhys) nur eine giftige Schlange,
die Otter (Adder). 
Eine andere Schlange, die *Grass Snake* ist nicht giftig,
und dann kommt noch der *Slow Worm* in Frage,
der gar nicht zur Familie der Schlangen geh√∂rt.
Prim√§r interessiert uns die Frage, haben wir jetzt eine Otter gesehen?
Oder was f√ºr ein Tier war es?

Zum Gl√ºck wissen wir einiges √ºber Schlangen bzw. schlangen√§hnliche Tiere Englands.
N√§mlich k√∂nnen wir die betreffenden Tierarten in Gr√∂√üe und Aggressivit√§t einsch√§tzen,
das ist in Abbildung @fig-slang dargestellt.

```{r slang, echo = FALSE, fig.cap = "Haben wir gerade eine Otter gesehen?"}
#| label: fig-slang
knitr::include_graphics("img/rhys-fig3-2.jpeg")
```

Der Algorithmus von kNN sieht einfach gesagt vor,
dass wir schauen, welcher Tierarten Tiere mit √§hnlicher Aggressivit√§t und Gr√∂√üe angeh√∂ren.
Die Tierart die bei diesen "Nachbarn" hinsichtlich √Ñhnlichkeit relevanter Merkmale am h√§ufigsten vertreten ist, ordnen wir die bisher unklassifizierte Beobachtung zu.

Etwas zugespitzt:

>   Wenn es quakt wie eine Ente ü¶Ü, l√§uft wie eine Ente ü¶Üund aussieht wie eine Ente ü¶Ü, dann ist es eine Ente ü¶Ü.


Die Anzahl $k$ der n√§chsten Nachbarn k√∂nnen wir frei w√§hlen; 
der Wert wird *nicht* vom Algorithmuss bestimmt.
Solche vom Nutzi zu bestimmenden Gr√∂√üen nennt man auch *Tuningparameter*.




## Krebsdiagnostik 1

Betrachten wir ein Beispiel von @timbers_data_2022,
das [hier](https://datasciencebook.ca/classification.html#classification-with-k-nearest-neighbors) frei eingesehen werden kann.

Die Daten sind so zu beziehen:


```{r}
data_url <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv"
cancer <- read.csv(data_url)
```

In diesem Beispiel versuchen wir Tumore der Brust zu klassifizieren,
ob sie einen schweren Verlauf (maligne, engl. malignant) oder einen weniger schweren Verlauf (benigne, engl. benign) erwarten lassen.
Der Datensatz ist [hier](https://datasciencebook.ca/classification.html#describing-the-variables-in-the-cancer-data-set) n√§her erl√§utert.


Wie in  @fig-cancer1 ersichtlich,
steht eine Tumordiagnose (malignant vs. benign) in Abh√§ngigkeit
von Umfang (engl. perimeter) und [Konkavit√§t](https://de.wikipedia.org/wiki/Konvexe_und_konkave_Funktionen),
die "Gekr√ºmmtheit nach innen".

```{r fig.cap = "Streudiagramm zur Einsch√§tzung von Tumordiagnosen", echo = FALSE}
#| label: fig-cancer1
perim_concav <- cancer |>
  ggplot(aes(x = Perimeter, y = Concavity, color = Class)) +
  geom_point(alpha = 0.6) +
  labs(x = "Durchmesser (z)", 
       y = "Konkavit√§t (z)",
       color = "Diagnose") +
  scale_color_manual(labels = c("Malign", "Benign"), 
                     values = c("orange2", "steelblue2")) +
  theme(text = element_text(size = 12))
perim_concav
```

In diesem Code-Beispiel wird die seit R 4.1.0 verf√ºgbare R-native Pfeife verwendet. 
Wichtig ist vielleicht vor allem, dass diese Funktion nicht l√§uft auf R-Versionen vor 4.1.0. 
Einige Unterschiede zur seit l√§ngerem bekannten Magrittr-Pfeife sind [hier](https://stackoverflow.com/questions/67633022/what-are-the-differences-between-rs-new-native-pipe-and-the-magrittr-pipe) erl√§utert.

Wichtig ist, dass die Merkmale standardisiert sind, also eine identische Skalierung aufweisen,
da sonst das Merkmal mit kleinerer Skala weniger
in die Berechnung der N√§he (bzw. Abstand) eingeht.

F√ºr einen neuen, bisher unklassifizierten Fall suchen nur nun nach einer Diagnose,
also nach der am besten passenden Diagnose (maligne oder benigne),
s.  @fig-cancer2, wieder aus @timbers_data_2022.
Ihr Quellcode f√ºr dieses Diagramm (und das ganze Kapitel) findet sich [hier](https://github.com/UBC-DSCI/introduction-to-datascience/blob/master/classification1.Rmd).

```{r cancer2, fig.cap = "Ein neuer Fall, bisher unklassifiziert", echo = FALSE}
#| label: fig-cancer2
new_point <- c(2, 4)
attrs <- c("Perimeter", "Concavity")

perim_concav_with_new_point <-  bind_rows(cancer, 
                                          tibble(Perimeter = new_point[1], 
                                                 Concavity = new_point[2], 
                                                 Class = "unknown")) |>
  ggplot(aes(x = Perimeter, 
             y = Concavity, 
             color = Class, 
             shape = Class, 
             size = Class)) +
  geom_point(alpha = 0.6) +
  labs(color = "Diagnosis", x = "Durchmesser (z)", 
       y = "Konkavit√§t (z)") +
  scale_color_manual(name = "Diagnose", 
                     labels = c("Benign", "Malign", "Unbekannt"), 
                     values = c("steelblue2", "orange2", "red")) +
  scale_shape_manual(name = "Diagnose", 
                     labels = c("Benign", "Malign", "Unbekannt"),
                     values= c(16, 16, 18))+ 
  scale_size_manual(name = "Diagnose", 
                    labels = c("Benign", "Malign", "Unbekannt"),
                    values= c(2, 2, 2.5))
perim_concav_with_new_point
```

Wir k√∂nnen zun√§chst den (im euklidischen Koordinatensystem) n√§chst gelegenen Fall (der "n√§chste Nachbar") betrachten,
und vereinbaren, 
dass wir dessen Klasse als Sch√§tzwert f√ºr den unklassiffizierten Fall √ºbernehmen,
s.  @fig-cancer3.




```{r cancer3}
#| echo: false
#| eval: false
new_point <- c(2, 4)
attrs <- c("Perimeter", "Concavity")

euclidDist <- function(point1, point2) {
  # Returns the Euclidean distance between point1 and point2.
  # Each argument is an array containing the coordinates of a point."""
  (sqrt(sum((point1 - point2)^2)))
}

distance_from_point <- function(row) {
  euclidDist(new_point, row)
}

all_distances <- function(training, new_point) {
  # Returns an array of distances
  # between each point in the training set
  # and the new point (which is a row of attributes)
  distance_from_point <- function(row) {
    euclidDist(new_point, row)
  }
  apply(training, MARGIN = 1, distance_from_point)
}

table_with_distances <- function(training, new_point) {
  # Augments the training table
  # with a column of distances from new_point
  data.frame(training, Distance = all_distances(training, new_point))
}

my_distances <- table_with_distances(cancer[, attrs], new_point)
neighbors <- cancer[order(my_distances$Distance), ]

bind_rows(cancer, 
                                          tibble(Perimeter = new_point[1], 
                                                 Concavity = new_point[2], 
                                                 Class = "unknown")) |>
  ggplot(aes(x = Perimeter, 
             y = Concavity, 
             color = Class, 
             shape = Class, size = Class)) +
  geom_point(alpha = 0.6) +
  labs(color = "Diagnosis", 
       x = "Perimeter (standardized)", 
       y = "Concavity (standardized)") +
  scale_color_manual(name = "Diagnosis", 
                     labels = c("Benign", "Malignant", "Unknown"), 
                     values = c("steelblue2", "orange2", "red")) +
  scale_shape_manual(name = "Diagnosis", 
                     labels = c("Benign", "Malignant", "Unknown"),
                     values= c(16, 16, 18))+ 
  scale_size_manual(name = "Diagnosis", 
                    labels = c("Benign", "Malignant", "Unknown"),
                    values= c(2, 2, 2.5)) +  
  geom_segment(aes(
    x = new_point[1],
    y = new_point[2],
    xend = dplyr::pull(neighbors[1, attrs[1]]),
    yend = dplyr::pull(neighbors[1, attrs[2]])
  ), color = "black", size = 0.5)


```


![Ein n√§chster Nachbar](img/cancer3.png){#fig-cancer3}

Betrachten wir einen anderen zu klassifizierenden Fall, s. @fig-cancer4.
Ob hier die Klassifikation von "benign" korrekt ist?
Wom√∂glich nicht, denn viele andere Nachbarn, 
die etwas weiter weg gelegen sind, geh√∂ren zur anderen Diagnose, malign.


```{r cancer4, fig.cap = "Tr√ºgt der n√§chste Nachbar?", echo = FALSE}
#| label: fig-cancer4
knitr::include_graphics("https://datasciencebook.ca/_main_files/figure-html/05-knn-4-1.png")
```

Um die Vorhersage zu verbessern,
k√∂nnen wir nicht nur den n√§chstgelegenen Nachbarn betrachten,
sondern die $k$ n√§chstgelegenen, z.B. $k=3$, s. Abb @fig-cancer5.


```{r cancer5, fig.cap = "kNN mit k=3", echo = FALSE}
#| label: fig-cancer5
knitr::include_graphics("https://datasciencebook.ca/_main_files/figure-html/05-knn-5-1.png")
```


Die Entscheidungsregel ist dann einfach eine Mehrheitsentscheidung:
Wir klassifizieren den neuen Fall entsprechend der Mehrheit in den $k$ n√§chst gelegenen Nachbarn.


## Berechnung der N√§he


Es gibt verschiedenen Algorithmen,
um die N√§he bzw. Distanz der Nachbarn zum zu klassifizieren Fall zu berechnen.

Eine gebr√§uchliche Methode ist der *euklidische* Abstand,
der mit Pythagoras berechnet werden kann, s.  @fig-pyth1 aus @modar.


```{r pyth1, echo = FALSE, fig.cap = "Euklidischer Abstand wird mit der Regel von Pythagoras berechnet"}
#| label: fig-pyth1
knitr::include_graphics("img/distanz_crop.png")
```

Wie war das noch mal?

$$c^2 = a^2 + b^2$$

Im Beispiel oben also:

$c^2 = 3^2 + 4^2 = 5^2$

Damit gilt: $c = \sqrt{c^2} = \sqrt{5^2}=5$.


Im 2D-Raum ist das so einfach, dass man das (fast) mit blo√üem Augenschein entscheiden kann.
In mehr als 2 Dimensionen wird es aber schwierig f√ºr das Auge, wie ein [Beispiel](https://datasciencebook.ca/classification1.html#more-than-two-explanatory-variables) aus @timbers_data_2022 zeigt.


Allerdings kann man den guten alten Pythagoras auch auf Dreiecke mit mehr als zwei Dimensionen anwenden, s.  @fig-pyth2 aus @modar, Kap. 21.1.2.




:::{#fig-pyth2 layout-ncol=2}

![Pythagoras mit mehr als zwei Dimensionen](img/pythagoras-crop.png){#fig-pyth2a}

![Pythagoras mit mehr als zwei Dimensionen](img/pythagoras2-crop.png){#fig-pyth2b}

Pythagoras in der Ebene (links) und in 3D (rechts)

:::



Bleiben wir beim Beispiel von Anna und Berta und nehmen wir eine dritte Variable 
hinzu (Statistikliebe). 
Sagen wir, der Unterschied in dieser dritten Variable zwischen Anna und Berta betrage 2.

Es gilt:

$$
\begin{aligned}
e^2 &= c^2 + d^2 \\
e^2 &= 5^2 + 2^2 \\
e^2 &= 25 + 4\\
e &= \sqrt{29} \approx 5.4
\end{aligned}
$$





## kNN mit Tidymodels




### Analog zu Timbers et al.

Eine Anwendung von kNN mit Tidymodels ist in @timbers_data_2022, Kap. 5.6, [hier](https://datasciencebook.ca/classification.html#k-nearest-neighbors-with-tidymodels) beschrieben.


Die Daten aus @timbers_data_2022 finden sich [in diesem Github-Repo](https://github.com/UBC-DSCI/introduction-to-datascience/tree/master/data)-

Die (z-transformierten) Daten zur Tumorklassifikation k√∂nnen [hier](https://raw.githubusercontent.com/UBC-DSCI/data-science-a-first-intro-worksheets/main/worksheet_classification1/data/clean-wdbc-data.csv) bezogen werden.


```{r}
data_url <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv"
cancer <- read_csv(data_url)
```

@timbers_data_2022 verwenden in Kap. 5 auch noch nicht standardisierte Daten, `unscales_wdbc.csv`, die [hier](https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv) als CSV-Datei heruntergeladen werden k√∂nnen.


```{r}
cancer_unscales_path <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv"

unscaled_cancer <- read_csv(cancer_unscales_path) |>
  mutate(Class = as_factor(Class)) |>
  select(Class, Area, Smoothness)
unscaled_cancer
```


:::{#callout-important}
Damit Tidymodels ein Modell als Klassifikation versteht,
muss die AV als `factor` definiert sein.
Man sollte diese Transformation *au√üerhalb* eines Rezepts druchf√ºhren.$\square$
:::

### Rezept definieren

```{r}
uc_recipe <- recipe(Class ~ ., data = unscaled_cancer)
print(uc_recipe)
```

Und jetzt die z-Transformation:


```{r}
uc_recipe <- 
  uc_recipe |>
  step_scale(all_predictors()) |>
  step_center(all_predictors())
```


Die Schritte `prep()` und `bake()` sparen wir uns, da `fit()` und `predict()` bzw. `last_fit()`
das f√ºr uns besorgen.

### Modell definieren

Tidymodels greift auf den Engine (das Paket) [`kknn`](https://www.rdocumentation.org/packages/kknn/versions/1.3.1/topics/kknn) zur√ºck, das im Standard die Euklidische Distanz aus Distanzma√ü berechnet.
Daher muss die Engine nicht extra spezifiziert werden.


```{r}
knn_spec <-
  nearest_neighbor() |>
  set_mode("classification")
knn_spec
```

In der Voreinstellung wird $k=5$ gew√§hlt.

:::{.callout-note}
### $k$ ist ein Tuningparameter
Der Parameter $k$ im knn-Algorithmus wird nicht √ºber die Daten bestimmt,
sondern muss durch dis Nutzi ausgew√§hlt werden.
Solche Parameter nennt man *Tuningparameter* (synonym: Hyperparameter),
s. @sec-res-tune.$\square$
:::

Das Paket `dials` (Teil von Tidymodels) schl√§gt Werte f√ºr $k$ vor, das ist praktisch. Mehr dazu in @sec-res-tune.


### Workflow definieren und fitten

Unser Workflow ist die "Summe" von Rezept und Modell: 

```{r}
knn_wf <- workflow() |>
  add_recipe(uc_recipe) |>
  add_model(knn_spec) 
```


Welche Variablen waren noch mal Teil des Rezepts?
Mit `str(uc_recipe)` bekommt man eine Einblick in die `str`uktur eines Objekts.
Dann ziehen wir uns das Objekt, das die Infos zu den Variablen im Rezept beheimatet:

```{r}
uc_recipe %>% 
  pluck("var_info")
```
Nat√ºrlich kann man auch einfach seinen Code anschauen. üòÅ


Den Workflow fitten wir dann:

```{r}
knn_fit <- 
  knn_wf |> 
  fit(data = unscaled_cancer)

knn_fit
```




### Vorhersagen


```{r}
new_observation <- 
  tibble(
    Area = c(500, 1500), 
    Smoothness = c(0.075, 0.1)
  )

prediction <- predict(knn_fit, new_observation)

prediction
```



## Krebsdiagnostik 2

Im Kapitel 5 greifen @timbers_data_2022 die Aufteilung in Train- vs. Test-Sample noch nicht auf (aber in Kapitel 6).

Da in diesem Kurs diese Aufteilung aber schon besprochen wurde,
soll dies hier auch dargestellt werden.

```{r}
cancer_split <- initial_split(cancer, strata = Class)
cancer_train <- training(cancer_split)
cancer_test <- testing(cancer_split) 
```



### Rezept definieren

```{r}
cancer_recipe <- recipe(
  Class ~ Smoothness + Concavity, data = cancer_train) |>
  step_scale(all_predictors()) |>
  step_center(all_predictors())
```


### Modell definieren


```{r}
knn_spec <- nearest_neighbor() |>
  #set_engine("kknn") |>
  set_mode("classification")
```



### Workflow definieren


```{r}
knn_wf <- workflow() %>%  
  add_recipe(cancer_recipe) %>% 
  add_model(knn_spec) 

knn_wf
```


### Vorhersagen

Im Gegensatz zu @timbers_data_2022 verwenden wir hier `last_fit()` und `collect_metrics()`,
da wir dies  bereits eingef√ºhrt haben und k√ºnftig darauf aufbauen werden.



```{r}
cancer_test_fit <- last_fit(knn_wf, cancer_split)

cancer_test_fit
```


### Modellg√ºte

```{r}
cancer_test_fit %>% collect_metrics()
```

Die eigentlichen Predictions stecken in der Listenspalte `.predictions` im Fit-Objekt.

```{r}
names(cancer_test_fit)
```

Genau genommen ist `.predictions` eine Listenspalte, in der in jeder Zeile (und damit Zelle) eine Tabelle (Tibble) steht. 
Wir haben nur eine Zeile und wollen das erste Element dieser Spalte herausziehen, die Vorhersagen (Wahrscheinlichkeit) f√ºr benigne Struktur ($\hat{y}$; die Spalte hei√üt √ºbrigens `.pred_B`).
Au√üerdem brauchen wir die tats√§chlichen Diagnosen, $y$, die "wohnen" in der Spalte mit Namen `Class`.
Das Element `.predictions` ist eine Liste(nspalte), die aus Tibbles besteht. 
Ziehen wir uns den ersten Tibble heraus mit `pluck()`:

```{r}
cancer_test_fit %>%  
  pluck(".predictions", 1) %>% str()
```


Nat√ºrlich kann man auch (einfacher) `collect_predictions` verwenden anstelle von `pluck`.

Hat man die Vorhersagen (und die wahren Werte) zur Hand, kann man die richtigen und falschen Werte gegen√ºberstellen lassen.
So eine Tabelle nennt man auch eine *Konfusionsmatrix*^[seltener "Wahrheitsmatrix"]:


```{r comp-conf}
cancer_test_predictions <- 
cancer_test_fit %>% 
  collect_predictions()  # alternativ: pluck(".predictions", 1)

confusion <- cancer_test_predictions |>
             conf_mat(truth = Class, estimate = .pred_class)

confusion
```


### Schwellenwerte

Im Standard wird eine Beobachtung der Klasse mit der h√∂chsten Wahrscheinlichkeit zugeordnet. M√∂chte man das √§ndern, hilft das [R-Paket `probably`](https://probably.tidymodels.org/articles/where-to-use.html).



### Visualisierung

Verbildlichen wir die Konfusionsmatrix, so dass wir sehen welche `B` als `B` klassifiziert wurden und welche `M` als `M` klassifiziert wurden (bzw. welche nicht), s. @fig-conf-bm.



```{r}
#| label: fig-conf-bm
#| fig-cap: "Konfusionsmatrix f√ºr die Krebsdiagnostik. Die Gr√∂√üe eines Rechtecks ist proportional zu der Anzahl der F√§llen dieser Gruppe."
# autoplot(confusion, type = "mosaic")
autoplot(confusion, type = "heatmap") +
  labs(x = "Beobachtung",
       y = "Vorhersage",
       title = "Konfusionsmatrix")
```


## Klassifikationsg√ºte



### Die vier m√∂glichen Ergebnisse eines Tests



Ein Test kann vier verschiedenen Ergebnisse haben:

```{r class-stats, echo = FALSE}
df <- readr::read_csv("children/class_results.csv")

gt::gt(df,
  caption = "Vier Arten von Ergebnissen von Klassifikationen")
```


Von den vier m√∂glichen Ergebnissen sind zwei falsch (und zwei richtig). 
Ein Test kann also zwei Arten von Fehlern machen, s. @fig-4arten.
Dort kann man die Punkte im roten Hintergrund als *kranke* Menschen verstehen (links des schr√§gen Strichs); auf der anderen Seite sind man gesunde Menschen (gr√ºner Hintergrund).
Die Punkte in der Ellipse zeigen die Klassifikationsergebnisse bzw. -fehler.

1. Fehler erster Art: Gesunde als krank klassifizieren ("Fehlalarm")
2. Fehler zweiter Art: Kranke als gesund klassifizieren ("√úbersehfehler")


![Zwei Fehlerarten einer Klassifikation](img/Binary-classification-measures.svg (2).png){#fig-4arten width="50%"}

[Quelle: Von Nichtich - Eigenes Werk, Gemeinfrei](https://commons.wikimedia.org/w/index.php?curid=3494986)


Bei [Wikipedia](https://de.wikipedia.org/wiki/Beurteilung_eines_bin%C3%A4ren_Klassifikators) findet sich eine n√ºtzliche Erl√§uterung der Kennzahlen der Klassifikationsg√ºte, vgl. @fig-sens-fn und @fig-spec-fp.

:::{#fig-sens-fn layout-ncol=2}

![Sensitivit√§t](img/sens-440px-Binary-classification-file_sensitivity.svg.png){#fig-sens}

![FN-Rate](img/fn-rate-Binary-classification-file_false_negative_rate.svg.png){#fig-fn-rante}

Sensitivit√§t und Falsch-Negativrate addieren sich zu 1.
:::


:::{#fig-spec-fp layout-ncol=2}

![Spezifit√§t](img/spec-Binary-classification-file_specifity.svg.png){#fig-spec}

![FP-Rate](img/fp-rate-Binary-classification-file_fallout.svg.png){#fig-fp-rate}

Spezifit√§t und FP-Rate addieren sich zu 1.
:::


:::{.callout-note}
Es ist einfach, in nur einem der beiden Fehlerarten gut abzuschneiden.
So k√∂nnte ein Test alle Personen als *krank* klassifizieren. 
Damit h√§tte er auomatisch keine √úbersehfehler. Leider w√§ren aber potenziell viele Fehlalarme dabei.
Die H√∂he des √úbersehfehler und die H√∂he der Fehlalarme m√ºssen daher nicht gleich sein.
Man muss daher beide Fehlerarten ber√ºcksichtigen, um die G√ºte eines Tests einzusch√§tzen.
Welcher Fehler schwerer wiegt, der Fehlalarm oder der √úbersehfehler,
h√§ngt vom Sachgegenstand ab und ist keine Frage der Statistik.$\square$
:::





### Kennzahlen der Klassfikation


Es gibt eine (verwirrende) Vielfalt von Kennzahlen,
um die G√ºte einer Klassifikation einzusch√§tzen.
In @tbl-diag-stats sind einige davon aufgef√ºhrt.


```{r diag-stats, echo = FALSE}
#| label: tbl-diag-stats
#| tbl-cap: "Gel√§ufige Kennwerte der Klassifikation. F: Falsch. R: Richtig. P: Positiv. N: Negativ"
df <- readr::read_csv("children/diag_stats.csv")

knitr::kable(df)
```




In @modar, Kap. 19.6, findet sich einige Erkl√§rung zu Kennzahlen der Klassifikationsg√ºte.

Auf der [Seite des R-Pakets `yardstick`](https://yardstick.tidymodels.org/reference/index.html) finden Sie eine √úbersicht an unterst√ºtzter Kennzahlen.


### Schwellenwerte der Klassifiktion

Im Standard wird ein Fall der Klasse zugeordnet, die die h√∂chste Wahrscheinlichkeit hat.
Mit dem R-Paket [`probably`](https://probably.tidymodels.org/articles/where-to-use.html) kann man (als Teil eines Post-Processing des Modellierens) diese Schwellenwerte^[engl. thresholds, cutoffs] √§ndern.

:::{#exm-thresholds}
Da eine √Ñrztin auf keinen Fall einen Krebsfall √ºbersehen m√∂chte - da Sie den √úbersehfehler als deutlich schlimmer einsch√§tzt als den Fehlalarm - setzt sie die Schwelle f√ºr die Klasse "Gesund" auf 95%.$\square$
:::


### ROC-Kurve



Eine ROC-Kurve^[Receiver Operating Characteristic Curve] ist ein Graph, der die Modellg√ºte eines Klassfikationsmodells *zu allen Schwellenwerten* aufzeigt.
Eine ROC-Kurve ist eine n√ºtzliche und gebr√§uchliche Methode zur Bestimmung der insgesamten Klassifikationsg√ºte eines Modells.

Die Kurve hat zwei Parameter:

- TP-Rate (Y-Achse)
- FP-Rate (X-Achse)


Praktisch w√ºrde man f√ºr die vorhergesagten Wahrscheinlichkeiten eines Klassifikationsmodells viele Schwellenwerte anlegen, z.B. von 0%, 1%, ..., 100%.
F√ºr jeden Schwellenwert berechnet man die vorhergesagte Klasse.
In `tidymodels` besorgt [`roc_curve`](https://yardstick.tidymodels.org/reference/roc_curve.html) diesen Job:



```{r}
cancer_roc <- 
cancer_test_predictions %>% 
  roc_curve(truth = Class, .pred_B)
cancer_roc
```

Mit `autoplot` kann man dann die ROC-Kurve zeichnen, s. @fig-roc1.

```{r}
#| label: fig-roc1
#| fig-cap: ROC-Kurve f√ºr das Fallbeispiel der Krebsdiagnostik
cancer_test_predictions %>% 
  roc_curve(truth = Class, .pred_B) %>% 
  autoplot()
```


Die *Fl√§che unter der Kurve* (area under curve, AUC), bezogen auf die ROC-Kurve, ist ein Ma√ü f√ºr die G√ºte der Klassifikation. @fig-example-rocs aus @modar stellt drei Beispiele von Klassifikationsg√ºten dar: sehr gute (A), gute (B) und schlechte (C). 
Ein hohe Klassifikationsg√ºte zeigt sich daran, dass eine hohe Richtig-Positiv-Rate mit einer geringen Fehlalarmquote einhergeht: Wir finden alle Kranken, aber nur die Kranken. Die ROC-Kurve "h√§ngt oben links an der Decke"; der AUC-Wert geht gegen 1.
Ein schlechter Klassifikator trifft so gut wie ein M√ºnzwurf: Ist das Ereignis selten, hat er eine hohe Falsch-Positiv-Rate und eine geringe Falsch-Negativ-Rate. 
Ist das Ereignis hingegen h√§ufig, liegen die Fehlerh√∂hen genau umgekehrt: Eine hohe Richtig-Positiv-Rate geht dann mit einer hohen Falsch-Positiv-Rate einher.



```{r example-rocs, echo = FALSE,  out.width = "100%", fig.asp = .3}
#| echo: false
#| label: fig-example-rocs
#| fig-cap: "Beispiel f√ºr eine sehr gute (A), gute (B) und schlechte (C) Klassifikation"
library(plotROC)
library(gridExtra)
D.ex <- rbinom(200, size = 1, prob = .5)
M1 <- rnorm(200, mean = D.ex, sd = .3)
M2 <- rnorm(200, mean = D.ex, sd = 1.5)
M3 <- rnorm(200, mean = D.ex, sd = 10)


test <- data.frame(D = D.ex, D.str = c("Healthy", "Ill")[D.ex + 1],
                   M1 = M1, M2 = M2, stringsAsFactors = FALSE)


p1 <- ggplot(test, aes(d = D, m = M1)) + geom_roc(labels = FALSE) + style_roc() + ggtitle("A")
p2 <- ggplot(test, aes(d = D, m = M2)) + geom_roc(labels = FALSE) + style_roc() + ggtitle("B")
p3 <- ggplot(test, aes(d = D, m = M3)) + geom_roc(labels = FALSE) + style_roc() + ggtitle("C")

grid.arrange(p1, p2, p3, nrow = 1)

```











### Krebstest-Beispiel

Betrachten wir [diese Daten](https://raw.githubusercontent.com/sebastiansauer/datascience1/main/data/Krebstest.csv) eines fiktiven Krebstest, aber mit realistischen Werte, s. @fig-krebstest.

```{r}
krebstest <- read_csv("data/krebstest.csv")
```


```{r echo = FALSE, message=FALSE}
library(vtree)
library(magick)
# krebstest_vtree <- vtree(krebstest, "Krebs Test")
# vtree_png <- grVizToPNG(krebstest_vtree, width = 500,
#                         folder = "img")
krebstest_img <- image_read(paste0("img/krebstest_vtree.png"))
```


```{r}
#| echo: false
#| label: fig-krebstest
#| fig-cap: Kennwerte zu tats√§chlichem und laut Test Krebs-Status
print(krebstest_img)
```

Wie gut ist dieser Test?
Berechnen wir einige Kennzahlen.^[aus dem Paket `{yardstick}`, das Teil von Tidymodels ist. [Hier](https://yardstick.tidymodels.org/) ist die Hilfeseite zum Paket.]

Da die Funktionen zur Klassifikation stets einen Faktor wollen,
wandeln wir die relevanten Spalten zuerst in einen Faktor um (aktuell sind es numerische Spalten).


```{r}
krebstest <-
  krebstest  %>% 
  mutate(Krebs = factor(Krebs),
         Test = factor(Test))
```


Die Konfusionsmatrix ist in @fig-krebs-cm gezeigt.

```{r}
cm_krebs <- conf_mat(krebstest, truth = Krebs, estimate = Test)
cm_krebs
```


```{r}
#| label: fig-krebs-cm
#| echo: false
#| fig-cap: "Konfusionsmatrix f√ºr das Krebs-Beispiel"
autoplot(cm_krebs)
```


Gesamtgenauigkeit:


```{r}
accuracy(krebstest, truth = Krebs, estimate = Test)
```


:::{.callout-important}
Die Kennzahl der Gesamtgenauigkeit z√§hlt nur den Anteil richtiger Klassifikation.
Sind z.B. 95% der Menschen gesund, und wir klassifizieren alle Menschen als gesund,
erreichen wir auf einfachem Weg eine Gesamtgenauigkeit von 95%.
Trotz dieses scheinbar hohen Werts haben wir alle kranken Menschen fehlklassifiziert.
In dem Fall, wie die Klassen (krank vs. gesund) ungleich gro√ü sind, sinkt die N√ºtzlichkeit dieser Kennzahl.
Aber sie kann als Referenzwert herhalten, an dem sich andere Modelle messen lassen m√ºssen.
N√ºtzliche Alternativen sind dann z.B. Cohens Kappa oder ROC-AUC. Oder man schaut sich mehrere Kennwerte an, was meist der richtige Weg ist.
$\square$
:::



Sensitivit√§t:

```{r}
sens(krebstest, truth = Krebs, estimate = Test)
```

Spezifit√§t:

```{r}
yardstick::spec(krebstest, truth = Krebs, estimate = Test)
```

[Cohens Kappa](https://de.wikipedia.org/wiki/Cohens_Kappa):

```{r}
yardstick::kap(krebstest, truth = Krebs, estimate = Test)
```

Ein Wert von 0 zeigt eine Klassifikation an, die von einer Zufallzuordnung nicht zu unterscheiden ist.
Ein Wert von 1 zeigt eine perfekte Klassifikation an.
Damit ist Kappa eine Kennzahl der Gesamtgenauigkeit einer Klassifikation,
die das Problem ungleicher Klassengr√∂√üen, worunter die Kennzahl Gesamtgenauigkeit leider,
umgeht.


Positiver Vorhersagewert:

```{r}
ppv(krebstest, truth = Krebs, estimate = Test)
```

Negativer Vorhersagewert:

```{r}
npv(krebstest, truth = Krebs, estimate = Test)
```

W√§hrend Sensitivit√§t und Spezitivit√§t sehr hoch sind,
ist die der negative Vorhersagewert sehr gering:

Wenn man einen positiven Test erh√§lt, ist die 
Wahrscheinlichkeit, in Wahrheit krank zu sein gering, zum Gl√ºck!



Mit `metrics` kann man sich eine Auswahl von Metriken (der Modellg√ºte) anzeigen lassen:

```{r}
metrics(krebstest, truth = Krebs, estimate = Test)
```

Man kann sich auch eine "eigene" Funktion `metrics` erstellen, bzw. `metrics` √§ndern:

```{r}
my_metrics <- metric_set(accuracy, ppv, sensitivity)
```

Diese Funktion ruft man dann genauso auf wie `metrics`:

```{r}
my_metrics(krebstest, truth = Krebs, estimate = Test)
```




## Aufgaben

- Arbeiten Sie sich so gut als m√∂glich durch [diese Analyse zum Verlauf von Covid-F√§llen](https://github.com/sebastiansauer/covid-icu)
- [Fallstudie zur Modellierung einer logististischen Regression mit tidymodels](https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/)
- [Fallstudie zu Vulkanausbr√ºchen](https://juliasilge.com/blog/multinomial-volcano-eruptions/)
- [Fallstudie Himalaya](https://juliasilge.com/blog/himalayan-climbing/)
- [Fallstudie Immobilienpreise von Jan Kirzenz](https://www.kirenz.com/post/2021-02-17-r-classification-tidymodels/); diese Fallstudie beinhaltet mehrere Lernalgorithmen, die Sie vielleicht noch nicht kennen. 

Falls Sie in einer Fallstudie auf Inhalte treffen, die Sie noch nicht kennen: Im Zweifel einfach ignorieren.


## Fazit

*Keep kalm and proceed* üòé




