{"options":{"chapters":true},"headings":["lernsteuerung","vorbereitung","lernziele","literatur","hinweise","r-pakete","was-ist-data-science","was-ist-machine-learning","algorithmus","rule-based","data-based","modell-vs.-algorithmus","modell","beispiel-für-einen-ml-algorithmus","taxonomie","geleitetes-lernen","regression-numerische-vorhersage","klassifikation-nominale-vorhersage","ungeleitetes-lernen","ziele-des-ml","sec-overfit","overfitting","underfitting","beispiel-1","beispiel-2","mittlere-modellkomplexität-ist-optimal","do-it-yourself-under-overfitting","train--und-test-datensatz","overfitting-1","overfitting-2","no-free-lunch","bias-varianz-abwägung","vertiefung","aufgaben","videos"],"entries":[{"caption":"","order":{"number":1,"section":[4,3,0,0,0,0,0]},"key":"exm-algo"},{"caption":"Algorithmus","order":{"number":2,"section":[4,3,0,0,0,0,0]},"key":"def-algo"},{"caption":"Overfitting 2","order":{"number":2,"section":[4,7,4,0,0,0,0]},"key":"exr-overfitting2"},{"caption":"Wenig (links) vs. viel (rechts) Vorhersagefehler","order":{"number":13,"section":[4,6,0,0,0,0,0]},"key":"fig-resid"},{"caption":"Grad 4","parent":"fig-poly","order":{"number":4},"key":"fig-poly-4"},{"caption":"Geleitetes Lernen geschieht in zwei Phasen","order":{"number":9,"section":[4,5,1,0,0,0,0]},"key":"fig-supervid"},{"caption":"Overfitting","order":{"number":1,"section":[4,7,4,0,0,0,0]},"key":"exr-overfitting"},{"caption":"Taxonomie der Arten des maschinellen Lernens","order":{"number":8,"section":[4,5,0,0,0,0,0]},"key":"fig-taxonomie"},{"caption":"Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem höheren Vorhersagefehler (bei neuen Daten!) resultieren","order":{"number":18,"section":[4,8,0,0,0,0,0]},"key":"fig-2-10"},{"caption":"Gegenstand und Modell","order":{"number":7,"section":[4,4,1,0,0,0,0]},"key":"fig-modell"},{"caption":"Polynome vom Grad 1-4","order":{"number":16,"section":[4,7,4,0,0,0,0]},"key":"fig-poly"},{"caption":"Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung","order":{"number":19,"section":[4,8,0,0,0,0,0]},"key":"fig-2-11"},{"caption":"Vorhersage des Einkommens durch Ausbildungsjahre","order":{"number":3,"section":[4,3,2,0,0,0,0]},"key":"fig-statlearning"},{"caption":"Grad 2","parent":"fig-poly","order":{"number":2},"key":"fig-poly-2"},{"caption":"Mittlere Modellkomplexität führt zur besten Vorhersagegüte: Gute Balance von Bias und Präzision","order":{"number":15,"section":[4,7,3,0,0,0,0]},"key":"fig-overfitting"},{"caption":"4.7 Über- vs. Unteranpassung","order":{"number":1,"section":[4,7,0,0,0,0,0]},"key":"sec-overfit"},{"caption":"Abwängung von Bias vs. Varianz","order":{"number":20,"section":[4,9,0,0,0,0,0]},"key":"fig-bias-var"},{"caption":"Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren","order":{"number":4,"section":[4,3,2,0,0,0,0]},"key":"fig-sl2"},{"caption":"Grad 1","parent":"fig-poly","order":{"number":1},"key":"fig-poly-1"},{"caption":"Grad 3","parent":"fig-poly","order":{"number":3},"key":"fig-poly-3"},{"caption":"Ein Modell-Auto","order":{"number":6,"section":[4,4,1,0,0,0,0]},"key":"fig-vw"},{"caption":"Vergleich von klassischer KI (rule-based) und ML (data-based)","order":{"number":5,"section":[4,3,2,0,0,0,0]},"key":"fig-ki-ml2"},{"caption":"KI und Maschinelles Lernen","order":{"number":1,"section":[4,3,0,0,0,0,0]},"key":"fig-ai-ml2"},{"caption":"Zwei Arten des ungeleitete Modellieren","order":{"number":11,"section":[4,5,2,0,0,0,0]},"key":"fig-ungel"},{"caption":"ML-Matroschka","order":{"number":2,"section":[4,3,0,0,0,0,0]},"key":"fig-algos"},{"caption":"Overfitting","order":{"number":3,"section":[4,7,0,0,0,0,0]},"key":"def-overfit"},{"caption":"Ziele des maschinellen Lernens","order":{"number":12,"section":[4,6,0,0,0,0,0]},"key":"fig-ziele"},{"caption":"","order":{"number":1,"section":[4,3,0,0,0,0,0]},"key":"def-ml"},{"caption":"Train- und Test-Datensatz","order":{"number":5,"section":[4,7,4,0,0,0,0]},"key":"def-traintest"},{"caption":"Over- vs. Underfitting","order":{"number":14,"section":[4,7,1,0,0,0,0]},"key":"fig-overunder"},{"caption":"Underfitting","order":{"number":4,"section":[4,7,0,0,0,0,0]},"key":"def-underfit"},{"caption":"In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut","order":{"number":17,"section":[4,7,4,0,0,0,0]},"key":"fig-polytest"},{"caption":"Die zwei Phasen des unüberwachten Lernens","order":{"number":10,"section":[4,5,2,0,0,0,0]},"key":"fig-unsuper"}]}