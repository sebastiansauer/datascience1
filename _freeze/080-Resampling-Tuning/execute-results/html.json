{
  "hash": "61dd6e350b2e7f242a9e1ed6c25a9b6f",
  "result": {
    "markdown": "# Resampling und Tuning\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-1_a4ddb5e8314c9e73856ba49c84032ff7'}\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Lernsteuerung\n\n\n### Lernziele\n- Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.\n- Sie können Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.\n    \n### Vorbereitung\n- Lesen Sie die Literatur.\n\n###  Literatur\n- Rhys, Kap. 3\n- TMWR, Kap. 10, 12\n\n\n### Benötigte R-Pakete\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/libs-resampling-tuning_7b991e6c2516e8f0a997958e23d5ae2e'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tune)  #  wird nicht autaomtisch mit tidymodels gestartet\n```\n:::\n\n\n\n## Überblick\n\n\n\n\n\n\nDer Standardablauf des maschinellen Lernens ist in @fig-process1 dargestellt.\nEine alternative, hilfreich Abbildung findet sich [hier](https://www.tmwr.org/resampling.html) in Kap. 10.2 in @silge_tidy_2022.\n\n\n```{mermaid}\n%%| label: fig-process1\n%%| fig-cap: Standardablauf des maschinellen Lernens mit Tuning und Resampling\n\nflowchart TD\n   \nGesamtdatensatz --> Split[In Train- und Test aufteilen]\nsubgraph Fit[Für jeden Modellkandidaten i]\n  subgraph Kand[Modellkandidat i]\n  F[Fitte im Train-S] --> T[Teste im Assessment-S]\n  end\nend\nSplit --> Fit\nFit --> Best[Bestimmte besten Kandidaten]\nBest --> lastFit[Fitte ihn im ganzen Train-S]\nlastFit --> test[Teste im Tes-S]\n```\n\n\n\n\n\n\n\n\n\n## tidymodels\n\n\n### Datensatz aufteilen\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-split_a5df97c83b871b3e743eb1c3456bad56'}\n\n```{.r .cell-code}\ndata(ames)\n\nset.seed(4595)\ndata_split <- initial_split(ames, strata = \"Sale_Price\")\n\names_train <- training(data_split)\names_test <- testing(data_split)\n```\n:::\n\n\n\n### Rezept, Modell und Workflow definieren\n\nIn gewohnter Weise definieren wir den Workflow\nmit einem kNN-Modell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-wf_56d506a0044e16443a75ff3baa26c0d7'}\n\n```{.r .cell-code}\names_rec <-\n  recipe(Sale_Price ~ ., data = ames_train) %>%\n  step_log(Sale_Price, base = 10) %>%\n  step_other(Neighborhood, threshold = .1)  %>%\n  step_dummy(all_nominal()) %>%\n  step_zv(all_predictors()) \n\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\",\n  ) %>%\n  set_engine(\"kknn\")\n\names_wflow <-\n  workflow() %>%\n  add_recipe(ames_rec) %>%\n  add_model(knn_model)\n```\n:::\n\n\nDas kNN-Modell ist noch *nicht* *berechnet*,\nes ist nur ein \"Rezept\" erstellt:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-3_2b67a03ba6eb05a11365727e433c2b1c'}\n\n```{.r .cell-code}\nknn_model\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Computational engine: kknn\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-4_c96d699304eea6b8e7a6b4d643323350'}\n\n```{.r .cell-code}\names_wflow\n## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 4 Recipe Steps\n## \n## • step_log()\n## • step_other()\n## • step_dummy()\n## • step_zv()\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Computational engine: kknn\n```\n:::\n\n\n\n\n## Resampling\n\n\nVergleichen Sie die drei Fälle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:\n\n1. Wir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe \"vorher\". Wir finden eine Gesamtgenauigkeit von 80%.\n2. Wir fitten ein Klassifikationsmodell in einem Teil der ursprünglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der ursprünglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.\n3. Wir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der Fälle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.\n\n\nWelchen der drei Fälle finden Sie am sinnvollsten? Warum?\n\n\n\n## Illustration des Resampling\n\n*Resampling* stellt einen Oberbegriff dar; *Kreuzvalidierung* ist ein Unterbegriff dazu.\nEs gibt noch andere Arten des Resampling, etwa *Bootstrapping* oder *Leave-One-Out-Cross-Validation* (LOOCV).\n\nIm Folgenden ist nur die Kreuzvalidierung dargestellt,\nda es eines der wichtigsten und vielleicht das Wichtigste ist.\nIn vielen Quellen finden sich Erläuterungen anderer Verfahren dargestellt,\netwa in @silge_tidy_2022, @islr oder @rhys.\n\n\n\n\n### Einfache v-fache Kreuzvalidierung\n\n@fig-resampling illustriert die zufällige Aufteilung von $n=10$ Fällen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe. \nMan spricht von *Kreuzvalidierung* (cross validation, CV).\n\nIn diesem Fall wurden 70% der ($n=10$) Fälle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe);\nein willkürlicher, aber nicht unüblicher Anteil.\nDiese Aufteilung wurde $v=3$ Mal vorgenommen,\nes resultieren drei \"Resampling-Stichproben\", die\nmanchmal auch als \"Faltungen\" bezeichnet werden.\n\n\n\n::: {.cell messagen='false' hash='080-Resampling-Tuning_cache/html/fig-resampling_1b39eb81b6c542698cd170d9cfb81257'}\n::: {.cell-output-display}\n![Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt](080-Resampling-Tuning_files/figure-html/fig-resampling-1.png){#fig-resampling width=100%}\n:::\n:::\n\n\n\n\n\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvmodar.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvmodar_d53146a97b478773a81f015de9ef1f19'}\n::: {.cell-output-display}\n![Kreuzvalidierung, Aufteilung in Train- vs. Testsample](img/crossval.png){#fig-cvmodar width=861}\n:::\n:::\n\n\n\nDer Gesamtfehler der Vorhersage wird als Mittelwerte der Vorhersagefehler in den einzelnen Faltungen berechnet.\n\nWarum ist die Vorhersage besser,\nwenn man mehrere Faltungen, mehrere Schätzungen für $y$ also, vornimmt?\n\nDer Grund ist das Gesetz der großen Zahl,\nnachdem sich eine Schätzung in Mittelwert und Variabilität stabilisiert mit steigendem\nStichprobenumfang,\ndem wahren Mittelwert also präziser schätzt.\nBei Normalverteilungen klappt das gut,\nbei randlastigen Verteilungen leider nicht mehr [@fattails].\n\n\n\nHäufig werden $v=10$ Faltungen verwendet,\nwas sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.\n\n\n\n\n### Wiederholte Kreuzvalidierung\n\n\nDie $r$-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (nämlich $r=4$ mal),\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvrep.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvrep_c9fae0c3bbdfc82690b35729aae4bf33'}\n::: {.cell-output-display}\n![Wiederholte Kreuzvalidierung](img/crossval_repeated.png){#fig-cvrep width=916}\n:::\n:::\n\n\nDie wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.\n\n@silge_tidy_2022 zeigen die Verringerung des Schätzfehlers als Funktion der $r$ Wiederholungen dar,\ns. @fig-repcvred.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-repcvred_0dc4a9002cf6d8b9edec77e8711509b8'}\n::: {.cell-output-display}\n![Reduktion des Schätzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung](https://www.tmwr.org/figures/variance-reduction-1.png){#fig-repcvred}\n:::\n:::\n\n\n\nWarum ist die Wiederholung der Kreuzvalidierung nützlich?\n\nDie Kreuvalidierung liefert einen Schätzwert der Modellparameter,\ndie wahren Modellparameter werden also anhand einer Stichprobe von $n=1$ geschätzt.\nMit höherem Stichprobenumfang kann diese Schätzung natürlich präzisiert werden.\n\nDa jede Stichprobenverteilung bei $n \\rightarrow \\infty$ normalverteilt ist - \nein zentrales Theorem der Statistik, der *Zentrale Grenzwertsatz* (Central Limit Theorem) - \nkann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem $n$ ebenfalls annähernd\nnormalverteilt^[Das klappt bei randlastigen Verteilungen nicht]. \nDann sind die Quantile bekannt und man kann die Streuung der Schätzers, \n${\\sigma }_{\\bar {x}}$, z.B. für den Mittelwert,\neinfach schätzen:\n\n$${\\displaystyle {\\sigma }_{\\bar {x}}\\ ={\\frac {\\sigma }{\\sqrt {n}}}}$$\n\n\n### Resampling passiert im Train-Sample\n\nWichtig zu beachten ist, dass\ndie Resampling nur im Train-Sample stattfindet.\nDas Test-Sample bleibt unangerührt.\nDieser Sachverhalt ist in @fig-initialsplit, aus @silge_tidy_2022, illustriert.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-initialsplit_d96efecaf6968b46dcb18c5445ede02d'}\n::: {.cell-output-display}\n![Resampling im Train-, nicht im Test-Sample](https://www.tmwr.org/premade/resampling.svg){#fig-initialsplit}\n:::\n:::\n\n\n\n\nWie in @fig-initialsplit dargestellt,\nwird das Modell im *Analyse-Sample* berechnet (gefittet),\nund im *Assessment-Sample* auf Modellgüte hin überprüft.\n\nDie letztliche Modellgüte ist dann die Zusammenfassung (Mittelwert) der einzelnen Resamples.\n\n\n### Andere Illustrationen\n\n\nEs gibt eine Reihe vergleichbarer Illustrationen in anderen Büchern:\n\n- [Timbers, Campbell & Lee, 2022, Kap. 6](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.1](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.2](https://www.tmwr.org/premade/three-CV.svg)\n- [Silge & Kuhn, 2022, 10.3](https://www.tmwr.org/premade/three-CV-iter.svg)\n- James, Witten, hastie & Tishirani, 2021, 5.3\n\n\n\n## Gesetz der großen Zahl\n\nNach dem *Gesetz der großen Zahl* (Law of Large Numbers) sollte sich der Mittelwert einer großen Stichprobe \ndem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess) \nsehr nahe kommen.\n\n$$\\displaystyle \\lim _{n\\to \\infty }\\sum _{i=1}^{n}{\\frac {X_{i}}{n}}={\\overline {X}}$$\n\nDavid Salazar visualisiert das folgendermaßen in [diesem Post](https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/) seines lesenswerten [Blogs](https://david-salazar.github.io/), s. @fig-lln).\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-lln_116dd9cc6960879ce9c7b09f1f28276d'}\n\n```{.r .cell-code}\n# source: https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/\nsamples <- 1000\n\nthin <- rnorm(samples, sd = 20)\n\ncumulative_mean <- function(numbers) {\n    x <- seq(1, length(numbers))\n    cum_mean <- cumsum(numbers)/x \n    cum_mean\n}\n\nthin_cum_mean <- cumulative_mean(thin)\n\nthin_cum_mean %>%\n  tibble(running_mean = .) %>% \n  add_rownames(var = 'number_samples') %>% \n  mutate(number_samples = as.double(number_samples)) %>% \n  arrange(number_samples) %>% \n  ggplot(aes(x = number_samples, y = running_mean)) +\n    geom_line(color = 'dodgerblue4') +\n    geom_hline(yintercept = 0, linetype = 2, color = 'red') +\n  hrbrthemes::theme_ipsum_rc(grid = 'Y') +\n  scale_x_continuous(labels = scales::comma) +\n  labs(x = \"Stichprobengröße\",\n       title = \"Gesetz der großen Zahl\", \n       subtitle = \"Kumulierter Mittelwert aus einer Normalverteilung mit sd=20\")\n```\n\n::: {.cell-output-display}\n![Gesetz der großen Zahl](080-Resampling-Tuning_files/figure-html/fig-lln-1.png){#fig-lln width=672}\n:::\n:::\n\n\nWie man sieht, nähert sich der empirische Mittelwert (also in der Stichprobe)\nimmer mehr dem theoretischen Mittelwert, 0, an.\n\nAchtung: Bei randlastigen Verteilungen darf man dieses schöne, wohlerzogene Verhalten nicht erwarten [@fattails].\n\n\n\n\n\n## Über- und Unteranpassung an einem Beispiel\n\n\n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-overfitting-4-plots_53adb86192f1fc826682da08dd250bda'}\n::: {.cell-output-display}\n![Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die 'wahre Funktion', der datengenerierende Prozess ist im Teil A dargestellt](080-Resampling-Tuning_files/figure-html/fig-overfitting-4-plots-1.png){#fig-overfitting-4-plots width=100%}\n:::\n:::\n\n\n@fig-overfitting-4-plots zeigt:\n\n- Teil *A*: Die 'wahre Funktion', $f$, die die Daten  erzeugt. Man spricht auch von der \"datengenerierenden Funktion\". Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das heißt nicht, dass die wahre Funktion die Daten perfekt erklärt, schließlich kann die Funktion zwar wahr, aber unvollständig sein oder unsere Messinstrumente sind nicht perfekt präzise.\n- Teil *B:* Die Daten, erzeugt aus A plus etwas zufälliges Fehler (Rauschen).\n- Teil *C*: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *D*: Ein zu komplexes Modell: Überanpassung.  Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *E*: Ein Modell mittlerer Komplexität. Keine Überanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.\n\n\n\n## CV in tidymodels\n\n### CV definieren\n\nSo kann man eine *einfache* v-fache Kreuzvalidierung in Tidymodels auszeichnen:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-7_5c2a1082a16dc57d6ac1a33ef6c1df56'}\n\n```{.r .cell-code}\nset.seed(2453)\names_folds <- vfold_cv(ames_train, strata = \"Sale_Price\")\names_folds\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWerfen wir einen Blick in die Spalte `splits`, erste Zeile:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-8_3e749cb21cbd332b9a45673bd0fe5346'}\n\n```{.r .cell-code}\names_folds %>% pluck(1, 1)\n## <Analysis/Assess/Total>\n## <1976/221/2197>\n```\n:::\n\n\n\nMöchte man die Defaults vpn `vfold_cv` wissen, schaut man in der Hilfe nach: `?vfold_cv`:\n\n\n`vfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)` \n\n\nProbieren wir $v=5$ und $r=2$:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-9_a6fcf0bf92ed704d36c181d6ec980a4b'}\n\n```{.r .cell-code}\names_folds_rep <- vfold_cv(ames_train, \n                           strata = \"Sale_Price\", \n                           v = 5,\n                           repeats = 2)\names_folds_rep\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id2\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat1\",\"3\":\"Fold1\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat1\",\"3\":\"Fold2\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat1\",\"3\":\"Fold3\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat1\",\"3\":\"Fold4\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat1\",\"3\":\"Fold5\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat2\",\"3\":\"Fold1\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat2\",\"3\":\"Fold2\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat2\",\"3\":\"Fold3\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat2\",\"3\":\"Fold4\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat2\",\"3\":\"Fold5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Resamples fitten\n\n\nHat unser Computer mehrere Rechenkerne, dann können wir diese nutzen und die Berechnungen beschleunigen.\nIm Standard wird sonst nur ein Kern verwendet.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-10_85e675fcf613092f61b3a4d96ba5b1fd'}\n\n```{.r .cell-code}\nmycores <- parallel::detectCores(logical = FALSE)\nmycores\n## [1] 4\n```\n:::\n\n\nAuf Unix/MacOC-Systemen kann man dann die Anzahl der parallen Kerne so einstellen^[In Windows gibt es andere Wege.]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-11_c2c4e07673b264acc17b271561b444e5'}\n\n```{.r .cell-code}\nlibrary(doMC)\nregisterDoMC(cores = mycores)\n```\n:::\n\n\n\n\nSo, und jetzt fitten wir die Resamples und trachten die Modellgüte in den Resamples:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-12_375c3442c36475423e6645dc36aa43cc'}\n\n```{.r .cell-code}\names_resamples_fit <- \n  ames_wflow %>% \n  fit_resamples(ames_folds)\n\n ames_resamples_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.09281732\",\"4\":\"10\",\"5\":\"0.001871143\",\"6\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.72161155\",\"4\":\"10\",\"5\":\"0.008644440\",\"6\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nNatürlich interessiert uns primär die Modellgüte im Test-Sample:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-13_844070c735242fce0cd72cb9519558b9'}\n\n```{.r .cell-code}\nfinal_ames <-\n  last_fit(ames_wflow, data_split)\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-14_cf7e101883238c44c455330b4c85dbfe'}\n\n```{.r .cell-code}\nfinal_ames %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.1029721\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.6783940\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## Tuning\n\n### Tuning auszeichnen\n\nIn der Modellspezifikation des Modells können wir mit `tune()` auszeichnen,\nwelche Parameter wir tunen möchten. \nWir könenn\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-15_5b87132ddfd7d60ad06c35e9be2722b8'}\n\n```{.r .cell-code}\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()\n  ) %>%\n  set_engine(\"kknn\")\n```\n:::\n\n\n\nWir können dem Tuningparameter auch einen Namen (ID/Laben) geben, z.B. \"K\":\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-16_507372555fb1c7c46a5eacca77711a04'}\n\n```{.r .cell-code}\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\")\n  ) %>%\n  set_engine(\"kknn\")\n```\n:::\n\n\n\n### Grid Search vs. Iterative Search\n\n\nIm K-Nächste-Nachbarn-Modell ist der vorhergesagt Wert, $\\hat{y}$ für eine neue Beobachtung $x_0$ wie folgt definiert:\n\n$$\n\\hat y = \\frac{1}{K}\\sum_{\\ell = 1}^K x_\\ell^*,\n$$\n\nwobei $K$ die Anzahl der zu berücksichtigen nächsten Nachbarn darstellt und $x_\\ell^*$ die Werte dieser berücksichtiggten Nachbarn.\n\nDie Wahl von $K$ hat einen gewaltigen Einfluss auf die Vorhersagen und damit auf die Vorhersagegüte.\nAllerdings wird $K$ nicht vom Modell geschätzt.\nEs liegt an den Nutzi,\ndiesen Wert zu wählen.\n\nParameter dieser Art (die von den Nutzi zu bestimmen sind, nicht vom Algorithmus),\nnennt man *Tuningparameter*.\n\n\nAbbildung @fig-nnoverfit aus @silge_tidy_2022 stellt exemplarisch dar,\nwelchen großen Einfluss die Wahl des Werts eines Tuningparameters auf die \nVorhersagen eines Modells haben.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-nnoverfit_183c3e636ebe31bad469328b9aa8f9b7'}\n::: {.cell-output-display}\n![Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter](https://www.tmwr.org/figures/two-class-boundaries-1.png){#fig-nnoverfit}\n:::\n:::\n\n\n\nAber wie wählt man \"gute\" Werte der Tuningparater?\nZwei Ansätze, grob gesprochen, bieten sich an.\n\n1. *Grid Search:* Probiere viele Werte aus und schaue, welcher der beste ist. Dabei musst du hoffen, dass du die Werte erwischt, die nicht nur im Train-, sondern auch im Test-Sample gut funktionieren werden.\n\n2. *Iterative Search:* Wenn du einen Wert eines Tuningparameters hast, nutze diesen, um intelligenter einen neuen Wert eines Tuningparameters zu finden.\n\n\nDer Unterschied beider Ansätze ist in @silge_tidy_2022 wie in @fig-tuning1 dargestellt.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-tuning1_f8dc718950a2926ec7554abf9ab3d59b'}\n::: {.cell-output-display}\n![Links: Grid Search. Rechts: Iterative Search2](https://www.tmwr.org/figures/tuning-strategies-1.png){#fig-tuning1}\n:::\n:::\n\n\n\nIn `tidymodels` kann man mit `tune()` angeben, dass man einen bestimmten Parameter tunen möchte. \n`tidymodels` führt das dann ohne weiteres Federlesens für uns durch.\n\n\n## Tuning mit Tidymodels\n\n#### Tuningparameter betrachten\n\n\n\nMöchte man wissen, \nwelche und wie viele Tuningparameter tidymodels in einem Modell berücksichtigt,\nkann man `extract_parameter_set_dials()` aufrufen:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-17_ef485a84e22048c6fbbf48327ae57f2c'}\n\n```{.r .cell-code}\nextract_parameter_set_dials(knn_model)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"component\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"component_id\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"object\"],\"name\":[6],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"neighbors\",\"2\":\"K\",\"3\":\"model_spec\",\"4\":\"nearest_neighbor\",\"5\":\"main\",\"6\":\"<S3: quant_param>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nDie Ausgabe informiert uns,\ndass es nur einen Tuningparameter gibt in diesem Modell und\ndass der Name (Label, ID) des Tuningparameters \"K\" ist.\nAußerdem sollen die Anzahl der Nachbarn getunt werden.\nDer Tuningparameter ist numerisch; das sieht man an `nparam[+]`.\n\n\n\nSchauen wir uns mal an,\nauf welchen Wertebereich `tidymodels` den Parameter $K$ begrenzt hat:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-18_857e726b6f4e7d2612a85a7e0e23fc73'}\n\n```{.r .cell-code}\nknn_model %>% \n  extract_parameter_dials(\"K\")\n## # Nearest Neighbors (quantitative)\n## Range: [1, 15]\n```\n:::\n\n\n\nAktualisieren wir mal unseren Workflow entsprechend:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-19_4b2185091c6d35066b7d13457053c332'}\n\n```{.r .cell-code}\names_wflow <-\n  ames_wflow %>% \n  update_model(knn_model)\n```\n:::\n\n\n\n\nWir können auch Einfluss nehmen und angeben,\ndass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll \n(für den Tuningparameter `neighbors`):\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-update_eb8cab012a3569ca6e1f908a48bcf0bb'}\n\n```{.r .cell-code}\names_set <-\n  extract_parameter_set_dials(ames_wflow) %>%\n  update(K = neighbors(c(1, 50)))\n\names_set\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"name\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"source\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"component\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"component_id\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"object\"],\"name\":[6],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"neighbors\",\"2\":\"K\",\"3\":\"model_spec\",\"4\":\"nearest_neighbor\",\"5\":\"main\",\"6\":\"<S3: quant_param>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Datenabhängige Tuningparameter\n\nManche Tuningparameter kann man nur bestimmen,\nwenn man den Datensatz kennt.\nSo ist die Anzahl der Prädiktoren, `mtry` in einem Random-Forest-Modell \nsinnvollerweise als Funktion der Prädiktorenzahl zu wählen.\nDer Workflow kennt aber den Datensatz nicht.\nDaher muss der Workflow noch \"finalisiert\" oder \"aktualisiert\" werden,\num den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen.\n\n\n\n\n\n\nWenn wir im Rezept aber z.B. die Anzahl der Prädiktoren verändert haben,\nmöchten wir die Grenzen des Wertebereichs für `mtry` (oder andere Tuningparameter) vielleicht nicht händisch, \"hartverdrahtet\" selber bestimmen,\nsondern lieber den Computer anweisen, und sinngemäß sagen:\n\"Warte mal mit der Bestimmung der Werte der Tuningparameter,\nbis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir, \ndass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch ändern musst. Und tu das dann auch.\" Dazu später mehr.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-finalize_61bfb67be588c6eb66920c01377e8d8a'}\n\n```{.r .cell-code}\names_set <-\n  workflow() %>% \n  add_model(knn_model) %>% \n  add_recipe(ames_rec) %>% \n  extract_parameter_set_dials() %>% \n  finalize(ames_train)\n```\n:::\n\n\n\n### Modelle mit Tuning berechnen\n\nNachdem wir die Tuningwerte bestimmt haben, \nkönnen wir jetzt das Modell berechnen:\nFür jeden Wert des Tuningparameters wird ein Modell berechnet:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-tune-grid_8241badcbf6002f022ad28ec3e461f20'}\n\n```{.r .cell-code}\names_grid_search <-\n  tune_grid(\n    ames_wflow,\n    resamples = ames_folds\n  )\names_grid_search\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIm Default berechnet `tiymodels` 10 Kandidatenmodelle.\n\nDie Spalte `.metrics` beinhaltet die Modellgüte für jedes Kandidatenmodell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-20_75ef926c582d59916c6ce940fb97e474'}\n\n```{.r .cell-code}\names_grid_search %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"K\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"2\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.10349535\",\"5\":\"10\",\"6\":\"0.002127888\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"2\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.66158238\",\"5\":\"10\",\"6\":\"0.011179503\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"4\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09501120\",\"5\":\"10\",\"6\":\"0.001881864\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"4\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.70841461\",\"5\":\"10\",\"6\":\"0.009163055\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"6\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09120649\",\"5\":\"10\",\"6\":\"0.001889243\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"6\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.73187950\",\"5\":\"10\",\"6\":\"0.008416866\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"7\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08999211\",\"5\":\"10\",\"6\":\"0.001917548\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"7\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.74006777\",\"5\":\"10\",\"6\":\"0.008293791\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"9\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08830447\",\"5\":\"10\",\"6\":\"0.002005757\",\"7\":\"Preprocessor1_Model5\"},{\"1\":\"9\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.75232427\",\"5\":\"10\",\"6\":\"0.008270258\",\"7\":\"Preprocessor1_Model5\"},{\"1\":\"11\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08721929\",\"5\":\"10\",\"6\":\"0.002107469\",\"7\":\"Preprocessor1_Model6\"},{\"1\":\"11\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.76098086\",\"5\":\"10\",\"6\":\"0.008451436\",\"7\":\"Preprocessor1_Model6\"},{\"1\":\"13\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08650671\",\"5\":\"10\",\"6\":\"0.002168429\",\"7\":\"Preprocessor1_Model7\"},{\"1\":\"13\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.76732938\",\"5\":\"10\",\"6\":\"0.008484678\",\"7\":\"Preprocessor1_Model7\"},{\"1\":\"15\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08606349\",\"5\":\"10\",\"6\":\"0.002208369\",\"7\":\"Preprocessor1_Model8\"},{\"1\":\"15\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.77201730\",\"5\":\"10\",\"6\":\"0.008497265\",\"7\":\"Preprocessor1_Model8\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nDas können wir uns einfach visualisieren lassen:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-21_ea3a0fad71379e98a40de14c09bac30d'}\n\n```{.r .cell-code}\nautoplot(ames_grid_search)\n```\n\n::: {.cell-output-display}\n![](080-Resampling-Tuning_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\nAuf Basis dieser Ergebnisse könnte es Sinn machen, \nnoch größere Werte für $K$ zu überprüfen.\n\n### Vorhersage im Test-Sample\n\nWelches Modellkandidat war jetzt am besten?\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-22_c39767e38e0c16a8ad9a116918d8f11e'}\n\n```{.r .cell-code}\nshow_best(ames_grid_search)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"K\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"15\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08606349\",\"5\":\"10\",\"6\":\"0.002208369\",\"7\":\"Preprocessor1_Model8\"},{\"1\":\"13\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08650671\",\"5\":\"10\",\"6\":\"0.002168429\",\"7\":\"Preprocessor1_Model7\"},{\"1\":\"11\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08721929\",\"5\":\"10\",\"6\":\"0.002107469\",\"7\":\"Preprocessor1_Model6\"},{\"1\":\"9\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08830447\",\"5\":\"10\",\"6\":\"0.002005757\",\"7\":\"Preprocessor1_Model5\"},{\"1\":\"7\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.08999211\",\"5\":\"10\",\"6\":\"0.001917548\",\"7\":\"Preprocessor1_Model4\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nWählen wir jetzt mal das beste Modell aus (im Sinne des Optimierungskriteriusms):\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-23_4feb34694c00cc666c4621aac376c7f8'}\n\n```{.r .cell-code}\nselect_best(ames_grid_search)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"K\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"15\",\"2\":\"Preprocessor1_Model8\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nOk,\nnotieren wir uns die Kombination der Tuningparameterwerte \nim besten Kandiatenmodell.\nIn diesem Fall hat das Modull nur einen Tuningparameter:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-24_d3889a3692d6f13d9f7276273abea0f5'}\n\n```{.r .cell-code}\names_knn_best_params <-\n  tibble(K = 15)\n```\n:::\n\n\nUnser Workflow weiß noch nicht,\nwelche Tuningparameterwerte am besten sind:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-25_b182804b71ffc4fdde5e4f576959b788'}\n\n```{.r .cell-code}\names_wflow\n## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 4 Recipe Steps\n## \n## • step_log()\n## • step_other()\n## • step_dummy()\n## • step_zv()\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = tune(\"K\")\n## \n## Computational engine: kknn\n```\n:::\n\n\n`neighbors = tune(\"K\")` sagt uns,\ndass er diesen Parameter tunen will.\nDas haben wir jetzt ja erledigt.\nWir wollen für das Test-Sample nur noch einen Wert,\neben aus dem besten Kandidatenmodell, \nverwenden:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-finalize-wf_f24636e56e4743e9863fbc45faed70c4'}\n\n```{.r .cell-code}\names_final_wflow <-\n  ames_wflow %>% \n  finalize_workflow(ames_knn_best_params)\n\names_final_wflow\n## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## 4 Recipe Steps\n## \n## • step_log()\n## • step_other()\n## • step_dummy()\n## • step_zv()\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = 15\n## \n## Computational engine: kknn\n```\n:::\n\n\nWie man sieht,\nsteht im Workflow nichts mehr von Tuningparameter.\n\nWir können jetzt das *ganze Train-Sample* fitten,\nalso das Modell auf das ganze Train-Sample anwenden -\nnicht nur auf ein Analysis-Sample.\nUnd mit den dann resultierenden Modellkoeffizienten sagen\nwir das TestSample vorher:\n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-last-fit_de86425d4b82a92d256c87cc03ae1007'}\n\n```{.r .cell-code}\nfinal_ames_knn_fit <-\n  last_fit(ames_final_wflow, data_split)\n\nfinal_ames_knn_fit\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".predictions\"],\"name\":[5],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".workflow\"],\"name\":[6],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: initial_split>\",\"2\":\"train/test split\",\"3\":\"<tibble[,4]>\",\"4\":\"<tibble[,3]>\",\"5\":\"<tibble[,4]>\",\"6\":\"<S3: workflow>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nHolen wir uns die Modellgüte:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-26_f23fd97add67d3412762cc1ac61bba9d'}\n\n```{.r .cell-code}\ncollect_metrics(final_ames_knn_fit)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.0951007\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.7356398\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n<!-- ### Vorhersage von Hand -->\n\n<!-- Natürlich könnten wir auch \"von Hand\" vorhersagen: -->\n\n\n<!-- ```{r ames-fit-von-hand} -->\n<!-- final_ames_knn_fit <- -->\n<!--   ames_final_wflow %>%  -->\n<!--   fit(ames_train) -->\n<!-- ``` -->\n\n<!-- Man beachte, -->\n<!-- dass die Vorhersagegüte für das Train-Sample überoptimistisch ist. -->\n\n<!-- Und jetzt sagen wir auf dieser Basis das Test-Sample vorher: -->\n\n<!-- ```{r error = TRUE} -->\n<!-- ames_pred <- -->\n<!--   predict(final_ames_knn_fit, new_data = ames_test) -->\n<!-- ``` -->\n\n<!-- Oh Nein! Es geht nicht, woran liegt das wohl? -->\n\n<!-- Wir müssen noch die Transformationen des Rezept auf das Test-Sample anwenden.  -->\n<!-- Puh, ganz schön unkomfortabel. -->\n\n<!-- Es ist nicht empfehlenswert, den folgenden Weg einzuschlagen, -->\n<!-- viel einfacher ist es, mit `last_fit()` seine Ergebnisse zu bekommen. -->\n<!-- Aber sei's drum, jetzt ziehen wir das halt mal durch. -->\n\n\n<!-- Zuerst berechnen wir die Werte des *Rezepts*, z.B. -->\n<!-- die MW- und SD-Werte für z-Transformationen oder die Anzahl -->\n<!-- der Prädiktoren im Datensatz. -->\n\n<!-- ```{r ames-prep} -->\n<!-- ames_prep <- -->\n<!--   prep(ames_rec, training = ames_train) -->\n\n<!-- ames_prep -->\n<!-- ``` -->\n<!-- Mit `prep()` haben wir *nur* das Rezept berechnet, -->\n<!-- noch kein Modell auf einen Datensatz gefittet! -->\n\n<!-- Alternativ könnten wir uns das trainierte Rezept auch so holen: -->\n\n<!-- ```{r} -->\n<!-- extract_recipe(final_ames_knn_fit) -->\n<!-- ``` -->\n\n\n\n\n<!-- Jetzt wenden wir das Rezept auf den Test-Datensatz an: -->\n\n<!-- ```{r ames-bake} -->\n<!-- ames_test_baked <-  -->\n<!--   bake(ames_prep, new_data = ames_test) -->\n<!-- ``` -->\n\n<!-- Das Ergebnis ist jetzt der \"gebackene\" Datensatz `ames_test_baked`, -->\n<!-- in dem jetzt die Transformationen des Test-Samples angewendet sind. -->\n\n<!-- Damit können wir jetzt die Vorhersagen im Test-Sample durchführen. -->\n\n\n\n\n<!-- ```{r ames-pred-final-von-hand, error = TRUE} -->\n<!-- ames_pred <- -->\n<!--   predict(final_ames_knn_fit, new_data = ames_test) -->\n<!-- ``` -->\n\n<!-- Und damit haben wir unsere Modellgüte für das Test-Sample. -->\n\n\n\n\n## Aufgaben\n\n\n- Arbeiten Sie sich so gut als möglich durch [diese Analyse zum Verlauf von Covid-Fällen](https://github.com/sebastiansauer/covid-icu)\n- [Fallstudie zur Modellierung einer logististischen Regression mit tidymodels](https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/)\n- [Fallstudie zu Vulkanausbrüchen](https://juliasilge.com/blog/multinomial-volcano-eruptions/)\n- [Fallstudie Himalaya](https://juliasilge.com/blog/himalayan-climbing/)\n\n\n##  Vertiefung\n\n[Fields arranged by purity, xkcd 435](https://xkcd.com/435/)\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}