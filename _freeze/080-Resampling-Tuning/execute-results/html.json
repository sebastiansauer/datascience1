{
  "hash": "3b0b15c9fdf8b602373eb38020c300e9",
  "result": {
    "markdown": "# Resampling und Tuning\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-1_a4ddb5e8314c9e73856ba49c84032ff7'}\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Lernsteuerung\n\n\n### Lernziele\n- Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.\n- Sie kÃ¶nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.\n    \n### Vorbereitung\n- Lesen Sie die Literatur.\n\n###  Literatur\n- Rhys, Kap. 3\n- TMWR, Kap. 10, 12\n\n\n### Daten\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-2_823a54fda0e1fe85062eb3dca585e670'}\n\n```{.r .cell-code}\ndata(ames)\n```\n:::\n\n\n\n\n### BenÃ¶tigte R-Pakete\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/libs-resampling-tuning_c26dfe43e95416089da75866ee91b5ea'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\n```\n:::\n\n\n\n## Ãœberblick\n\n\n### Train- und Test-Sample vervielfacht\n\nIn @sec-overfit haben wir gelernt, dass ein Modell in einem zweiten Datensatz auf seine ModellgÃ¼te hin Ã¼berprÃ¼ft werden und sollte und nicht in dem (ersten) Datensatz, in dem die Modellparameter berechnet wurden.\n\nIn diesem Kapitel werden wir wir von einem Modell *mehrere Varianten* berechnen,\ndaher benÃ¶tigen wir fÃ¼r jeden dieser Varianten oder \"Modellkandidaten\" eine eigene Train-Test-Aufteilung. \nZur Klarheit der Begrifflichkeiten nennt man die resultierenden Teile in dem Fall *Analyse- und Assessment-Sample*, s. @fig-analys-assess-test dargestellt aus \nKap. 10.2 in @silge_tidy_2022 ([Quelle](https://www.tmwr.org/resampling.html)).\n\n\n![Die Aufteilung der Daten im Falle mehrerer Modellkandidaten](img/resampling.svg){#ig-analys-assess-test width=\"50%\"}\n\n\n### Standardablauf\n\nEin Standardablauf des maschinellen Lernens ist in @fig-process1 dargestellt.\n\n\n```{mermaid}\n%%| label: fig-process1\n%%| fig-cap: \"Standardablauf des maschinellen Lernens mit Tuning und Resampling (S: Sample bzw. Stichprobe)\"\n\nflowchart TD\n   \nGesamtdatensatz --> Split[In Train- und Test aufteilen]\nsubgraph Fit[FÃ¼r jeden Modellkandidaten i]\n  subgraph Kand[Modellkandidat i]\n  F[Fitte im Train-S] --> T[Teste im Assessment-S]\n  end\nend\nSplit --> Fit\nFit --> Best[Bestimmte besten Kandidaten]\nBest --> lastFit[Fitte ihn im ganzen Train-S]\nlastFit --> test[Teste im Test-S]\n```\n\n\n\n\n\n\n\n\n\n## tidymodels\n\nBetrachten wir dieses Konzept an einem konkreten Beispiel mit Tidymodels.\n\n#\n\n\n### AbhÃ¤ngige Variable transformieren\n\n:::{callout-note}\nMÃ¶chte man eine abhÃ¤ngige Variable transformieren, \nso sollte das *auÃŸerhalb* des Rezepts passieren,\nda das \"Backen\" nicht auf die `outcome`-Variable ausgefÃ¼hrt wird.$\\square$\n:::\n\n\nAus der [Dokumentation von `step_scale`](https://recipes.tidymodels.org/reference/step_scale.html):\n\n>   skip - A logical. Should the step be skipped when the recipe is baked by bake()? While all operations are baked when prep() is run, some operations may not be able to be conducted on new data (e.g. processing the outcome variable(s)). Care should be taken when using skip = TRUE as it may affect the computations for subsequent operations.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-4_c6d7e529a88c2695cfe7e1133cc82830'}\n\n```{.r .cell-code}\names <-\n  ames %>% \n  mutate(Sale_Price = log(Sale_Price, base = 10))\n```\n:::\n\n\n\n[Hier](https://www.tmwr.org/recipes.html#skip-equals-true) finden Sie eine Antwort,\nwarum tidymodels sich weigert, Informationen Ã¼ber die AV vom Train- in das Test-Sample zu transferieren.\n\n\n\n\n## Datensatz aufteilen\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-split_51de8c4e0f645e00c3740a1eee431fa4'}\n\n```{.r .cell-code}\nset.seed(4595)\ndata_split <- initial_split(ames, strata = \"Sale_Price\")\n\names_train <- training(data_split)\names_test <- testing(data_split)\n```\n:::\n\n\n\n### Rezept, Modell und Workflow definieren\n\nIn gewohnter Weise definieren wir zunÃ¤chst den Workflow\nmit einem kNN-Modell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-wf_a1d9805e420ba6607ad90154000e180f'}\n\n```{.r .cell-code}\names_rec <-\n  recipe(Sale_Price ~ Lot_Area + Fireplaces + Longitude + Latitude,\n         data = ames_train) %>%\n  step_zv(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_impute_median(all_predictors())\n\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\"\n  ) \n\names_wflow1 <-\n  workflow() %>%\n  add_recipe(ames_rec) %>%\n  add_model(knn_model)\n```\n:::\n\n\nMit dem Rezept kNN-Modell ist noch *nicht* *berechnet,\nes ist nur ein \"Rezept\" erstellt.\n\n\n\n\n\n## Resampling\n\n\nVergleichen Sie die drei FÃ¤lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:\n\n1. Wir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe \"vorher\". Wir finden eine Gesamtgenauigkeit von 80%.\n2. Wir fitten ein Klassifikationsmodell in einem Teil der ursprÃ¼nglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der ursprÃ¼nglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.\n3. Wir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der FÃ¤lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.\n\n\nWelchen der drei FÃ¤lle finden Sie am sinnvollsten? Warum?\n\n\n:::{.callout-note}\nVerschiedene (zufÃ¤llige) Aufteilung eines Datensatzes in Train- und Test-Sample kÃ¶nnen zu verschiedenen ModellgÃ¼ten fÃ¼hren. So kÃ¶nnten im Train-Sample durch eine bestimmte Zufallsaufteilung relativ viele (oder wenige) schwer zu klassifizierende FÃ¤lle zusammen kommen.$\\square$\n:::\n\nFall Nummer 3 bezeichnet man als *Kruezvalidierung*.\n\n\n## Illustration des Resampling\n\n*Resampling* stellt einen Oberbegriff dar; *Kreuzvalidierung* ist ein Unterbegriff dazu.\nEs gibt noch andere Arten des Resampling, etwa *Bootstrapping* oder *Leave-One-Out-Cross-Validation* (LOOCV).\n\nIm Folgenden ist nur die Kreuzvalidierung dargestellt,\nda es eines der wichtigsten und vielleicht das am hÃ¤ufigsten verwendete Verfahren des Resampling ist.\nIn vielen Quellen finden sich ErlÃ¤uterungen anderer Verfahren dargestellt,\netwa in @silge_tidy_2022, @islr oder @rhys.\n\n\n\n\n### Einfache v-fache Kreuzvalidierung\n\n@fig-resampling illustriert die zufÃ¤llige Aufteilung von $n=10$ FÃ¤llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe. \nMan spricht von *Kreuzvalidierung* (cross validation, CV).\n\nIn diesem Fall wurden 70% der ($n=10$) FÃ¤lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe);\nein willkÃ¼rlicher, aber nicht unÃ¼blicher Anteil.\nDiese Aufteilung wurde $v=3$ Mal vorgenommen,\nes resultieren drei \"Resampling-Stichproben\", die\nmanchmal auch als \"Faltungen\" bezeichnet werden.\n\n\n\n::: {.cell messagen='false' hash='080-Resampling-Tuning_cache/html/fig-resampling_1b39eb81b6c542698cd170d9cfb81257'}\n::: {.cell-output-display}\n![Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt](080-Resampling-Tuning_files/figure-html/fig-resampling-1.png){#fig-resampling width=100%}\n:::\n:::\n\n\n\n\n\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvmodar.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvmodar_d53146a97b478773a81f015de9ef1f19'}\n::: {.cell-output-display}\n![Kreuzvalidierung, Aufteilung in Train- vs. Testsample](img/crossval.png){#fig-cvmodar width=861}\n:::\n:::\n\n\n\nDer Gesamtfehler der Vorhersage (die ModellgÃ¼te) wird als *Mittelwert der Vorhersagefehler* in den einzelnen Faltungen berechnet.\n\nWarum ist die Vorhersage besser,\nwenn man mehrere Faltungen, mehrere SchÃ¤tzungen fÃ¼r $y$ also, vornimmt?\n\nDer Grund ist das Gesetz der groÃŸen Zahl,\nnachdem sich eine SchÃ¤tzung in Mittelwert und VariabilitÃ¤t stabilisiert mit steigendem\nStichprobenumfang,\ndem wahren Mittelwert also prÃ¤ziser schÃ¤tzt.^[Bei Normalverteilungen klappt das gut\nbei randlastigen Verteilungen leider nicht mehr [@fattails].]\nMit mehr Faltungen nÃ¤hern wir uns also einem \"wahren\" Mittelwert der ModellgÃ¼te (und sonstiger Kennzahlen) nÃ¤her an.\n\n\nHÃ¤ufig werden $v=10$ Faltungen verwendet,\nwas sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.\n\nDie Nachteile der Kreuzvalidierung sind:\n\n1. Die Rechenzeit steigt (in der Regel) etwa proportional zur Anzahl der $v$ Faltungen.\n2. Da die Train-Stichprobe kleiner ist (als bei der einfachen Train-Test-Aufteilung), wird die SchÃ¤tzung der Modellkoeffizienten ungenauer sein und damit die ModellgÃ¼te geringer.\n\nInsgesamt Ã¼berwiegen zumeist die Vorteiler eines Resamplings (wie eine Kreuzvalidierung) im Vergleich zu einfachen Train-Test-Aufteilung.\n\n\n\n\n### Wiederholte Kreuzvalidierung\n\n\nDie $r$-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (nÃ¤mlich $r=4$ mal),\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvrep.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvrep_c9fae0c3bbdfc82690b35729aae4bf33'}\n::: {.cell-output-display}\n![Wiederholte Kreuzvalidierung](img/crossval_repeated.png){#fig-cvrep width=916}\n:::\n:::\n\n\nDie wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.\n\n@silge_tidy_2022 zeigen die Verringerung des SchÃ¤tzfehlers als Funktion der $r$ Wiederholungen dar,\ns. @fig-repcvred.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-repcvred_0dc4a9002cf6d8b9edec77e8711509b8'}\n::: {.cell-output-display}\n![Reduktion des SchÃ¤tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung](https://www.tmwr.org/figures/variance-reduction-1.png){#fig-repcvred}\n:::\n:::\n\n\n\nWarum ist die Wiederholung der Kreuzvalidierung nÃ¼tzlich?\n\nDie Kreuvalidierung liefert einen SchÃ¤tzwert der Modellparameter,\ndie wahren Modellparameter werden also anhand einer Stichprobe von $n=1$ geschÃ¤tzt.\nMit hÃ¶herem Stichprobenumfang kann diese SchÃ¤tzung natÃ¼rlich prÃ¤zisiert werden.\n\nDa jede Stichprobenverteilung bei $n \\rightarrow \\infty$ normalverteilt ist - \nein zentrales Theorem der Statistik, der *Zentrale Grenzwertsatz* (Central Limit Theorem) - \nkann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem $n$ ebenfalls annÃ¤hernd\nnormalverteilt^[Das klappt bei randlastigen Verteilungen nicht]. \nDann sind die Quantile bekannt und man kann die Streuung der SchÃ¤tzers, \n${\\sigma }_{\\bar {x}}$, z.B. fÃ¼r den Mittelwert,\neinfach schÃ¤tzen:\n\n$${\\displaystyle {\\sigma }_{\\bar {x}}\\ ={\\frac {\\sigma }{\\sqrt {n}}}}$$\n\n\n### Resampling passiert im Train-Sample\n\nWichtig zu beachten ist, dass\ndie Resampling nur im Train-Sample stattfindet.\nDas Test-Sample bleibt unangerÃ¼hrt.\nDieser Sachverhalt ist in @fig-analys-assess-test, aus @silge_tidy_2022, illustriert.\n\n\n\n\n\nWie in @fig-initialsplit dargestellt,\nwird das Modell im *Analyse-Sample* berechnet (gefittet),\nund im *Assessment-Sample* auf ModellgÃ¼te hin Ã¼berprÃ¼ft.\n\nDie letztliche ModellgÃ¼te ist dann die Zusammenfassung (Mittelwert) der einzelnen Resamples.\n\n\n### Andere Illustrationen\n\n\nEs gibt eine Reihe vergleichbarer Illustrationen in anderen BÃ¼chern:\n\n- [Timbers, Campbell & Lee, 2022, Kap. 6](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.1](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.2](https://www.tmwr.org/premade/three-CV.svg)\n- [Silge & Kuhn, 2022, 10.3](https://www.tmwr.org/premade/three-CV-iter.svg)\n- James, Witten, hastie & Tishirani, 2021, 5.3\n\n\n\n## Gesetz der groÃŸen Zahl\n\nNach dem *Gesetz der groÃŸen Zahl* (Law of Large Numbers) sollte sich der Mittelwert einer groÃŸen Stichprobe \ndem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess) \nsehr nahe kommen.\n\n$$\\displaystyle \\lim _{n\\to \\infty }\\sum _{i=1}^{n}{\\frac {X_{i}}{n}}={\\overline {X}}$$\n\nDavid Salazar visualisiert das folgendermaÃŸen in [diesem Post](https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/) seines lesenswerten [Blogs](https://david-salazar.github.io/), s. @fig-lln).\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-lln_fcbedab8d82ada9437c4e56b3c3a121d'}\n::: {.cell-output-display}\n![Gesetz der groÃŸen Zahl](080-Resampling-Tuning_files/figure-html/fig-lln-1.png){#fig-lln width=672}\n:::\n:::\n\n\nWie man sieht, nÃ¤hert sich der empirische Mittelwert (also in der Stichprobe)\nimmer mehr dem theoretischen Mittelwert, 0, an.\n\nAchtung: Bei randlastigen Verteilungen darf man dieses schÃ¶ne, wohlerzogene Verhalten nicht erwarten [@fattails].\n\n\n\n\n\n\n\n\n## CV in tidymodels\n\n### CV definieren\n\nSo kann man eine *einfache* v-fache Kreuzvalidierung in Tidymodels auszeichnen^[$v=10$ in der Voreinstellung]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-6_38725b0c80a0765357feb8465b3f968c'}\n\n```{.r .cell-code}\nset.seed(2453)\names_folds <- vfold_cv(ames_train, strata = \"Sale_Price\")\names_folds\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWerfen wir einen Blick in die Spalte `splits`, erste Zeile:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-7_7f6ddac93ec56c563e7394630600bc59'}\n\n```{.r .cell-code}\names_folds %>% pluck(1, 1)\n## <Analysis/Assess/Total>\n## <1976/221/2197>\n```\n:::\n\n\n\nMÃ¶chte man die Defaults vpn `vfold_cv` wissen, schaut man in der Hilfe nach: `?vfold_cv`:\n\n\n`vfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)` \n\n\nProbieren wir $v=10$ und $r=10$:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-8_d77b0cd71e5c6a0578cd15debf62504b'}\n\n```{.r .cell-code}\names_folds_rep <- vfold_cv(ames_train, \n                           strata = \"Sale_Price\", \n                           v = 10,\n                           repeats = 10)\names_folds_rep\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id2\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Resamples fitten\n\n\nHat unser Computer mehrere Rechenkerne, dann kÃ¶nnen wir diese nutzen und die Berechnungen beschleunigen.\nIm Standard wird sonst nur ein Kern verwendet.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-9_1cf6ba188b363ec1d342c38ceb927016'}\n\n```{.r .cell-code}\nmycores <- parallel::detectCores(logical = FALSE)\nmycores\n## [1] 4\n```\n:::\n\n\nAuf Unix/MacOC-Systemen kann man dann die Anzahl der parallen Kerne so einstellen^[In Windows gibt es andere Wege.]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-10_71ce5f7f59ef06f235e357da034b0fbd'}\n\n```{.r .cell-code}\nlibrary(doMC)\nregisterDoMC(cores = mycores)\n```\n:::\n\n\n\n\nSo, und jetzt fitten wir die Resamples und betrachten die ModellgÃ¼te in den Resamples:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-11_210d576713f442f8c16e755b2283f262'}\n\n```{.r .cell-code}\ntic()\names_resamples_fit <- \n  ames_wflow1 %>% \n  fit_resamples(ames_folds)\ntoc()\n## 1.514 sec elapsed\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-12_fe29c3993fd5c225ea22a82bbbf6b9ab'}\n\n```{.r .cell-code}\n ames_resamples_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.09931566\",\"4\":\"10\",\"5\":\"0.00221264\",\"6\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.68455234\",\"4\":\"10\",\"5\":\"0.01221973\",\"6\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nNatÃ¼rlich interessiert uns primÃ¤r die ModellgÃ¼te im *Test*-Sample:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-13_b9bb60536a33bc8a05aa4957b2efc273'}\n\n```{.r .cell-code}\nfinal_ames1 <-\n  last_fit(ames_wflow1, data_split)\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-14_8a6a48b67200f8e2e2e2e2f19078ca9d'}\n\n```{.r .cell-code}\nfinal_ames1 %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.1020273\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.6847473\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Streuung in der ModellgÃ¼te zwischen den Resamples\n\nBetrachten wir die Streuungen der ModellgÃ¼te (RSMSE) in der 10-fachen, nicht wiederholten Kreuzvalidierung, s. @fig-cv-rmse.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-15_4dc851ecf082c0ed504d902c6b221d22'}\n\n```{.r .cell-code}\nrmse_resamples <-\n  ames_resamples_fit %>% \n  unnest(.metrics) %>% \n  filter(.metric == \"rmse\") %>% \n  select(id, .metric, .estimate) \n\np_rmse_cv1r <- \n  rmse_resamples %>% \n  ggplot(aes(x = id, y = .estimate)) +\n  geom_point() +\n  geom_hline(yintercept = mean(rmse_resamples$.estimate), linetype = \"dashed\") +\n  labs(caption = paste0(\"SD: \", round(sd(rmse_resamples$.estimate), 4)),\n       y = \"ModellgÃ¼te: RMSE\")\n```\n:::\n\n\n\nJetzt wiederholen wir die Kreuzvalidierung $r=5$ mal und betrachten wieder die Streuung der ModellgÃ¼te.\nDa wir $r$ mal so viele Modelle berechnen, benÃ¶tigen wir - wenn nur ein einzelnen Rechenkern benutzt wird - $r$ mal so viel  Rechenzeit^[theoretisch].\n\n\nZuerst berechnen wir die wiederholte Kreuzvalidierung, das kann etwas dauern:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-16_f2195a7181333c2f54689b3bca252cf7'}\n\n```{.r .cell-code}\ntic()\names_resamples_fit_rep <- \n  ames_wflow1 %>% \n  fit_resamples(ames_folds_rep)\ntoc()\n## 4.264 sec elapsed\n```\n:::\n\n\n\nDann analysieren wir die Ergebnisse:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-17_3ac29992ca5ee6053b5d467c5c419c32'}\n\n```{.r .cell-code}\nmse_resamples_rep <-\n  ames_resamples_fit_rep %>% \n  unnest(.metrics) %>% \n  filter(.metric == \"rmse\") %>% \n  select(id, id2, .estimate)\n\nmse_resamples_rep_summ <-\n  mse_resamples_rep %>% \n  group_by(id) %>% \n  summarise(\n    .estimate_rep_mean = mean(.estimate),\n    .estimate_rep_sd = sd(.estimate),\n    .estimate = .estimate_rep_mean) \n\np_rmse_cv5r <- \nmse_resamples_rep %>% \n  ggplot(aes(x = id)) +\n  geom_point(alpha = .7, aes(y = .estimate)) + \n  geom_errorbar(data = mse_resamples_rep_summ,\n                aes(ymin = .estimate - .estimate_rep_sd,\n                    ymax = .estimate + .estimate_rep_sd)) +\n  geom_hline(yintercept = mean(mse_resamples_rep$.estimate), linetype = \"dashed\") +\n  labs(caption = paste0(\"SD: \", round(sd(mse_resamples_rep$.estimate), 4)),\n       y = \"ModellgÃ¼te: RMSE\")\n```\n:::\n\n\n\n\nWie man sieht, streuen die $v=10$ Faltungen in ihre ModellgÃ¼te, s. @fig-cv-rmse.\nDurch das Wiederholen *sinkt*, nach dem Gesetz der groÃŸen Zahl, die Streuung.\nMit geringerer Streuung schÃ¤tzen wir den wahren Fehler prÃ¤ziser.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cv-rmse_d7997db83b20d2d072daf576a1728768'}\n\n```{.r .cell-code}\n# fig-cap: \"Streuung der ModellgÃ¼te (RMSE) bei nicht wiederholter und wiederholter CV\"\n#| layout-ncol: 2\n#| fig-subcap: \n#|   - \"Streuung der ModellgÃ¼te (RMSE) mit v=10 r=1 CV\"\n#|   - \"Streuung der ModellgÃ¼te (RMSE) mit v=10 r=5 CV\"\n#| echo: false\n\n\n\np_rmse_cv1r\np_rmse_cv5r\n```\n\n::: {.cell-output-display}\n![](080-Resampling-Tuning_files/figure-html/fig-cv-rmse-1.png){#fig-cv-rmse-1 width=672}\n:::\n\n::: {.cell-output-display}\n![](080-Resampling-Tuning_files/figure-html/fig-cv-rmse-2.png){#fig-cv-rmse-2 width=672}\n:::\n:::\n\n\n\n\nPuh, das war recht theoretisch. Ja, das Leben des Data-Scientisten ist nicht immer einfach,\nfindet auch Grumpy Cat, s. @fig-grumpy1.\n\n![Grumpy Cat und die Schwierigkeiten im Leben des Data-Scientisten](img/7h9qvw.jpg){#fig-grumpy1 width=\"50%\"}\n\n[Quelle: imgflip](https://imgflip.com/i/7h9qvw)\n\n\n## Tuning\n\n\n:::{#def-tuning}\n\n>   ğŸ‘¨â€ğŸ« Hey ChatGPT: Definiere Tuning mit maschinellen Lernen am Beispiel von knn und dem Parameter k.\n\n>   ğŸ¤– KNN (K-nearest neighbors) ist ein Machine-Learning-Algorithmus, bei dem die Vorhersage eines neuen Datenpunkts auf der Basis der k nÃ¤chsten Nachbarn im Trainingsdatensatz getroffen wird. Der Parameter k gibt an, wie viele Nachbarn zur Vorhersage verwendet werden sollen. Eine wichtige Aufgabe beim Tuning von KNN besteht darin, den optimalen Wert fÃ¼r den Parameter k zu finden.\nWenn k zu klein gewÃ¤hlt wird, kann dies zu einer Ãœberanpassung an den Trainingsdatensatz fÃ¼hren, wÃ¤hrend bei zu groÃŸ gewÃ¤hltem k das Modell unteranpassung aufweisen kann. Durch Tuning kann ein optimales k gefunden werden, das zu einer besseren Leistung des Modells auf einem Validierungsdatensatz fÃ¼hrt.\nEs gibt verschiedene Methoden zum Tuning des k-Parameters. Eine MÃ¶glichkeit besteht darin, ein Rastersuchverfahren durchzufÃ¼hren, bei dem eine vordefinierte Menge von k-Werten getestet wird, um dasjenige zu finden, das die beste Leistung auf einem Validierungsdatensatz aufweist. Eine andere MÃ¶glichkeit besteht darin, eine zufÃ¤llige Suche durchzufÃ¼hren, indem man zufÃ¤llig verschiedene k-Werte auswÃ¤hlt und deren Leistung bewertet.\nDas Ziel des Tunings ist es, den besten Wert fÃ¼r den Parameter k zu finden, um das KNN-Modell zu verbessern und die Vorhersagegenauigkeit auf einem Testdatensatz zu maximieren. Das Tuning sollte jedoch immer mit einem unabhÃ¤ngigen Testdatensatz durchgefÃ¼hrt werden, um sicherzustellen, dass das Modell nicht Ã¼berangepasst wird und auf neuen Daten gut funktioniert.^[https://chat.openai.com/chat, 2023-04-06]$\\square$\n:::\n\n\n\n\n\n### Tuning auszeichnen\n\nIn der Modellspezifikation des Modells kÃ¶nnen wir mit `tune()` *auszeichnen*,\nwelche Parameter wir tunen mÃ¶chten. \n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-19_b3d54662f8dd2fbc7a34f29a2bec7504'}\n\n```{.r .cell-code}\nknn_model2 <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()  # Wir tunen den Parameter \"neighbors\"\n  ) \n```\n:::\n\n\n\nWir kÃ¶nnen dem Tuningparameter auch einen Namen (ID/Label) geben, z.B. \"K\":\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-20_4a5681bb4bcc95a266451b9af7c40ba7'}\n\n```{.r .cell-code}\nknn_model2a <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\")\n  ) \n```\n:::\n\n\n\n:::{.callout-note}\nTidymodels trennt generell das Spezifizieren vom Evaluieren:\nErst definieren wir ein Rezept und ein Modell, dann fitten wir es.\nDas gilt auch fÃ¼r das Tunen: Erst weisen wir Parameter zum Tunen aus,\ndann wÃ¤hlen wir Tuningparameter und tunen.$\\square\n:::\n\n### Tuning durchfÃ¼hren\n\nWir betrachten zwei zentrale Arten von Tuning: Grid Search vs. Iterative Search.\n\n\nIm K-NÃ¤chste-Nachbarn-Modell (Klassifikation) ist der vorhergesagt Wert, $\\hat{y}$ fÃ¼r eine neue Beobachtung $x_0$ der Modus der $K$ nÃ¤chsten Nachbarn.\n\n\nDie Wahl von $K$ hat einen zentralen Einfluss auf die Vorhersagen und damit auf die VorhersagegÃ¼te.\nAllerdings wird $K$ nicht vom Modell geschÃ¤tzt.\nEs liegt an den Nutzi,\ndiesen Wert zu wÃ¤hlen.\n\nParameter dieser Art (die von den Nutzi zu bestimmen sind, nicht vom Algorithmus),\nnennt man *Tuningparameter*.\n\n\nAbbildung @fig-nnoverfit aus [diesem Kapitel von](https://www.tmwr.org/tuning.html#overfitting-bad) @silge_tidy_2022 stellt exemplarisch an den Vorhersagen eines neuronalen Netzes dar,\nwelchen groÃŸen Einfluss die Wahl des Werts eines Tuningparameters auf die \nVorhersagen eines Modells haben.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-nnoverfit_183c3e636ebe31bad469328b9aa8f9b7'}\n::: {.cell-output-display}\n![Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter](https://www.tmwr.org/figures/two-class-boundaries-1.png){#fig-nnoverfit}\n:::\n:::\n\n\n\nAber wie wÃ¤hlt man \"gute\" Werte der Tuningparater?\nZwei AnsÃ¤tze, grob gesprochen, bieten sich an.\n\n1. *Grid Search:* Probiere viele Werte aus und schaue, welcher der beste ist. Dabei musst du hoffen, dass du die Werte erwischt, die nicht nur im Train-, sondern auch im Test-Sample gut funktionieren werden.\n\n2. *Iterative Search:* Wenn du einen Wert eines Tuningparameters hast, nutze diesen, um intelligenter einen neuen Wert eines Tuningparameters zu finden.\n\n\nDer Unterschied beider AnsÃ¤tze ist in @silge_tidy_2022 wie in @fig-tuning1 dargestellt.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-tuning1_f8dc718950a2926ec7554abf9ab3d59b'}\n::: {.cell-output-display}\n![Links: Grid Search. Rechts: Iterative Search2](https://www.tmwr.org/figures/tuning-strategies-1.png){#fig-tuning1}\n:::\n:::\n\n\n\nIn `tidymodels` kann man mit `tune()` angeben, dass man einen bestimmten Parameter tunen mÃ¶chte. \n`tidymodels` fÃ¼hrt das dann ohne weiteres Federlesens fÃ¼r uns durch.\n\n\n\n\n\nMÃ¶chte man wissen, \nwelche und wie viele Tuningparameter tidymodels in einem Modell berÃ¼cksichtigt,\nkann man so aufrufen^[Alle Tuningparameter eines Modells sieht man so: `knn_model2 %>% \n  extract_parameter_set_dials()`]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-21_718a6317cbde80c764f8adc4b24c5599'}\n\n```{.r .cell-code}\nknn_model2 %>% \n  extract_parameter_dials(\"neighbors\")\n## # Nearest Neighbors (quantitative)\n## Range: [1, 15]\n```\n:::\n\n\n\n\n\n\nDie Ausgabe informiert uns,\ndass es nur einen Tuningparameter gibt in diesem Modell und\ndass der Name (Label, ID) des Tuningparameters \"K\" ist.\nAuÃŸerdem erfahren wir, dass der Tuningparmaeter die Anzahl der zu berÃ¼cksichtigen Nachbarn bezeichent.\nDer Tuningparameter ist numerisch; das sieht man an `nparam[+]`.\nTidymodels wÃ¤hlt einen Range von 1 bis 15 Nachbarn.\n\n:::{.callout-note}\nPraktisch! Oft ist es nicht leicht zu wissen, was ein gutes Spektrum an Werten eines Tuningparameters ist. `tidymodels` bzw. `dials` macht es einfach: \nEs gibt uns einen Bereich plausibler Tuningwerte vor.$\\square$\n:::\n\n\n\nAktualisieren wir  unseren Workflow entsprechend:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-22_93449c5b573608f7c9fffb78eb7de7b3'}\n\n```{.r .cell-code}\names_wflow2 <-\n  ames_wflow1 %>% \n  update_model(knn_model2)\n\names_wflow2\n## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 3 Recipe Steps\n## \n## â€¢ step_zv()\n## â€¢ step_normalize()\n## â€¢ step_impute_median()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = tune()\n## \n## Computational engine: kknn\n```\n:::\n\n\n\n\nWir kÃ¶nnen auch Einfluss nehmen und angeben,\ndass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll \n(fÃ¼r den Tuningparameter `neighbors`):\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-23_4c94ed641e4b606afe1937ebc4d68d3f'}\n\n```{.r .cell-code}\nknn_model3 <-\nnearest_neighbor(\n  mode = \"classification\",\n  neighbors = tune(id = \"K\") %>% set_range(c(1, 50))\n)\n```\n:::\n\n\nDen Wertebereich eines PrÃ¤diktors kann man aber auch mit `search_grid` bestimmen.\n\n\n<!-- ```{r ames-update} -->\n<!-- ames_set <- -->\n<!--   extract_parameter_set_dials(ames_wflow) %>% -->\n<!--   update(K = neighbors(c(1, 50))) -->\n\n<!-- ames_set -->\n<!-- ``` -->\n\n\n<!-- ### DatenabhÃ¤ngige Tuningparameter -->\n\n<!-- Manche Tuningparameter kann man nur bestimmen, -->\n<!-- wenn man den Datensatz kennt. -->\n<!-- So ist die Anzahl der PrÃ¤diktoren, `mtry` in einem Random-Forest-Modell  -->\n<!-- sinnvollerweise als Funktion der PrÃ¤diktorenzahl zu wÃ¤hlen. -->\n<!-- Der Workflow kennt aber den Datensatz nicht. -->\n<!-- Daher muss der Workflow noch \"finalisiert\" oder \"aktualisiert\" werden, -->\n<!-- um den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen. -->\n\n\n\n\n\n\n<!-- Wenn wir im Rezept aber z.B. die Anzahl der PrÃ¤diktoren verÃ¤ndert haben, -->\n<!-- mÃ¶chten wir die Grenzen des Wertebereichs fÃ¼r `mtry` (oder andere Tuningparameter) vielleicht nicht hÃ¤ndisch, \"hartverdrahtet\" selber bestimmen, -->\n<!-- sondern lieber den Computer anweisen, und sinngemÃ¤ÃŸ sagen: -->\n<!-- \"Warte mal mit der Bestimmung der Werte der Tuningparameter, -->\n<!-- bis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir,  -->\n<!-- dass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch Ã¤ndern musst. Und tu das dann auch.\" Dazu spÃ¤ter mehr. -->\n\n\n<!-- ```{r ames-finalize} -->\n<!-- ames_set <- -->\n<!--   workflow() %>%  -->\n<!--   add_model(knn_model2) %>%  -->\n<!--   add_recipe(ames_rec) %>%  -->\n<!--   extract_parameter_set_dials() %>%  -->\n<!--   finalize(ames_train) -->\n\n<!-- ames_set -->\n<!-- ``` -->\n\n\n### Modelle mit Tuning berechnen\n\nNachdem wir die Tuningwerte bestimmt haben, \nkÃ¶nnen wir jetzt das Modell berechnen:\nFÃ¼r jeden Wert des Tuningparameters wird ein Modell berechnet:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-tune-grid_6fb144a38224af0da4a8a02617d57393'}\n\n```{.r .cell-code}\names_folds <- vfold_cv(ames_train, strata = \"Sale_Price\")\n\names_grid_search <-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,\n    grid = 5,  # 5 Tuningwerte insgesamt\n    tuning_control = control_grid(save_workflow = TRUE)\n  )\names_grid_search\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIm Default berechnet `tiymodels` 10 Kandidatenmodelle.\n\nMit `control_grid` kann man beim Tuning einige Schalter umlegen,\nhier haben wir den Workflow an das Ergebnisobjekt angehÃ¤ngt.\n\nDie Spalte `.metrics` beinhaltet die ModellgÃ¼te fÃ¼r jedes Kandidatenmodell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-24_e9c3de77aff9b7981f5f82c74ad3282c'}\n\n```{.r .cell-code}\names_grid_search %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.12220611\",\"5\":\"10\",\"6\":\"0.003150178\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"1\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.57392094\",\"5\":\"10\",\"6\":\"0.015226184\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"5\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09948533\",\"5\":\"10\",\"6\":\"0.001913394\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"5\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.68511706\",\"5\":\"10\",\"6\":\"0.009690052\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"8\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09681643\",\"5\":\"10\",\"6\":\"0.001943049\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"8\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.69870184\",\"5\":\"10\",\"6\":\"0.010172142\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"12\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09625844\",\"5\":\"10\",\"6\":\"0.001920883\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"12\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.70095267\",\"5\":\"10\",\"6\":\"0.010264812\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"14\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09645052\",\"5\":\"10\",\"6\":\"0.001884852\",\"7\":\"Preprocessor1_Model5\"},{\"1\":\"14\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.69955747\",\"5\":\"10\",\"6\":\"0.010266771\",\"7\":\"Preprocessor1_Model5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nDie ModellgÃ¼te in AbhÃ¤ngigkeit der Tuningwerte kÃ¶nnen wir uns einfach visualisieren lassen:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-25_87297b6112299ae01e29adc1b03ebbce'}\n\n```{.r .cell-code}\nautoplot(ames_grid_search)\n```\n\n::: {.cell-output-display}\n![](080-Resampling-Tuning_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\nAuf Basis dieser Ergebnisse kÃ¶nnte es Sinn machen, \nnoch grÃ¶ÃŸere Werte fÃ¼r $K$ zu Ã¼berprÃ¼fen.\n\nTidymodels bietet verschiedene Optionen, \num ein \"Gitter\" (`grid`) an Werten von einem oder (in vielen Modellen) mehreren Tuningparametern zu durchsuchen.\nEine MÃ¶glichkeit ist, ein Gitter mit *regelmÃ¤ÃŸigen* AbstÃ¤nden der Werte zu erstellen, z.B. mit 5 AusprÃ¤gungen pro Tuningparameter:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-26_b7ed82447feeed2e66561457d2f4f2d2'}\n\n```{.r .cell-code}\ngrid1 <- \n  grid_regular(\n    neighbors(range = c(5L, 30L)),\n    levels = 5\n    )\ngrid1\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5\"},{\"1\":\"11\"},{\"1\":\"17\"},{\"1\":\"23\"},{\"1\":\"30\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-27_1af1489603c7d7e83dd1cd55663d6054'}\n\n```{.r .cell-code}\names_grid_search2 <-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,  \n    grid = grid1,\n    control = control_grid(save_workflow = TRUE)\n  )\names_grid_search2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Vorhersage im Test-Sample\n\nWelches Modellkandidat war jetzt am besten?\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-28_0b3d181ccb6a6d2e156d0977aebe5492'}\n\n```{.r .cell-code}\nshow_best(ames_grid_search2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"11\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09625154\",\"5\":\"10\",\"6\":\"0.001932229\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"17\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09694334\",\"5\":\"10\",\"6\":\"0.001845879\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"23\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09826881\",\"5\":\"10\",\"6\":\"0.001788245\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"5\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09948533\",\"5\":\"10\",\"6\":\"0.001913394\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"30\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09968967\",\"5\":\"10\",\"6\":\"0.001767765\",\"7\":\"Preprocessor1_Model5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nWÃ¤hlen wir jetzt mal den besten Modellkandidaten aus (im Sinne des Optimierungskriteriusms, RMSE) und fitten damit das *gesamte* Train-Sample:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-29_a664b44581f528a42bd9afeb7b4334c3'}\n\n```{.r .cell-code}\nfit_best_train <- fit_best(ames_grid_search2)\nfit_best_train\n## â•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## 3 Recipe Steps\n## \n## â€¢ step_zv()\n## â€¢ step_normalize()\n## â€¢ step_impute_median()\n## \n## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n## \n## Call:\n## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(11L,     data, 5))\n## \n## Type of response variable: continuous\n## minimal mean absolute error: 0.06805458\n## Minimal mean squared error: 0.009173394\n## Best kernel: optimal\n## Best k: 11\n```\n:::\n\n\n\nUnd mit den dann resultierenden Modellkoeffizienten sagen\nwir das TestSample vorher:\n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-last-fit_68217eaaa31d047ab6b9359489a8d0fc'}\n\n```{.r .cell-code}\nfit_best_train %>% \n  predict(new_data = ames_test) %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".pred\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5.248966\"},{\"1\":\"5.309815\"},{\"1\":\"5.228309\"},{\"1\":\"5.163397\"},{\"1\":\"5.400410\"},{\"1\":\"5.427851\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-30_fcfce345d2c718908a9d291bdf49f7fa'}\n\n```{.r .cell-code}\nfit_best_train %>% \n  predict(new_data = ames_test) %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".pred\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5.248966\"},{\"1\":\"5.309815\"},{\"1\":\"5.228309\"},{\"1\":\"5.163397\"},{\"1\":\"5.400410\"},{\"1\":\"5.427851\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nMit `augment` kann man die Vorhersagen eines Modells zum Test-Datensatz hinzufÃ¼gen:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-31_b7f2f01255b1aff212f0b2618d5d92ea'}\n\n```{.r .cell-code}\names_test <- \n  augment(fit_best_train, new_data = ames_test)\n```\n:::\n\n\n\n\n\nHolen wir uns die ModellgÃ¼te:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-32_9a2da9596e44ce194263a83f886d4b09'}\n\n```{.r .cell-code}\nrsq(data = ames_test,\n    truth = Sale_Price,\n    estimate = .pred)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.6871914\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n\n\n\n## Aufgaben\n1. [tidymodels-penguins01](https://datenwerk.netlify.app/posts/tidymodels-penguins1/tidymodels-penguins01.html)\n1. [tidymodels-penguins02](https://datenwerk.netlify.app/posts/tidymodels-penguins02/tidymodels-penguins02.html)\n1. [tidymodels-penguins03](https://datenwerk.netlify.app/posts/tidymodels-penguins03/tidymodels-penguins03.html)\n1. [tidymodels-penguins04](https://datenwerk.netlify.app/posts/tidymodels-penguins04/tidymodels-penguins04.html)\n1. [tidymodels-penguins05](https://datenwerk.netlify.app/posts/tidymodels-penguins05/tidymodels-penguins05.html)\n\n\n## Fallstudien\n\nIn @sec-fallstudien finden Sie eine ausfÃ¼hrliche Liste an Fallstudien.\n\n\n- Arbeiten Sie sich so gut als mÃ¶glich durch [diese Analyse zum Verlauf von Covid-FÃ¤llen](https://github.com/sebastiansauer/covid-icu)\n- [Fallstudie zur Modellierung einer logististischen Regression mit tidymodels](https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/)\n- [Fallstudie zu VulkanausbrÃ¼chen (Resampling and kein Tuning)](https://juliasilge.com/blog/multinomial-volcano-eruptions/)\n- [Fallstudie Himalaya (Resampling and kein Tuning)](https://juliasilge.com/blog/himalayan-climbing/)\n- [Fallstudie Serie The Office: Lasso tunen](https://juliasilge.com/blog/lasso-the-office/)\n- [Fallstudie BÃ¤ume in San Francisco: Random Forest tunen](https://dev.to/juliasilge/tuning-random-forest-hyperparameters-in-r-with-tidytuesday-trees-data-4ilh)\n\n\n\n##  Vertiefung\n\n[Fields arranged by purity, xkcd 435](https://xkcd.com/435/)\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}