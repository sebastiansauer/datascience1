{
  "hash": "2844c2d8419f6104b10d15dba95c49cc",
  "result": {
    "markdown": "# Resampling und Tuning {#sec-res-tune}\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-1_a4ddb5e8314c9e73856ba49c84032ff7'}\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Lernsteuerung\n\n\n### Lernziele\n- Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.\n- Sie k√∂nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.\n    \n### Vorbereitung\n- Lesen Sie die Literatur.\n\n###  Literatur\n- Rhys, Kap. 3\n- TMWR, Kap. 10, 12\n\n\n\n\n### Ben√∂tigte R-Pakete\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/libs-resampling-tuning_c26dfe43e95416089da75866ee91b5ea'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(tictoc)  # Rechenzeit messen, optional\n```\n:::\n\n\n\n\n\n### Daten\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-2_823a54fda0e1fe85062eb3dca585e670'}\n\n```{.r .cell-code}\ndata(ames)\n```\n:::\n\n\n\n## √úberblick\n\n\n### Train- und Test-Sample vervielfacht\n\nIn @sec-overfit haben wir gelernt, dass ein Modell in einem zweiten Datensatz auf seine Modellg√ºte hin √ºberpr√ºft werden und sollte und nicht in dem (ersten) Datensatz, in dem die Modellparameter berechnet wurden.\n\nIn diesem Kapitel werden wir wir von einem Modell *mehrere Varianten* berechnen,\ndaher ben√∂tigen wir f√ºr jeden dieser Varianten oder \"Modellkandidaten\" eine eigene Train-Test-Aufteilung. \nZur Klarheit der Begrifflichkeiten nennt man die resultierenden Teile in dem Fall *Analyse- und Assessment-Sample*, s. @fig-analys-assess-test dargestellt aus \nKap. 10.2 in @silge_tidy_2022 ([Quelle](https://www.tmwr.org/resampling.html)).\n\n\n![Die Aufteilung der Daten im Falle mehrerer Modellkandidaten](img/resampling.svg){#fig-analys-assess-test width=\"50%\"}\n\n\n### Standardablauf\n\nEin Standardablauf des maschinellen Lernens ist in @fig-process1 dargestellt.\n\n\n```{mermaid}\n%%| label: fig-process1\n%%| fig-cap: \"Standardablauf des maschinellen Lernens mit Tuning und Resampling (S: Sample bzw. Stichprobe)\"\n\nflowchart TD\n   \nGesamtdatensatz --> Split[In Train- und Test aufteilen]\nsubgraph Fit[F√ºr jeden Modellkandidaten i]\n  subgraph Kand[Modellkandidat i]\n  F[Fitte im Train-S] --> T[Teste im Assessment-S]\n  end\nend\nSplit --> Fit\nFit --> Best[Bestimmte besten Kandidaten]\nBest --> lastFit[Fitte ihn im ganzen Train-S]\nlastFit --> test[Teste im Test-S]\n```\n\n\n\n\n\n\n### Datensatz aufteilen\n\nBisher haben wir den Gesamt-Datensatz stets in ein Train- und ein Test-Sample aufgeteilt.\n\n\n\n\nAber es k√∂nnte ja sein, dass die Aufteilung just die \"schwer zu  vorherzusagenden\" F√§lle in das Test-Sample bef√∂rdert.\nDann w√ºrde sich unser Modell √ºber die Ma√üen schwer tun und zu schlecht abschneiden.\nUmgekehrt k√∂nnte es ja passieren, dass die \"einfach zu vorherzusagenden\" F√§lle ins Test-Sample wandern, einfach durch die Zuf√§lligkeit der Aufteilung von Train- und Test-Sample.\n\nEine L√∂sung, die sich anbietet, lautet, die Train-Test-Aufteilung ein paar Mal durchzuf√ºhren, und sich dann mit dem Mittelwert der Modellg√ºte  zu begn√ºgen.\nVoil√†: Resampling!\n\n:::{.def-resampling}\n### Resampling\nResampling ist eine Verallgemeinerung des einfachen Aufteilens in Train- und Test-Sample.\nIm Kern wird aus dem Datensatz mehrere Stichproben durch wiederholtes Ziehen gezogen.\nDurch Resampling kann die Modellg√ºte besser bestimmt werden als durch einfaches Train-Test-Aufteilen.$\\square$\n:::\n\n:::{.callout-note}\nVerschiedene (zuf√§llige) Aufteilung eines Datensatzes in Train- und Test-Sample k√∂nnen zu verschiedenen Modellg√ºten f√ºhren. So k√∂nnten im Train-Sample durch eine bestimmte Zufallsaufteilung relativ viele (oder wenige) schwer zu klassifizierende F√§lle zusammen kommen.$\\square$\n:::\n\n\n### Resampling-Varianten\n\n\nVergleichen Sie die drei F√§lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:\n\n1. Wir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe \"vorher\". Wir finden eine Gesamtgenauigkeit von 80%.\n2. Wir fitten ein Klassifikationsmodell in einem Teil der urspr√ºnglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der urspr√ºnglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.\n3. Wir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der F√§lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.\n\n\nWelchen der drei F√§lle finden Sie am sinnvollsten? Warum?\nFall Nummer 3 bezeichnet man als *Kreuzvalidierung*.\n\n\n\n\n\n\n\n\n\n\n### Illustration des Resampling\n\n*Resampling* stellt einen Oberbegriff dar; *Kreuzvalidierung* ist ein Unterbegriff dazu.\nEs gibt noch andere Arten des Resampling, etwa *Bootstrapping* oder *Leave-One-Out-Cross-Validation* (LOOCV).\n\nIm Folgenden ist nur die Kreuzvalidierung dargestellt,\nda es eines der wichtigsten und vielleicht das am h√§ufigsten verwendete Verfahren des Resampling ist.\nIn vielen Quellen finden sich Erl√§uterungen anderer Verfahren dargestellt,\netwa in @silge_tidy_2022, @islr oder @rhys.\n\n\n\n\n\n\n\n## Umsetzung in tidymodels\n\nBetrachten wir dieses Konzept an einem konkreten Beispiel mit Tidymodels.\n\n\n\n### Keine Train-Test-Aufteilung\n\nWir teilen beim Resampling nicht einmal in Train- und Test-Sample, sondern mehrfach.\nDaher k√∂nnen wir uns die einfache Train-Test-Aufteilung sparen.\n\n\n:::{.callout-caution}\nWenn man ein Model auch tuned, also Tuning verwendet, dann werden wir wiederum die Train-Test-Aufteilung verwenden. Dazu sp√§ter mehr.$\\square$\n:::\n\n\n### Abh√§ngige Variable transformieren\n\nWir beginnen mit etwas Datenvorverarbeitung. \nHier transformieren wir die abh√§ngige Variable, und zwar mit einer Log-Transformation.\n\n:::{callout-note}\nM√∂chte man eine abh√§ngige Variable transformieren, \nso sollte das *au√üerhalb* des Rezepts passieren,\nda Tidymodels das \"Backen\" nicht auf die `outcome`-Variable ausf√ºhrt.$\\square$\n:::\n\n\nAus der [Dokumentation von `step_scale`](https://recipes.tidymodels.org/reference/step_scale.html):\n\n>   skip - A logical. Should the step be skipped when the recipe is baked by bake()? While all operations are baked when prep() is run, some operations may not be able to be conducted on new data (e.g. processing the outcome variable(s)). Care should be taken when using skip = TRUE as it may affect the computations for subsequent operations.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-4_c6d7e529a88c2695cfe7e1133cc82830'}\n\n```{.r .cell-code}\names <-\n  ames %>% \n  mutate(Sale_Price = log(Sale_Price, base = 10))\n```\n:::\n\n\n\n[Hier](https://www.tmwr.org/recipes.html#skip-equals-true) finden Sie eine Antwort,\nwarum tidymodels sich weigert, Informationen √ºber die AV vom Train- in das Test-Sample zu transferieren.\n\n\n\n\n\n\n### Rezept, Modell und Workflow definieren\n\nIn gewohnter Weise definieren wir zun√§chst den Workflow\nmit einem kNN-Modell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-wf_052328b91ba4b7e7948b7de79b77c51e'}\n\n```{.r .cell-code}\names_rec <-\n  recipe(Sale_Price ~ Lot_Area + Fireplaces + Longitude + Latitude,\n         data = ames) %>%\n  step_zv(all_predictors()) %>% \n  step_normalize(all_predictors()) %>% \n  step_impute_median(all_predictors())\n\nknn_model <-\n  nearest_neighbor(\n    mode = \"regression\"\n  ) \n\names_wflow1 <-\n  workflow() %>%\n  add_recipe(ames_rec) %>%\n  add_model(knn_model)\n```\n:::\n\n\nZur Erinnerung: Mit dem Rezept kNN-Modell ist noch *nicht* *berechnet,\nes ist nur ein \"Rezept\" erstellt.\n\n\n\n\n\n\n\n### Einfache v-fache Kreuzvalidierung\n\n@fig-resampling illustriert die zuf√§llige Aufteilung von $n=10$ F√§llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe. \nMan spricht von *Kreuzvalidierung* (cross validation, CV).\n\nIn diesem Fall wurden 70% der ($n=10$) F√§lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe);\nein willk√ºrlicher, aber nicht un√ºblicher Anteil.\nDiese Aufteilung wurde $v=3$ Mal vorgenommen,\nes resultieren drei \"Resampling-Stichproben\", die\nmanchmal auch als \"Faltungen\" bezeichnet werden.\n\n\n\n::: {.cell messagen='false' hash='080-Resampling-Tuning_cache/html/fig-resampling_1b39eb81b6c542698cd170d9cfb81257'}\n::: {.cell-output-display}\n![Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt](080-Resampling-Tuning_files/figure-html/fig-resampling-1.png){#fig-resampling width=100%}\n:::\n:::\n\n\n\n\n\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvmodar.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvmodar_d53146a97b478773a81f015de9ef1f19'}\n::: {.cell-output-display}\n![Kreuzvalidierung, Aufteilung in Train- vs. Testsample](img/crossval.png){#fig-cvmodar width=861}\n:::\n:::\n\n\n\nDer Gesamtfehler der Vorhersage (die Modellg√ºte) wird als *Mittelwert der Vorhersagefehler* in den einzelnen Faltungen berechnet.\n\nWarum ist die Vorhersage besser,\nwenn man mehrere Faltungen, mehrere Sch√§tzungen f√ºr $y$ also, vornimmt?\n\nDer Grund ist das Gesetz der gro√üen Zahl,\nnachdem sich eine Sch√§tzung in Mittelwert und Variabilit√§t stabilisiert mit steigendem\nStichprobenumfang,\ndem wahren Mittelwert also pr√§ziser sch√§tzt.^[Bei Normalverteilungen klappt das gut\nbei randlastigen Verteilungen leider nicht mehr [@fattails].]\nMit mehr Faltungen n√§hern wir uns also einem \"wahren\" Mittelwert der Modellg√ºte (und sonstiger Kennzahlen) n√§her an.\n\n\nH√§ufig werden $v=10$ Faltungen verwendet,\nwas sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.\n\nDie Nachteile der Kreuzvalidierung sind:\n\n1. Die Rechenzeit steigt (in der Regel) etwa proportional zur Anzahl der $v$ Faltungen.\n2. Da die Train-Stichprobe kleiner ist (als bei der einfachen Train-Test-Aufteilung), wird die Sch√§tzung der Modellkoeffizienten ungenauer sein und damit die Modellg√ºte geringer.\n\nInsgesamt √ºberwiegen zumeist die Vorteiler eines Resamplings (wie eine Kreuzvalidierung) im Vergleich zu einfachen Train-Test-Aufteilung.\n\n\n\n\n### Wiederholte Kreuzvalidierung\n\n\nDie $r$-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (n√§mlich $r=4$ mal),\n@modar stellt das Resampling so dar (S. 259), s. @fig-cvrep.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-cvrep_c9fae0c3bbdfc82690b35729aae4bf33'}\n::: {.cell-output-display}\n![Wiederholte Kreuzvalidierung](img/crossval_repeated.png){#fig-cvrep width=916}\n:::\n:::\n\n\nDie wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.\n\n<!-- @silge_tidy_2022 zeigen die Verringerung des Sch√§tzfehlers als Funktion der $r$ Wiederholungen dar, -->\n<!-- s. @fig-repcvred. -->\n\n\n<!-- ```{r repcvred, echo = FALSE, fig.cap = \"Reduktion des Sch√§tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung\"} -->\n<!-- #| label: fig-repcvred -->\n<!-- knitr::include_graphics(\"https://www.tmwr.org/figures/variance-reduction-1.png\") -->\n<!-- ``` -->\n\n\nWarum ist die Wiederholung der Kreuzvalidierung n√ºtzlich?\n\nDie Kreuvalidierung liefert einen Sch√§tzwert der Modellparameter,\ndie wahren Modellparameter werden also anhand einer Stichprobe von $n=1$ gesch√§tzt.\nMit h√∂herem Stichprobenumfang kann diese Sch√§tzung nat√ºrlich pr√§zisiert werden.\n\nDa jede Stichprobenverteilung bei $n \\rightarrow \\infty$ normalverteilt ist - \nein zentrales Theorem der Statistik, der *Zentrale Grenzwertsatz* (Central Limit Theorem) - \nkann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem $n$ ebenfalls ann√§hernd\nnormalverteilt^[Das klappt bei randlastigen Verteilungen nicht]. \nDann sind die Quantile bekannt und man kann die Streuung der Sch√§tzers, \n${\\sigma }_{\\bar {x}}$, z.B. f√ºr den Mittelwert,\neinfach sch√§tzen:\n\n$${\\displaystyle {\\sigma }_{\\bar {x}}\\ ={\\frac {\\sigma }{\\sqrt {n}}}}$$\n\n## Vertiefung\n\n### Andere Illustrationen\n\n\nEs gibt eine Reihe n√ºtzlicher, vergleichbarer Illustrationen in anderen B√ºchern zum Resampling:\n\n- [Timbers, Campbell & Lee, 2022, Kap. 6](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.1](https://datasciencebook.ca/img/cv.png)\n- [Silge & Kuhn, 2022, 10.2](https://www.tmwr.org/premade/three-CV.svg)\n- [Silge & Kuhn, 2022, 10.3](https://www.tmwr.org/premade/three-CV-iter.svg)\n- James, Witten, hastie & Tishirani, 2021, 5.3\n\n\n\n### Gesetz der gro√üen Zahl\n\nNach dem *Gesetz der gro√üen Zahl* (Law of Large Numbers) sollte sich der Mittelwert einer gro√üen Stichprobe \ndem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess) \nsehr nahe kommen.\n\n$$\\displaystyle \\lim _{n\\to \\infty }\\sum _{i=1}^{n}{\\frac {X_{i}}{n}}={\\overline {X}}$$\n\nDavid Salazar visualisiert das folgenderma√üen in [diesem Post](https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/) seines lesenswerten [Blogs](https://david-salazar.github.io/), s. @fig-lln).\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/fig-lln_fcbedab8d82ada9437c4e56b3c3a121d'}\n::: {.cell-output-display}\n![Gesetz der gro√üen Zahl](080-Resampling-Tuning_files/figure-html/fig-lln-1.png){#fig-lln width=672}\n:::\n:::\n\n\nWie man sieht, n√§hert sich der empirische Mittelwert (also in der Stichprobe)\nimmer mehr dem theoretischen Mittelwert, 0, an.\n\nAchtung: Bei randlastigen Verteilungen darf man dieses sch√∂ne, wohlerzogene Verhalten nicht erwarten [@fattails].\n\n\n\n\n\n\n\n\n## Kreuzvalidierung in tidymodels\n\n### Kreuzvalidierung definieren\n\nSo kann man eine *einfache* v-fache Kreuzvalidierung (cross-validation, CV) in Tidymodels auszeichnen^[$v=10$ in der Voreinstellung]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-6_f6fffaabf7d78e029b42e32dd81b74c2'}\n\n```{.r .cell-code}\nset.seed(2453)\names_folds <- vfold_cv(ames, strata = \"Sale_Price\")\names_folds\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWerfen wir einen Blick in die Spalte `splits`, erste Zeile:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-7_7f6ddac93ec56c563e7394630600bc59'}\n\n```{.r .cell-code}\names_folds %>% pluck(1, 1)\n## <Analysis/Assess/Total>\n## <2635/295/2930>\n```\n:::\n\n\n\nM√∂chte man die Defaults von `vfold_cv` wissen, schaut man in der Hilfe nach: `?vfold_cv`:\n\n\n`vfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)` \n\n\nProbieren wir $v=10$ und $r=10$:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-8_2e805abb2da9b8d1089a380c1d516db0'}\n\n```{.r .cell-code}\names_folds_rep <- vfold_cv(ames, \n                           strata = \"Sale_Price\", \n                           v = 10,\n                           repeats = 10)\names_folds_rep\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id2\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat01\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat02\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat03\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat04\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat05\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat06\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat07\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat08\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat09\",\"3\":\"Fold10\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold01\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold02\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold03\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold04\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold05\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold06\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold07\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold08\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold09\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Repeat10\",\"3\":\"Fold10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Resamples fitten\n\n\nHat unser Computer mehrere Rechenkerne, dann k√∂nnen wir diese nutzen und die Berechnungen beschleunigen.\nIm Standard wird sonst nur ein Kern verwendet.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-9_1cf6ba188b363ec1d342c38ceb927016'}\n\n```{.r .cell-code}\nmycores <- parallel::detectCores(logical = FALSE)\nmycores\n## [1] 4\n```\n:::\n\n\nAuf Unix/MacOC-Systemen kann man dann die Anzahl der parallelen Kerne so einstellen^[In Windows gibt es andere Wege.]:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-10_71ce5f7f59ef06f235e357da034b0fbd'}\n\n```{.r .cell-code}\nlibrary(doMC)\nregisterDoMC(cores = mycores)\n```\n:::\n\n\n\n\nSo, und jetzt fitten wir die Resamples und betrachten die Modellg√ºte in den Resamples:\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-11_210d576713f442f8c16e755b2283f262'}\n\n```{.r .cell-code}\ntic()\names_resamples_fit <- \n  ames_wflow1 %>% \n  fit_resamples(ames_folds)\ntoc()\n## 1.564 sec elapsed\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-12_fe29c3993fd5c225ea22a82bbbf6b9ab'}\n\n```{.r .cell-code}\n ames_resamples_fit %>%\n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.09819232\",\"4\":\"10\",\"5\":\"0.002151453\",\"6\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.69654336\",\"4\":\"10\",\"5\":\"0.010852310\",\"6\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n\n### Streuung in der Modellg√ºte zwischen den Resamples\n\nBetrachten wir die Streuungen der Modellg√ºte (RSMSE) in der 10-fachen, nicht wiederholten Kreuzvalidierung, s. @fig-cv-rmse.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-13_bae797a79e663d44bcf5ea32781934f7'}\n\n:::\n\n\n\nJetzt wiederholen wir die Kreuzvalidierung $r=5$ mal und betrachten wieder die Streuung der Modellg√ºte.\nDa wir $r$ mal so viele Modelle berechnen, ben√∂tigen wir - wenn nur ein einzelnen Rechenkern benutzt wird - $r$ mal so viel  Rechenzeit^[theoretisch].\n\n\nZuerst berechnen wir die wiederholte Kreuzvalidierung, das kann etwas dauern:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-14_799c600ab550b9e7ecad30c9c5a43e00'}\n\n```{.r .cell-code}\ntic()\names_resamples_fit_rep <- \n  ames_wflow1 %>% \n  fit_resamples(ames_folds_rep)\ntoc()\n## 7.843 sec elapsed\n```\n:::\n\n\nUnd hier sind die G√ºtekennzahlen der wiederholten Kreuzvalidierung.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-15_ba7955fd80637255da7dd6e04beb2d4d'}\n\n```{.r .cell-code}\names_resamples_fit_rep %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.09830861\",\"4\":\"100\",\"5\":\"0.0008507707\",\"6\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.69627852\",\"4\":\"100\",\"5\":\"0.0036773155\",\"6\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWie man sieht, ist der Standardfehler (`std_err`),\nalso die Streuung der Modellg√ºten *deutlich kleiner* in der wiederholten Kreuzvalidierung (verglichen mit der einfachen, r=1, Kreuzvalidierung).\n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-16_75dbe4c773f19ae63ce41174f8a98089'}\n\n:::\n\n\n\n\nAuf dieser Basis visualisieren wir die Ergebnisse: Wie man sieht, streuen die $v=10$ Faltungen in ihre Modellg√ºte, s. @fig-cv-rmse, links.\n\n:::{.callout-note}\nH√§tten wir nur ein Mal, nicht 10 Mal, in Train- und Test-Sample aufgeteilt, h√§ttten wir einen Wert der Modellg√ºte (z.B. den ersten) beobachtet. \nWir h√§tten (vielleicht) nicht geahnt, dass unser Wert nicht der einzig m√∂gliche ist.\nJetzt sehen wir aber, dass ein einzelner Wert nicht zuverl√§ssig ist.\nErst mehrere Wiederholungen (Resamples) erm√∂glichen eine zuverl√§ssige(re) Sch√§tzung der Modellg√ºte.$\\square$\n::::\n\n\n@fig-cv-rmse, rechts, zeigt ein zweites Ph√§nomen. \nDurch das Wiederholen ($r=5$) *sinkt*, nach dem Gesetz der gro√üen Zahl, die Streuung.\nGeringere Streuung bedeutet eine genauere Sch√§tzung des wahren G√ºtewerts. \n\n\n\n::: {#fig-cv-rmse .cell layout-ncol=\"2\" hash='080-Resampling-Tuning_cache/html/fig-cv-rmse_33eb78cbccc4f108df1cb3f6d4a7d883'}\n::: {.cell-output-display}\n![Streuung der Modellg√ºte (RMSE) mit v=10 r=1 CV](080-Resampling-Tuning_files/figure-html/fig-cv-rmse-1.png){#fig-cv-rmse-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Streuung der Modellg√ºte (RMSE) mit v=10 r=5 CV](080-Resampling-Tuning_files/figure-html/fig-cv-rmse-2.png){#fig-cv-rmse-2 width=672}\n:::\n\nStreuung der Modellg√ºte (RMSE) bei nicht wiederholter und wiederholter CV\n:::\n\n\n\n\nPuh, das war recht theoretisch. Ja, das Leben des Data-Scientisten ist nicht immer einfach,\nfindet auch Grumpy Cat, s. @fig-grumpy1.\n\n![Grumpy Cat und die Schwierigkeiten im Leben des Data-Scientisten](img/7h9qvw.jpg){#fig-grumpy1 width=\"50%\"}\n\n[Quelle: imgflip](https://imgflip.com/i/7h9qvw)\n\n\n## Tuning\n\n\n:::{.def-tuning}\n### Tuning\n\n>   üë®‚Äçüè´ Hey ChatGPT: Definiere Tuning mit maschinellen Lernen am Beispiel von knn und dem Parameter k.\n\n>   ü§ñ KNN (K-nearest neighbors) ist ein Machine-Learning-Algorithmus, bei dem die Vorhersage eines neuen Datenpunkts auf der Basis der k n√§chsten Nachbarn im Trainingsdatensatz getroffen wird. Der Parameter k gibt an, wie viele Nachbarn zur Vorhersage verwendet werden sollen. Eine wichtige Aufgabe beim Tuning von KNN besteht darin, den optimalen Wert f√ºr den Parameter k zu finden.\nWenn k zu klein gew√§hlt wird, kann dies zu einer √úberanpassung an den Trainingsdatensatz f√ºhren, w√§hrend bei zu gro√ü gew√§hltem k das Modell unteranpassung aufweisen kann. Durch Tuning kann ein optimales k gefunden werden, das zu einer besseren Leistung des Modells auf einem Validierungsdatensatz f√ºhrt.\nEs gibt verschiedene Methoden zum Tuning des k-Parameters. Eine M√∂glichkeit besteht darin, ein Rastersuchverfahren durchzuf√ºhren, bei dem eine vordefinierte Menge von k-Werten getestet wird, um dasjenige zu finden, das die beste Leistung auf einem Validierungsdatensatz aufweist. Eine andere M√∂glichkeit besteht darin, eine zuf√§llige Suche durchzuf√ºhren, indem man zuf√§llig verschiedene k-Werte ausw√§hlt und deren Leistung bewertet.\nDas Ziel des Tunings ist es, den besten Wert f√ºr den Parameter k zu finden, um das KNN-Modell zu verbessern und die Vorhersagegenauigkeit auf einem Testdatensatz zu maximieren. Das Tuning sollte jedoch immer mit einem unabh√§ngigen Testdatensatz durchgef√ºhrt werden, um sicherzustellen, dass das Modell nicht √ºberangepasst wird und auf neuen Daten gut funktioniert.^[https://chat.openai.com/chat, 2023-04-06]$\\square$\n:::\n\n\n\n### Tuning am Beispiel von knn\n\n\n\nIm K-N√§chste-Nachbarn-Modell (Klassifikation) ist der vorhergesagt Wert, $\\hat{y}$ f√ºr eine neue Beobachtung $x_0$ der *Modus* der $K$ n√§chsten Nachbarn.\n\n\nDie Wahl von $K$ hat einen zentralen Einfluss auf die Vorhersagen und damit auf die Vorhersageg√ºte.\nAllerdings wird $K$ *nicht* vom Modell gesch√§tzt.\nEs liegt an uns,\ndiesen Wert zu w√§hlen.\n\n\n:::{.def-tuningparameter}\n### Tuningparmaeter\nParameter eines Lernmodells, die vom Nutzer zu bestimmen sind, also nicht vom Lernmodell gesch√§tzt werden,\nnennt man *Tuningparameter*.$\\square$\n:::\n\n\n>    üßë‚Äçüéì Hab ich nicht genau verstanden!\n\n>    üë®‚Äçüè´ Lies es hier oder anderer Stelle noch einmal nach. Oder frag mal einen Bot wie ChatGPT!\n\n\n\n### Tuning in Tidymodels\n\nIn der Modellspezifikation des Modells k√∂nnen wir mit `tune()` *auszeichnen*,\nwelche Parameter wir tunen m√∂chten. \n\n\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-18_1a0f600932e498427feca6aa8860e23e'}\n\n```{.r .cell-code}\nknn_model2 <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune()  # Wir tunen den Parameter \"neighbors\"\n  ) \n```\n:::\n\n\n\nWir k√∂nnen dem Tuningparameter auch einen Namen (ID/Label) geben, z.B. \"K\":\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-19_ab556b94a7c0833aae28355910cb027b'}\n\n```{.r .cell-code}\nknn_model2a <-\n  nearest_neighbor(\n    mode = \"regression\",\n    neighbors = tune(\"K\")\n  ) \n```\n:::\n\n\n\n:::{.callout-note}\nTidymodels trennt generell das Spezifizieren vom Evaluieren:\nErst definieren wir ein Rezept und ein Modell, dann fitten wir es.\nDas gilt auch f√ºr das Tunen: Erst weisen wir Parameter zum Tunen aus,\ndann w√§hlen wir Tuningparameter und tunen.$\\square$\n:::\n\n\n\n\nIn `tidymodels` kann man mit `tune()` angeben, dass man einen bestimmten Parameter tunen m√∂chte. \n`tidymodels` f√ºhrt das dann ohne weiteres Federlesens f√ºr uns durch.\n\n\n\n\n\n<!-- M√∂chte man wissen,  -->\n<!-- welche und wie viele Tuningparameter tidymodels in einem Modell ber√ºcksichtigt, -->\n<!-- kann man so aufrufen^[Alle Tuningparameter eines Modells sieht man so: `knn_model2 %>%  -->\n<!--   extract_parameter_set_dials()`]: -->\n\n<!-- ```{r} -->\n<!-- knn_model2 %>%  -->\n<!--   extract_parameter_dials(\"neighbors\") -->\n<!-- ``` -->\n\n\n\n\n\nDie Ausgabe informiert uns,\ndass es nur einen Tuningparameter gibt in diesem Modell und\ndass der Name (Label, ID) des Tuningparameters \"K\" ist.\nAu√üerdem erfahren wir, dass der Tuningparmaeter die Anzahl der zu ber√ºcksichtigen Nachbarn bezeichent.\nDer Tuningparameter ist numerisch; das sieht man an `nparam[+]`.\nTidymodels w√§hlt einen Range von 1 bis 15 Nachbarn.\n\n:::{.callout-note}\nPraktisch! Oft ist es nicht leicht zu wissen, was ein gutes Spektrum an Werten eines Tuningparameters ist. `tidymodels` bzw. `dials` macht es einfach: \nEs gibt uns einen Bereich plausibler Tuningwerte vor.$\\square$\n:::\n\n\nJetzt aktualisieren wir unseren Workflow mit dem neuen `knn_model2`,\nin dem jetzt ein Modellparameter ($k$) zum Tunen ausgezeichnet ist:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-20_f782533177ebcd91e04c821c2ddb2f32'}\n\n```{.r .cell-code}\names_wflow2 <-\n  ames_wflow1 %>% \n  update_model(knn_model2)\n```\n:::\n\n\n\nNat√ºrlich h√§tten wir auch von Anfang an den Workflow mit Tuning auszeichnen k√∂nnen:\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-21_b0825883c961beaf8d71c940ab5b253d'}\n\n```{.r .cell-code}\names_wflow2 <- \n  workflow() %>% \n  add_model(knn_model2) %>% \n  add_recipe(ames_rec)\n```\n:::\n\n\n\n<!-- Wir k√∂nnen auch Einfluss nehmen und angeben, -->\n<!-- dass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll  -->\n<!-- (f√ºr den Tuningparameter `neighbors`): -->\n\n\n<!-- ```{r} -->\n<!-- knn_model3 <- -->\n<!-- nearest_neighbor( -->\n<!--   mode = \"classification\", -->\n<!--   neighbors = tune(id = \"K\") %>% set_range(c(1, 50)) -->\n<!-- ) -->\n<!-- ``` -->\n\n<!-- Den Wertebereich eines Pr√§diktors kann man aber auch mit `search_grid` bestimmen. -->\n\n\n<!-- ```{r ames-update} -->\n<!-- ames_set <- -->\n<!--   extract_parameter_set_dials(ames_wflow) %>% -->\n<!--   update(K = neighbors(c(1, 50))) -->\n\n<!-- ames_set -->\n<!-- ``` -->\n\n\n<!-- ### Datenabh√§ngige Tuningparameter -->\n\n<!-- Manche Tuningparameter kann man nur bestimmen, -->\n<!-- wenn man den Datensatz kennt. -->\n<!-- So ist die Anzahl der Pr√§diktoren, `mtry` in einem Random-Forest-Modell  -->\n<!-- sinnvollerweise als Funktion der Pr√§diktorenzahl zu w√§hlen. -->\n<!-- Der Workflow kennt aber den Datensatz nicht. -->\n<!-- Daher muss der Workflow noch \"finalisiert\" oder \"aktualisiert\" werden, -->\n<!-- um den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen. -->\n\n\n\n\n\n\n<!-- Wenn wir im Rezept aber z.B. die Anzahl der Pr√§diktoren ver√§ndert haben, -->\n<!-- m√∂chten wir die Grenzen des Wertebereichs f√ºr `mtry` (oder andere Tuningparameter) vielleicht nicht h√§ndisch, \"hartverdrahtet\" selber bestimmen, -->\n<!-- sondern lieber den Computer anweisen, und sinngem√§√ü sagen: -->\n<!-- \"Warte mal mit der Bestimmung der Werte der Tuningparameter, -->\n<!-- bis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir,  -->\n<!-- dass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch √§ndern musst. Und tu das dann auch.\" Dazu sp√§ter mehr. -->\n\n\n<!-- ```{r ames-finalize} -->\n<!-- ames_set <- -->\n<!--   workflow() %>%  -->\n<!--   add_model(knn_model2) %>%  -->\n<!--   add_recipe(ames_rec) %>%  -->\n<!--   extract_parameter_set_dials() %>%  -->\n<!--   finalize(ames_train) -->\n\n<!-- ames_set -->\n<!-- ``` -->\n\n\n### Doch wieder Train- und Test-Sample\n\nWenn man Tuning betreibt, ben√∂tigt man *doch* wieder die Aufteilung von Train- und Test-Sample.\nUm Overfitting zu vermeiden, sollte man das Test-Sample nur *einmal* verwenden.\nW√ºrde man viele Modelle am Test-Sample √ºberpr√ºfen, w√§re es nur eine Frage der Zeit,\nbis man - allein durch Rauschen - eine (scheinbar) hohe Modellg√ºte findet.\nDaher f√ºhrt man Tuning und Resampling nur im Train-Sample durch.\nDen besten, \"finalen\" Wert des Tuningparameters nutzt man dann um das ganze Train-Sample auf dieser Basis zu fitten. \nSchlie√ülich sagt man dann das Test-Sample vorher.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-split_51de8c4e0f645e00c3740a1eee431fa4'}\n\n```{.r .cell-code}\nset.seed(4595)\ndata_split <- initial_split(ames, strata = \"Sale_Price\")\n\names_train <- training(data_split)\names_test <- testing(data_split)\n```\n:::\n\n\n\n\n### Modelle mit Tuning berechnen\n\nNachdem wir die Tuningwerte bestimmt haben, \nk√∂nnen wir jetzt das Modell berechnen:\nF√ºr jeden Wert des Tuningparameters wird ein Modell berechnet:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/ames-tune-grid_0df91c4ef6b19b882d64fde0c91f0e17'}\n\n```{.r .cell-code}\names_grid_search <-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,\n    grid = 5  # 5 Tuningwerte insgesamt\n  )\names_grid_search\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIm Default berechnet `tiymodels` 10 verschiedene Tuningparamweterwerte (\"Kandidatenmodelle\").\nHier haben wir mit `grid = 5` uns mit 5 verschiedenen Werten zufrieden gegeben.\nTidymodels sucht uns nach einigen (recht vern√ºnftigen) Daumenregeln ein paar Werte aus.\n\n\nDie Spalte `.metrics` beinhaltet die Modellg√ºte f√ºr jedes Kandidatenmodell.\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-22_efbda543d35b317efca7dfeb0795ff16'}\n\n```{.r .cell-code}\names_grid_search %>% \n  collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"2\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.10883232\",\"5\":\"10\",\"6\":\"0.002266551\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"2\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.64383503\",\"5\":\"10\",\"6\":\"0.013328780\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"6\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09714204\",\"5\":\"10\",\"6\":\"0.002191705\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"6\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.70181334\",\"5\":\"10\",\"6\":\"0.010745119\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"8\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09592597\",\"5\":\"10\",\"6\":\"0.002333779\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"8\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.70790226\",\"5\":\"10\",\"6\":\"0.011108349\",\"7\":\"Preprocessor1_Model3\"},{\"1\":\"11\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09523430\",\"5\":\"10\",\"6\":\"0.002563218\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"11\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.71121114\",\"5\":\"10\",\"6\":\"0.012012210\",\"7\":\"Preprocessor1_Model4\"},{\"1\":\"14\",\"2\":\"rmse\",\"3\":\"standard\",\"4\":\"0.09517949\",\"5\":\"10\",\"6\":\"0.002674685\",\"7\":\"Preprocessor1_Model5\"},{\"1\":\"14\",\"2\":\"rsq\",\"3\":\"standard\",\"4\":\"0.71116732\",\"5\":\"10\",\"6\":\"0.012545013\",\"7\":\"Preprocessor1_Model5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nIm Standard wird bei Regression (numerischer Vorhersage) der RMSE und R-Quadrat ausgegeben.\n\nDie Modellg√ºte in Abh√§ngigkeit der Tuningwerte k√∂nnen wir uns einfach visualisieren lassen:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-23_ef4e637ad5fc09d6738a8e3dd38232e9'}\n\n```{.r .cell-code}\nautoplot(ames_grid_search)\n```\n\n::: {.cell-output-display}\n![](080-Resampling-Tuning_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\nAuf Basis dieser Ergebnisse k√∂nnte es Sinn machen, \nnoch gr√∂√üere Werte f√ºr $K$ zu √ºberpr√ºfen.\n\nTidymodels bietet verschiedene Optionen, \num ein \"Gitter\" (`grid`) an Werten von einem oder (in vielen Modellen) mehreren Tuningparametern zu durchsuchen.\n\nAm einfachsten ist es, wenn wir ein Gitter an Werten als Tabelle (Tibble) vorgeben:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-24_9b2c8e1e557fadea71cbdce1645fd6fa'}\n\n```{.r .cell-code}\ngrid1 <- \n  tibble(neighbors = 1:10)\n```\n:::\n\n\n\nDabei m√ºssen die Spalten so hei√üen, wie Tidymodels die Tuningparameter benennt.\n\n:::{.callout-tip}\nDie Namen der Tuningparameter erf√§hrt man auf der Hilfeseite des Modells, z.B. `nearest_neighbor`. Oder mit `show_model_info(\"nearest_neighbor\")`.\nAm komfortabelsten geht es mit `extract_parameter_set_dials(ames_wflow2)`.$\\square$\n:::\n\n\n\n\nEine andere M√∂glichkeit ist, ein Gitter mit *regelm√§√üigen* Abst√§nden der Werte zu erstellen, z.B. mit 5 Auspr√§gungen pro Tuningparameter:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-25_e78e50231981c761a0dfe5126376b669'}\n\n```{.r .cell-code}\ngrid2 <- \n  grid_regular(\n    neighbors(range = c(5L, 30L)),\n    levels = 5\n    )\ngrid2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5\"},{\"1\":\"11\"},{\"1\":\"17\"},{\"1\":\"23\"},{\"1\":\"30\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-26_73f3cb0fad2c1dcae61d35e331986766'}\n\n```{.r .cell-code}\names_grid_search2 <-\n  tune_grid(\n    object = ames_wflow2,\n    resamples = ames_folds,  \n    grid = grid2\n  )\names_grid_search2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"splits\"],\"name\":[1],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metrics\"],\"name\":[3],\"type\":[\"list\"],\"align\":[\"right\"]},{\"label\":[\".notes\"],\"name\":[4],\"type\":[\"list\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold01\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold02\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold03\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold04\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold05\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold06\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold07\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold08\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold09\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"},{\"1\":\"<S3: vfold_split>\",\"2\":\"Fold10\",\"3\":\"<tibble[,5]>\",\"4\":\"<tibble[,3]>\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Workflow finalisieren\n\n\nWelcher Modellkandidat war jetzt am besten?\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-27_6f51157f9377cf2ff87b22dfa1a81b25'}\n\n```{.r .cell-code}\nbester_modellkandidat <- select_best(ames_grid_search2)\nbester_modellkandidat\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neighbors\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"11\",\"2\":\"Preprocessor1_Model2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAha! Mit diesem Wert updaten bzw. \"finalisieren\" wir jetzt unseren Workflow.\nDann fitten wir zum letzten Mal mit diesem finalisierten Workflow das ganze Train-Sample,\num dann, endlich, das Test-Sample vorherzusagen.\n\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-28_795ff0f461d31de896030bdfcb57dc05'}\n\n```{.r .cell-code}\names_wflow2_final <- finalize_workflow(ames_wflow2, bester_modellkandidat)\names_wflow2_final\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 3 Recipe Steps\n## \n## ‚Ä¢ step_zv()\n## ‚Ä¢ step_normalize()\n## ‚Ä¢ step_impute_median()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = 11\n## \n## Computational engine: kknn\n```\n:::\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-29_8103d61b4808a90711afbf761b896343'}\n\n```{.r .cell-code}\names_last_fit <- last_fit(ames_wflow2_final, data_split)\n```\n:::\n\n\n\nModellg√ºte im Test-Sample:\n\n\n::: {.cell hash='080-Resampling-Tuning_cache/html/unnamed-chunk-30_06eafe6ddf306a7bdb3b16daf78ec369'}\n\n```{.r .cell-code}\ncollect_metrics(ames_last_fit)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"rmse\",\"2\":\"standard\",\"3\":\"0.1015789\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.6871914\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Mini-Projekt\n\n\nMan lernt eine Sache erst richtig, wenn man sie anwendet. Zuh√∂ren reicht nicht.\nDaher sollten Sie nicht nur den Stoff h√∂ren/lesen/sehen,\nsondern vor allen Dingen selber anwenden.\n\n:::{#exr-miniprojekt1}\n### Erstellen Sie eine pr√§diktive Modellierung\n\nErstellen Sie eine pr√§diktive Modellierung umgesetzt mit R/tidymodels entsprechend der hier vermittelten Methoden. Stellen Sie Code und Ergebnis bereit, am besten in Form eines Quarto-Dokuments auf einem geeigneten Github-Repositorium. \nVon (hohem) Nutzen ist, wenn Ihre Analyse reproduzierbar ist, also von Dritten nachpr√ºfbar ist.\nKurz gesagt hei√üt das: Stellen Sie Code und Daten bereit.\nDen zu analyisierenden Datensatz k√∂nnen Sie selber bestimmen.\nBereiten Sie sich darauf vor, Ihre Analyse (ca. 5 Min.) zu pr√§sentieren bzw. im Gespr√§ch Ihre Analyse zu diskutieren.$\\square$\n:::\n\n\n\n\n\n\n## Aufgaben\n1. [tidymodels-penguins01](https://datenwerk.netlify.app/posts/tidymodels-penguins1/tidymodels-penguins01.html)\n1. [tidymodels-penguins02](https://datenwerk.netlify.app/posts/tidymodels-penguins02/tidymodels-penguins02.html)\n1. [tidymodels-penguins03](https://datenwerk.netlify.app/posts/tidymodels-penguins03/tidymodels-penguins03.html)\n1. [tidymodels-penguins04](https://datenwerk.netlify.app/posts/tidymodels-penguins04/tidymodels-penguins04.html)\n1. [tidymodels-penguins05](https://datenwerk.netlify.app/posts/tidymodels-penguins05/tidymodels-penguins05.html)\n1. [tidymodels-poly01](https://datenwerk.netlify.app/posts/tidymodels-poly01/tidymodels-poly01.html)\n1. [tidymodels-poly02](https://datenwerk.netlify.app/posts/tidymodels-poly02/tidymodels-poly02.html)\n1. [knn-ames01](https://datenwerk.netlify.app/posts/knn-ames01/knn-ames01.html)\n\n## Fallstudien\n\nIn @sec-fallstudien finden Sie eine ausf√ºhrliche Liste an Fallstudien.\n\n\n- Arbeiten Sie sich so gut als m√∂glich durch [diese Analyse zum Verlauf von Covid-F√§llen](https://github.com/sebastiansauer/covid-icu)\n- [Fallstudie zur Modellierung einer logististischen Regression mit tidymodels](https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/)\n- [Fallstudie zu Vulkanausbr√ºchen (Resampling and kein Tuning)](https://juliasilge.com/blog/multinomial-volcano-eruptions/)\n- [Fallstudie Himalaya (Resampling and kein Tuning)](https://juliasilge.com/blog/himalayan-climbing/)\n- [Fallstudie Serie The Office: Lasso tunen](https://juliasilge.com/blog/lasso-the-office/)\n- [Fallstudie B√§ume in San Francisco: Random Forest tunen](https://dev.to/juliasilge/tuning-random-forest-hyperparameters-in-r-with-tidytuesday-trees-data-4ilh)\n\n\n\n##  Vertiefung\n\n[Fields arranged by purity, xkcd 435](https://xkcd.com/435/)\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}