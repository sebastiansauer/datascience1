{
  "hash": "cec6b4804fa916a05060456dde9f3001",
  "result": {
    "markdown": "\n\n# Statistisches Lernen \n\n\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-1_75d898d4604306e45f5458c7fdd47aea'}\n\n:::\n\n\n\n\n\n\n\n## Lernsteuerung\n\n### Vorbereitung\n\n- Lesen Sie die Hinweise zum Modul.\n- Installieren (oder Updaten) Sie die f√ºr dieses Modul angegeben Software.\n Lesen Sie die Literatur.\n\n\n###  Lernziele\n\n- Sie k√∂nnen erl√§utern, was man unter statistischem Lernen versteht.\n Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann.\n Sie kennen verschiedenen Arten von statistischem Lernen und k√∂nnen Algorithmen zu diesen Arten zuordnen.\n\n\n###  Literatur\n\n- Rhys, Kap. 1\n- evtl. Sauer, Kap. 15\n\n\n### Hinweise\n\n- Bitte beachten Sie die Hinweise zum Pr√§senzunterricht und der Streamingoption.\n- Bitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) l√§uft.\n\n\n### R-Pakete\n\n\n\n\nBen√∂tigte R-Pakete f√ºr dieses Kapitel:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-2_7f37a2d25af196cd8b81902d40f71170'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)\n```\n:::\n\n\n\n## Was ist Data Science?\n\n\nEs gibt mehrere Definitionen von *Data Science*, aber keinen kompletten Konsens.\n@baumer_modern_2017 definieren Data Science wie folgt (S. 4):\n\n\n::::{.callout-note}\nThe science of extracting meaningful information from data.$\\square$\n:::\n\nAuf der anderen Seite entgegen viele Statistiker: \"Hey, das machen wir doch schon immer!\".\n\n\nEine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (\"Dom√§ne\"), die sozusagen den Empf√§nger bzw. die Kunden oder den Rahmen stellt.\nDieser \"Dreiklang\" ist in folgendem Venn-Diagramm dargestellt.\n\n\n\n\n\n<script type=\"module\" src=\"https://unpkg.com/venny?module\"></script>\n\n<venn-diagram>\n  <venn-set name=\"A\" label=\"Statistik\"></venn-set>\n  <venn-set name=\"B\" label=\"Informatik\"></venn-set>\n  <venn-set name=\"C\" label=\"Dom√§ne\" size = \"5\"></venn-set>\n  <venn-n sets=\"A B C\">\n</venn-diagram>\n\n\n\n\n## Was ist Machine Learning?\n\n\n:::{#def-ml}\n*Maschinelles Lernen* (ML), oft auch (synonym) als *statistisches Lernen* (statistical learning) bezeichnet, ist ein Teilgebiet der *k√ºnstlichen Intelligenz* (KI; artificial intelligence, AI) [@rhys]. ML wird auch als *data-based* bezeichnet in Abgrenzung von *rule-based*, was auch als \"klassische KI\" bezeichnet wird, vgl. @fig-ai-ml2.\n:::\n\n\n\n\n\n```{mermaid}\n%%| label: fig-ai-ml2\n%%| fig-cap: \"KI und Maschinelles Lernen\"\n\nflowchart LR\n  subgraph KI[K√ºnstliche Intelligenz KI]\n    rb[rule based]\n    db[data based]\n  end   \n```\n\n\n\n\n\nIn beiden F√§llen finden Algorithmen Verwendung.\n\n:::{#def-algo}\n### Algorithmus\nAlgorithmen sind nichts anderes als genaue Schritt-f√ºr-Schritt-Anleitungen, um etwas zu erledigen.$\\square$\n:::\n\n\n:::{#exm-algo}\nEin Kochrezept ist ein klassisches Beispiel f√ºr einen Algorithmus.$\\square$\n:::\n\n[Hier](https://www.c-programming-simple-steps.com/images/xsum-two-numbers-h.png.pagespeed.ic.AM9WYFPgEo.webp) findet sich ein Beispiel f√ºr einen einfachen Additionsalgorithmus.\n\n\n\nEs gibt viele ML-Algorithmen, vgl. @fig-algos.\n\n\n\n```{mermaid}\n%%| label: fig-algos\n%%| fig-cap: ML-Matroschka\n\nflowchart LR\n  subgraph KI[KI]\n    subgraph ML[ML]\n      A[Regression]\n      B[Neuronale Netze]\n      C[weitere]\n    end\n  end\n```\n\n\n\n\n### Rule-based\n\nKlassische (√§ltere) KI implementiert Regeln \"hartverdrahtet\" in ein Computersystem. \nNutzer f√ºttern Daten in dieses System. Das System leitet dann daraus Antworten ab.\n\n*Regeln* kann man prototypisch mit *Wenn-Dann-Abfragen* darstellen:\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-5_fc782845c3d76d3d788b814b71804067'}\n\n```{.r .cell-code}\nlernzeit <- c(0, 10, 10, 20)\nschlauer_nebensitzer <- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] > 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}\n## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\n```\n:::\n\n\n\nSicherlich k√∂nnte man das schlauer programmieren, vielleicht so:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-6_48a8b281d015c00f765e85d1392875ff'}\n\n```{.r .cell-code}\nd <- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %>% \n  mutate(bestanden = ifelse(lernzeit > 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"lernzeit\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"schlauer_nebensitzer\"],\"name\":[2],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"bestanden\"],\"name\":[3],\"type\":[\"lgl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"FALSE\",\"3\":\"FALSE\"},{\"1\":\"10\",\"2\":\"FALSE\",\"3\":\"FALSE\"},{\"1\":\"10\",\"2\":\"TRUE\",\"3\":\"TRUE\"},{\"1\":\"20\",\"2\":\"TRUE\",\"3\":\"TRUE\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Data-based\n\nML hat zum Ziel, Regeln aus den Daten zu lernen. Man f√ºttert Daten und Antworten in das System, das System gibt Regeln zur√ºck.\n\n\n\n@islr definieren ML so:\nNehmen wir an, wir haben die abh√§ngige Variable $Y$ und $p$ Pr√§diktoren, $X_1,X_2, \\ldots, X_p$.\nWeiter nehmen wir an, die Beziehung zwischen $Y$ und $X = (X_1, X_2, \\ldots, X_p)$ kann durch eine Funktion $f$ beschrieben werden.\nDas kann man so darstellen:\n\n$$Y = f(X) + \\epsilon$$\n\nML kann man auffassen als eine Menge an Verfahren, um $f$ zu sch√§tzen.\n\nEin Beispiel ist in Abb. @fig-statlearning gezeigt [@islr].\n\n![Vorhersage des Einkommens durch Ausbildungsjahre](img/2-2.png){#fig-statlearning}\n\n\nNat√ºrlich kann $X$ mehr als eine Variable beinhalten, vgl. @fig-sl2) [@islr].\n\n![Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren](img/2-3.png){#fig-sl2}\n\n\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gef√ºttert und liefern Antworten.\nML-Systeme werden mit Daten und Antworten gef√ºttert und liefern Regeln zur√ºck, s.  @fig-ki-ml2.\n\n\n```{mermaid}\n%%| label: fig-ki-ml2\n%%| fig-cap: \"Vergleich von klassischer KI (rule-based) und ML (data-based)\"\nflowchart LR\n  subgraph rb[rule-based]\n  D[Daten] -->A[Antworten]\n  R[Regeln] -->A\n  end\n  subgraph db[data-based]\n  D2[Daten] --> R2[Regeln]\n  A2[Antworten] --> R2\n  end\n```\n\n\n\n\n## Modell vs. Algorithmus\n\n\n### Modell \n\nEin Modell, s. Abb. @fig-vw) [@spurzem_vw_2017]!\n\n![Ein Modell-Auto](img/vw_modell.JPG){#fig-vw width=\"33%\"}\n\n\n\n\nWie man sieht, ist ein Modell eine vereinfachte Repr√§sentation eines Gegenstands.\n\nDer Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. @fig-modell).\n\n\n![Gegenstand und Modell](img/Modell-crop.png){#fig-modell}\n\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln,\ndie aus den Daten gelernt wurden.\n\n\n### Beispiel f√ºr einen ML-Algorithmus\n\nUnter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren,\nanhand dessen die Beziehung zwischen $X$ und $Y$ \"gelernt\" wird. Bei @rhys (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:\n\n\n*Beispiel eines Regressionsalgorithmus*\n\n1. Setze Gerade in die Daten mit $b_0 = \\hat{y}, b_1 = 0$\n2. Berechne $MSS = \\sum (y_i - \\hat{y_i})^2$\n3. \"Drehe\" die Gerade ein bisschen, d.h. erh√∂he $b_1^{neu} = b_1^{alt} + 0.1$\n4. Wiederhole 2-3 solange, bis $MSS < \\text{Zielwert}$\n\n\nDiesen Algorithmus kann man \"von Hand\" z.B. mit [dieser App](https://shinyapps.org/showapp.php?app=https://shiny.psy.lmu.de/felix/lmfit&by=Felix%20Sch%C3%B6nbrodt&title=Find-a-fit!&shorttitle=Find-a-fit!) durchspielen.\n\n\n## Taxonomie\n\nMethoden des maschinellen Lernens lassen sich verschiedentlich gliedern.\nEine typische Gliederung unterscheidet in *supervidierte* (geleitete) und *nicht-supervidierte* (ungeleitete) Algorithmen, s. Abb. @fig-taxonomie).\n\n\n\n```{mermaid}\n%%| fig-cap: Taxonomie der Arten des maschinellen Lernens\n%%| label: fig-taxonomie\n\nflowchart LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --> SL\n  ML --> NSL\n  SL --> Re\n  SL --> Class\n  NSL --> DimRed\n  NSL --> Clust\n\n```\n\n\n\n\n### Geleitetes Lernen\n\nDie zwei Phasen des geleiteten Lernens sind in Abb. @fig-supervid) dargestellt.\n\n\n```{mermaid}\n%%| label: fig-supervid\n%%| fig-cap: \"Geleitetes Lernen geschieht in zwei Phasen\"\n\n\nflowchart TD\n  subgraph A[Lernphase]\n    B[Daten mit Antwort] --> C[Geleiteter Algorithmus]\n    C --> D[Modell]\n  end\n  subgraph E[Vorhersagephase]\n    H[Neue Daten ohne Antwort] --> F[Modell]\n    F --> G[Antworten]\n  end\n  A-->E\n```\n\n\n\n#### Regression: Numerische Vorhersage\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-10_1159516ea66e9d7c770fd13cc5c8c249'}\n\n```{.r .cell-code}\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](040-Statistisches-Lernen_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden *G√ºtekoeffizienten* gemessen:\n\n- Mean Squared Error (Mittlerer Quadratfehler):\n\n$$MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2$$\n\n\n- Mean Absolute Error (Mittlerer Absolutfehler):\n\n$$MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|$$\n\n\n:::: {.infobox .caution}\nWir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzusch√§tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.\n:::\n\n\n#### Klassifikation: Nominale Vorhersage\n\n![Bei einer Klassifikation wird nicht eine Zahl, sondern eine Klasse vorhergesagt](img/aktien-plot-1.png)\n\n\nDie Modellg√ºte eines numerischen Vorhersagemodells wird oft mit folgendem *G√ºtekoeffizienten* gemessen:\n\n- Mittlerer Klassifikationfehler $e$:\n\n$$e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) $$\n\nDabei ist $I$ eine Indikatorfunktion, die `1` zur√ºckliefert, \nwenn tats√§chlicher Wert und vorhergesagter Wert identisch sind.\n\n### Ungeleitetes Lernen\n\nDie zwei Phasen des ungeleiteten Lernens sind in @fig-unsuper dargestellt.\n\n\n\n\n```{mermaid}\n%%| label: fig-unsuper\n%%| fig-cap: \"Die zwei Phasen des un√ºberwachten Lernens\"\n\n\nflowchart LR\n  subgraph X[Lernphase]\n    A[Daten ohne Antwort] --> B[Ungeleiteter Algorithmus]\n    B --> C[Modell]\n  end\n  subgraph D[Vorhersagephase]\n    E[Neue Daten, ohne Antwort] --> C2[Modell]\n    C2 --> F[Zuordnung zu den Regeln des Modells]\n  end  \n  X--->D\n```\n\n\n\n\nUngeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. @fig-ungel):\n\n1. Fallreduzierendes Modellieren (Clustering)\n2. Dimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\n\n![Zwei Arten des ungeleitete Modellieren](img/ungeleitetes_Modellieren_crop.png){#fig-ungel}\n\n\n\n\n## Ziele des ML\n\nMan kann vier Ziele des ML unterscheiden, s. @fig-ziele.\n\n\n```{mermaid}\n%%| label: fig-ziele\n%%| fig-cap: Ziele des maschinellen Lernens\nflowchart TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[Erkl√§rung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --> V\n  ML --> E\n  ML --> B\n  ML --> DimRed\n```\n\n\n*Vorhersage* bezieht sich auf die Sch√§tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit).\n*Erkl√§rung* meint die kausale Analyse von Zusammenh√§ngen.\n*Beschreibung* ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken.\n*Dimensionsreduktion* ist ein Oberbegriff f√ºr Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s\n\n\nWie \"gut\" ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellg√ºte oder *model fit*. \nJe schlechter die Modellg√ºte, desto h√∂her der *Modellfehler*, vgl. @fig-resid.\n\n\n![Wenig (links) vs. viel (rechts) Vorhersagefehler](img/resids-plot-1.png){#fig-resid}\n\n\n\n\n\nDie Modellg√ºte eines Modells ist v.a. relevant f√ºr *neue Beobachtungen*,\nan denen das Modell *nicht* trainiert wurde.\n\n\n\n\n\n## √úber- vs. Unteranpassung {#sec-overfit}\n\n\n:::{#def-overfit}\n\n### Overfitting\nEin Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als \"bare M√ºnze\", also f√§lschlich als Signal. Solche Modelle haben zu viel *Varianz* in ihren Vorhersagen.$\\square$\n:::\n\n\n:::{#def-underfit}\n### Underfitting\nEin Modell ist zu simpel (ungenau, grobk√∂rnig) - es unterschl√§gt Nuancen des tats√§chlichen Musters. Solche Modelle haben zu viel *Verzerrung* (Bias) in ihren Vorhersagen.$\\square$\n:::\n\n\n### Beispiel 1\n\nWelches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. @fig-overunder), vgl. [@modar], Kap. 15?\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/fig-overunder_0c5c922df1ee9058bbf91e163e7538b9'}\n::: {.cell-output-display}\n![Over- vs. Underfitting](img/overfitting-4-plots-1.png){#fig-overunder width=576}\n:::\n:::\n\n\n\nWelches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?\n\nModell D zeigt sehr gute Beschreibung (\"Retrodiktion\") der Werte, anhand derer das Modell trainiert wurde (\"Trainingsstichprobe\").\nWird es aber \"ehrlich\" getestet, d.h. anhand neuer Daten (\"Test-Stichprobe\"),\nwird es vermutlich *nicht* so gut abschneiden.\n\n\nEs gilt, ein Modell mit \"mittlerer\" Komplexit√§t zu finden, um √úber- und Unteranpassung in Grenzen zu halten.\nLeider ist es nicht m√∂glich, vorab zu sagen, was der richtige, \"mittlere\" Wert an Komplexit√§t eines Modells ist, vgl. @fig-overfitting aus [@modar].\n\n\n\n\n### Beispiel 2\n\n\n@fig-overfitting-4-plots zeigt √úber- und Unteranpassung an einem Beispiel.\n\n\n\n\n\n\n\n\n- Teil *A*: Die 'wahre Funktion', $f$, die die Daten  erzeugt. Man spricht auch von der \"datengenerierenden Funktion\". Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das hei√üt nicht, dass die wahre Funktion die Daten perfekt erkl√§rt, schlie√ülich kann die Funktion zwar wahr, aber unvollst√§ndig sein oder unsere Messinstrumente sind nicht perfekt pr√§zise.\n- Teil *B:* Die Daten, erzeugt aus A plus etwas zuf√§lliges Fehler (Rauschen).\n- Teil *C*: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *D*: Ein zu komplexes Modell: √úberanpassung.  Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *E*: Ein Modell mittlerer Komplexit√§t. Keine √úberanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.\n\n\n### Mittlere Modellkomplexit√§t ist optimal\n\nWie @fig-overfitting zeigt, ist eine \"mittlere\" Modellkomplexit√§t (oft) optimal.\nFragt sich nur, was bzw. wo \"mittel\" genau liegt. ü§∑‚Äç‚ôÄÔ∏è\n\n\n![Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte: Gute Balance von Bias und Pr√§zision](img/overfitting-crop.png){#fig-overfitting width=\"50%\"}\n\n\n\n\n\n### Do-it-yourself Under-/Overfitting\n\nErkunden wir die Effekte von Under- und Overfitting an einem einfachen, \nsimulierten Datenbeispiel:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-14_26a706efe975934f449eacfee2e0bc24'}\n\n```{.r .cell-code}\nd <- tibble(\n  x = -2:2,\n  y = c(-1, -.5, 0, 0.1, 2)\n)\n```\n:::\n\n\n\nJetzt \"fitten\" wir eine zunehmend komplexe Funktion in diese Daten.\nAls Funktion w√§hlen wir ein Polynom von Grad 1 bis 4.\n\n- Ein Polynom 1. Grades ist eine lineare Funktion: $y \\sim  x¬π$.\n- Ein Polynom 2. Grades ist eine quadratische Funktion: $y \\sim x¬≤ + x$\n- Ein Polynom $n$. Grades ist eine Funktion der Form $y \\sim x^n + x^{n-1} + x^{n-2} + \\ldots + x$  \n\nPolynome werden flexibler (mehr \"T√§ler\" und \"Gipfel\" haben), je h√∂her ihr Grad ist.\nDaher stellt sich die Frage, welcher Grad der \"richtige\" ist.\nLeider wissen wir in der Praxis nicht, welche Funktion die Natur ausgew√§hlt hat.\nDaher w√§re eine L√∂sung, die Funktion auszuw√§hlen, welche die Daten am besten erkl√§rt.\n\n\n\n::: {#fig-poly .cell layout-ncol=\"2\" hash='040-Statistisches-Lernen_cache/html/fig-poly_7e7ceaed0e79596fdc463d9c41fecc5f'}\n\n```{.r .cell-code}\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE)\n```\n\n::: {.cell-output-display}\n![Grad 1](040-Statistisches-Lernen_files/figure-html/fig-poly-1.png){#fig-poly-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 2](040-Statistisches-Lernen_files/figure-html/fig-poly-2.png){#fig-poly-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 3](040-Statistisches-Lernen_files/figure-html/fig-poly-3.png){#fig-poly-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 4](040-Statistisches-Lernen_files/figure-html/fig-poly-4.png){#fig-poly-4 width=672}\n:::\n\nPolynome vom Grad 1-4\n:::\n\n\nWie man sieht, wird der Modellfehler immer kleiner, der \"Fit\" zunehmens besser.\n\nDas kann man sich nat√ºrlich auch pr√§ziser berechnen lassen.\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-16_e936000c0f55f395bd634e095e25ff6c'}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ poly(x, 1), data = d)\nlm2 <- lm(y ~ poly(x, 2), data = d)\nlm3 <- lm(y ~ poly(x, 3), data = d)\nlm4 <- lm(y ~ poly(x, 4), data = d)\n\nresults <-\n  tibble(r2_lm1 = r2(lm1)$R2,\n         r2_lm2 = r2(lm2)$R2,\n         r2_lm3 = r2(lm3)$R2,\n         r2_lm4 = r2(lm4)$R2)\n\nresults\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"r2_lm1\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm2\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm3\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm4\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.8396299\",\"2\":\"0.9189338\",\"3\":\"0.9813856\",\"4\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n:::{.callout-note}\nJe komplexer das Modell, desto besser der Fit^[ceteris paribus]\nin dem Modell, in das Modell berechnet wurde.\n:::\n\n\nAber wie gut werden die Vorhersagen f√ºr neue Daten sein?\n\nSagen wir, *in Wirklichkeit* ist der *datengenerierende Prozess*^[data-generating process, DGP] (DGP) eine einfache lineare Funktion, plus etwas Rauschen (Fehler, $\\epsilon$):\n\n$y \\sim x + \\epsilon$\n\nSagen wir, das Rauschen ist normalverteilt mit Streuung 0.5.\n\nSimulieren wir uns jetzt ein paar neue Daten, die aus dieser Funktion resultieren.\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-17_8f3b35eddaddfeb62e61cb9169a02ed0'}\n\n```{.r .cell-code}\nd1 <- tibble(\n  x = -2:2,\n  e = rnorm(n = 5, mean = 0, sd = .5), \n  y = x,  # \"wahrer\" Wert\n  y_hat = y + e  # beobachteter Wert mit Rauschen\n)\n\nd1\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"e\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"y_hat\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-2\",\"2\":\"-0.4028050\",\"3\":\"-2\",\"4\":\"-2.4028050\"},{\"1\":\"-1\",\"2\":\"-0.4714080\",\"3\":\"-1\",\"4\":\"-1.4714080\"},{\"1\":\"0\",\"2\":\"-0.7585373\",\"3\":\"0\",\"4\":\"-0.7585373\"},{\"1\":\"1\",\"2\":\"0.9261601\",\"3\":\"1\",\"4\":\"1.9261601\"},{\"1\":\"2\",\"2\":\"-1.5714355\",\"3\":\"2\",\"4\":\"0.4285645\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n:::{#def-traintest}\n### Train- und Test-Datensatz\nDen Datensatz, in dem man ein Modell berechnet (\"fittet\"), nennt man auch *Train-Datensatz*.\nEinen anderen Datensatz, den man nutzt, um die G√ºte des Modells zu √ºberpr√ºfen, nennt man *Test-Datensatz*\n:::\n\n\n\n\n\nDamit wir eine stabilere Datenbasis haben, simulieren wir aber pro X-Wert (-2, -1, 0, 1, 2) nicht nur einen Wert,\nsondern, sagen wir, 10:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-18_4ea6406f872c4e47f85f2d473f779b43'}\n\n```{.r .cell-code}\nd2 <- \n  tibble(\n    x = rep(-2:2, times = 10),\n    e = rnorm(n = 50, mean = 0, sd = .5),  # Rauschen, Fehlerterm\n    y_hat = x,  # \"wahrer\" Wert\n    y = x + e  # beobachteter Wert mit Rauschen\n  )\n\nd2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"e\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y_hat\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-2\",\"2\":\"-0.977194240\",\"3\":\"-2\",\"4\":\"-2.97719424\"},{\"1\":\"-1\",\"2\":\"-0.048994715\",\"3\":\"-1\",\"4\":\"-1.04899472\"},{\"1\":\"0\",\"2\":\"0.053811070\",\"3\":\"0\",\"4\":\"0.05381107\"},{\"1\":\"1\",\"2\":\"0.001139958\",\"3\":\"1\",\"4\":\"1.00113996\"},{\"1\":\"2\",\"2\":\"0.410066120\",\"3\":\"2\",\"4\":\"2.41006612\"},{\"1\":\"-2\",\"2\":\"0.430749210\",\"3\":\"-2\",\"4\":\"-1.56925079\"},{\"1\":\"-1\",\"2\":\"0.439262703\",\"3\":\"-1\",\"4\":\"-0.56073730\"},{\"1\":\"0\",\"2\":\"0.733344459\",\"3\":\"0\",\"4\":\"0.73334446\"},{\"1\":\"1\",\"2\":\"0.234004252\",\"3\":\"1\",\"4\":\"1.23400425\"},{\"1\":\"2\",\"2\":\"-0.508835762\",\"3\":\"2\",\"4\":\"1.49116424\"},{\"1\":\"-2\",\"2\":\"-0.028419029\",\"3\":\"-2\",\"4\":\"-2.02841903\"},{\"1\":\"-1\",\"2\":\"-0.620066726\",\"3\":\"-1\",\"4\":\"-1.62006673\"},{\"1\":\"0\",\"2\":\"-0.024476266\",\"3\":\"0\",\"4\":\"-0.02447627\"},{\"1\":\"1\",\"2\":\"0.253377468\",\"3\":\"1\",\"4\":\"1.25337747\"},{\"1\":\"2\",\"2\":\"-0.465556428\",\"3\":\"2\",\"4\":\"1.53444357\"},{\"1\":\"-2\",\"2\":\"-0.358957836\",\"3\":\"-2\",\"4\":\"-2.35895784\"},{\"1\":\"-1\",\"2\":\"-0.346773706\",\"3\":\"-1\",\"4\":\"-1.34677371\"},{\"1\":\"0\",\"2\":\"0.121081604\",\"3\":\"0\",\"4\":\"0.12108160\"},{\"1\":\"1\",\"2\":\"0.050939847\",\"3\":\"1\",\"4\":\"1.05093985\"},{\"1\":\"2\",\"2\":\"-0.217995656\",\"3\":\"2\",\"4\":\"1.78200434\"},{\"1\":\"-2\",\"2\":\"-0.605799955\",\"3\":\"-2\",\"4\":\"-2.60579996\"},{\"1\":\"-1\",\"2\":\"-0.448655249\",\"3\":\"-1\",\"4\":\"-1.44865525\"},{\"1\":\"0\",\"2\":\"-0.054598582\",\"3\":\"0\",\"4\":\"-0.05459858\"},{\"1\":\"1\",\"2\":\"0.174501000\",\"3\":\"1\",\"4\":\"1.17450100\"},{\"1\":\"2\",\"2\":\"0.281773653\",\"3\":\"2\",\"4\":\"2.28177365\"},{\"1\":\"-2\",\"2\":\"-0.300265537\",\"3\":\"-2\",\"4\":\"-2.30026554\"},{\"1\":\"-1\",\"2\":\"-0.934239434\",\"3\":\"-1\",\"4\":\"-1.93423943\"},{\"1\":\"0\",\"2\":\"0.040337674\",\"3\":\"0\",\"4\":\"0.04033767\"},{\"1\":\"1\",\"2\":\"-0.418894187\",\"3\":\"1\",\"4\":\"0.58110581\"},{\"1\":\"2\",\"2\":\"-0.144917415\",\"3\":\"2\",\"4\":\"1.85508258\"},{\"1\":\"-2\",\"2\":\"-0.435713671\",\"3\":\"-2\",\"4\":\"-2.43571367\"},{\"1\":\"-1\",\"2\":\"0.234661754\",\"3\":\"-1\",\"4\":\"-0.76533825\"},{\"1\":\"0\",\"2\":\"0.059742889\",\"3\":\"0\",\"4\":\"0.05974289\"},{\"1\":\"1\",\"2\":\"-0.738143335\",\"3\":\"1\",\"4\":\"0.26185666\"},{\"1\":\"2\",\"2\":\"0.793748884\",\"3\":\"2\",\"4\":\"2.79374888\"},{\"1\":\"-2\",\"2\":\"-0.301493385\",\"3\":\"-2\",\"4\":\"-2.30149339\"},{\"1\":\"-1\",\"2\":\"-0.299690728\",\"3\":\"-1\",\"4\":\"-1.29969073\"},{\"1\":\"0\",\"2\":\"0.809602588\",\"3\":\"0\",\"4\":\"0.80960259\"},{\"1\":\"1\",\"2\":\"-0.278634478\",\"3\":\"1\",\"4\":\"0.72136552\"},{\"1\":\"2\",\"2\":\"0.718404201\",\"3\":\"2\",\"4\":\"2.71840420\"},{\"1\":\"-2\",\"2\":\"0.218507186\",\"3\":\"-2\",\"4\":\"-1.78149281\"},{\"1\":\"-1\",\"2\":\"0.012257550\",\"3\":\"-1\",\"4\":\"-0.98774245\"},{\"1\":\"0\",\"2\":\"-0.688885019\",\"3\":\"0\",\"4\":\"-0.68888502\"},{\"1\":\"1\",\"2\":\"0.003081538\",\"3\":\"1\",\"4\":\"1.00308154\"},{\"1\":\"2\",\"2\":\"-0.206078688\",\"3\":\"2\",\"4\":\"1.79392131\"},{\"1\":\"-2\",\"2\":\"-0.763762402\",\"3\":\"-2\",\"4\":\"-2.76376240\"},{\"1\":\"-1\",\"2\":\"-0.536746312\",\"3\":\"-1\",\"4\":\"-1.53674631\"},{\"1\":\"0\",\"2\":\"0.779829748\",\"3\":\"0\",\"4\":\"0.77982975\"},{\"1\":\"1\",\"2\":\"0.397344427\",\"3\":\"1\",\"4\":\"1.39734443\"},{\"1\":\"2\",\"2\":\"-0.358514446\",\"3\":\"2\",\"4\":\"1.64148555\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/fig-polytest_5c5c6182f2bf68968f90b520a550a3e4'}\n\n```{.r .cell-code}\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE) +\n  geom_point(data = d2, color = \"blue\") \n```\n\n::: {.cell-output-display}\n![In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut](040-Statistisches-Lernen_files/figure-html/fig-polytest-1.png){#fig-polytest width=672}\n:::\n:::\n\n\n\nJetzt sieht das R-Quadrat schon nicht mehr so gut aus, s. @fig-polytest.\nBerechnen wir mal das R-Quadrat:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-20_22efc601fa13140bc4f006a8e8686b25'}\n\n```{.r .cell-code}\nrsq(data = d2, truth = y, estimate = y_hat)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.9279096\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n:::{#exr-overfitting}\n### Overfitting\n\nSimulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine einfache lineare Funktion sein (Polynom 1. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.$\\square$\n:::\n\n:::{#exr-overfitting2}\n### Overfitting 2\n\nSimulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine  Polynomfunktion sein (Polynom 2. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.$\\square$\n:::\n\n\n\n\n## No free lunch\n\n![Yoda meint: Es gibt nicht \"das\" beste Modell](img/yoda-best-model.jpg){width=\"50%\"}\n\n[Quelle: ImgFlip Meme Generator](https://imgflip.com/i/687izk)\n\n\n\nWenn $f$ (die Beziehung zwischen $Y$ und $X$, auch *datengenerierender Prozess* genannt) linear oder fast linear ist,\ndann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. \\@ref(fig:2-10) aus @islr, dort zeigt die schwarze Linie den \"wahren Zusammenhang\", also $f$ an. In orange sieht man ein lineares Modell, in gr√ºn ein hoch komplexes Modell,\ndas sich in einer \"wackligen\" Funktion - also mit hoher Varianz - \nniederschl√§gt. Das gr√ºne Modell k√∂nnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \n$y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon$. \nDas lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias.\nDaher ist es f√ºr dieses $f$ gut passend.\nDie gr√ºne Funktion zeigt dagegen √úberanpassung (overfitting), \nalso viel Modellfehler (f√ºr eine Test-Stichprobe).\n\n\n:::: {.callout-caution}\nDie gr√ºne Funktion in  @fig-2-10 wird neue, beim Modelltraining unbekannte Beobachtungen ($y_0$) vergleichsweise schlecht vorhersagen. In @fig-2-11 ist es umgekehrt.\n:::\n\n![Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren](img/2-10.png){#fig-2-10}\n\n\n\nBetrachten wir im Gegensatz dazu  @fig-2-11 aus @islr, die (in schwarz) eine hochgradig *nichtlineare* Funktion $f$ zeigt.\nEntsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. \nEin lineares Modell wird der Komplexit√§t von $f$ nicht gerecht,\nUnteranpassung (underfitting) liegt vor.\n\n\n\n![Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung](2-11.png){#fig-2-11}\n\n\n\n## Bias-Varianz-Abw√§gung\n\nDer Gesamtfehler $E$ des Modells ist die Summe dreier Terme:\n\n$$E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon$$\n\nDabei meint $\\epsilon$ den *nicht reduzierbaren Fehler*, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).\n\nBias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl.  @fig-bias-var aus @modar.\n\n\n![Abw√§ngung von Bias vs. Varianz](img/plot-bias-variance-1.png){#fig-bias-var}\n\n\n\n\n\n\n\n## Vertiefung\n\n\n- [Verdienst einer deutschen Data Scientistin](https://www.zeit.de/arbeit/2020-10/data-scientist-gehalt-geldanlage-programmieren-kontoauszug)\n- [Weitere Fallstudie zum Thema Regression auf Kaggle](https://www.kaggle.com/micahshull/r-bike-sharing-linear-regression)\n- [Crashkurs Data Science (Coursera, Johns Hopkins University) mit 'Star-Dozenten'](https://www.coursera.org/learn/data-science-course)\n- [Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf](https://www.kaggle.com/pranjalpandey12/performing-simple-linear-regression-in-r)\n- [Werfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise](https://www.kaggle.com/lazaro97/data-preprocessing-and-linear-regression-with-r)\n- [Wiederholen Sie unser Vorgehen in der Fallstudie zu den Flugversp√§tungen](https://data-se.netlify.app/2021/03/10/fallstudie-modellierung-von-flugversp%C3%A4tungen/)\n\n\n\n##  Aufgaben:\n- [Machen Sie sich mit 'Kaggle' vertraut](https://www.kaggle.com/)\n- [Bearbeiten Sie die Fallstudie 'TitaRnic' auf Kaggle](https://www.kaggle.com/code/headsortails/tidy-titarnic/report)\n- [Machen Sie sich mit dieser einfachen Fallstudie zur linearen Regression vertraut: The Movie Data Base Revenue (Kaggle)](https://www.kaggle.com/code/ssauer/notebook9188bfa616)\n\n\n##  Videos\n\n- [Prognose-Wettbewerbe bei Kaggle am Beispiel von *The Movie Data Base Revenue*](https://youtu.be/vR9l-k50I1M)\n  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}