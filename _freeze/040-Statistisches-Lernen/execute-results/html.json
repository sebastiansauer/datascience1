{
  "hash": "cec6b4804fa916a05060456dde9f3001",
  "result": {
    "markdown": "\n\n# Statistisches Lernen \n\n\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-1_75d898d4604306e45f5458c7fdd47aea'}\n\n:::\n\n\n\n\n\n\n\n## Lernsteuerung\n\n### Vorbereitung\n\n- Lesen Sie die Hinweise zum Modul.\n- Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\n Lesen Sie die Literatur.\n\n\n###  Lernziele\n\n- Sie können erläutern, was man unter statistischem Lernen versteht.\n Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann.\n Sie kennen verschiedenen Arten von statistischem Lernen und können Algorithmen zu diesen Arten zuordnen.\n\n\n###  Literatur\n\n- Rhys, Kap. 1\n- evtl. Sauer, Kap. 15\n\n\n### Hinweise\n\n- Bitte beachten Sie die Hinweise zum Präsenzunterricht und der Streamingoption.\n- Bitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) läuft.\n\n\n### R-Pakete\n\n\n\n\nBenötigte R-Pakete für dieses Kapitel:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-2_7f37a2d25af196cd8b81902d40f71170'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)\n```\n:::\n\n\n\n## Was ist Data Science?\n\n\nEs gibt mehrere Definitionen von *Data Science*, aber keinen kompletten Konsens.\n@baumer_modern_2017 definieren Data Science wie folgt (S. 4):\n\n\n::::{.callout-note}\nThe science of extracting meaningful information from data.$\\square$\n:::\n\nAuf der anderen Seite entgegen viele Statistiker: \"Hey, das machen wir doch schon immer!\".\n\n\nEine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (\"Domäne\"), die sozusagen den Empfänger bzw. die Kunden oder den Rahmen stellt.\nDieser \"Dreiklang\" ist in folgendem Venn-Diagramm dargestellt.\n\n\n\n\n\n<script type=\"module\" src=\"https://unpkg.com/venny?module\"></script>\n\n<venn-diagram>\n  <venn-set name=\"A\" label=\"Statistik\"></venn-set>\n  <venn-set name=\"B\" label=\"Informatik\"></venn-set>\n  <venn-set name=\"C\" label=\"Domäne\" size = \"5\"></venn-set>\n  <venn-n sets=\"A B C\">\n</venn-diagram>\n\n\n\n\n## Was ist Machine Learning?\n\n\n:::{#def-ml}\n*Maschinelles Lernen* (ML), oft auch (synonym) als *statistisches Lernen* (statistical learning) bezeichnet, ist ein Teilgebiet der *künstlichen Intelligenz* (KI; artificial intelligence, AI) [@rhys]. ML wird auch als *data-based* bezeichnet in Abgrenzung von *rule-based*, was auch als \"klassische KI\" bezeichnet wird, vgl. @fig-ai-ml2.\n:::\n\n\n\n\n\n```{mermaid}\n%%| label: fig-ai-ml2\n%%| fig-cap: \"KI und Maschinelles Lernen\"\n\nflowchart LR\n  subgraph KI[Künstliche Intelligenz KI]\n    rb[rule based]\n    db[data based]\n  end   \n```\n\n\n\n\n\nIn beiden Fällen finden Algorithmen Verwendung.\n\n:::{#def-algo}\n### Algorithmus\nAlgorithmen sind nichts anderes als genaue Schritt-für-Schritt-Anleitungen, um etwas zu erledigen.$\\square$\n:::\n\n\n:::{#exm-algo}\nEin Kochrezept ist ein klassisches Beispiel für einen Algorithmus.$\\square$\n:::\n\n[Hier](https://www.c-programming-simple-steps.com/images/xsum-two-numbers-h.png.pagespeed.ic.AM9WYFPgEo.webp) findet sich ein Beispiel für einen einfachen Additionsalgorithmus.\n\n\n\nEs gibt viele ML-Algorithmen, vgl. @fig-algos.\n\n\n\n```{mermaid}\n%%| label: fig-algos\n%%| fig-cap: ML-Matroschka\n\nflowchart LR\n  subgraph KI[KI]\n    subgraph ML[ML]\n      A[Regression]\n      B[Neuronale Netze]\n      C[weitere]\n    end\n  end\n```\n\n\n\n\n### Rule-based\n\nKlassische (ältere) KI implementiert Regeln \"hartverdrahtet\" in ein Computersystem. \nNutzer füttern Daten in dieses System. Das System leitet dann daraus Antworten ab.\n\n*Regeln* kann man prototypisch mit *Wenn-Dann-Abfragen* darstellen:\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-5_fc782845c3d76d3d788b814b71804067'}\n\n```{.r .cell-code}\nlernzeit <- c(0, 10, 10, 20)\nschlauer_nebensitzer <- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] > 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}\n## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\n```\n:::\n\n\n\nSicherlich könnte man das schlauer programmieren, vielleicht so:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-6_48a8b281d015c00f765e85d1392875ff'}\n\n```{.r .cell-code}\nd <- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %>% \n  mutate(bestanden = ifelse(lernzeit > 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"lernzeit\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"schlauer_nebensitzer\"],\"name\":[2],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"bestanden\"],\"name\":[3],\"type\":[\"lgl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"FALSE\",\"3\":\"FALSE\"},{\"1\":\"10\",\"2\":\"FALSE\",\"3\":\"FALSE\"},{\"1\":\"10\",\"2\":\"TRUE\",\"3\":\"TRUE\"},{\"1\":\"20\",\"2\":\"TRUE\",\"3\":\"TRUE\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Data-based\n\nML hat zum Ziel, Regeln aus den Daten zu lernen. Man füttert Daten und Antworten in das System, das System gibt Regeln zurück.\n\n\n\n@islr definieren ML so:\nNehmen wir an, wir haben die abhängige Variable $Y$ und $p$ Prädiktoren, $X_1,X_2, \\ldots, X_p$.\nWeiter nehmen wir an, die Beziehung zwischen $Y$ und $X = (X_1, X_2, \\ldots, X_p)$ kann durch eine Funktion $f$ beschrieben werden.\nDas kann man so darstellen:\n\n$$Y = f(X) + \\epsilon$$\n\nML kann man auffassen als eine Menge an Verfahren, um $f$ zu schätzen.\n\nEin Beispiel ist in Abb. @fig-statlearning gezeigt [@islr].\n\n![Vorhersage des Einkommens durch Ausbildungsjahre](img/2-2.png){#fig-statlearning}\n\n\nNatürlich kann $X$ mehr als eine Variable beinhalten, vgl. @fig-sl2) [@islr].\n\n![Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren](img/2-3.png){#fig-sl2}\n\n\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gefüttert und liefern Antworten.\nML-Systeme werden mit Daten und Antworten gefüttert und liefern Regeln zurück, s.  @fig-ki-ml2.\n\n\n```{mermaid}\n%%| label: fig-ki-ml2\n%%| fig-cap: \"Vergleich von klassischer KI (rule-based) und ML (data-based)\"\nflowchart LR\n  subgraph rb[rule-based]\n  D[Daten] -->A[Antworten]\n  R[Regeln] -->A\n  end\n  subgraph db[data-based]\n  D2[Daten] --> R2[Regeln]\n  A2[Antworten] --> R2\n  end\n```\n\n\n\n\n## Modell vs. Algorithmus\n\n\n### Modell \n\nEin Modell, s. Abb. @fig-vw) [@spurzem_vw_2017]!\n\n![Ein Modell-Auto](img/vw_modell.JPG){#fig-vw width=\"33%\"}\n\n\n\n\nWie man sieht, ist ein Modell eine vereinfachte Repräsentation eines Gegenstands.\n\nDer Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. @fig-modell).\n\n\n![Gegenstand und Modell](img/Modell-crop.png){#fig-modell}\n\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln,\ndie aus den Daten gelernt wurden.\n\n\n### Beispiel für einen ML-Algorithmus\n\nUnter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren,\nanhand dessen die Beziehung zwischen $X$ und $Y$ \"gelernt\" wird. Bei @rhys (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:\n\n\n*Beispiel eines Regressionsalgorithmus*\n\n1. Setze Gerade in die Daten mit $b_0 = \\hat{y}, b_1 = 0$\n2. Berechne $MSS = \\sum (y_i - \\hat{y_i})^2$\n3. \"Drehe\" die Gerade ein bisschen, d.h. erhöhe $b_1^{neu} = b_1^{alt} + 0.1$\n4. Wiederhole 2-3 solange, bis $MSS < \\text{Zielwert}$\n\n\nDiesen Algorithmus kann man \"von Hand\" z.B. mit [dieser App](https://shinyapps.org/showapp.php?app=https://shiny.psy.lmu.de/felix/lmfit&by=Felix%20Sch%C3%B6nbrodt&title=Find-a-fit!&shorttitle=Find-a-fit!) durchspielen.\n\n\n## Taxonomie\n\nMethoden des maschinellen Lernens lassen sich verschiedentlich gliedern.\nEine typische Gliederung unterscheidet in *supervidierte* (geleitete) und *nicht-supervidierte* (ungeleitete) Algorithmen, s. Abb. @fig-taxonomie).\n\n\n\n```{mermaid}\n%%| fig-cap: Taxonomie der Arten des maschinellen Lernens\n%%| label: fig-taxonomie\n\nflowchart LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --> SL\n  ML --> NSL\n  SL --> Re\n  SL --> Class\n  NSL --> DimRed\n  NSL --> Clust\n\n```\n\n\n\n\n### Geleitetes Lernen\n\nDie zwei Phasen des geleiteten Lernens sind in Abb. @fig-supervid) dargestellt.\n\n\n```{mermaid}\n%%| label: fig-supervid\n%%| fig-cap: \"Geleitetes Lernen geschieht in zwei Phasen\"\n\n\nflowchart TD\n  subgraph A[Lernphase]\n    B[Daten mit Antwort] --> C[Geleiteter Algorithmus]\n    C --> D[Modell]\n  end\n  subgraph E[Vorhersagephase]\n    H[Neue Daten ohne Antwort] --> F[Modell]\n    F --> G[Antworten]\n  end\n  A-->E\n```\n\n\n\n#### Regression: Numerische Vorhersage\n\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-10_1159516ea66e9d7c770fd13cc5c8c249'}\n\n```{.r .cell-code}\nggplot(mtcars) +\n  aes(x = hp, y = mpg) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](040-Statistisches-Lernen_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\nDie Modellgüte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden *Gütekoeffizienten* gemessen:\n\n- Mean Squared Error (Mittlerer Quadratfehler):\n\n$$MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2$$\n\n\n- Mean Absolute Error (Mittlerer Absolutfehler):\n\n$$MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|$$\n\n\n:::: {.infobox .caution}\nWir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzuschätzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.\n:::\n\n\n#### Klassifikation: Nominale Vorhersage\n\n![Bei einer Klassifikation wird nicht eine Zahl, sondern eine Klasse vorhergesagt](img/aktien-plot-1.png)\n\n\nDie Modellgüte eines numerischen Vorhersagemodells wird oft mit folgendem *Gütekoeffizienten* gemessen:\n\n- Mittlerer Klassifikationfehler $e$:\n\n$$e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) $$\n\nDabei ist $I$ eine Indikatorfunktion, die `1` zurückliefert, \nwenn tatsächlicher Wert und vorhergesagter Wert identisch sind.\n\n### Ungeleitetes Lernen\n\nDie zwei Phasen des ungeleiteten Lernens sind in @fig-unsuper dargestellt.\n\n\n\n\n```{mermaid}\n%%| label: fig-unsuper\n%%| fig-cap: \"Die zwei Phasen des unüberwachten Lernens\"\n\n\nflowchart LR\n  subgraph X[Lernphase]\n    A[Daten ohne Antwort] --> B[Ungeleiteter Algorithmus]\n    B --> C[Modell]\n  end\n  subgraph D[Vorhersagephase]\n    E[Neue Daten, ohne Antwort] --> C2[Modell]\n    C2 --> F[Zuordnung zu den Regeln des Modells]\n  end  \n  X--->D\n```\n\n\n\n\nUngeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. @fig-ungel):\n\n1. Fallreduzierendes Modellieren (Clustering)\n2. Dimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\n\n![Zwei Arten des ungeleitete Modellieren](img/ungeleitetes_Modellieren_crop.png){#fig-ungel}\n\n\n\n\n## Ziele des ML\n\nMan kann vier Ziele des ML unterscheiden, s. @fig-ziele.\n\n\n```{mermaid}\n%%| label: fig-ziele\n%%| fig-cap: Ziele des maschinellen Lernens\nflowchart TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[Erklärung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --> V\n  ML --> E\n  ML --> B\n  ML --> DimRed\n```\n\n\n*Vorhersage* bezieht sich auf die Schätzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit).\n*Erklärung* meint die kausale Analyse von Zusammenhängen.\n*Beschreibung* ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken.\n*Dimensionsreduktion* ist ein Oberbegriff für Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s\n\n\nWie \"gut\" ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellgüte oder *model fit*. \nJe schlechter die Modellgüte, desto höher der *Modellfehler*, vgl. @fig-resid.\n\n\n![Wenig (links) vs. viel (rechts) Vorhersagefehler](img/resids-plot-1.png){#fig-resid}\n\n\n\n\n\nDie Modellgüte eines Modells ist v.a. relevant für *neue Beobachtungen*,\nan denen das Modell *nicht* trainiert wurde.\n\n\n\n\n\n## Über- vs. Unteranpassung {#sec-overfit}\n\n\n:::{#def-overfit}\n\n### Overfitting\nEin Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als \"bare Münze\", also fälschlich als Signal. Solche Modelle haben zu viel *Varianz* in ihren Vorhersagen.$\\square$\n:::\n\n\n:::{#def-underfit}\n### Underfitting\nEin Modell ist zu simpel (ungenau, grobkörnig) - es unterschlägt Nuancen des tatsächlichen Musters. Solche Modelle haben zu viel *Verzerrung* (Bias) in ihren Vorhersagen.$\\square$\n:::\n\n\n### Beispiel 1\n\nWelches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. @fig-overunder), vgl. [@modar], Kap. 15?\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/fig-overunder_0c5c922df1ee9058bbf91e163e7538b9'}\n::: {.cell-output-display}\n![Over- vs. Underfitting](img/overfitting-4-plots-1.png){#fig-overunder width=576}\n:::\n:::\n\n\n\nWelches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?\n\nModell D zeigt sehr gute Beschreibung (\"Retrodiktion\") der Werte, anhand derer das Modell trainiert wurde (\"Trainingsstichprobe\").\nWird es aber \"ehrlich\" getestet, d.h. anhand neuer Daten (\"Test-Stichprobe\"),\nwird es vermutlich *nicht* so gut abschneiden.\n\n\nEs gilt, ein Modell mit \"mittlerer\" Komplexität zu finden, um Über- und Unteranpassung in Grenzen zu halten.\nLeider ist es nicht möglich, vorab zu sagen, was der richtige, \"mittlere\" Wert an Komplexität eines Modells ist, vgl. @fig-overfitting aus [@modar].\n\n\n\n\n### Beispiel 2\n\n\n@fig-overfitting-4-plots zeigt Über- und Unteranpassung an einem Beispiel.\n\n\n\n\n\n\n\n\n- Teil *A*: Die 'wahre Funktion', $f$, die die Daten  erzeugt. Man spricht auch von der \"datengenerierenden Funktion\". Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das heißt nicht, dass die wahre Funktion die Daten perfekt erklärt, schließlich kann die Funktion zwar wahr, aber unvollständig sein oder unsere Messinstrumente sind nicht perfekt präzise.\n- Teil *B:* Die Daten, erzeugt aus A plus etwas zufälliges Fehler (Rauschen).\n- Teil *C*: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *D*: Ein zu komplexes Modell: Überanpassung.  Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.\n- Teil *E*: Ein Modell mittlerer Komplexität. Keine Überanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.\n\n\n### Mittlere Modellkomplexität ist optimal\n\nWie @fig-overfitting zeigt, ist eine \"mittlere\" Modellkomplexität (oft) optimal.\nFragt sich nur, was bzw. wo \"mittel\" genau liegt. 🤷‍♀️\n\n\n![Mittlere Modellkomplexität führt zur besten Vorhersagegüte: Gute Balance von Bias und Präzision](img/overfitting-crop.png){#fig-overfitting width=\"50%\"}\n\n\n\n\n\n### Do-it-yourself Under-/Overfitting\n\nErkunden wir die Effekte von Under- und Overfitting an einem einfachen, \nsimulierten Datenbeispiel:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-14_26a706efe975934f449eacfee2e0bc24'}\n\n```{.r .cell-code}\nd <- tibble(\n  x = -2:2,\n  y = c(-1, -.5, 0, 0.1, 2)\n)\n```\n:::\n\n\n\nJetzt \"fitten\" wir eine zunehmend komplexe Funktion in diese Daten.\nAls Funktion wählen wir ein Polynom von Grad 1 bis 4.\n\n- Ein Polynom 1. Grades ist eine lineare Funktion: $y \\sim  x¹$.\n- Ein Polynom 2. Grades ist eine quadratische Funktion: $y \\sim x² + x$\n- Ein Polynom $n$. Grades ist eine Funktion der Form $y \\sim x^n + x^{n-1} + x^{n-2} + \\ldots + x$  \n\nPolynome werden flexibler (mehr \"Täler\" und \"Gipfel\" haben), je höher ihr Grad ist.\nDaher stellt sich die Frage, welcher Grad der \"richtige\" ist.\nLeider wissen wir in der Praxis nicht, welche Funktion die Natur ausgewählt hat.\nDaher wäre eine Lösung, die Funktion auszuwählen, welche die Daten am besten erklärt.\n\n\n\n::: {#fig-poly .cell layout-ncol=\"2\" hash='040-Statistisches-Lernen_cache/html/fig-poly_7e7ceaed0e79596fdc463d9c41fecc5f'}\n\n```{.r .cell-code}\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x, se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 2), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 3), se = FALSE)\n\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE)\n```\n\n::: {.cell-output-display}\n![Grad 1](040-Statistisches-Lernen_files/figure-html/fig-poly-1.png){#fig-poly-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 2](040-Statistisches-Lernen_files/figure-html/fig-poly-2.png){#fig-poly-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 3](040-Statistisches-Lernen_files/figure-html/fig-poly-3.png){#fig-poly-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Grad 4](040-Statistisches-Lernen_files/figure-html/fig-poly-4.png){#fig-poly-4 width=672}\n:::\n\nPolynome vom Grad 1-4\n:::\n\n\nWie man sieht, wird der Modellfehler immer kleiner, der \"Fit\" zunehmens besser.\n\nDas kann man sich natürlich auch präziser berechnen lassen.\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-16_e936000c0f55f395bd634e095e25ff6c'}\n\n```{.r .cell-code}\nlm1 <- lm(y ~ poly(x, 1), data = d)\nlm2 <- lm(y ~ poly(x, 2), data = d)\nlm3 <- lm(y ~ poly(x, 3), data = d)\nlm4 <- lm(y ~ poly(x, 4), data = d)\n\nresults <-\n  tibble(r2_lm1 = r2(lm1)$R2,\n         r2_lm2 = r2(lm2)$R2,\n         r2_lm3 = r2(lm3)$R2,\n         r2_lm4 = r2(lm4)$R2)\n\nresults\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"r2_lm1\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm2\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm3\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"r2_lm4\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0.8396299\",\"2\":\"0.9189338\",\"3\":\"0.9813856\",\"4\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n:::{.callout-note}\nJe komplexer das Modell, desto besser der Fit^[ceteris paribus]\nin dem Modell, in das Modell berechnet wurde.\n:::\n\n\nAber wie gut werden die Vorhersagen für neue Daten sein?\n\nSagen wir, *in Wirklichkeit* ist der *datengenerierende Prozess*^[data-generating process, DGP] (DGP) eine einfache lineare Funktion, plus etwas Rauschen (Fehler, $\\epsilon$):\n\n$y \\sim x + \\epsilon$\n\nSagen wir, das Rauschen ist normalverteilt mit Streuung 0.5.\n\nSimulieren wir uns jetzt ein paar neue Daten, die aus dieser Funktion resultieren.\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-17_8f3b35eddaddfeb62e61cb9169a02ed0'}\n\n```{.r .cell-code}\nd1 <- tibble(\n  x = -2:2,\n  e = rnorm(n = 5, mean = 0, sd = .5), \n  y = x,  # \"wahrer\" Wert\n  y_hat = y + e  # beobachteter Wert mit Rauschen\n)\n\nd1\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"e\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"y_hat\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-2\",\"2\":\"-0.23932340\",\"3\":\"-2\",\"4\":\"-2.23932340\"},{\"1\":\"-1\",\"2\":\"0.24135968\",\"3\":\"-1\",\"4\":\"-0.75864032\"},{\"1\":\"0\",\"2\":\"-0.01730621\",\"3\":\"0\",\"4\":\"-0.01730621\"},{\"1\":\"1\",\"2\":\"0.83150338\",\"3\":\"1\",\"4\":\"1.83150338\"},{\"1\":\"2\",\"2\":\"0.76442165\",\"3\":\"2\",\"4\":\"2.76442165\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n:::{#def-traintest}\n### Train- und Test-Datensatz\nDen Datensatz, in dem man ein Modell berechnet (\"fittet\"), nennt man auch *Train-Datensatz*.\nEinen anderen Datensatz, den man nutzt, um die Güte des Modells zu überprüfen, nennt man *Test-Datensatz*\n:::\n\n\n\n\n\nDamit wir eine stabilere Datenbasis haben, simulieren wir aber pro X-Wert (-2, -1, 0, 1, 2) nicht nur einen Wert,\nsondern, sagen wir, 10:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-18_4ea6406f872c4e47f85f2d473f779b43'}\n\n```{.r .cell-code}\nd2 <- \n  tibble(\n    x = rep(-2:2, times = 10),\n    e = rnorm(n = 50, mean = 0, sd = .5),  # Rauschen, Fehlerterm\n    y_hat = x,  # \"wahrer\" Wert\n    y = x + e  # beobachteter Wert mit Rauschen\n  )\n\nd2\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"x\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"e\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"y_hat\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"y\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-2\",\"2\":\"0.913650017\",\"3\":\"-2\",\"4\":\"-1.08634998\"},{\"1\":\"-1\",\"2\":\"-0.328004411\",\"3\":\"-1\",\"4\":\"-1.32800441\"},{\"1\":\"0\",\"2\":\"-0.093228606\",\"3\":\"0\",\"4\":\"-0.09322861\"},{\"1\":\"1\",\"2\":\"0.099773604\",\"3\":\"1\",\"4\":\"1.09977360\"},{\"1\":\"2\",\"2\":\"-1.191450093\",\"3\":\"2\",\"4\":\"0.80854991\"},{\"1\":\"-2\",\"2\":\"0.835700016\",\"3\":\"-2\",\"4\":\"-1.16429998\"},{\"1\":\"-1\",\"2\":\"0.137169575\",\"3\":\"-1\",\"4\":\"-0.86283042\"},{\"1\":\"0\",\"2\":\"-0.073156073\",\"3\":\"0\",\"4\":\"-0.07315607\"},{\"1\":\"1\",\"2\":\"0.500588390\",\"3\":\"1\",\"4\":\"1.50058839\"},{\"1\":\"2\",\"2\":\"-0.854361524\",\"3\":\"2\",\"4\":\"1.14563848\"},{\"1\":\"-2\",\"2\":\"0.291402644\",\"3\":\"-2\",\"4\":\"-1.70859736\"},{\"1\":\"-1\",\"2\":\"-0.176212910\",\"3\":\"-1\",\"4\":\"-1.17621291\"},{\"1\":\"0\",\"2\":\"0.232533881\",\"3\":\"0\",\"4\":\"0.23253388\"},{\"1\":\"1\",\"2\":\"-0.590661412\",\"3\":\"1\",\"4\":\"0.40933859\"},{\"1\":\"2\",\"2\":\"-0.529873335\",\"3\":\"2\",\"4\":\"1.47012667\"},{\"1\":\"-2\",\"2\":\"0.078612866\",\"3\":\"-2\",\"4\":\"-1.92138713\"},{\"1\":\"-1\",\"2\":\"-0.557684843\",\"3\":\"-1\",\"4\":\"-1.55768484\"},{\"1\":\"0\",\"2\":\"-0.410463338\",\"3\":\"0\",\"4\":\"-0.41046334\"},{\"1\":\"1\",\"2\":\"0.068389458\",\"3\":\"1\",\"4\":\"1.06838946\"},{\"1\":\"2\",\"2\":\"-0.531968407\",\"3\":\"2\",\"4\":\"1.46803159\"},{\"1\":\"-2\",\"2\":\"-0.078865464\",\"3\":\"-2\",\"4\":\"-2.07886546\"},{\"1\":\"-1\",\"2\":\"0.840211109\",\"3\":\"-1\",\"4\":\"-0.15978889\"},{\"1\":\"0\",\"2\":\"-0.161650158\",\"3\":\"0\",\"4\":\"-0.16165016\"},{\"1\":\"1\",\"2\":\"-0.566698882\",\"3\":\"1\",\"4\":\"0.43330112\"},{\"1\":\"2\",\"2\":\"-1.205235952\",\"3\":\"2\",\"4\":\"0.79476405\"},{\"1\":\"-2\",\"2\":\"-0.157482289\",\"3\":\"-2\",\"4\":\"-2.15748229\"},{\"1\":\"-1\",\"2\":\"-0.424128310\",\"3\":\"-1\",\"4\":\"-1.42412831\"},{\"1\":\"0\",\"2\":\"-0.331814573\",\"3\":\"0\",\"4\":\"-0.33181457\"},{\"1\":\"1\",\"2\":\"-0.365267382\",\"3\":\"1\",\"4\":\"0.63473262\"},{\"1\":\"2\",\"2\":\"0.528090431\",\"3\":\"2\",\"4\":\"2.52809043\"},{\"1\":\"-2\",\"2\":\"-0.001670189\",\"3\":\"-2\",\"4\":\"-2.00167019\"},{\"1\":\"-1\",\"2\":\"-0.127055922\",\"3\":\"-1\",\"4\":\"-1.12705592\"},{\"1\":\"0\",\"2\":\"0.041085093\",\"3\":\"0\",\"4\":\"0.04108509\"},{\"1\":\"1\",\"2\":\"0.053989031\",\"3\":\"1\",\"4\":\"1.05398903\"},{\"1\":\"2\",\"2\":\"0.111489446\",\"3\":\"2\",\"4\":\"2.11148945\"},{\"1\":\"-2\",\"2\":\"0.594475916\",\"3\":\"-2\",\"4\":\"-1.40552408\"},{\"1\":\"-1\",\"2\":\"0.466142352\",\"3\":\"-1\",\"4\":\"-0.53385765\"},{\"1\":\"0\",\"2\":\"-0.150038624\",\"3\":\"0\",\"4\":\"-0.15003862\"},{\"1\":\"1\",\"2\":\"-0.243682310\",\"3\":\"1\",\"4\":\"0.75631769\"},{\"1\":\"2\",\"2\":\"-0.805981143\",\"3\":\"2\",\"4\":\"1.19401886\"},{\"1\":\"-2\",\"2\":\"-0.830935052\",\"3\":\"-2\",\"4\":\"-2.83093505\"},{\"1\":\"-1\",\"2\":\"0.150488135\",\"3\":\"-1\",\"4\":\"-0.84951186\"},{\"1\":\"0\",\"2\":\"0.754185688\",\"3\":\"0\",\"4\":\"0.75418569\"},{\"1\":\"1\",\"2\":\"0.745282948\",\"3\":\"1\",\"4\":\"1.74528295\"},{\"1\":\"2\",\"2\":\"-0.067873291\",\"3\":\"2\",\"4\":\"1.93212671\"},{\"1\":\"-2\",\"2\":\"0.302485992\",\"3\":\"-2\",\"4\":\"-1.69751401\"},{\"1\":\"-1\",\"2\":\"-0.610898517\",\"3\":\"-1\",\"4\":\"-1.61089852\"},{\"1\":\"0\",\"2\":\"-0.546457089\",\"3\":\"0\",\"4\":\"-0.54645709\"},{\"1\":\"1\",\"2\":\"0.362245889\",\"3\":\"1\",\"4\":\"1.36224589\"},{\"1\":\"2\",\"2\":\"-0.281479987\",\"3\":\"2\",\"4\":\"1.71852001\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/fig-polytest_5c5c6182f2bf68968f90b520a550a3e4'}\n\n```{.r .cell-code}\nggplot(d) +\n  aes(x, y) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ poly(x, 4), se = FALSE) +\n  geom_point(data = d2, color = \"blue\") \n```\n\n::: {.cell-output-display}\n![In neuen Daten sind die Vorhersagen vom Polynom 4. Grades nicht mehr so gut](040-Statistisches-Lernen_files/figure-html/fig-polytest-1.png){#fig-polytest width=672}\n:::\n:::\n\n\n\nJetzt sieht das R-Quadrat schon nicht mehr so gut aus, s. @fig-polytest.\nBerechnen wir mal das R-Quadrat:\n\n\n::: {.cell hash='040-Statistisches-Lernen_cache/html/unnamed-chunk-20_22efc601fa13140bc4f006a8e8686b25'}\n\n```{.r .cell-code}\nrsq(data = d2, truth = y, estimate = y_hat)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"rsq\",\"2\":\"standard\",\"3\":\"0.8730394\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n:::{#exr-overfitting}\n### Overfitting\n\nSimulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine einfache lineare Funktion sein (Polynom 1. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.$\\square$\n:::\n\n:::{#exr-overfitting2}\n### Overfitting 2\n\nSimulieren Sie Daten, um ein Polynom 9. Grades zu berechnen. Die wahre Funktion soll eine  Polynomfunktion sein (Polynom 2. Grades). Berechnen und visualisieren Sie das Modell. Vergleichen Sie dann das R-Quadrat im Train- und im Test-Datensatz.$\\square$\n:::\n\n\n\n\n## No free lunch\n\n![Yoda meint: Es gibt nicht \"das\" beste Modell](img/yoda-best-model.jpg){width=\"50%\"}\n\n[Quelle: ImgFlip Meme Generator](https://imgflip.com/i/687izk)\n\n\n\nWenn $f$ (die Beziehung zwischen $Y$ und $X$, auch *datengenerierender Prozess* genannt) linear oder fast linear ist,\ndann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. \\@ref(fig:2-10) aus @islr, dort zeigt die schwarze Linie den \"wahren Zusammenhang\", also $f$ an. In orange sieht man ein lineares Modell, in grün ein hoch komplexes Modell,\ndas sich in einer \"wackligen\" Funktion - also mit hoher Varianz - \nniederschlägt. Das grüne Modell könnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \n$y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon$. \nDas lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias.\nDaher ist es für dieses $f$ gut passend.\nDie grüne Funktion zeigt dagegen Überanpassung (overfitting), \nalso viel Modellfehler (für eine Test-Stichprobe).\n\n\n:::: {.callout-caution}\nDie grüne Funktion in  @fig-2-10 wird neue, beim Modelltraining unbekannte Beobachtungen ($y_0$) vergleichsweise schlecht vorhersagen. In @fig-2-11 ist es umgekehrt.\n:::\n\n![Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem höheren Vorhersagefehler (bei neuen Daten!) resultieren](img/2-10.png){#fig-2-10}\n\n\n\nBetrachten wir im Gegensatz dazu  @fig-2-11 aus @islr, die (in schwarz) eine hochgradig *nichtlineare* Funktion $f$ zeigt.\nEntsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. \nEin lineares Modell wird der Komplexität von $f$ nicht gerecht,\nUnteranpassung (underfitting) liegt vor.\n\n\n\n![Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung](2-11.png){#fig-2-11}\n\n\n\n## Bias-Varianz-Abwägung\n\nDer Gesamtfehler $E$ des Modells ist die Summe dreier Terme:\n\n$$E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon$$\n\nDabei meint $\\epsilon$ den *nicht reduzierbaren Fehler*, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).\n\nBias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl.  @fig-bias-var aus @modar.\n\n\n![Abwängung von Bias vs. Varianz](img/plot-bias-variance-1.png){#fig-bias-var}\n\n\n\n\n\n\n\n## Vertiefung\n\n\n- [Verdienst einer deutschen Data Scientistin](https://www.zeit.de/arbeit/2020-10/data-scientist-gehalt-geldanlage-programmieren-kontoauszug)\n- [Weitere Fallstudie zum Thema Regression auf Kaggle](https://www.kaggle.com/micahshull/r-bike-sharing-linear-regression)\n- [Crashkurs Data Science (Coursera, Johns Hopkins University) mit 'Star-Dozenten'](https://www.coursera.org/learn/data-science-course)\n- [Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf](https://www.kaggle.com/pranjalpandey12/performing-simple-linear-regression-in-r)\n- [Werfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise](https://www.kaggle.com/lazaro97/data-preprocessing-and-linear-regression-with-r)\n- [Wiederholen Sie unser Vorgehen in der Fallstudie zu den Flugverspätungen](https://data-se.netlify.app/2021/03/10/fallstudie-modellierung-von-flugversp%C3%A4tungen/)\n\n\n\n##  Aufgaben:\n- [Machen Sie sich mit 'Kaggle' vertraut](https://www.kaggle.com/)\n- [Bearbeiten Sie die Fallstudie 'TitaRnic' auf Kaggle](https://www.kaggle.com/code/headsortails/tidy-titarnic/report)\n- [Machen Sie sich mit dieser einfachen Fallstudie zur linearen Regression vertraut: The Movie Data Base Revenue (Kaggle)](https://www.kaggle.com/code/ssauer/notebook9188bfa616)\n\n\n##  Videos\n\n- [Prognose-Wettbewerbe bei Kaggle am Beispiel von *The Movie Data Base Revenue*](https://youtu.be/vR9l-k50I1M)\n  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}