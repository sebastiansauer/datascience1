[["k-nächste-nachbarn.html", "Kapitel 8 K-Nächste-Nachbarn 8.1 Intuitive Erklärung 8.2 Krebsdiagnostik 8.3 Berechnung der Nähe 8.4 kNN mit Tidymodels 8.5 Mit Train-Test-Aufteilung 8.6 Kennzahlen der Klassifikation 8.7 Krebstest-Beispiel", " Kapitel 8 K-Nächste-Nachbarn Benötigte R-Pakete für dieses Kapitel: library(tidyverse) library(tidymodels) 8.1 Intuitive Erklärung K-Nächste-Nachbarn (k nearest neighbors, kNN) ist ein einfacher Algorithmus des maschinellen Lernens, der sowohl für Klassifikation als auch für numerische Vorhersage (Regression) genutzt werden kann. Wir werden kNN als Beispiel für eine Klassifikation betrachten. Betrachen wir ein einführendes Beispiel von Rhys (2020), für das es eine Online-Quelle gibt. Stellen Sie sich vor, wir laufen durch englische Landschaft, vielleicht die Grafschaft Kent, und sehen ein kleines Tier durch das Gras huschen. Eine Schlange?! In England gibt es (laut Rhys (2020)) nur eine giftige Schlange, die Otter (Adder). Eine andere Schlange, die Grass Snake ist nicht giftig, und dann kommt noch der Slow Worm in Frage, der gar nicht zur Familie der Schlangen gehört. Primär interessiert uns die Frage, haben wir jetzt eine Otter gesehen? Oder was für ein Tier war es? Zum Glück wissen wir einiges über Schlangen bzw. schlangenähnliche Tiere Englands. Nämlich können wir die betreffenden Tierarten in Größe und Aggressivität einschätzen, das ist in Abbildung 8.1 dargestellt. Figure 8.1: Haben wir gerade eine Otter gesehen? Der Algorithmus von kNN sieht einfach gesagt vor, dass wir schauen, welcher Tierarten Tiere mit ähnlicher Aggressivität und Größe angehören. Die Tierart die bei diesen “Nachbarn” hinsichtlich Ähnlichkeit relevanter Merkmale am häufigsten vertreten ist, ordnen wir die bisher unklassifizierte Beobachtung zu. Etwas zugespitzt: Wenn es quakt wie eine Ente, läuft wie eine Ente und aussieht wie eine Ente, dann ist es eine Ente. Die Anzahl \\(k\\) der nächsten Nachbarn können wir frei wählen; der Wert wird nicht vom Algorithmuss bestimmt. Solche vom Nutzi zu bestimmenden Größen nennt man auch Tuningparameter. 8.2 Krebsdiagnostik Betrachten wir ein Beispiel von Timbers, Campbell, and Lee (2022), das hier frei eingesehen werden kann. Die Daten sind so zu beziehen: data_url &lt;- &quot;https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv&quot; cancer &lt;- read_csv(data_url) In diesem Beispiel versuchen wir Tumore der Brust zu klassifizieren, ob sie einen schweren Verlauf (maligne, engl. malignant) oder einen weniger schweren Verlauf (benigne, engl. benign) erwarten lassen. Der Datensatz ist hier näher erläutert. Wie in Abb. 8.2 ersichtlich, steht eine Tumordiagnose (malignant vs. benign) in Abhängigkeit von Umfang (engl. perimeter) und Konkavität, die “Gekrümmtheit nach innen”. Figure 8.2: Streudiagramm zur Einschätzung von Tumordiagnosen Wichtig ist, dass die Merkmale standardisiert sind, also eine identische Skalierung aufweisen, da sonst das Merkmal mit kleinerer Skala weniger in die Berechnung der Nähe (bzw. Abstand) eingeht. Für einen neuen, bisher unklassifizierten Fall suchen nur nun nach einer Diagnose, also nach der am besten passenden Diagnose (maligne oder benigne), s. Abb. 8.3, wieder aus Timbers, Campbell, and Lee (2022). Ihr Quellcode für dieses Diagramm (und das ganze Kapitel) findet sich hier. Figure 8.3: Ein neuer Fall, bisher unklassifiziert Wir können zunächst den (im euklidischen Koordinatensystem) nächst gelegenen Fall (der “nächste Nachbar”) betrachten, und vereinbaren, dass wir dessen Klasse als Schätzwert für den unklassiffizierten Fall übernehmen, s. Abb. 8.4. Figure 8.4: Ein nächster Nachbar Betrachten wir einen anderen zu klassifizierenden Fall, s. Abb 8.5. Ob hier die Klassifikation von “benign” korrekt ist? Womöglich nicht, denn viele andere Nachbarn, die etwas weiter weg gelegen sind, gehören zur anderen Diagnose, malign. Figure 8.5: Trügt der nächste Nachbar? Um die Vorhersage zu verbessern, können wir nicht nur den nächst gelegenen Nachbarn betrachten, sondern die \\(k\\) nächst gelegenen, z.B. \\(k=3\\), s. Abb 8.6. Figure 8.6: kNN mit k=3 Die Entscheidungsregel ist dann einfach eine Mehrheitsentscheidung: Wir klassifizieren den neuen Fall entsprechend der Mehrheit in den \\(k\\) nächst gelegenen Nachbarn. 8.3 Berechnung der Nähe Es gibt verschiedenen Algorithmen, um die Nähe bzw. Distanz der Nachbarn zum zu klassifizieren Fall zu berechnen. Eine gebräuchliche Methode ist der euklidische Abstand, der mit Pythagoras berechnet werden kann, s. Abb. 8.7 aus Sauer (2019). Figure 8.7: Euklidischer Abstand wird mit der Regel von Pythagoras berechnet Wie war das noch mal? \\[c^2 = a^2 + b^2\\] Im Beispiel oben also: \\(c^2 = 3^2 + 4^2 = 5^2\\) Damit gilt: \\(c = \\sqrt{c^2} = \\sqrt{5^2}=5\\). Im 2D-Raum ist das so einfach, dass man das (fat) mit bloßem Augenschein entscheiden kann. In mehr als 2 Dimensionen wird es aber schwierig für das Auge, wie ein Beispiel aus Timbers, Campbell, and Lee (2022) zeigt. Allerdings kann man den guten alten Pythagoras auch auf Dreiecke mit mehr als zwei Dimensionen anwenden, s. Abb. 8.8 aus Sauer (2019), Kap. 21.1.2. Figure 8.8: Pythagoras in der Ebene (links) und in 3D (rechts) Bleiben wir beim Beispiel von Anna und Berta und nehmen wir eine dritte Variable hinzu (Statistikliebe). Sagen wir, der Unterschied in dieser dritten Variable zwischen Anna und Berta betrage 2. Es gilt: \\[ \\begin{aligned} e^2 &amp;= c^2 + d^2 \\\\ e^2 &amp;= 5^2 + 2^2 \\\\ e^2 &amp;= 25 + 4\\\\ e &amp;= \\sqrt{29} \\approx 5.4 \\end{aligned} \\] 8.4 kNN mit Tidymodels 8.4.1 Analog zu Timbers et al. Eine Anwendung von kNN mit Tidymodels ist in Timbers, Campbell, and Lee (2022), Kap. 5.6, hier beschrieben. Die Daten aus Timbers, Campbell, and Lee (2022) finden sich in diesem Github-Repo- Die (z-transformierten) Daten zur Tumorklassifikation können hier bezogen werden. data_url &lt;- &quot;https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv&quot; cancer &lt;- read_csv(data_url) Timbers, Campbell, and Lee (2022) verwenden in Kap. 5 auch noch nicht standardisierte Daten, unscales_wdbc.csv, die hier als CSV-Datei heruntergeladen werden können. cancer_unscales_path &lt;- &quot;https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv&quot; unscaled_cancer &lt;- read_csv(cancer_unscales_path) |&gt; mutate(Class = as_factor(Class)) |&gt; select(Class, Area, Smoothness) unscaled_cancer ## # A tibble: 569 × 3 ## Class Area Smoothness ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M 1001 0.118 ## 2 M 1326 0.0847 ## 3 M 1203 0.110 ## 4 M 386. 0.142 ## 5 M 1297 0.100 ## 6 M 477. 0.128 ## 7 M 1040 0.0946 ## 8 M 578. 0.119 ## 9 M 520. 0.127 ## 10 M 476. 0.119 ## # … with 559 more rows 8.4.2 Rezept definieren uc_recipe &lt;- recipe(Class ~ ., data = unscaled_cancer) print(uc_recipe) ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 2 Und jetzt die z-Transformation: uc_recipe &lt;- uc_recipe |&gt; step_scale(all_predictors()) |&gt; step_center(all_predictors()) Die Schritte prep() und bake() sparen wir uns, da fit() und predict() das für uns besorgen. 8.4.3 Modell definieren knn_spec &lt;- nearest_neighbor(weight_func = &quot;rectangular&quot;, neighbors = 5) |&gt; set_engine(&quot;kknn&quot;) |&gt; set_mode(&quot;classification&quot;) knn_spec ## K-Nearest Neighbor Model Specification (classification) ## ## Main Arguments: ## neighbors = 5 ## weight_func = rectangular ## ## Computational engine: kknn 8.4.4 Workflow definieren knn_fit &lt;- workflow() |&gt; add_recipe(uc_recipe) |&gt; add_model(knn_spec) |&gt; fit(data = unscaled_cancer) knn_fit ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: nearest_neighbor() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_scale() ## • step_center() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5, data, 5), kernel = ~&quot;rectangular&quot;) ## ## Type of response variable: nominal ## Minimal misclassification: 0.1107206 ## Best kernel: rectangular ## Best k: 5 8.4.5 Vorhersagen new_observation &lt;- tibble(Area = c(500, 1500), Smoothness = c(0.075, 0.1)) prediction &lt;- predict(knn_fit, new_observation) prediction ## # A tibble: 2 × 1 ## .pred_class ## &lt;fct&gt; ## 1 B ## 2 M 8.5 Mit Train-Test-Aufteilung Im Kapitel 5 greifen Timbers, Campbell, and Lee (2022) die Aufteilung in Train- vs. Test-Sample noch nicht auf (aber in Kapitel 6). Da in diesem Kurs diese Aufteilung aber schon besprochen wurde, soll dies hier auch dargestellt werden. cancer_split &lt;- initial_split(cancer, prop = 0.75, strata = Class) cancer_train &lt;- training(cancer_split) cancer_test &lt;- testing(cancer_split) 8.5.1 Rezept definieren cancer_recipe &lt;- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |&gt; step_scale(all_predictors()) |&gt; step_center(all_predictors()) 8.5.2 Modell definieren knn_spec &lt;- nearest_neighbor(weight_func = &quot;rectangular&quot;, neighbors = 3) |&gt; set_engine(&quot;kknn&quot;) |&gt; set_mode(&quot;classification&quot;) 8.5.3 Workflow definieren knn_fit &lt;- workflow() |&gt; add_recipe(cancer_recipe) |&gt; add_model(knn_spec) |&gt; fit(data = cancer_train) knn_fit ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: nearest_neighbor() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 2 Recipe Steps ## ## • step_scale() ## • step_center() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ## Call: ## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(3, data, 5), kernel = ~&quot;rectangular&quot;) ## ## Type of response variable: nominal ## Minimal misclassification: 0.1408451 ## Best kernel: rectangular ## Best k: 3 8.5.4 Vorhersagen Im Gegensatz zu Timbers, Campbell, and Lee (2022) verwenden wir hier last_fit() und collect_metrics(), da wir dies bereits eingeführt haben und künftig darauf aufbauen werden. cancer_test_fit &lt;- last_fit(knn_fit, cancer_split) cancer_test_fit ## # Resampling results ## # Manual resampling ## # A tibble: 1 × 6 ## splits id .metrics .notes .predictions .workflow ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [426/143]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;workflow&gt; 8.5.5 Modellgüte cancer_test_fit %&gt;% collect_metrics() ## # A tibble: 2 × 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy binary 0.909 Preprocessor1_Model1 ## 2 roc_auc binary 0.934 Preprocessor1_Model1 Die eigentlichen Predictions stecken in der Listenspalte .predictions im Fit-Objekt: names(cancer_test_fit) ## [1] &quot;splits&quot; &quot;id&quot; &quot;.metrics&quot; &quot;.notes&quot; &quot;.predictions&quot; ## [6] &quot;.workflow&quot; Genau genommen ist .predictions eine Spalte, in der in jeder Zeile (und damit Zelle) eine Tabelle (Tibble) steht. Wir haben nur eine Zeile und wollen das erste Element dieser Spalte herausziehen. Da hilft pluck(): cancer_test_predictions &lt;- cancer_test_fit %&gt;% pluck(&quot;.predictions&quot;, 1) confusion &lt;- cancer_test_predictions |&gt; conf_mat(truth = Class, estimate = .pred_class) confusion ## Truth ## Prediction B M ## B 82 5 ## M 8 48 8.5.6 Visualisierung autoplot(confusion, type = &quot;mosaic&quot;) autoplot(confusion, type = &quot;heatmap&quot;) + labs(x = &quot;Beobachtung&quot;, y = &quot;Vorhersage&quot;, title = &quot;Konfusionsmatrix&quot;) 8.6 Kennzahlen der Klassifikation In Sauer (2019), Kap. 19.6, findet sich einige Erklärung zu Kennzahlen der Klassifikationsgüte. Ein Test kann vier verschiedenen Ergebnisse haben: html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #vplwylbjib .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #vplwylbjib .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vplwylbjib .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #vplwylbjib .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #vplwylbjib .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vplwylbjib .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #vplwylbjib .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #vplwylbjib .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #vplwylbjib .gt_column_spanner_outer:first-child { padding-left: 0; } #vplwylbjib .gt_column_spanner_outer:last-child { padding-right: 0; } #vplwylbjib .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #vplwylbjib .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #vplwylbjib .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #vplwylbjib .gt_from_md > :first-child { margin-top: 0; } #vplwylbjib .gt_from_md > :last-child { margin-bottom: 0; } #vplwylbjib .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #vplwylbjib .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #vplwylbjib .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vplwylbjib .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #vplwylbjib .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #vplwylbjib .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #vplwylbjib .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #vplwylbjib .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #vplwylbjib .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vplwylbjib .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #vplwylbjib .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #vplwylbjib .gt_sourcenote { font-size: 90%; padding: 4px; } #vplwylbjib .gt_left { text-align: left; } #vplwylbjib .gt_center { text-align: center; } #vplwylbjib .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #vplwylbjib .gt_font_normal { font-weight: normal; } #vplwylbjib .gt_font_bold { font-weight: bold; } #vplwylbjib .gt_font_italic { font-style: italic; } #vplwylbjib .gt_super { font-size: 65%; } #vplwylbjib .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Table 8.1: Vier Arten von Ergebnissen von Klassifikationen Wahrheit Als negativ (-) vorhergesagt Als positiv (+) vorhergesagt Summe In Wahrheit negativ (-) Richtig negativ (RN) Falsch positiv (FP) N In Wahrheit positiv (+) Falsch negativ (FN) Richtig positiv (RN) P Summe N* P* N+P Es gibt eine verwirrende Vielfalt von Kennzahlen, um die Güte einer Klassifikation einzuschätzen. Hier sind einige davon: html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #wjnwlmnegs .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #wjnwlmnegs .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wjnwlmnegs .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #wjnwlmnegs .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #wjnwlmnegs .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wjnwlmnegs .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #wjnwlmnegs .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #wjnwlmnegs .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #wjnwlmnegs .gt_column_spanner_outer:first-child { padding-left: 0; } #wjnwlmnegs .gt_column_spanner_outer:last-child { padding-right: 0; } #wjnwlmnegs .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #wjnwlmnegs .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #wjnwlmnegs .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #wjnwlmnegs .gt_from_md > :first-child { margin-top: 0; } #wjnwlmnegs .gt_from_md > :last-child { margin-bottom: 0; } #wjnwlmnegs .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #wjnwlmnegs .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #wjnwlmnegs .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wjnwlmnegs .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #wjnwlmnegs .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #wjnwlmnegs .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #wjnwlmnegs .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #wjnwlmnegs .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #wjnwlmnegs .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wjnwlmnegs .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #wjnwlmnegs .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #wjnwlmnegs .gt_sourcenote { font-size: 90%; padding: 4px; } #wjnwlmnegs .gt_left { text-align: left; } #wjnwlmnegs .gt_center { text-align: center; } #wjnwlmnegs .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #wjnwlmnegs .gt_font_normal { font-weight: normal; } #wjnwlmnegs .gt_font_bold { font-weight: bold; } #wjnwlmnegs .gt_font_italic { font-style: italic; } #wjnwlmnegs .gt_super { font-size: 65%; } #wjnwlmnegs .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } Geläufige Kennwerte der Klassifikation. F: Falsch. R: Richtig. P: Positiv. N: Negativ Name Definition Synonyme FP-Rate FP/N Alphafehler, Typ-1-Fehler, 1-Spezifität, Fehlalarm RP-Rate RP/N Power, Sensitivität, 1-Betafehler, Recall FN-Rate FN/N Fehlender Alarm, Befafehler RN-Rate RN/N Spezifität, 1-Alphafehler Pos. Vorhersagewert RP/P* Präzision, Relevanz Neg. Vorhersagewert RN/N* Segreganz Richtigkeit (RP+RN)/(N+P) Korrektklassifikationsrate, Gesamtgenauigkeit 8.7 Krebstest-Beispiel Betrachten wir Daten eines fiktiven Krebstest, aber realistischen Daten. ## # A tibble: 1 × 7 ## format width height colorspace matte filesize density ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;int&gt; &lt;chr&gt; ## 1 PNG 500 429 sRGB TRUE 40643 72x72 Wie gut ist dieser Test? Berechnen wir einige Kennzahlen. Da die Funktionen zur Klassifikation stets einen Faktor wollen, wandeln wir die relevanten Spalten zuerst in einen Faktor um (aktuell sind es numerische Spalten). krebstest &lt;- krebstest %&gt;% mutate(Krebs = factor(Krebs), Test = factor(Test)) Gesamtgenauigkeit: accuracy(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 accuracy binary 0.87 Sensitivität: sens(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 sens binary 0.884 Spezifität: spec(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 spec binary 0.6 Kappa: kap(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 kap binary 0.261 Positiver Vorhersagewert: ppv(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ppv binary 0.977 Negativer Vorhersagewert: npv(krebstest, truth = Krebs, estimate = Test) ## # A tibble: 1 × 3 ## .metric .estimator .estimate ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 npv binary 0.214 Während Sensitivität und Spezitivität sehr hoch sind, ist die der negative Vorhersagewert sehr gering: Wenn man einen positiven Test erhält, ist die Wahrscheinlichkeit, in Wahrheit krank zu sein gering, zum Glück! References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
