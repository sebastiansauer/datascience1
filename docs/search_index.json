[["index.html", "DataScience1 Grundlagen der Prognosemodellierung üîÆüß∞ Kapitel 1 √úberblick 1.1 Was Sie hier lernen und wozu das gut ist 1.2 Lernziele 1.3 Voraussetzungen 1.4 Hinweise zu diesem Projekt 1.5 Lernhilfen 1.6 Modulzeitplan 1.7 Literatur 1.8 FAQ", " DataScience1 Grundlagen der Prognosemodellierung üîÆüß∞ Sebastian Sauer 2022-03-16 18:29:03 Kapitel 1 √úberblick from Imgflip Meme Generator 1.1 Was Sie hier lernen und wozu das gut ist Alle Welt spricht von Big Data, aber ohne die Analyse sind die gro√üen Daten nur gro√ües Rauschen. Was letztlich interessiert, sind die Erkenntnisse, die Einblicke, nicht die Daten an sich. Dabei ist es egal, ob die Daten gro√ü oder klein sind. Nat√ºrlich erlauben die heutigen Datenmengen im Verbund mit leistungsf√§higen Rechnern und neuen Analysemethoden ein Verst√§ndnis, das vor Kurzem noch nicht m√∂glich war. Und wir stehen erst am Anfang dieser Entwicklung. Vielleicht handelt es sich bei diesem Feld um eines der dynamischsten Fachgebiete der heutigen Zeit. Sie sind dabei: Sie lernen einiges Handwerkszeugs des ‚ÄúDatenwissenschaftlers‚Äù. Wir konzentrieren uns auf das vielleicht bekannteste Teilgebiet: Ereignisse vorhersagen auf Basis von hoch strukturierten Daten und geeigneter Algorithmen und Verfahren. Nach diesem Kurs sollten Sie in der Lage sein, typisches Gebabbel des Fachgebiet mit L√§ssigkeit mitzumachen. Ach ja, und mit einigem Erfolg Vorhersagemodelle entwickeln. 1.2 Lernziele Nach diesem Kurs sollten Sie grundlegende Konzepte des statistischen Lernens verstehen und mit R anwenden k√∂nnen g√§ngige Prognose-Algorithmen kennen, in Grundz√ºgen verstehen und mit R anwenden k√∂nnen die G√ºte und Grenze von Prognosemodellen einsch√§tzen k√∂nnen 1.3 Voraussetzungen Um von diesem Kurs am besten zu profitieren, sollten Sie folgendes Wissen mitbringen: grundlegende Kenntnisse im Umgang mit R, m√∂glichst auch mit dem tidyverse grundlegende Kenntnisse der deskriptiven Statistik grundlegende Kenntnis der Regressionsanalyse 1.4 Hinweise zu diesem Projekt Die URL zu diesem Projekt lautet &lt;test.io&gt;. Lesen Sie sich die folgenden Informationen bitte gut durch: Hinweise Den Quellcode finden Sie in diesem Github-Repo. Sie haben Feedback, Fehlerhinweise oder W√ºnsche zur Weiterentwicklung? Am besten stellen Sie hier einen Issue ein. Dieses Projekt steht unter der MIT-Lizenz. 1.5 Lernhilfen 1.5.1 Software Installieren Sie R und seine Freunde. Installieren Sie die folgende R-Pakete: tidyverse tidymodels weitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren) R Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester. 1.5.2 Videos Playlist zu den Themen 1.5.3 Online-Zusammenarbeit Frag-Jetzt-Raum zum anonymen Fragen stellen w√§hrend des Unterrichts. Der Keycode wird Ihnen vom Dozenten bereitgestellt. Padlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeitr√§gen. Die Zugangsdaten stellt Ihnen der Dozent bereit. 1.6 Modulzeitplan Nr. Kalenderwoche Datum Thema 1 11 14.-18.3.22 Grundkonzepte 2 12 21.3.-25.3. tidyverse, 2. Blick 3 13 28.3.-1.4. tidymodels 4 14 4.4.-8.4. kNN 5 15 11.4.-15.4. Statistisches Lernen 6 16 18.4.-22.4 Wiederholung 7 17 25.4.-29.4 Logistische Regression 8 18 2.5.-6.5. Naive Bayes 9 19 9.5.-13.5. Entscheidungsb√§ume 10 20 16.5.-20.5. Zufallsw√§lder 11 21 23.5.-27.5. Fallstudie 12 23 6.6.-10.6. Wiederholung 13 24 13.6.-17.6. GAM 14 25 20.6.-24.6. Lasso und Co 15 26 27.6.-1.7. Vertiefung 1.7 Literatur Zentrale Kursliteratur f√ºr die theoretischen Konzepte ist Rhys (2020). Bitte pr√ºfen Sie, ob das Buch in einer Bibliothek verf√ºgbar ist. Die praktische Umsetzung in R basiert auf Silge and Kuhn (2022); das Buch ist frei online verf√ºgbar. Eine theoretische Konzepte sind James et al. (2021) entnommen; dieser Test ist frei online verf√ºgbar. In einigen Punkten ist Sauer (2019) hilfreich; das Buch ist √ºber SpringerLink in Ihrer Hochschul-Bibliothek verf√ºgbar. 1.8 FAQ Folien Frage: Gibt es ein Folienskript? Antwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zug√§ngliche Literatur gibt, dort gibt es ein Skript. Englisch Ist die Literatur auf Englisch? Ja. Allerdings ist die Literatur gut zug√§nglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca in Wissenschaft und Wirtschaft. Ein solides Verst√§ndnis englischer (geschriebener) Sprache ist f√ºr eine gute Ausbildung unerl√§sslich. Zu dem sollte die Kursliteratur fachlich passende und gute B√ºcher umfassen; oft sind das englische Titel. Anstrengend Ist der Kurs sehr anstrengend, aufw√§ndig? Der Kurs hat ein mittleres Anspruchsniveau. Mathe Muss man ein Mathe-Crack sein, um eine gute Note zu erreichen? Nein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur an, sie werden wenig Mathe darin finden. Pr√ºfungsliteratur Welche Literatur ist pr√ºfungsrelevant? Die Pr√ºfung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, in der reines Wissen abgefragt wird. Nur R? Wird nur R in dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig. In der Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. In einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit einger√§umt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen. References "],["modul√ºberblick.html", "Kapitel 2 Modul√ºberblick 2.1 Grundkonzepte 2.2 tidyverse, 2. Blick 2.3 tidymodels 2.4 kNN 2.5 Statistisches Lernen 2.6 Wiederholung 2.7 Logistische Regression 2.8 Naive Bayes 2.9 Entscheidungsb√§ume 2.10 Zufallsw√§lder 2.11 Fallstudie 2.12 Wiederholung 2.13 GAM 2.14 Lasso und Co 2.15 Vertiefung", " Kapitel 2 Modul√ºberblick 2.1 Grundkonzepte 2.1.1 Datum 14.-18.3.22 2.1.2 Lernziele Sie k√∂nnen erl√§utern, was man unter statistischem Lernen versteht. Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann. Sie kennen verschiedenen Arten von statistischem Lernen und k√∂nnen Algorithmen zu diesen Arten zuordnen. 2.1.3 Vorbereitung Lesen Sie die Hinweise zum Modul. Installieren (oder Updaten) Sie die f√ºr dieses Modul angegeben Software. Lesen Sie die Literatur. 2.1.4 Literatur Rhys, Kap. 1 evtl. Sauer, Kap. 15 2.1.5 Aufgaben Machen Sie sich mit ‚ÄòKaggle‚Äô vertraut Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf Werfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise Wiederholen Sie unser Vorgehen in der Fallstudie zu den Flugversp√§tungen 2.1.6 Vertiefung Verdienst einer deutschen Data Scientistin Weitere Fallstudie zum Thema Regression auf Kaggle Crashkurs Data Science (Coursera, Johns Hopkins University) mit ‚ÄòStar-Dozenten‚Äô 2.1.7 Hinweise Bitte beachten Sie die Hinweise zum Pr√§senzunterricht und der Streamingoption. Bitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (in aktueller Version) l√§uft. 2.2 tidyverse, 2. Blick 2.2.1 Datum 21.3.-25.3. 2.2.2 Lernziele Sie k√∂nnen Funktionen, auch anonyme, in R schreiben. Sie k√∂nnen Datens√§tze vom Lang- und Breit-Format wechseln. Sie k√∂nnen Mapping-Funktionen anwenden. Sie k√∂nnen eine dplyr-Funktion auf mehrere Spalten gleichzeitig anwenden. 2.2.3 Vorbereitung Lesen Sie die Literatur. 2.2.4 Literatur Rhys, Kap. 2 2.3 tidymodels 2.3.1 Datum 28.3.-1.4. 2.3.2 Literatur TMWR 2.4 kNN 2.4.1 Datum 4.4.-8.4. 2.4.2 Literatur Rhys, Kap. 3 2.5 Statistisches Lernen 2.5.1 Datum 11.4.-15.4. 2.5.2 Literatur Rhys, Kap. 3 2.5.3 Vertiefung Fields arranged by purity, xkcd 435 2.5.4 Hinweise In dieser Woche f√§llt die √úbung aus (Ostern). 2.6 Wiederholung 2.6.1 Datum 18.4.-22.4 2.6.2 Hinweise In dieser Woche f√§llt die Vorlesung aus (Ostern). 2.7 Logistische Regression 2.7.1 Datum 25.4.-29.4 2.7.2 Literatur Rhys, Kap. 4 2.8 Naive Bayes 2.8.1 Datum 2.5.-6.5. 2.8.2 Literatur Rhys, Kap. 6 2.9 Entscheidungsb√§ume 2.9.1 Datum 9.5.-13.5. 2.9.2 Literatur Rhys, Kap. 7 2.10 Zufallsw√§lder 2.10.1 Datum 16.5.-20.5. 2.10.2 Literatur Rhys, Kap. 8 2.11 Fallstudie 2.11.1 Datum 23.5.-27.5. 2.11.2 Literatur Rhys, Kap.9 2.11.3 Hinweise N√§chste Woche ist Blockwoche; es findet kein regul√§rer Unterricht statt. Diese Woche f√§llt die √úbung aus. 2.12 Wiederholung 2.12.1 Datum 6.6.-10.6. 2.12.2 Hinweise In dieser Woche f√§llt die Vorlesung aus (Pfingsten). 2.13 GAM 2.13.1 Datum 13.6.-17.6. 2.13.2 Literatur Rhys, Kap. 10 2.14 Lasso und Co 2.14.1 Datum 20.6.-24.6. 2.14.2 Literatur Rhys, Kap. 11 2.15 Vertiefung 2.15.1 Datum 27.6.-1.7. 2.15.2 Literatur Rhys, Kap. 12 2.15.3 Vertiefung Wie man eine Data-Science-Projekt strukturiert 2.15.4 Hinweise Nach dieser Woche endet der Unterricht. "],["pr√ºfung.html", "Kapitel 3 Pr√ºfung 3.1 Pr√ºfungleistung 3.2 tl;dr: Zusammenfassung 3.3 Vorhersage 3.4 Hauptziel: Genaue Prognose 3.5 Zum Aufbau Ihrer Prognosedatei im CSV-Format 3.6 Einzureichende Dateien 3.7 Tipps 3.8 Bewertung 3.9 Hinweise 3.10 Formalia 3.11 Wo finde ich Beispiele? 3.12 Plagiatskontrolle", " Kapitel 3 Pr√ºfung 3.1 Pr√ºfungleistung Die Pr√ºfungsleistung besteht aus einem Prognosewettbewerb. 3.2 tl;dr: Zusammenfassung Vorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen. Wenn Sie den DAX-Stand von morgen genau vorhersagen k√∂nnen, rufen Sie mich bitte sofort an. Genau das ist Ihre Aufgabe in dieser Pr√ºfungsleistung: Sie sollen Werte vorhersagen. Etwas konkreter: Stellen Sie sich ein paar Studentis vor. Von allen wissen Sie, wie lange die Person f√ºr die Statistikklausur gelernt hat. Au√üerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos. Und Sie wissen die Note jeder Person in der Statistikklausur. Auf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die Pr√ºfung in Statistik schreiben muss will: ‚ÄúSag mal, wenn ich 100 Stunden lerne und so mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?‚Äù. Mit Hilfe Ihrer Analyse k√∂nnen Sie diese Frage (und andere) beantworten. Nat√ºrlich k√∂nnten Sie es sich leicht machen und antworten: ‚ÄúMei, der Notendurchschnitt war beim letzten Mal 2.7. Also ist 2.7 kein ganz doofer Tipp f√ºr deine Note.‚Äù Ja, das ist keine doofe Antwort, aber man genauere Prognose machen, wenn man es geschickt anstellt. Da hilft Ihnen die Statistik (doch, wirklich). Kurz gesagt gehen Sie so vor: Importieren Sie die Daten in R, starten Sie die n√∂tigen R-Pakete und schauen Sie sich die Daten unter verschiedenen Blickwinkeln an. Dann nehmen Sie die vielversprechendsten Pr√§diktoren in ein Regressionsmodell und schauen sich an, wie gut die Vorhersage ist. Wiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden. Mit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher. Je genauer Ihre Vorhersage, desto besser ist Ihr Pr√ºfungsergebnis. 3.3 Vorhersage Neben der erkl√§renden, r√ºckw√§rtsgerichteten Modellierung spielt insbesondere in der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle: Ziel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. f√ºr neue Kunden auf Basis von soziodemographischen Daten den Kundenwert ‚Äì m√∂glichst genau ‚Äì zu prognostizieren. Dies geschieht auf Basis der vorhandenen Daten der Bestandskunden, d.h. inklusive des f√ºr diese Kunden bekannten Kundenwertes. Ihnen werden zwei Teildatenmengen zur Verf√ºgung gestellt: Zum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet. Bei den Trainingsdaten (Train-Sample) liegen sowohl die erkl√§renden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor. Auf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) gesch√§tzt. Es ist also die Variable \\(y\\) vorherszusagen. Dieses gesch√§tzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(\\bf{x}_0\\), f√ºr die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) berechnet. Der unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert. Liegt zu einem noch sp√§teren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, so kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden, d.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden. In der praktischen Anwendung k√∂nnen zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben): die Trainingsphase, d.h., die Phase f√ºr die sowohl erkl√§rende (\\({\\bf{x}}\\)) als auch die erkl√§rte Variable (\\(y\\)) bekannt sind. Hier wird das Modell gesch√§tzt (gelernt): \\(\\hat{f}(\\bf{x})\\). Daf√ºr wird der Trainingsdatensatz genutzt. In der folgenden Anwendungsphase sind nur die erkl√§renden Variablen (\\({\\bf{x_0}}\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert. Evt. gibt es sp√§ter noch die Evaluierungsphase, f√ºr die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, so dass die Vorhersageg√ºte des Modells √ºberpr√ºft werden kann. Im Computer kann man dieses Anwendungsszenario simulieren: man teilt die Datenmenge zuf√§llig in eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((\\bf{x},y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((\\bf{x_0})\\)) auf: Die Modellierung erfolgt auf den Trainingsdaten. Das Modell wird angewendet auf die Testdaten (Anwendungsdaten). Da man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden. 3.4 Hauptziel: Genaue Prognose Ihre Aufgabe ist: Spielen Sie den Data-Scientist! Konstruieren Sie ein Modell auf Basis der Trainingsdaten \\((\\bf{x},y\\)) und sagen Sie f√ºr die Anwendungsdaten (\\(\\bf{x_0}\\)) die Zielvariable m√∂glichst genau voraus (\\(\\hat{y}_0\\)). Ihr(e) Dozent*in kennt den Wert der Zielvariable (\\(y_0\\)). Von zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser, das weniger Vorhersagefehler aufweist, also genauer vorhersagt. Kurz gesagt: Genauer ist besser. 3.5 Zum Aufbau Ihrer Prognosedatei im CSV-Format Die CSV-Datei muss aus genau zwei Spalten mit (exakt) folgenden Spaltennamen bestehen: id: Den ID-Wert jedes vorhergesagten Wertes pred: Der vorhergesagte Wert. Umlaute sind zu ersetzen (also S√º√ü wird Suess etc.). Die CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung). Die CSV-Datei muss genau die Anzahl an Zeilen aufweisen, die der Zeilenl√§nge im Test-Datensatz entspricht. Pr√ºfen Sie, dass Ihre CSV-Datei sich problemlos lesen l√§sst. Falls keine (funktionst√ºchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Pr√ºfung nicht bestanden. Tipp: √ñffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich an, ob alles vern√ºnftig aussieht. Achtung: √ñffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat, der CSV-Dateien verf√§lschen kann auch ohne dass man die Datei speichert. 3.6 Einzureichende Dateien Folgende* Dateiarten* sind einzureichen: Prognose: Ihre Prognose-Datei (CSV-Datei) Analyse: Ihr Analyseskript (R-, Rmd- oder Rmd-Notebook-Datei) Weitere Dateien sind nicht einzureichen. Komprimieren Sie die Dateien nicht (z.B. via zip). Der Name jeder eingereichnte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd. 3.7 Tipps 3.7.1 Tipps f√ºr eine gute Prognose Schauen Sie in die Literatur. Evtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausrei√üern) helfen. √úberlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierf√ºr gibt es Algorithmen und R-Funktionen. Vermeiden Sie √úber-Anpassung (Overfitting). Vermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgef√ºllt. 3.7.2 Tipps zur Datenverarbeitung Ein ‚Äúdeutsches‚Äù Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets k√∂nnen dies allerdings. 3.7.3 Tipps zum Aufbau des Analyseskripts Zu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden. Zu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (nicht von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Pr√ºfer, nicht lauff√§hig ist). 3.7.4 Sonstiges Legen Sie regelm√§√üig Sicherheitskopien Ihrer Arbeit an (ggf. auf einem anderen Datentr√§ger). Achten Sie darauf, dass Sie nicht durcheinander kommen, in welcher Datei der aktuelle Stand Ihrer Arbeit liegt. 3.8 Bewertung 3.8.1 Kriterien Es gibt drei Bewertungskriterien: Formalia: u.a. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, √úbersichtlichkeit der Analyse. Methode: u.a. methodischer Anspruch und Korrektheit in der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode. Inhalt: Vorhersageg√ºte. Das zentrale Bewertungskriterium ist Inhalt; die √ºbrigen beiden Kriterien flie√üen nur bei besonders guter oder schlechter Leistung in die Gesamtnote ein. Die quantitative Datenanalyse in Durchf√ºhrung und Interpretation ist der Schwerpunkt dieser Arbeit. Zuf√§lliges identisches Vorgehen, z.B. im R Code, ist sehr unwahrscheinlich und kann als Plagiat bewertet werden. Die Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben. Es werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben. 3.8.2 Kennzahl der Modellg√ºte Die G√ºte der Vorhersage wird anhand des mittleren Absolutfehlers (mae) bemessen: \\[\\text{mae} = \\frac{1}{n} \\sum_{i=1}^n(y_i - \\hat{y}_i)\\] 3.8.3 Notenstufen Zur Vorhersageg√ºte: Die Vorhersageg√ºte eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\). Ihre Bewertung erfolgt entsprechend Ihrer Vorhersageg√ºte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier in diesem Teilaspekt eine bessere Note als \\(2,0\\)! 3.8.4 Bewertungsprozess Der Gutachter legt im Nachgang der Pr√ºfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellg√ºte offen. Au√üerdem werden die vorherzusagenden Daten ver√∂ffentlicht sowie die Grenzwerte f√ºr jede Notenstufe. Auf dieser Basis ist es allen Teilnehmis m√∂glich, die Korrektheit Ihrer Note zu √ºberpr√ºfen. 3.9 Hinweise Sie haben freie Methodenwahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie k√∂nnen aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen. Eine Einf√ºhrung in verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling with R.2. Die B√ºcher beinhalten jeweils Beispiele und Anwendung mit R. Auch ist es Ihnen √ºberlassen, welche Variablen Sie zur Modellierung heranziehen ‚Äì und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausrei√üer bereinigen o.√Ñ.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchf√ºhren, auch auf den Testdaten (Anwendungsdaten) durchzuf√ºhren. Hinweise zur Modellwahl usw. gibt es auch in erw√§hnter Literatur, aber auch in vielen B√ºchern zum Thema Data-Science. Alles, was Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent und reproduzierbar sein. Im √úbrigen lautet die Aufgabe: Finden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine sch√∂ne Antwort, trifft die Wirklichkeit aber leider nicht immer. Eine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangsl√§ufig eine gute Vorhersage (Test-Set). 3.10 Formalia Es sind nur Einzelarbeiten zul√§ssig. In der Analyse muss als Ausgangspunkt der vom/von der Dozenten/in bereitgestellten Datensatz genutzt werden. Alle Analyseschritte bzw. alle Ver√§nderungen an den Daten m√ºssen im (eingereichten) Analyseskript nachvollziehbar (transparent und reproduzierbar) aufgef√ºhrt sein. Das Analyseskript ist als R-Skript, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie k√∂nnen die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd). Das Analyseskript muss funktionst√ºchtig f√ºr den Pr√ºfer sein: Alle Befehle m√ºssen ohne Fehlermeldung durchlaufen (abgesehen von etwaiger Installation fehlender Pakete). Es d√ºrfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzul√§ssig. Nichtbeachtung der f√ºr dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug f√ºhren. Der Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten. Es muss keine Literatur zitiert werden. Ein ausgedrucktes Exemplar muss nicht abgegeben werden. W√§hrend der Pr√ºfungsphase werden keine inhaltlichen Fragen (‚Äúwie macht man nochmal eine Log-Transformation?‚Äù) und keine technischen Fragen (‚Äúwie installiert man nochmal ein R-Paket?‚Äù) beantwortet. 3.11 Wo finde ich Beispiele? Eine Beispiel-Modellierung finden Sie in der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd. Eine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen k√∂nnen, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt. Im Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen k√∂nnen. 3.12 Plagiatskontrolle Die eingereichten Arbeiten k√∂nnen automatisiert auf Plagiate √ºberpr√ºft werden. Gibt es substanzielle √úberschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungen√ºgend bewertet oder es folgt eine Abwertung der Note. "],["grundkonzepte-1.html", "Kapitel 4 Grundkonzepte 4.1 Was ist Data Science? 4.2 Was ist Machine Learning? 4.3 Modell vs.¬†Algorithmus 4.4 Taxonomie 4.5 Ziele des ML 4.6 √úber- vs.¬†Unteranpassung 4.7 No free lunch 4.8 Bias-Varianz-Abw√§gung", " Kapitel 4 Grundkonzepte 4.1 Was ist Data Science? Es gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, and Horton (2017) definieren Data Science wie folgt (S. 4): The science of extracting meaningful information from data Auf der anderen Seite entgegen viele Statistiker: ‚ÄúHey, das machen wir doch schon immer!‚Äù. Eine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (‚ÄúDom√§ne‚Äù), die sozusagen den Empf√§nger bzw. die Kunden oder den Rahmen stellt. Dieser ‚ÄúDreiklang‚Äù ist in folgendem Venn-Diagramm dargestellt. 4.2 Was ist Machine Learning? Maschinelles Lernen (ML), oft auch (synonym) als statistisches Lernen (statistical learning) bezeichnet, ist ein Teilgebiet der k√ºnstlichen Intelligenz (KI; artificial intelligence, AI) (Rhys 2020). ML wird auch als data-based bezeichnet in Abgrenzung von rule-based, was auch als ‚Äúklassische KI‚Äù bezeichnet wird, vgl. Abb. 4.1. Figure 4.1: KI und Maschinelles Lernen In beiden F√§llen finden Algorithmen Verwendung. Algorithmen sind nichts anderes als genaue Schritt-f√ºr-Schritt-Anleitungen, um etwas zu erledigen. Ein Kochrezept ist ein klassisches Beispiel f√ºr einen Algorithmus. Hier findet sich ein Beispiel f√ºr einen einfachen Additionsalgorithmus. Es gibt viele ML-Algorithmen, vgl. Abb. 4.2. Figure 4.2: ML-Matroschka 4.2.1 Rule-based Klassische (√§ltere) KI implementiert Regeln ‚Äúhartverdrahtet‚Äù in ein Computersystem. Nutzer f√ºttern Daten in dieses System. Das System leitet dann daraus Antworten ab. Regeln kann man prototypisch mit Wenn-Dann-Abfragen darstellen: lernzeit &lt;- c(0, 10, 10, 20) schlauer_nebensitzer &lt;- c(FALSE, FALSE, TRUE, TRUE) for (i in 1:4) { if (lernzeit[i] &gt; 10) { print(&quot;bestanden!&quot;) } else { if (schlauer_nebensitzer[i] == TRUE) { print(&quot;bestanden!&quot;) } else print(&quot;Durchgefallen!&quot;) } } ## [1] &quot;Durchgefallen!&quot; ## [1] &quot;Durchgefallen!&quot; ## [1] &quot;bestanden!&quot; ## [1] &quot;bestanden!&quot; Sicherlich k√∂nnte man das schlauer programmieren, vielleicht so: ## # A tibble: 4 √ó 3 ## lernzeit schlauer_nebensitzer bestanden ## &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 0 FALSE FALSE ## 2 10 FALSE FALSE ## 3 10 TRUE TRUE ## 4 20 TRUE TRUE 4.2.2 Data-based ML hat zum Ziel, Regeln aus den Daten zu lernen. Man f√ºttert Daten und Antworten in das System, das System gibt Regeln zur√ºck. James et al. (2021) definieren ML so: Nehmen wir an, wir haben die abh√§ngige Variable \\(Y\\) und \\(p\\) Pr√§diktoren, \\(X_1,X_2, \\ldots, X_p\\). Weiter nehmen wir an, die Beziehung zwischen \\(Y\\) und \\(X = (X_1, X_2, \\ldots, X_p)\\) kann durch eine Funktion \\(f\\) beschrieben werden. Das kann man so darstellen: \\[Y = f(X) + \\epsilon\\] ML kann man auffassen als eine Menge an Verfahren, um \\(f\\) zu sch√§tzen. Ein Beispiel ist in Abb. 4.3 gezeigt (James et al. 2021). Figure 4.3: Vorhersage des Einkommens durch Ausbildungsjahre Nat√ºrlich kann \\(X\\) mehr als eine Variable beinhalten, vgl. Abb. 4.4 (James et al. 2021). Figure 4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren Anders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gef√ºttert und liefern Antworten. ML-Systeme werden mit Daten und Antworten gef√ºttert und liefern Regeln zur√ºck, vgl. Abb. 4.5. Figure 4.5: Vergleich von klassischer KI und ML 4.3 Modell vs.¬†Algorithmus 4.3.1 Modell Ein Modell, s. Abb. 4.6 (Spurzem 2017)! Figure 4.6: Ein Modell-Auto Wie man sieht, ist ein Modell eine vereinfachte Repr√§sentation eines Gegenstands. Der Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. 4.7. Figure 4.7: Gegenstand und Modell Im maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln, die aus den Daten gelernt wurden. 4.3.2 Beispiel f√ºr einen ML-Algorithmus Unter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren, anhand dessen die Beziehung zwischen \\(X\\) und \\(Y\\) ‚Äúgelernt‚Äù wird. Bei Rhys (2020) (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet: Beispiel eines Regressionsalgorithmus Setze Gerade in die Daten mit \\(b_0 = \\hat{y}, b_1 = 0\\) Berechne \\(MSS = \\sum (y_i - \\hat{y_i})^2\\) ‚ÄúDrehe‚Äù die Gerade ein bisschen, d.h. erh√∂he \\(b_1^{neu} = b_1^{alt} + 0.1\\) Wiederhole 2-3 solange, bis \\(MSS &lt; \\text{Zielwert}\\) Diesen Algorithmus kann man ‚Äúvon Hand‚Äù z.B. mit dieser App durchspielen. 4.4 Taxonomie Methoden des maschinellen Lernens lassen sich verschiedentlich gliedern. Eine typische Gliederung unterscheidet in supervidierte (geleitete) und nicht-supervidierte (ungeleitete) Algorithmen, s. Abb. 4.8. Figure 4.8: Taxonomie der Arten des maschinellen Lernens 4.4.1 Geleitetes Lernen Die zwei Phasen des geleiteten Lernens sind in Abb. 4.9 dargestellt. Figure 4.9: Geleitetes Lernen geschieht in zwei Phasen 4.4.1.1 Regression: Numerische Vorhersage Die Modellg√ºte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden G√ºtekoeffizienten gemessen: Mean Squared Error (Mittlerer Quadratfehler): \\[MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\] Mean Absolute Error (Mittlerer Absolutfehler): \\[MAE := \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|\\] Wir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzusch√§tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren. 4.4.1.2 Klassifikation: Nominale Vorhersage Die Modellg√ºte eines numerischen Vorhersagemodells wird oft mit folgendem G√ºtekoeffizienten gemessen: Mittlerer Klassifikationfehler \\(e\\): \\[e := \\frac{1}{n} I(y_i \\ne \\hat{y}_i) \\] Dabei ist \\(I\\) eine Indikatorfunktion, die 1 zur√ºckliefert, wenn tats√§chlicher Wert und vorhergesagter Wert identisch sind. 4.4.2 Ungeleitetes Lernen Die zwei Phasen des ungeleiteten Lernens sind in Abb. 4.10 dargestellt. Figure 4.10: Die zwei Phasen des ungeleiteten Lernens Ungeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. 4.11: Fallreduzierendes Modellieren (Clustering) Dimensionsreduzierendes Modellieren (z.B. Faktorenanalyse) Figure 4.11: Zwei Arten von ungeleitetem Modellieren 4.5 Ziele des ML Man kann vier Ziele des ML unterscheiden, s. Abb. 4.12. Figure 4.12: Ziele des maschinellen Lernens Vorhersage bezieht sich auf die Sch√§tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit). Erkl√§rung meint die kausale Analyse von Zusammenh√§ngen. Beschreibung ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken. Dimensionsreduktion ist ein Oberbegriff f√ºr Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s Wie ‚Äúgut‚Äù ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellg√ºte oder model fit. Je schlechter die Modellg√ºte, desto h√∂her der Modellfehler, vgl. Abb. 4.13. Figure 4.13: Wenig (links) vs.¬†viel (rechts) Vorhersagefehler Die Modellg√ºte eines Modells ist nur relevant f√ºr neue Beobachtungen, an denen das Modell nicht trainiert wurde. 4.6 √úber- vs.¬†Unteranpassung Overfitting: Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als ‚Äúbare M√ºnze‚Äù, also f√§lschlich als Signal. Solche Modelle haben zu viel Varianz in ihren Vorhersagen. Underfitting: Ein Modell ist zu simpel (ungenau, grobk√∂rnig) - es unterschl√§gt Nuancen des tats√§chlichen Musters. Solche Modelle haben zu viel Verzerrung (Bias) in ihren Vorhersagen. Welches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. Abb. 4.14, vgl. (Sauer 2019), Kap. 15. Figure 4.14: Over- vs.¬†Underfitting Welches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie? Modell D zeigt sehr gute Beschreibung (‚ÄúRetrodiktion‚Äù) der Werte, anhand derer das Modell trainiert wurde (‚ÄúTrainingsstichprobe‚Äù). Wird es aber ‚Äúehrlich‚Äù getestet, d.h. anhand neuer Daten (‚ÄúTest-Stichprobe‚Äù), wird es vermutlich nicht so gut abschneiden. Es gilt, ein Modell mit ‚Äúmittlerer‚Äù Komplexit√§t zu finden, um √úber- und Unteranpassung in Grenzen zu halten. Leider ist es nicht m√∂glich, vorab zu sagen, was der richtige, ‚Äúmittlere‚Äù Wert an Komplexit√§t eines Modells ist, vgl. Abb. 4.15 aus (Sauer 2019). Figure 4.15: Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte 4.7 No free lunch from Imgflip Meme Generator Wenn \\(f\\) (die Beziehung zwischen \\(Y\\) und \\(X\\), auch datengenerierender Prozess genannt) linear oder fast linear ist, dann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. 4.16 aus James et al. (2021), dort zeigt die schwarze Linie den ‚Äúwahren Zusammenhang‚Äù, also \\(f\\) an. In orange sieht man ein lineares Modell, in gr√ºn ein hoch komplexes Modell, das sich in einer ‚Äúwackligen‚Äù Funktion - also mit hoher Varianz - niederschl√§gt. Das gr√ºne Modell k√∂nnte z.B. ein Polynom-Modell hohen Grades sein, z. B. \\(y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon\\). Das lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias. Daher ist es f√ºr dieses \\(f\\) gut passend. Die gr√ºne Funktion zeigt dagegen √úberanpassung (overfitting), also viel Modellfehler (f√ºr eine Test-Stichprobe). Die gr√ºne Funktion in Abb. 4.16 wird neue, beim Modelltraining unbekannte Beobachtungen (\\(y_0\\)) vergleichsweise schlecht vorhersagen. In Abb. 4.17 ist es umgekehrt. Figure 4.16: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren. Betrachten wir im Gegensatz dazu Abb. 4.17 aus James et al. (2021), die (in schwarz) eine hochgradig nichtlineare Funktion \\(f\\) zeigt. Entsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel. Ein lineares Modell wird der Komplexit√§t von \\(f\\) nicht gerecht, Unteranpassung (underfitting) liegt vor. Figure 4.17: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung. 4.8 Bias-Varianz-Abw√§gung Der Gesamtfehler \\(E\\) des Modells ist die Summe dreier Terme: \\[E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon\\] Dabei meint \\(\\epsilon\\) den nicht reduzierbaren Fehler, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung). Bias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. Abb. 4.18 aus Sauer (2019). Figure 4.18: Abw√§ngung von Bias vs.¬†Varianz References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
