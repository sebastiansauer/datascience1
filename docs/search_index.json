[["ensemble-lerner.html", "Kapitel 11 Ensemble Lerner 11.1 Lernsteuerung 11.2 Vorbereitung 11.3 Hinweise zur Literatur 11.4 Wir brauchen einen Wald 11.5 Was ist ein Ensemble-Lerner? 11.6 Bagging 11.7 Bagging-Algorithmus 11.8 Random Forests 11.9 Boosting 11.10 Tidymodels 11.11 Aufgaben Pakete starten Daten importieren CV Rezept 1 Modell 1: RF Workflow 1 Modell fitten (und tunen) Bester Kandidat Workflow Finalisieren Final Fit Submission df Kaggle Score Aufgabe Vorbereitung Rezpet Rezept definieren Check das Rezept variable | mean | sd | iqr | range | skewness | kurtosis | n | n_missing Kreuzvalidierung Modelle Baum Random Forest Workflows Fitten und tunen Tree RF Kaggle Score Aufgabe Vorbereitung Train-Set verschlanken Datensatz kennenlernen Fehlende Werte pr√ºfen Rezept Rezept definieren Check das Rezept Check Test-Sample Kreuzvalidierung Modelle Baum Random Forest XGBoost LM Workflow-Set Fitten und tunen Finalisieren Welcher Algorithmus schneidet am besten ab? Finalisieren Final Fit Submission Kaggle Score Aufgabe Vorbereitung Train-Set verschlanken Test-Set verschlanken Outcome logarithmieren Fehlende Werte pr√ºfen Rezept Rezept definieren Check das Rezept Check Test-Sample Kreuzvalidierung Modelle LM Workflow-Set Fitten und tunen Finalisieren Finalisieren Final Fit Submission df Zur√ºcktransformieren Kaggle Score Pakete starten Daten importieren CV Rezept 1 Modell 1 Workflow 1 Modell fitten (und tunen) Final Fit Submission df Kaggle Score Startup Data import Recipe Model 1 Workflow 1 Fit 11.12 Vertiefung", " Kapitel 11 Ensemble Lerner 11.1 Lernsteuerung 11.1.1 Lernziele Sie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest Sie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann Sie k√∂nnen diese Verfahren in R berechnen 11.1.2 Literatur Rhys, Kap. 8 11.2 Vorbereitung In diesem Kapitel werden folgende R-Pakete ben√∂tigt: library(tidymodels) library(tictoc) # Zeitmessung library(vip) # Variable importance plot 11.3 Hinweise zur Literatur Die folgenden Ausf√ºhrungen basieren prim√§r auf Rhys (2020), aber auch auf James et al. (2021) und (weniger) Kuhn and Johnson (2013). 11.4 Wir brauchen einen Wald Ein Pluspunkt von Entscheidungsb√§umen ist ihre gute Interpretierbarkeit. Man k√∂nnte behaupten, dass B√§ume eine typische Art des menschlichen Entscheidungsverhalten nachahmen: ‚ÄúWenn A, dann tue B, ansonsten tue C‚Äù (etc.). Allerdings: Einzelne Entscheidungsb√§ume haben oft keine so gute Prognosegenauigkeit. Der oder zumindest ein Grund ist, dass sie (zwar wenig Bias aber) viel Varianz aufweisen. Das sieht man z.B. daran, dass die Vorhersagegenauigkeit stark schwankt, w√§hlt man eine andere Aufteilung von Train- vs.¬†Test-Sample. Anders gesagt: B√§ume overfitten ziemlich schnell. Und obwohl das No-Free-Lunch-Theorem zu den Grundfesten des maschinellen Lernens (oder zu allem wissenschaftlichen Wissen) geh√∂rt, kann man festhalten, dass sog. Ensemble-Lernen fast immer besser sind als einzelne Baummodelle. Kurz gesagt: Wir brauchen einen Wald: üå≥üå≥üå≥1 11.5 Was ist ein Ensemble-Lerner? Ensemble-Lerner kombinieren mehrere schwache Lerner zu einem starken Lerner. Das Paradebeispiel sind baumbasierte Modelle; darauf wird sich die folgende Ausf√ºhrung auch begrenzen. Aber theoretisch kann man jede Art von Lerner kombinieren. Bei numerischer Pr√§diktion wird bei Ensemble-Lerner zumeist der Mittelwert als Optmierungskriterium herangezogen; bei Klassifikation (nominaler Pr√§diktion) hingegen die modale Klasse (also die h√§ufigste). Warum hilft es, mehrere Modelle (Lerner) zu einem zu aggregieren? Die Antwort lautet, dass die Streuung der Mittelwerte sinkt, wenn die Stichprobengr√∂√üe steigt. Zieht man Stichproben der Gr√∂√üe 1, werden die Mittelwerte stark variieren, aber bei gr√∂√üeren Stichproben (z.B. Gr√∂√üe 100) deutlich weniger2. Die Streuung der Mittelwerte in den Stichproben nennt man bekanntlich Standardefehler (se). Den se des Mittelwerts (\\(se_M\\)) f√ºr eine normalverteilte Variable \\(X \\sim \\mathcal{N}(\\mu, \\sigma)\\) gilt: \\(se_{M} = \\sigma / \\sqrt(n)\\), wobei \\(\\sigma\\) die SD der Verteilung und \\(\\mu\\) den Erwartungswert (‚ÄúMittelwert‚Äù) meint, und \\(n\\) ist die Stichprobengr√∂√üe. Je gr√∂√üer die Stichprobe, desto kleiner die Varianz des Sch√§tzers (ceteris paribus). Anders gesagt: Gr√∂√üere Stichproben sch√§tzen genauer als kleine Stichproben. Aus diesem Grund bietet es sich an, schwache Lerner mit viel Varianz zu kombinieren, da die Varianz so verringert wird. 11.6 Bagging 11.6.1 Bootstrapping Das erste baumbasierte Modell, was vorgestellt werden soll, basiert auf sog. Bootstrapping, ein Standardverfahren in der Statistik (James et al. 2021). Bootstrapping ist eine Nachahmung f√ºr folgende Idee: H√§tte man viele Stichproben aus der relevanten Verteilung, so k√∂nnte man z.B. die Genauigkeit eines Modells \\(\\hat{f}_{\\bar{X}}\\) zur Sch√§tzung des Erwartungswertes \\(\\mu\\) einfach dadurch bestimmen, indem man se berechnet, also die Streuung der Mitterwerte \\(\\bar{X}\\) berechnet. Au√üerdem gilt, dass die Pr√§zision der Sch√§tzung des Erwartungswerts steigt mit steigendem Stichprobenumfang \\(n\\). Wir k√∂nnten also f√ºr jede der \\(B\\) Stichproben, \\(b=1,\\ldots, B\\), ein (Baum-)Modell berechnen, \\(\\hat{f}^b\\), und dann deren Vorhersagen aggregieren (zum Mittelwert oder Modalwert). Das kann man formal so darstellen (James et al. 2021): \\[\\hat{f}_{\\bar{X}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^b\\] Mit diesem Vorgehen kann die Varianz des Modells \\(\\hat{f}_{\\bar{X}}\\) verringert werden; die Vorhersagegenauigkeit steigt. Leider haben wir in der Regel nicht viele (\\(B\\)) Datens√§tze. Daher ‚Äúbauen‚Äù wir uns aus dem einzelnen Datensatz, der uns zur Verf√ºgung steht, viele Datens√§tze. Das h√∂rt sich nach ‚Äútoo good to be true‚Äù an3 Weil es sich unglaubw√ºrdig anh√∂rt, nennt man das entsprechende Verfahren (gleich kommt es!) auch ‚ÄúM√ºnchhausen-Methode‚Äù, nach dem ber√ºhmten L√ºbgenbaron. Die Amerikaner ziehen sich √ºbrigens nicht am Schopf aus dem Sumpf, sondern mit den Stiefelschlaufen (die Cowboys wieder), daher spricht man im Amerikanischen auch von der ‚ÄúBoostrapping-Methode‚Äù. Diese ‚ÄúPseudo-Stichproben‚Äù oder ‚ÄúBootstrapping-Stichproben‚Äù sind aber recht einfach zu gewinnen.. Gegeben sei Stichprobe der Gr√∂√üe \\(n\\): Ziehe mit Zur√ºcklegen (ZmZ) aus der Stichprobe \\(n\\) Beobachtungen Fertig ist die Bootstrapping-Stichprobe. Abb. 11.1 verdeutlicht das Prinzip des ZMZ, d.h. des Bootstrappings. Wie man sieht, sind die Bootstrap-Stichproben (rechts) vom gleichen Umfang \\(n\\) wie die Originalstichprobe (links). Allerdins kommen nicht alle F√§lle (in der Regel) in den ‚ÄúBoostrap-Beutel‚Äù (in bag), sondern einige F√§lle werden oft mehrfach gezogen, so dass einige F√§lle nicht gezogen werden (out of bag). Figure 11.1: Bootstrapping: Der Topf links symbolisiert die Original-Stichprobe, aus der wir hier mehrere ZMZ-Stichproben ziehen (Rechts), dargestellt mit ‚Äòin bag‚Äô Man kann zeigen, dass ca. 2/3 der F√§lle gezogen werden, bzw. ca. 1/3 nicht gezogen werden. Die nicht gezogenen F√§lle nennt man auch out of bag (OOB). F√ºr die Entwicklung des Bootstrapping wurde der Autor, Bradley Efron, im Jahr 2018 mit dem internationalen Preis f√ºr Statistik ausgezeichnet; ‚ÄúWhile statistics offers no magic pill for quantitative scientific investigations, the bootstrap is the best statistical pain reliever ever produced,‚Äù says Xiao-Li Meng, Whipple V. N. Jones Professor of Statistics at Harvard University.‚Äú 11.7 Bagging-Algorithmus Bagging, die Kurzform f√ºr Bootstrap-Aggregation ist wenig mehr als die Umsetzung des Boostrappings. Der Algorithmus von Bagging kann so beschrieben werden: W√§hle \\(B\\), die Anzahl der Boostrap-Stichproben und damit auch Anzahl der Submodelle (Lerner) Ziehe \\(B\\) Boostrap-Stichproben Berechne das Modell \\(\\hat{f}^{*b}\\) f√ºr jede der \\(B\\) Stichproben (typischerweise ein einfacher Baum) Schicke die Test-Daten durch jedes Sub-Modell Aggregiere ihre Vorhersage zu einem Wert (Modus bzw. Mittelwert) pro Fall aus dem Test-Sample, zu \\(\\hat{f}_{\\text{bag}}\\) Anders gesagt: \\[\\hat{f}_{\\text{bag}} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{f}^{*b}\\] Der Bagging-Algorithmus ist in Abbildung 11.2 dargestellt. Figure 11.2: Bagging schematisch illustriert Die Anzahl der B√§ume (allgemeiner: Submodelle) \\(B\\) ist h√§ufig im oberen drei- oder niedrigem vierstelligen Bereich, z.B. \\(B=1000\\). Eine gute Nachricht ist, dass Bagging nicht √ºberanpasst, wenn \\(B\\) gro√ü wird. 11.7.1 Variablenrelevanz Man kann die Relevanz der Pr√§diktoren in einem Bagging-Modell auf mehrere Arten sch√§tzen. Ein Weg (bei numerischer Pr√§diktion) ist, dass man die RSS-Verringerung, die durch Aufteilung anhand eines Pr√§diktors erzeugt wird, mittelt √ºber alle beteiligten B√§ume (Modelle). Bei Klassifikation kann man die analog die Reduktion des Gini-Wertes √ºber alle B√§ume mitteln und als Sch√§tzwert f√ºr die Relevanz des Pr√§diktors heranziehen. 11.7.2 Out of Bag Vorhersagen Da nicht alle F√§lle der Stichprobe in das Modell einflie√üen (sondern nur ca. 2/3), kann der Rest der F√§lle zur Vorhersage genutzt werden. Bagging erzeugt sozusagen innerhalb der Stichprobe selbst√§ndig ein Train- und ein Test-Sample. Man spricht von Out-of-Bag-Sch√§tzung (OOB-Sch√§tzung). Der OOB-Fehler (z.B. MSE bei numerischen Modellen und Genauigkeit bei nominalen) ist eine valide Sch√§tzung des typischen Test-Sample-Fehlers. Hat man aber Tuningparameter, so wird man dennoch auf die typische Train-Test-Aufteilung zur√ºckgreifen, um Overfitting durch das Ausprobieren der Tuning-Kandidaten zu vermeiden (was sonst zu Zufallstreffern f√ºhren w√ºrde bei gen√ºgend vielen Modellkandidaten). 11.8 Random Forests Random Forests (‚ÄúZufallsw√§lder‚Äù) sind eine Weiterentwicklung von Bagging-Modellen. Sie sind Bagging-Modelle, aber haben noch ein Ass im √Ñrmel: Und zwar wird an jedem Slit (Astgabel, Aufteilung) nur eine Zufallsauswahl an \\(m\\) Pr√§diktoren ber√ºcksichtigt. Das h√∂rt sich verr√ºckt an: ‚ÄúWie, mit weniger Pr√§diktoren soll eine bessere Vorhersage erreicht werden?!‚Äù Ja, genau so ist es! Nehmen Sie an, es gibt im Datensatz einen sehr starken und ein paar mittelstarke Pr√§diktoren; der Rest der Pr√§diktoren ist wenig relevant. Wenn Sie jetzt viele ‚Äúgebootstrapte‚Äù4 ziehen, werden diese B√§ume sehr √§hnlich sein: Der st√§rkste Pr√§diktor steht vermutlich immer ob an der Wurzel, dann kommen die mittelstarken Pr√§diktoren. Jeder zus√§tzliche Baum tr√§gt dann wenig neue Information bei. Anders gesagt: Die Vorhersagen der B√§ume sind dann sehr √§hnlich bzw. hoch korreliert. Bildet man den Mittelwert von hoch korrelierten Variablen, verringert sich leider die Varianzu nur wenig im Vergleich zu nicht oder gering korrelierten Variablen (James et al. 2021). Dadurch dass Random Forests nur \\(m\\) der \\(p\\) Pr√§diktoren pro Split zulassen, werden die B√§ume unterschiedlicher. Wir ‚Äúdekorrelieren‚Äù die B√§ume. Bildet man den Mittelwert von gering(er) korrelierten Variablen, so ist die Varianzreduktion h√∂her - und die Vohersage genauer. L√§sst man pro Split \\(m=p\\) Pr√§diktoren zu, so gleicht Bagging dem Random Forest. Die Anzahl \\(m\\) der erlaubten Pr√§diktoren werden als Zufallstichprobe aus den \\(p\\) Pr√§diktoren des Datensatzes gezogen (ohne Zur√ºcklegen). \\(m\\) ist ein Tuningparameter; \\(m=\\sqrt(p)\\) ist ein beliebter Startwert. In den meisten Implementationen wird \\(m\\) mit mtry bezeichnet (so auch in Tidymodels). Der Random-Forest-Algorithmus ist in Abb. 11.3 illustriert. Figure 11.3: Zufallsw√§lder durch Ziehen mit Zur√ºcklegen (zmz) und Ziehen ohne Zur√ºcklegen (ZoZ) Abb. 11.4 vergleicht die Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen aus James et al. (2021). In diesem Fall ist die Vorhersageg√ºte deutlich unter der OOB-G√ºte; laut James et al. (2021) ist dies hier ‚ÄúZufall‚Äù. Figure 11.4: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen Den Effekt von \\(m\\) (Anzahl der Pr√§diktoren pro Split) ist in Abb. 11.5 dargestellt (James et al. 2021). Man erkennt, dass der Zusatznutzen an zus√§tzlichen B√§umen, \\(B\\), sich abschw√§cht. \\(m=\\sqrt{p}\\) schneidet wie erwartet am besten ab. Figure 11.5: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen 11.9 Boosting Im Unterschied zu Bagging und Random-Forest-Modellen wird beim Boosting der ‚ÄúWald‚Äù sequenziell entwickelt, nicht gleichzeitig wie bei den anderen vorgestellten ‚ÄúWald-Modellen‚Äù. Die zwei bekanntesten Implementierungen bzw. Algorithmus-Varianten sind AdaBoost und XGBoost. Gerade XGBoost hat den Ruf, hervorragende Vorhersagen zu leisten. Auf Kaggle gewinnt nach einigen Berichten oft XGBoost. Nur neuronale Netze schneiden besser ab. Random-Forest-Modelle kommen nach diesem Bereich auf Platz 3. Allerdings ben√∂tigen neuronale Netzen oft riesige Stichprobengr√∂√üen und bei spielen ihre Nuanciertheit vor allem bei komplexen Daten wie Bildern oder Sprache aus. F√ºr ‚Äúrechteckige‚Äù Daten (also aus einfachen, normalen Tabellen) wird ein baumbasiertes Modell oft besser abschneiden. Die Idee des Boosting ist es, anschaulich gesprochen, aus Fehlern zu lernen: Fitte einen Baum, schau welche F√§lle er schlecht vorhergesagt hat, konzentriere dich beim n√§chsten Baum auf diese F√§lle und so weiter. Wie andere Ensemble-Methoden auch kann Boosting theoretisch f√ºr beliebige Algorithmen eingesetzt werden. Es macht aber Sinn, Boosting bei ‚Äúschwachen Lernern‚Äù einzusetzen. Typisches Beispiel ist ein einfacher Baum; ‚Äúeinfach‚Äù soll hei√üen, der Baum hat nur wenig Gabeln oder vielleicht sogar nur eine einzige. Dann spricht man von einem Stumpf, was intuitiv gut passt. 11.9.1 AdaBoost Der AdaBoost-Algorithmus funktioniert, einfach dargestellt, wie folgt. Zuerst hat jeder Fall \\(i\\) im Datensatz des gleiche Gewicht. Die erste (und alle weiteren) Stichprobe werden per Bootstrapping aus dem Datensatz gezogen. Dabei ist die Wahrscheinlichkeit, gezogen zu werden, proportional zum Gewicht des Falles, \\(w_i\\). Da im ersten Durchgang die Gewichte identisch sind, haben zun√§chst alle F√§lle die gleiche Wahrscheinlichkeit, in das Bootstrap-Sample gezogen zu werden. Die B√§ume bei AdaBoost sind eigentlich nur ‚ÄúSt√ºmpfe‚Äù: Sie bestehen aus einem einzelnen Split, s. Abb. 11.6. Figure 11.6: Ein Baumstumpf bei AdaBoost Nach Berechnung des Baumes und der Vorhersagen werden die richtig klassifizierten F√§lle heruntergewichtet und die falsch klassifizierten F√§lle hoch gewichtet, also st√§rker gewichtet (bleiben wir aus Gr√ºnden der Einfachheit zun√§chst bei der Klassifikation). Dieses Vorgehen folgt dem Gedanken, dass man sich seine Fehler genauer anschauen muss, die falsch klassifizierten F√§lle sozusagen mehr Aufmerksamkeit bed√ºrfen. Das n√§chste (zweite) Modell zieht ein weiteres Bootstrap-Sample. Jetzt sind allerdings die Gewichte schon angepasst, so dass mehr F√§lle, die im vorherigen Modell falsch klassifiziert wurden, in den neuen (zweiten) Baum gezogen werden. Das neue Modell hat also bessere Chancen, die Aspekte, die das Vorg√§nger-Modell √ºbersah zu korrigieren bzw. zu lernen. Jetzt haben wir zwei Modelle. Die k√∂nnen wir aggregieren, genau wie beim Bagging: Der Modus der Vorhersage √ºber alle (beide) B√§ume hinwig ist dann die Vorhersage f√ºr einen bestimmten Fall (‚ÄúFall‚Äù und ‚ÄúBeobachtung‚Äù sind stets synonym f√ºr \\(y_i\\) zu verstehen). So wiederholt sich das Vorgehen f√ºr \\(B\\) B√§ume: Die Gewichte werden angepasst, das neue Modell wird berechnet, alle Modelle machen ihre Vorhersagen, per Mehrheitsbeschluss - mit gewichteten Modellen - wird die Vorhersage bestimmt pro Fall. Irgendwann erreichen wir die vorab definierte Maximalzahl an B√§umen, \\(B\\), und das Modell kommt zu einem Ende. Da das Modell die Fehler seiner Vorg√§nger reduziert, wird der Bias im Gesamtmodell verringert. Da wir gleichzeitig auch Bagging vornehmen, wird aber die Varianz auch verringert. Klingt schon wieder (fast) nach Too-Good-to-be-True! Das Gewicht \\(w_i^b\\) des \\(i\\)ten Falls im \\(b\\)ten Modell von \\(B\\) berechnet sich wie folgt (Rhys 2020): \\[ w_i^b = \\begin{cases} w_i^{b-1} \\cdot e^{-\\text{model weight}} \\qquad \\text{wenn korrekt klassifiziert} \\\\ w_i^{b-1} \\cdot e^{\\text{model weight}} \\qquad \\text{wenn inkorrekt klassifiziert} \\\\ \\end{cases}\\] Das Modellgewicht \\(mw\\) berechnet sich dabei so (Rhys 2020): \\[mw_b = 0.5 \\cdot log\\left( \\frac{1-p(\\text{inkorrect})}{p(\\text{korrekt})} \\right) \\propto \\mathcal{L(p)} \\] \\(p(\\cdot)\\) ist der Anteil (Wahrscheinlichkeit) einer Vorhersage. Das Modellgewicht ist ein Faktor, der schlechtere Modelle bestraft. Das folgt dem Gedanken, dass schlechteren Modellen weniger Geh√∂rt geschenkt werden soll, aber schlecht klassifizierten F√§llen mehr Geh√∂r. Das Vorgehen von AdaBoost ist in Abb. 11.7 illustriert. Figure 11.7: AdaBoost illustriert 11.9.2 XGBoost XGBoost ist ein Gradientenverfahren, eine Methode also, die die Richtung des parziellen Ableitungskoeffizienten als Optimierungskriterium heranzieht. XGBoost ist √§hnlich zu AdaBoost, nur dass Residuen modelliert werden, nicht \\(y\\). Die Vorhersagefehler von \\(\\hat{f}^b\\) werden die Zielvariable von \\(\\hat{f}^{b+1}\\). Ein Residuum ist der Vorhersagefehler, bei metrischen Modellen etwa RMSE, oder schlicht \\(r_i = y_i - \\hat{y}_i\\). Details finden sich z.B. hier, dem Original XGBoost-Paper (Chen and Guestrin 2016). Die hohe Vorhersageg√ºte von Boosting-Modellen ist exemplarisch in Abb. 11.8 dargestellt (James et al. 2021, S. 358ff). Allerdings verwenden die Autoren Friedmans (2001) Gradient Boosting Machine, eine weitere Variante des Boosting . Figure 11.8: Vorhersageg√ºte von Boosting und Random Forest 11.10 Tidymodels 11.10.1 Datensatz Churn Wir betrachten einen Datensatz zur Kundenabwanderung (Churn) aus dieser Quelle. churn_df &lt;- read_rds(&#39;https://gmudatamining.com/data/churn_data.rds&#39;) Ein Blick in die Daten: churn_df %&gt;% head() %&gt;% gt::gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #htlyitsgmc .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #htlyitsgmc .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #htlyitsgmc .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #htlyitsgmc .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; border-top-color: #FFFFFF; border-top-width: 0; } #htlyitsgmc .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #htlyitsgmc .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #htlyitsgmc .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #htlyitsgmc .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #htlyitsgmc .gt_column_spanner_outer:first-child { padding-left: 0; } #htlyitsgmc .gt_column_spanner_outer:last-child { padding-right: 0; } #htlyitsgmc .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #htlyitsgmc .gt_group_heading { padding: 8px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #htlyitsgmc .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #htlyitsgmc .gt_from_md > :first-child { margin-top: 0; } #htlyitsgmc .gt_from_md > :last-child { margin-bottom: 0; } #htlyitsgmc .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #htlyitsgmc .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 12px; } #htlyitsgmc .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #htlyitsgmc .gt_first_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; } #htlyitsgmc .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #htlyitsgmc .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #htlyitsgmc .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #htlyitsgmc .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #htlyitsgmc .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #htlyitsgmc .gt_footnote { margin: 0px; font-size: 90%; padding: 4px; } #htlyitsgmc .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #htlyitsgmc .gt_sourcenote { font-size: 90%; padding: 4px; } #htlyitsgmc .gt_left { text-align: left; } #htlyitsgmc .gt_center { text-align: center; } #htlyitsgmc .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #htlyitsgmc .gt_font_normal { font-weight: normal; } #htlyitsgmc .gt_font_bold { font-weight: bold; } #htlyitsgmc .gt_font_italic { font-style: italic; } #htlyitsgmc .gt_super { font-size: 65%; } #htlyitsgmc .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 65%; } canceled_service enrollment_discount spouse_partner dependents phone_service internet_service online_security online_backup device_protection tech_support streaming_tv streaming_movies contract paperless_bill payment_method months_with_company monthly_charges late_payments yes no no no multiple_lines fiber_optic yes yes yes no no no one_year no credit_card 30 51.01440 3 yes no yes yes multiple_lines fiber_optic no yes yes yes yes no two_year yes electronic_check 39 80.42466 4 yes yes no no single_line fiber_optic no no no no yes yes month_to_month yes mailed_check 1 75.88737 3 yes no yes yes single_line fiber_optic yes no no no yes no two_year no credit_card 29 81.96467 3 yes yes no no single_line digital no no no no yes yes month_to_month yes bank_draft 9 101.34257 5 yes no yes no single_line fiber_optic yes yes no yes yes yes month_to_month no mailed_check 14 72.01285 4 11.10.2 Data Splitting und CV Das Kreuzvalidieren (CV) fassen wir auch unter diesen Punkt. churn_split &lt;- initial_split(churn_df, prop = 0.75, strata = canceled_service) churn_training &lt;- churn_split %&gt;% training() churn_test &lt;- churn_split %&gt;% testing() churn_folds &lt;- vfold_cv(churn_training, v = 5) 11.10.3 Feature Engineering Hier definieren wir zwei Rezepte. Gleichzeitig ver√§ndern wir die Pr√§diktoren (normalisieren, dummysieren, ‚Ä¶). Das nennt man auch Feature Engineering. churn_recipe1 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% step_normalize(all_numeric(), -all_outcomes()) %&gt;% step_dummy(all_nominal(), -all_outcomes()) churn_recipe2 &lt;- recipe(canceled_service ~ ., data = churn_training) %&gt;% step_YeoJohnson(all_numeric(), -all_outcomes()) %&gt;% step_normalize(all_numeric(), -all_outcomes()) %&gt;% step_dummy(all_nominal(), -all_outcomes()) step_YeoJohnson() reduziert Schiefe in der Verteilung. 11.10.4 Modelle tree_model &lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), min_n = tune()) %&gt;% set_engine(&#39;rpart&#39;) %&gt;% set_mode(&#39;classification&#39;) rf_model &lt;- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %&gt;% set_engine(&#39;ranger&#39;) %&gt;% set_mode(&#39;classification&#39;) boost_model &lt;- boost_tree(mtry = tune(), min_n = tune(), trees = tune()) %&gt;% set_engine(&quot;xgboost&quot;, nthreads = parallel::detectCores()) %&gt;% set_mode(&quot;classification&quot;) glm_model &lt;- logistic_reg() 11.10.5 Workflows Wir definieren ein Workflow-Set: preproc &lt;- list(rec1 = churn_recipe1, rec2 = churn_recipe2) models &lt;- list(tree1 = tree_model, rf1 = rf_model, boost1 = boost_model, glm1 = glm_model) all_workflows &lt;- workflow_set(preproc, models) Infos zu workflow_set bekommt man wie gewohnt mit ?workflow_set. Im Standard werden alle Rezepte und Modelle miteinander kombiniert (cross = TRUE), also preproc * models Modelle gefittet. 11.10.6 Modelle berechnen mit Tuning, einzeln Wir k√∂nnten jetzt jedes Modell einzeln tunen, wenn wir wollen. 11.10.6.1 Baum tree_wf &lt;- workflow() %&gt;% add_model(tree_model) %&gt;% add_recipe(churn_recipe1) tic() tree_fit &lt;- tree_wf %&gt;% tune_grid( resamples = churn_folds, metrics = metric_set(roc_auc, sens, yardstick::spec) ) toc() ## 16.273 sec elapsed Im Standard werden 10 Modellkandidaten getuned. tree_fit ## # Tuning results ## # 5-fold cross-validation ## # A tibble: 5 √ó 4 ## splits id .metrics .notes ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [2393/599]&gt; Fold1 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 2 &lt;split [2393/599]&gt; Fold2 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 3 &lt;split [2394/598]&gt; Fold3 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 4 &lt;split [2394/598]&gt; Fold4 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 5 &lt;split [2394/598]&gt; Fold5 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; Schauen wir uns das Objekt etwas n√§her an: tree_fit$.metrics[[1]] ## # A tibble: 30 √ó 7 ## cost_complexity tree_depth min_n .metric .estimator .estimate .config ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 0.000186 1 27 sens binary 0.824 Preprocessor1_‚Ä¶ ## 2 0.000186 1 27 spec binary 0.599 Preprocessor1_‚Ä¶ ## 3 0.000186 1 27 roc_auc binary 0.711 Preprocessor1_‚Ä¶ ## 4 0.00706 9 17 sens binary 0.827 Preprocessor1_‚Ä¶ ## 5 0.00706 9 17 spec binary 0.828 Preprocessor1_‚Ä¶ ## 6 0.00706 9 17 roc_auc binary 0.852 Preprocessor1_‚Ä¶ ## 7 0.00000000329 15 29 sens binary 0.812 Preprocessor1_‚Ä¶ ## 8 0.00000000329 15 29 spec binary 0.849 Preprocessor1_‚Ä¶ ## 9 0.00000000329 15 29 roc_auc binary 0.903 Preprocessor1_‚Ä¶ ## 10 0.0000116 3 22 sens binary 0.714 Preprocessor1_‚Ä¶ ## # ‚Ä¶ with 20 more rows 30 Zeilen: 3 G√ºtemetriken (Sens, Spec, ROC AUC) mit je 10 Werten (Submodellen), gibt 30 Koeffizienten. F√ºr jeden der 5 Faltungen haben wir also 10 Submodelle. Welches Modell ist das beste? show_best(tree_fit) ## # A tibble: 5 √ó 9 ## cost_complexity tree_depth min_n .metric .estimator mean n std_err ## &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 3.29e- 9 15 29 roc_auc binary 0.920 5 0.00560 ## 2 1.19e- 3 7 36 roc_auc binary 0.919 5 0.00613 ## 3 8.73e- 9 7 14 roc_auc binary 0.918 5 0.00485 ## 4 5.80e-10 11 12 roc_auc binary 0.910 5 0.00938 ## 5 7.06e- 3 9 17 roc_auc binary 0.886 5 0.0111 ## # ‚Ä¶ with 1 more variable: .config &lt;chr&gt; Aha, das sind die f√ºnf besten Modelle, bzw. ihre Tuningparameter, ihre mittlere G√ºte zusammen mit dem Standardfehler. autoplot(tree_fit) 11.10.6.2 RF Was f√ºr Tuningparameter hat den der Algorithmus bzw. seine Implementierung? show_model_info(&quot;rand_forest&quot;) ## Information for `rand_forest` ## modes: unknown, classification, regression, censored regression ## ## engines: ## classification: randomForest, ranger, spark ## regression: randomForest, ranger, spark ## ## arguments: ## ranger: ## mtry --&gt; mtry ## trees --&gt; num.trees ## min_n --&gt; min.node.size ## randomForest: ## mtry --&gt; mtry ## trees --&gt; ntree ## min_n --&gt; nodesize ## spark: ## mtry --&gt; feature_subset_strategy ## trees --&gt; num_trees ## min_n --&gt; min_instances_per_node ## ## fit modules: ## engine mode ## ranger classification ## ranger regression ## randomForest classification ## randomForest regression ## spark classification ## spark regression ## ## prediction modules: ## mode engine methods ## classification randomForest class, prob, raw ## classification ranger class, conf_int, prob, raw ## classification spark class, prob ## regression randomForest numeric, raw ## regression ranger conf_int, numeric, raw ## regression spark numeric Da die Berechnung einiges an Zeit braucht, kann man das (schon fr√ºher einmal berechnete) Ergebnisobjekt von der Festplatte lesen (sofern es existiert). Ansonsten berechnet man neu: if (file.exists(&quot;objects/rf_fit1.rds&quot;)){ rf_fit1 &lt;- read_rds(&quot;objects/rf_fit1.rds&quot;) } else { rf_wf1 &lt;- workflow() %&gt;% add_model(rf_model) %&gt;% add_recipe(churn_recipe1) tic() rf_fit1 &lt;- rf_wf1 %&gt;% tune_grid( resamples = churn_folds, metrics = metric_set(roc_auc, sens, spec) ) toc() } So kann man das berechnete Objekt abspeichern auf Festplatte, um k√ºnftig Zeit zu sparen: write_rds(rf_fit1, file = &quot;objects/rf_fit1.rds&quot;) rf_fit1 ## # Tuning results ## # 5-fold cross-validation ## # A tibble: 5 √ó 4 ## splits id .metrics .notes ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [2393/599]&gt; Fold1 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 2 &lt;split [2393/599]&gt; Fold2 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 3 &lt;split [2394/598]&gt; Fold3 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 4 &lt;split [2394/598]&gt; Fold4 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; ## 5 &lt;split [2394/598]&gt; Fold5 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt; show_best(rf_fit1) ## # A tibble: 5 √ó 9 ## mtry trees min_n .metric .estimator mean n std_err .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 6 1686 18 roc_auc binary 0.958 5 0.00330 Preprocessor1_Model03 ## 2 5 747 34 roc_auc binary 0.958 5 0.00324 Preprocessor1_Model10 ## 3 10 818 22 roc_auc binary 0.956 5 0.00378 Preprocessor1_Model01 ## 4 8 342 2 roc_auc binary 0.955 5 0.00361 Preprocessor1_Model09 ## 5 13 1184 25 roc_auc binary 0.954 5 0.00423 Preprocessor1_Model08 11.10.6.3 XGBoost boost_wf1 &lt;- workflow() %&gt;% add_model(boost_model) %&gt;% add_recipe(churn_recipe1) tic() boost_fit1 &lt;- boost_wf1 %&gt;% tune_grid( resamples = churn_folds, metrics = metric_set(roc_auc, sens, spec) ) toc() Wieder auf Festplatte speichern: write_rds(boost_fit1, file = &quot;objects/boost_fit1.rds&quot;) Und so weiter. 11.10.7 Workflow-Set tunen if (file.exists(&quot;objects/churn_model_set.rds&quot;)) { churn_model_set &lt;- read_rds(&quot;objects/churn_model_set.rds&quot;) } else { tic() churn_model_set &lt;- all_workflows %&gt;% workflow_map( resamples = churn_folds, grid = 20, metrics = metric_set(roc_auc), seed = 42, # reproducibility verbose = TRUE) toc() } Da die Berechnung schon etwas Zeit braucht, macht es Sinn, das Modell (bzw. das Ergebnisobjekt) auf Festplatte zu speichern: write_rds(churn_model_set, file = &quot;objects/churn_model_set.rds&quot;) Achtung Dieser Schritt ist gef√§hrlich: Wenn Sie Ihr Rezept und Fit-Objekt √§ndenr, kriegt das Ihre Festplatte nicht unbedingt mit. Sie k√∂nnten also unbemerkt mit dem alten Objekt von Ihrer Festplatte weiterarbeiten, ohne durch eine Fehlermeldung gewarnt zu werden. Entsprechend kann man das Modellobjekt wieder importieren, wenn einmal abgespeichert: churn_model_set &lt;- read_rds(file = &quot;objects/churn_model_set.rds&quot;) 11.10.8 Ergebnisse im Train-Sest Hier ist die Rangfolge der Modelle, geordnet nach mittlerem ROC AUC: rank_results(churn_model_set, rank_metric = &quot;roc_auc&quot;) ## # A tibble: 122 √ó 9 ## wflow_id .config .metric mean std_err n preprocessor model rank ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.963 0.00104 5 recipe boos‚Ä¶ 1 ## 2 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.963 0.00104 5 recipe boos‚Ä¶ 2 ## 3 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00106 5 recipe boos‚Ä¶ 3 ## 4 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00106 5 recipe boos‚Ä¶ 4 ## 5 rec2_glm1 Preprocesso‚Ä¶ roc_auc 0.961 0.00272 5 recipe logi‚Ä¶ 5 ## 6 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00102 5 recipe boos‚Ä¶ 6 ## 7 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00102 5 recipe boos‚Ä¶ 7 ## 8 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.960 0.00120 5 recipe boos‚Ä¶ 8 ## 9 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.960 0.00120 5 recipe boos‚Ä¶ 9 ## 10 rec1_rf1 Preprocesso‚Ä¶ roc_auc 0.960 0.00278 5 recipe rand‚Ä¶ 10 ## # ‚Ä¶ with 112 more rows autoplot(churn_model_set, metric = &quot;roc_auc&quot;) 11.10.9 Bestes Modell Und hier nur der beste Kandidat pro Algorithmus: autoplot(churn_model_set, metric = &quot;roc_auc&quot;, select_best = &quot;TRUE&quot;) + geom_text(aes(y = mean - .01, label = wflow_id), angle = 90, hjust = 1) + theme(legend.position = &quot;none&quot;) + lims(y = c(0.85, 1)) Boosting hat - knapp - am besten abgeschnitten. Allerdings sind Random Forest und die schlichte, einfache logistische Regression auch fast genau so gut. Das w√§re ein Grund f√ºr das einfachste Modell, das GLM, zu votieren. Zumal die Interpretierbarkeit am besten ist. Alternativ k√∂nnte man sich f√ºr das Boosting-Modell aussprechen. Man kann sich das beste Submodell auch von Tidymodels bestimmen lassen. Das scheint aber (noch) nicht f√ºr ein Workflow-Set zu funktionieren, sondern nur f√ºr das Ergebnisobjekt von tune_grid. select_best(churn_model_set, metric = &quot;roc_auc&quot;) ## Error in `is_metric_maximize()`: ## ! Please check the value of `metric`. rf_fit1 haben wir mit tune_grid() berechnet; mit diesem Modell kann select_best() arbeiten: select_best(rf_fit1) ## # A tibble: 1 √ó 4 ## mtry trees min_n .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 6 1686 18 Preprocessor1_Model03 Aber wir k√∂nnen uns h√§ndisch behelfen. Schauen wir uns mal die Metriken (Vorhersageg√ºte) an: churn_model_set %&gt;% collect_metrics() %&gt;% arrange(-mean) ## # A tibble: 122 √ó 9 ## wflow_id .config preproc model .metric .estimator mean n std_err ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 rec1_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.963 5 0.00104 ## 2 rec2_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.963 5 0.00104 ## 3 rec1_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.961 5 0.00106 ## 4 rec2_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.961 5 0.00106 ## 5 rec2_glm1 Preprocesso‚Ä¶ recipe logi‚Ä¶ roc_auc binary 0.961 5 0.00272 ## 6 rec1_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.961 5 0.00102 ## 7 rec2_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.961 5 0.00102 ## 8 rec1_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.960 5 0.00120 ## 9 rec2_boost1 Preprocesso‚Ä¶ recipe boos‚Ä¶ roc_auc binary 0.960 5 0.00120 ## 10 rec1_rf1 Preprocesso‚Ä¶ recipe rand‚Ä¶ roc_auc binary 0.960 5 0.00278 ## # ‚Ä¶ with 112 more rows rec1_boost1 scheint das beste Modell zu sein. best_model_params &lt;- extract_workflow_set_result(churn_model_set, &quot;rec1_boost1&quot;) %&gt;% select_best() best_model_params ## # A tibble: 1 √ó 4 ## mtry trees min_n .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 6 80 21 Preprocessor1_Model05 11.10.10 Finalisisieren Wir entscheiden uns mal f√ºr das Boosting-Modell, rec1_boost1. Diesen Workflow, in finalisierter Form, brauchen wir f√ºr den ‚Äúfinal Fit‚Äù. Finalisierte Form hei√üt: Schritt 1: Nimm den passenden Workflow, hier rec1 und boost1; das hatte uns oben rank_results() verraten. Schritt 2: Update (Finalisiere) ihn mit den besten Tuningparameter-Werten # Schritt 1: best_wf &lt;- all_workflows %&gt;% extract_workflow(&quot;rec1_boost1&quot;) best_wf ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: boost_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 2 Recipe Steps ## ## ‚Ä¢ step_normalize() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Boosted Tree Model Specification (classification) ## ## Main Arguments: ## mtry = tune() ## trees = tune() ## min_n = tune() ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost Jetzt finalisieren wir den Workflow, d.h. wir setzen die Parameterwerte des besten Submodells ein: # Schritt 2: best_wf_finalized &lt;- best_wf %&gt;% finalize_workflow(best_model_params) best_wf_finalized ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: boost_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 2 Recipe Steps ## ## ‚Ä¢ step_normalize() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Boosted Tree Model Specification (classification) ## ## Main Arguments: ## mtry = 6 ## trees = 80 ## min_n = 21 ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost 11.10.11 Last Fit fit_final &lt;- best_wf_finalized %&gt;% last_fit(churn_split) fit_final ## # Resampling results ## # Manual resampling ## # A tibble: 1 √ó 6 ## splits id .metrics .notes .predictions .workflow ## &lt;list&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [2992/998]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;workflow&gt; collect_metrics(fit_final) ## # A tibble: 2 √ó 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy binary 0.890 Preprocessor1_Model1 ## 2 roc_auc binary 0.951 Preprocessor1_Model1 11.10.12 Variablenrelevanz Um die Variablenrelevanz zu plotten, m√ºssen wir aus dem Tidymodels-Ergebnisobjekt das eigentliche Ergebnisobjekt herausziehen, von der R-Funktion, die die eigentliche Berechnung durchf√ºhrt, das w√§re glm() bei einer logistischen Regression oder xgboost::xgb.train() bei XGBoost: fit_final %&gt;% extract_fit_parsnip() ## parsnip model object ## ## ##### xgb.Booster ## raw: 110.7 Kb ## call: ## xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, ## colsample_bytree = 1, colsample_bynode = 0.285714285714286, ## min_child_weight = 21L, subsample = 1, objective = &quot;binary:logistic&quot;), ## data = x$data, nrounds = 80L, watchlist = x$watchlist, verbose = 0, ## nthreads = 8L, nthread = 1) ## params (as set within xgb.train): ## eta = &quot;0.3&quot;, max_depth = &quot;6&quot;, gamma = &quot;0&quot;, colsample_bytree = &quot;1&quot;, colsample_bynode = &quot;0.285714285714286&quot;, min_child_weight = &quot;21&quot;, subsample = &quot;1&quot;, objective = &quot;binary:logistic&quot;, nthreads = &quot;8&quot;, nthread = &quot;1&quot;, validate_parameters = &quot;TRUE&quot; ## xgb.attributes: ## niter ## callbacks: ## cb.evaluation.log() ## # of features: 21 ## niter: 80 ## nfeatures : 21 ## evaluation_log: ## iter training_logloss ## 1 0.573930 ## 2 0.493625 ## --- ## 79 0.185600 ## 80 0.185315 Dieses Objekt √ºbergeben wir dann an {vip}: fit_final %&gt;% extract_fit_parsnip() %&gt;% vip() 11.10.13 ROC-Curve Eine ROC-Kurve berechnet Sensitivit√§t und Spezifit√§t aus den Vorhersagen, bzw. aus dem Vergleich von Vorhersagen und wahrem Wert (d.h. der beobachtete Wert). Ziehen wir also zuerst die Vorhersagen heraus: fit_final %&gt;% collect_predictions() ## # A tibble: 998 √ó 7 ## id .pred_yes .pred_no .row .pred_class canceled_service .config ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 train/test spl‚Ä¶ 0.997 0.00296 3 yes yes Prepro‚Ä¶ ## 2 train/test spl‚Ä¶ 0.144 0.856 4 no yes Prepro‚Ä¶ ## 3 train/test spl‚Ä¶ 0.953 0.0475 6 yes yes Prepro‚Ä¶ ## 4 train/test spl‚Ä¶ 0.548 0.452 13 yes yes Prepro‚Ä¶ ## 5 train/test spl‚Ä¶ 0.972 0.0284 14 yes yes Prepro‚Ä¶ ## 6 train/test spl‚Ä¶ 0.964 0.0360 19 yes yes Prepro‚Ä¶ ## 7 train/test spl‚Ä¶ 0.893 0.107 25 yes yes Prepro‚Ä¶ ## 8 train/test spl‚Ä¶ 0.891 0.109 34 yes yes Prepro‚Ä¶ ## 9 train/test spl‚Ä¶ 0.905 0.0954 36 yes yes Prepro‚Ä¶ ## 10 train/test spl‚Ä¶ 0.928 0.0717 46 yes yes Prepro‚Ä¶ ## # ‚Ä¶ with 988 more rows Praktischerweise werden die ‚Äúwahren Werte‚Äù (also die beobachtaten Werte), canceled_service, ausch angegeben. Dann berechnen wir die roc_curve und autoplotten sie. fit_final %&gt;% collect_predictions() %&gt;% roc_curve(canceled_service, .pred_yes) %&gt;% autoplot() 11.11 Aufgaben Aufgabe Melden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?. Sie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden. Bei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-) Aufgabe Erstellen Sie ein Random-Forest-Modell mit Tidymodels! Reichen Sie es bei Kaggle ein un berichten Sie den Score! Hinweise Verzichten Sie auf Vorverarbeitung. Tunen Sie die typischen Parameter. Begrenzen Sie sich auf folgende Pr√§diktoren. preds_chosen &lt;- c(&quot;id&quot;, &quot;budget&quot;, &quot;popularity&quot;, &quot;runtime&quot;) L√∂sung Pakete starten library(tidyverse) library(tidymodels) library(tictoc) Daten importieren d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; d_train &lt;- read_csv(d_train_path) d_test &lt;- read_csv(d_test_path) Werfen wir einen Blick in die Daten: glimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Tim‚Ä¶ ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{‚Ä¶ ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whip‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;fathe‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.1749‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;Unite‚Ä¶ ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About‚Ä¶ ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, ‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 1600000‚Ä¶ glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pok√©mon Coll‚Ä¶ ## $ budget &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;‚Ä¶ ## $ homepage &lt;chr&gt; &quot;http://www.pokemon.com/us/movies/mov‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt1226251&quot;, &quot;tt0051380&quot;, &quot;tt0118556&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;ja&quot;, &quot;en&quot;, &quot;en&quot;, &quot;fr&quot;, &quot;en&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§&quot;, &quot;‚Ä¶ ## $ overview &lt;chr&gt; &quot;Ash and friends (this time accompani‚Ä¶ ## $ popularity &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.59601‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; NA, &quot;[{&#39;name&#39;: &#39;Woolner Brothers Pict‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;JP&#39;, &#39;name&#39;: &#39;Japan‚Ä¶ ## $ release_date &lt;chr&gt; &quot;7/14/07&quot;, &quot;5/19/58&quot;, &quot;5/23/97&quot;, &quot;9/4‚Ä¶ ## $ runtime &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;Somewhere Between Time &amp; Space... A ‚Ä¶ ## $ title &lt;chr&gt; &quot;Pok√©mon: The Rise of Darkrai&quot;, &quot;Atta‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 11451, &#39;name&#39;: &#39;pok‚àö¬©mon&#39;}, ‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 3, &#39;character&#39;: &#39;Tonio&#39;‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;52fe44e7c3a368484e03‚Ä¶ preds_chosen sind alle Pr√§diktoren im Datensatz, oder nicht? Das pr√ºfen wir mal kurz: preds_chosen %in% names(d_train) %&gt;% all() ## [1] TRUE Ja, alle Elemente von preds_chosen sind Pr√§diktoren im (Train-)Datensatz. CV cv_scheme &lt;- vfold_cv(d_train) Rezept 1 rec1 &lt;- recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% step_impute_bag(all_predictors()) %&gt;% step_naomit(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Operations: ## ## Bagged tree imputation for all_predictors() ## Removing rows with NA values in all_predictors() Man beachte, dass noch 21 Pr√§diktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (‚Äúgebacken‚Äù) wurde. tidy(rec1) ## # A tibble: 2 √ó 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step impute_bag FALSE FALSE impute_bag_KRpez ## 2 2 step naomit FALSE FALSE naomit_nPSJ2 Rezept checken: prep(rec1) ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Bagged tree imputation for budget, popularity, runtime [trained] ## Removing rows with NA values in budget, popularity, runtime [trained] d_train_baked &lt;- rec1 %&gt;% prep() %&gt;% bake(new_data = NULL) glimpse(d_train_baked) ## Rows: 3,000 ## Columns: 4 ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶ Fehlende Werte noch √ºbrig? library(easystats) describe_distribution(d_train_baked) %&gt;% select(Variable, n_Missing) ## Variable | n_Missing ## ---------------------- ## budget | 0 ## popularity | 0 ## runtime | 0 ## revenue | 0 Modell 1: RF model1 &lt;- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %&gt;% set_engine(&#39;ranger&#39;) %&gt;% set_mode(&#39;regression&#39;) Workflow 1 wf1 &lt;- workflow() %&gt;% add_model(model1) %&gt;% add_recipe(rec1) Modell fitten (und tunen) doParallel::registerDoParallel(4) tic() rf_fit1 &lt;- wf1 %&gt;% tune_grid(resamples = cv_scheme) toc() ## 65.17 sec elapsed rf_fit1[[&quot;.notes&quot;]][1] ## [[1]] ## # A tibble: 0 √ó 3 ## # ‚Ä¶ with 3 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt; Bester Kandidat select_best(rf_fit1) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. ## # A tibble: 1 √ó 4 ## mtry trees min_n .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 1 258 10 Preprocessor1_Model04 Workflow Finalisieren wf_best &lt;- wf1 %&gt;% finalize_workflow(parameters = select_best(rf_fit1)) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. Final Fit fit1_final &lt;- wf_best %&gt;% fit(d_train) fit1_final ## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: rand_forest() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 2 Recipe Steps ## ## ‚Ä¢ step_impute_bag() ## ‚Ä¢ step_naomit() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Ranger result ## ## Call: ## ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L, x), num.trees = ~258L, min.node.size = min_rows(~10L, x), num.threads = 1, verbose = FALSE, seed = sample.int(10^5, 1)) ## ## Type: Regression ## Number of trees: 258 ## Sample size: 3000 ## Number of independent variables: 3 ## Mtry: 1 ## Target node size: 10 ## Variable importance mode: none ## Splitrule: variance ## OOB prediction error (MSE): 6.668705e+15 ## R squared (OOB): 0.6474409 preds &lt;- fit1_final %&gt;% predict(d_test) Submission df submission_df &lt;- d_test %&gt;% select(id) %&gt;% bind_cols(preds) %&gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 √ó 2 ## id revenue ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3001 5019278. ## 2 3002 6458883. ## 3 3003 13366502. ## 4 3004 42798066. ## 5 3005 4254825. ## 6 3006 24553805. Abspeichern und einreichen: #write_csv(submission_df, file = &quot;submission.csv&quot;) Kaggle Score Diese Submission erzielte einen Score von Score: 2.76961 (RMSLE). sol &lt;- 2.76961 Aufgabe Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb. Ziel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme. Die Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so: d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; Aufgabe Reichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Kaggle-Score Hinweise: Sie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden. Berechnen Sie einen Entscheidungsbaum und einen Random-Forest. Tunen Sie nach Bedarf; verwenden Sie aber Default-Werte. Verwenden Sie Tidymodels. L√∂sung Vorbereitung library(tidyverse) library(tidymodels) library(tictoc) d_train &lt;- read_csv(d_train_path) d_test &lt;- read_csv(d_test_path) glimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Tim‚Ä¶ ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{‚Ä¶ ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whip‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;fathe‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.1749‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;Unite‚Ä¶ ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About‚Ä¶ ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, ‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 1600000‚Ä¶ glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pok√©mon Coll‚Ä¶ ## $ budget &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;‚Ä¶ ## $ homepage &lt;chr&gt; &quot;http://www.pokemon.com/us/movies/mov‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt1226251&quot;, &quot;tt0051380&quot;, &quot;tt0118556&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;ja&quot;, &quot;en&quot;, &quot;en&quot;, &quot;fr&quot;, &quot;en&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§&quot;, &quot;‚Ä¶ ## $ overview &lt;chr&gt; &quot;Ash and friends (this time accompani‚Ä¶ ## $ popularity &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.59601‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; NA, &quot;[{&#39;name&#39;: &#39;Woolner Brothers Pict‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;JP&#39;, &#39;name&#39;: &#39;Japan‚Ä¶ ## $ release_date &lt;chr&gt; &quot;7/14/07&quot;, &quot;5/19/58&quot;, &quot;5/23/97&quot;, &quot;9/4‚Ä¶ ## $ runtime &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;Somewhere Between Time &amp; Space... A ‚Ä¶ ## $ title &lt;chr&gt; &quot;Pok√©mon: The Rise of Darkrai&quot;, &quot;Atta‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 11451, &#39;name&#39;: &#39;pok‚àö¬©mon&#39;}, ‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 3, &#39;character&#39;: &#39;Tonio&#39;‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;52fe44e7c3a368484e03‚Ä¶ Rezpet Rezept definieren rec1 &lt;- recipe(revenue ~ ., data = d_train) %&gt;% update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% update_role(popularity, runtime, revenue, budget) %&gt;% update_role(revenue, new_role = &quot;outcome&quot;) %&gt;% step_mutate(budget = ifelse(budget &lt; 10, 10, budget)) %&gt;% step_log(budget) %&gt;% step_impute_knn(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## id 19 ## outcome 1 ## predictor 3 ## ## Operations: ## ## Variable mutation for ifelse(budget &lt; 10, 10, budget) ## Log transformation on budget ## K-nearest neighbor imputation for all_predictors() Check das Rezept rec1_prepped &lt;- prep(rec1, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step impute knn [training] ## The retained training set is ~ 28.71 Mb in memory. rec1_prepped ## Recipe ## ## Inputs: ## ## role #variables ## id 19 ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2793 incomplete rows. ## ## Operations: ## ## Variable mutation for ~ifelse(budget &lt; 10, 10, budget) [trained] ## Log transformation on budget [trained] ## K-nearest neighbor imputation for popularity, runtime, budget [trained] d_train_baked &lt;- rec1_prepped %&gt;% bake(new_data = NULL) head(d_train_baked) ## # A tibble: 6 √ó 23 ## id belongs_to_collection budget genres homepage imdb_id ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 [{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot ‚Ä¶ 16.5 [{&#39;id‚Ä¶ &lt;NA&gt; tt2637‚Ä¶ ## 2 2 [{&#39;id&#39;: 107674, &#39;name&#39;: &#39;The ‚Ä¶ 17.5 [{&#39;id‚Ä¶ &lt;NA&gt; tt0368‚Ä¶ ## 3 3 &lt;NA&gt; 15.0 [{&#39;id‚Ä¶ http://‚Ä¶ tt2582‚Ä¶ ## 4 4 &lt;NA&gt; 14.0 [{&#39;id‚Ä¶ http://‚Ä¶ tt1821‚Ä¶ ## 5 5 &lt;NA&gt; 2.30 [{&#39;id‚Ä¶ &lt;NA&gt; tt1380‚Ä¶ ## 6 6 &lt;NA&gt; 15.9 [{&#39;id‚Ä¶ &lt;NA&gt; tt0093‚Ä¶ ## # ‚Ä¶ with 17 more variables: original_language &lt;fct&gt;, ## # original_title &lt;fct&gt;, overview &lt;fct&gt;, popularity &lt;dbl&gt;, ## # poster_path &lt;fct&gt;, production_companies &lt;fct&gt;, ## # production_countries &lt;fct&gt;, release_date &lt;fct&gt;, runtime &lt;dbl&gt;, ## # spoken_languages &lt;fct&gt;, status &lt;fct&gt;, tagline &lt;fct&gt;, ## # title &lt;fct&gt;, Keywords &lt;fct&gt;, cast &lt;fct&gt;, crew &lt;fct&gt;, ## # revenue &lt;dbl&gt; Die AV-Spalte sollte leer sein: bake(rec1_prepped, new_data = head(d_test), all_outcomes()) ## # A tibble: 6 √ó 0 d_train_baked %&gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 √ó 23 ## id belongs_to_collection budget genres homepage imdb_id ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 2396 0 7 2054 0 ## # ‚Ä¶ with 17 more variables: original_language &lt;int&gt;, ## # original_title &lt;int&gt;, overview &lt;int&gt;, popularity &lt;int&gt;, ## # poster_path &lt;int&gt;, production_companies &lt;int&gt;, ## # production_countries &lt;int&gt;, release_date &lt;int&gt;, runtime &lt;int&gt;, ## # spoken_languages &lt;int&gt;, status &lt;int&gt;, tagline &lt;int&gt;, ## # title &lt;int&gt;, Keywords &lt;int&gt;, cast &lt;int&gt;, crew &lt;int&gt;, ## # revenue &lt;int&gt; Keine fehlenden Werte mehr in den Pr√§diktoren. Nach fehlenden Werten k√∂nnte man z.B. auch so suchen: datawizard::describe_distribution(d_train_baked) variable | mean | sd | iqr | range | skewness | kurtosis | n | n_missing id | 1500.50 | 866.17 | 1500.50 | \\[1.00, 3000.00\\] | 0.00 | -1.20 | 3000 | 0 budget | 12.51 | 6.44 | 14.88 | \\[2.30, 19.76\\] | -0.87 | -1.09 | 3000 | 0 popularity | 8.46 | 12.10 | 6.88 | \\[1.00e-06, 294.34\\] | 14.38 | 280.10 | 3000 | 0 runtime | 107.85 | 22.08 | 24.00 | \\[0.00, 338.00\\] | 1.02 | 8.20 | 3000 | 0 revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | \\[1.00, 1.52e+09\\] | 4.54 | 27.78 | 3000 | 0 So bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache. Das Test-Sample backen wir auch mal: d_test_baked &lt;- bake(rec1_prepped, new_data = d_test) d_test_baked %&gt;% head() ## # A tibble: 6 √ó 22 ## id belongs_to_collection budget genres homepage imdb_id ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 3001 [{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pok√©m‚Ä¶ 2.30 [{&#39;id‚Ä¶ &lt;NA&gt; &lt;NA&gt; ## 2 3002 &lt;NA&gt; 11.4 [{&#39;id‚Ä¶ &lt;NA&gt; &lt;NA&gt; ## 3 3003 &lt;NA&gt; 2.30 [{&#39;id‚Ä¶ &lt;NA&gt; &lt;NA&gt; ## 4 3004 &lt;NA&gt; 15.7 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 3005 &lt;NA&gt; 14.5 [{&#39;id‚Ä¶ &lt;NA&gt; &lt;NA&gt; ## 6 3006 &lt;NA&gt; 2.30 [{&#39;id‚Ä¶ &lt;NA&gt; &lt;NA&gt; ## # ‚Ä¶ with 16 more variables: original_language &lt;fct&gt;, ## # original_title &lt;fct&gt;, overview &lt;fct&gt;, popularity &lt;dbl&gt;, ## # poster_path &lt;fct&gt;, production_companies &lt;fct&gt;, ## # production_countries &lt;fct&gt;, release_date &lt;fct&gt;, runtime &lt;dbl&gt;, ## # spoken_languages &lt;fct&gt;, status &lt;fct&gt;, tagline &lt;fct&gt;, ## # title &lt;fct&gt;, Keywords &lt;fct&gt;, cast &lt;fct&gt;, crew &lt;fct&gt; Kreuzvalidierung cv_scheme &lt;- vfold_cv(d_train, v = 5, repeats = 3) Modelle Baum mod_tree &lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), mode = &quot;regression&quot;) Random Forest doParallel::registerDoParallel() mod_rf &lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000, mode = &quot;regression&quot;) %&gt;% set_engine(&quot;ranger&quot;, num.threads = 4) Workflows wf_tree &lt;- workflow() %&gt;% add_model(mod_tree) %&gt;% add_recipe(rec1) wf_rf &lt;- workflow() %&gt;% add_model(mod_rf) %&gt;% add_recipe(rec1) Fitten und tunen Tree tic() tree_fit &lt;- wf_tree %&gt;% tune_grid( resamples = cv_scheme, grid = 2 ) toc() ## 5.761 sec elapsed Hilfe zu tune_grid() bekommt man hier. tree_fit ## # Tuning results ## # 5-fold cross-validation repeated 3 times ## # A tibble: 15 √ó 5 ## splits id id2 .metrics .notes ## &lt;list&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;split [2400/600]&gt; Repeat1 Fold1 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 2 &lt;split [2400/600]&gt; Repeat1 Fold2 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 3 &lt;split [2400/600]&gt; Repeat1 Fold3 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 4 &lt;split [2400/600]&gt; Repeat1 Fold4 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 5 &lt;split [2400/600]&gt; Repeat1 Fold5 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 6 &lt;split [2400/600]&gt; Repeat2 Fold1 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 7 &lt;split [2400/600]&gt; Repeat2 Fold2 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 8 &lt;split [2400/600]&gt; Repeat2 Fold3 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 9 &lt;split [2400/600]&gt; Repeat2 Fold4 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 10 &lt;split [2400/600]&gt; Repeat2 Fold5 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 11 &lt;split [2400/600]&gt; Repeat3 Fold1 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 12 &lt;split [2400/600]&gt; Repeat3 Fold2 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 13 &lt;split [2400/600]&gt; Repeat3 Fold3 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 14 &lt;split [2400/600]&gt; Repeat3 Fold4 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; ## 15 &lt;split [2400/600]&gt; Repeat3 Fold5 &lt;tibble [4 √ó 6]&gt; &lt;tibble [0 √ó 3]&gt; Steht was in den .notes? tree_fit[[&quot;.notes&quot;]][[2]] ## # A tibble: 0 √ó 3 ## # ‚Ä¶ with 3 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt; Nein. collect_metrics(tree_fit) ## # A tibble: 4 √ó 8 ## cost_complexity tree_depth .metric .estimator mean n std_err ## &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 3.96e-10 5 rmse standard 8.86e+7 15 1.84e+6 ## 2 3.96e-10 5 rsq standard 5.92e-1 15 1.34e-2 ## 3 4.03e- 2 13 rmse standard 9.92e+7 15 2.26e+6 ## 4 4.03e- 2 13 rsq standard 4.87e-1 15 1.65e-2 ## # ‚Ä¶ with 1 more variable: .config &lt;chr&gt; show_best(tree_fit) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. ## # A tibble: 2 √ó 8 ## cost_complexity tree_depth .metric .estimator mean n std_err ## &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 3.96e-10 5 rmse standard 8.86e7 15 1.84e6 ## 2 4.03e- 2 13 rmse standard 9.92e7 15 2.26e6 ## # ‚Ä¶ with 1 more variable: .config &lt;chr&gt; Finalisieren best_tree_wf &lt;- wf_tree %&gt;% finalize_workflow(select_best(tree_fit)) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. best_tree_wf ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: decision_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 3 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_impute_knn() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Decision Tree Model Specification (regression) ## ## Main Arguments: ## cost_complexity = 3.96265898896028e-10 ## tree_depth = 5 ## ## Computational engine: rpart tree_last_fit &lt;- fit(best_tree_wf, data = d_train) tree_last_fit ## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: decision_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 3 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_impute_knn() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## n= 3000 ## ## node), split, n, deviance, yval ## * denotes terminal node ## ## 1) root 3000 5.672651e+19 66725850 ## 2) budget&lt; 18.32631 2845 1.958584e+19 46935270 ## 4) budget&lt; 17.19976 2252 5.443953e+18 25901120 ## 8) popularity&lt; 9.734966 1745 1.665118e+18 17076460 ## 16) popularity&lt; 5.761331 1019 3.184962e+17 8793730 ## 32) budget&lt; 15.44456 782 1.408243e+17 6074563 * ## 33) budget&gt;=15.44456 237 1.528117e+17 17765830 * ## 17) popularity&gt;=5.761331 726 1.178595e+18 28701940 ## 34) budget&lt; 16.15249 484 6.504138e+17 21093220 * ## 35) budget&gt;=16.15249 242 4.441208e+17 43919380 * ## 9) popularity&gt;=9.734966 507 3.175231e+18 56273980 ## 18) budget&lt; 15.36217 186 3.092335e+17 24880850 ## 36) popularity&lt; 14.04031 151 1.743659e+17 20728170 * ## 37) popularity&gt;=14.04031 35 1.210294e+17 42796710 * ## 19) budget&gt;=15.36217 321 2.576473e+18 74464390 ## 38) popularity&lt; 19.64394 300 2.025184e+18 68010500 * ## 39) popularity&gt;=19.64394 21 3.602808e+17 166662900 * ## 5) budget&gt;=17.19976 593 9.361685e+18 126815400 ## 10) popularity&lt; 19.63372 570 6.590372e+18 117422100 ## 20) budget&lt; 17.86726 374 2.692151e+18 94469490 ## 40) popularity&lt; 8.444193 149 6.363495e+17 68256660 * ## 41) popularity&gt;=8.444193 225 1.885623e+18 111828200 * ## 21) budget&gt;=17.86726 196 3.325222e+18 161219400 ## 42) popularity&lt; 11.60513 126 1.693483e+18 136587100 * ## 43) popularity&gt;=11.60513 70 1.417677e+18 205557600 * ## 11) popularity&gt;=19.63372 23 1.474624e+18 359605200 ## 22) runtime&gt;=109.5 16 9.882757e+17 299077200 * ## 23) runtime&lt; 109.5 7 2.937458e+17 497955000 * ## 3) budget&gt;=18.32631 155 1.557371e+19 429978800 ## 6) popularity&lt; 17.26579 101 4.711450e+18 299997300 ## 12) budget&lt; 18.73897 67 1.671489e+18 230290900 ## 24) popularity&lt; 12.66146 40 5.426991e+17 174328700 ## 48) budget&lt; 18.44536 18 1.099070e+17 134734600 * ## 49) budget&gt;=18.44536 22 3.814856e+17 206724000 * ## 25) popularity&gt;=12.66146 27 8.179336e+17 313197700 ## 50) budget&lt; 18.52944 13 1.273606e+17 234797100 * ## 51) budget&gt;=18.52944 14 5.364675e+17 385998300 * ## 13) budget&gt;=18.73897 34 2.072879e+18 437360100 ## 26) runtime&lt; 132.5 26 1.123840e+18 391271100 ## 52) popularity&lt; 11.34182 9 9.729505e+16 248614500 * ## 53) popularity&gt;=11.34182 17 7.464210e+17 466795200 * ## 27) runtime&gt;=132.5 8 7.143147e+17 587149400 * ## 7) popularity&gt;=17.26579 54 5.964228e+18 673092200 ## 14) budget&lt; 18.99438 33 2.082469e+18 534404700 ## 28) popularity&lt; 25.35778 19 5.425201e+17 416871200 * ## ## ... ## and 4 more lines. Vorhersage Test-Sample predict(tree_last_fit, new_data = d_test) ## # A tibble: 4,398 √ó 1 ## .pred ## &lt;dbl&gt; ## 1 6074563. ## 2 6074563. ## 3 21093221. ## 4 21093221. ## 5 6074563. ## 6 21093221. ## 7 6074563. ## 8 68256659. ## 9 43919378. ## 10 205557624. ## # ‚Ä¶ with 4,388 more rows RF Fitten und Tunen Um Rechenzeit zu sparen, kann man das Objekt, wenn einmal berechnet, abspeichern unter result_obj_path auf der Festplatte und beim n√§chsten Mal importieren, das geht schneller als neu berechnen. In diesem Fall hat result_obj_path den Inhalt tmbd_rf_fit1.rds. if (file.exists(result_obj_path)) { rf_fit &lt;- read_rds(result_obj_path) } else { tic() rf_fit &lt;- wf_rf %&gt;% tune_grid( resamples = cv_scheme) toc() } Achtung Ein Ergebnisobjekt von der Festplatte zu laden ist gef√§hrlich. Wenn Sie Ihr Modell ver√§ndern, aber vergessen, das Objekt auf der Festplatte zu aktualisieren, werden Ihre Ergebnisse falsch sein (da auf dem veralteten Objekt beruhend), ohne dass Sie durch eine Fehlermeldung von R gewarnt w√ºrden! So kann man das Ergebnisobjekt auf die Festplatte schreiben: #write_rds(rf_fit, file = &quot;objects/tmbd_rf_fit1.rds&quot;) collect_metrics(rf_fit) ## # A tibble: 20 √ó 8 ## mtry min_n .metric .estimator mean n std_err .config ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2 15 rmse standard 82814784. 15 1.71e+6 Prepro‚Ä¶ ## 2 2 15 rsq standard 0.643 15 1.15e-2 Prepro‚Ä¶ ## 3 1 34 rmse standard 82884640. 15 1.82e+6 Prepro‚Ä¶ ## 4 1 34 rsq standard 0.646 15 1.15e-2 Prepro‚Ä¶ ## 5 1 23 rmse standard 82457030. 15 1.78e+6 Prepro‚Ä¶ ## 6 1 23 rsq standard 0.648 15 1.15e-2 Prepro‚Ä¶ ## 7 1 29 rmse standard 82726287. 15 1.78e+6 Prepro‚Ä¶ ## 8 1 29 rsq standard 0.646 15 1.13e-2 Prepro‚Ä¶ ## 9 2 27 rmse standard 82386320. 15 1.74e+6 Prepro‚Ä¶ ## 10 2 27 rsq standard 0.645 15 1.21e-2 Prepro‚Ä¶ ## 11 3 20 rmse standard 83010493. 15 1.75e+6 Prepro‚Ä¶ ## 12 3 20 rsq standard 0.641 15 1.23e-2 Prepro‚Ä¶ ## 13 3 10 rmse standard 83920729. 15 1.72e+6 Prepro‚Ä¶ ## 14 3 10 rsq standard 0.634 15 1.22e-2 Prepro‚Ä¶ ## 15 2 40 rmse standard 82786794. 15 1.78e+6 Prepro‚Ä¶ ## 16 2 40 rsq standard 0.642 15 1.22e-2 Prepro‚Ä¶ ## 17 2 9 rmse standard 83237809. 15 1.71e+6 Prepro‚Ä¶ ## 18 2 9 rsq standard 0.640 15 1.14e-2 Prepro‚Ä¶ ## 19 2 3 rmse standard 83861944. 15 1.64e+6 Prepro‚Ä¶ ## 20 2 3 rsq standard 0.635 15 1.12e-2 Prepro‚Ä¶ select_best(rf_fit) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. ## # A tibble: 1 √ó 3 ## mtry min_n .config ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2 27 Preprocessor1_Model05 Finalisieren final_wf &lt;- wf_rf %&gt;% finalize_workflow(select_best(rf_fit)) ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. final_fit &lt;- fit(final_wf, data = d_train) final_preds &lt;- final_fit %&gt;% predict(new_data = d_test) %&gt;% bind_cols(d_test) submission &lt;- final_preds %&gt;% select(id, revenue = .pred) Abspeichern und einreichen: write_csv(submission, file = &quot;submission.csv&quot;) Kaggle Score Diese Submission erzielte einen Score von 2.7664 (RMSLE). sol &lt;- 2.7664 Aufgabe Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb. Ziel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme. Die Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so: d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; Aufgabe Reichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Score! Hinweise: Sie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden. Verwenden Sie mehrere, und zwar folgende Algorithmen: Random Forest, Boosting, lineare Regression. Tipp: Ein Workflow-Set ist hilfreich. Logarithmieren Sie budget. Betreiben Sie Feature Engineering, zumindest etwas. Insbesondere sollten Sie den Monat und das Jahr aus dem Datum extrahieren und als Features (Pr√§diktoren) nutzen. Verwenden Sie tidymodels. Die Zielgr√∂√üe ist revenue in Dollars; nicht in ‚ÄúLog-Dollars‚Äù. Sie m√ºssen also r√ºcktransformieren, falls Sie revenue logarithmiert haben. L√∂sung Vorbereitung library(tidyverse) library(tidymodels) library(tictoc) # Rechenzeit messen #library(Metrics) library(lubridate) # Datumsangaben library(VIM) # fehlende Werte library(visdat) # Datensatz visualisieren d_train_raw &lt;- read_csv(d_train_path) d_test &lt;- read_csv(d_test_path) Mal einen Blick werfen: glimpse(d_train_raw) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Tim‚Ä¶ ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{‚Ä¶ ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whip‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;fathe‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.1749‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;Unite‚Ä¶ ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About‚Ä¶ ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, ‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 1600000‚Ä¶ glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pok√©mon Coll‚Ä¶ ## $ budget &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;‚Ä¶ ## $ homepage &lt;chr&gt; &quot;http://www.pokemon.com/us/movies/mov‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt1226251&quot;, &quot;tt0051380&quot;, &quot;tt0118556&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;ja&quot;, &quot;en&quot;, &quot;en&quot;, &quot;fr&quot;, &quot;en&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§&quot;, &quot;‚Ä¶ ## $ overview &lt;chr&gt; &quot;Ash and friends (this time accompani‚Ä¶ ## $ popularity &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.59601‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; NA, &quot;[{&#39;name&#39;: &#39;Woolner Brothers Pict‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;JP&#39;, &#39;name&#39;: &#39;Japan‚Ä¶ ## $ release_date &lt;chr&gt; &quot;7/14/07&quot;, &quot;5/19/58&quot;, &quot;5/23/97&quot;, &quot;9/4‚Ä¶ ## $ runtime &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;Somewhere Between Time &amp; Space... A ‚Ä¶ ## $ title &lt;chr&gt; &quot;Pok√©mon: The Rise of Darkrai&quot;, &quot;Atta‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 11451, &#39;name&#39;: &#39;pok‚àö¬©mon&#39;}, ‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 3, &#39;character&#39;: &#39;Tonio&#39;‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;52fe44e7c3a368484e03‚Ä¶ Train-Set verschlanken d_train &lt;- d_train_raw %&gt;% select(popularity, runtime, revenue, budget, release_date) Datensatz kennenlernen library(visdat) vis_dat(d_train) Fehlende Werte pr√ºfen Welche Spalten haben viele fehlende Werte? vis_miss(d_train) Mit {VIM} kann man einen Datensatz gut auf fehlende Werte hin untersuchen: aggr(d_train) Rezept Rezept definieren rec1 &lt;- recipe(revenue ~ ., data = d_train) %&gt;% #update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% #update_role(revenue, new_role = &quot;outcome&quot;) %&gt;% step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% step_log(budget) %&gt;% step_mutate(release_date = mdy(release_date)) %&gt;% step_date(release_date, features = c(&quot;year&quot;, &quot;month&quot;), keep_original_cols = FALSE) %&gt;% step_impute_knn(all_predictors()) %&gt;% step_dummy(all_nominal()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Operations: ## ## Variable mutation for if_else(budget &lt; 10, 10, budget) ## Log transformation on budget ## Variable mutation for mdy(release_date) ## Date features from release_date ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal() tidy(rec1) ## # A tibble: 6 √ó 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step mutate FALSE FALSE mutate_FvTZg ## 2 2 step log FALSE FALSE log_2da9i ## 3 3 step mutate FALSE FALSE mutate_AYZMJ ## 4 4 step date FALSE FALSE date_24EWq ## 5 5 step impute_knn FALSE FALSE impute_knn_YNZ0Z ## 6 6 step dummy FALSE FALSE dummy_oxgYz Check das Rezept prep(rec1, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step mutate [training] ## oper 4 step date [training] ## oper 5 step impute knn [training] ## oper 6 step dummy [training] ## The retained training set is ~ 0.38 Mb in memory. ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Variable mutation for ~if_else(budget &lt; 10, 10, budget) [trained] ## Log transformation on budget [trained] ## Variable mutation for ~mdy(release_date) [trained] ## Date features from release_date [trained] ## K-nearest neighbor imputation for runtime, budget, release_date_year,... [trained] ## Dummy variables from release_date_month [trained] d_train_baked &lt;- prep(rec1) %&gt;% bake(new_data = NULL) d_train_baked ## # A tibble: 3,000 √ó 16 ## popularity runtime budget revenue release_date_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.58 93 16.5 12314651 2015 ## 2 8.25 113 17.5 95149435 2004 ## 3 64.3 105 15.0 13092000 2014 ## 4 3.17 122 14.0 16000000 2012 ## 5 1.15 118 2.30 3923970 2009 ## 6 0.743 83 15.9 3261638 1987 ## 7 7.29 92 16.5 85446075 2012 ## 8 1.95 84 2.30 2586511 2004 ## 9 6.90 100 2.30 34327391 1996 ## 10 4.67 91 15.6 18750246 2003 ## # ‚Ä¶ with 2,990 more rows, and 11 more variables: ## # release_date_month_Feb &lt;dbl&gt;, release_date_month_Mar &lt;dbl&gt;, ## # release_date_month_Apr &lt;dbl&gt;, release_date_month_May &lt;dbl&gt;, ## # release_date_month_Jun &lt;dbl&gt;, release_date_month_Jul &lt;dbl&gt;, ## # release_date_month_Aug &lt;dbl&gt;, release_date_month_Sep &lt;dbl&gt;, ## # release_date_month_Oct &lt;dbl&gt;, release_date_month_Nov &lt;dbl&gt;, ## # release_date_month_Dec &lt;dbl&gt; d_train_baked %&gt;% map_df(~ sum(is.na(.))) ## # A tibble: 1 √ó 16 ## popularity runtime budget revenue release_date_ye‚Ä¶ release_date_mo‚Ä¶ ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 ## # ‚Ä¶ with 10 more variables: release_date_month_Mar &lt;int&gt;, ## # release_date_month_Apr &lt;int&gt;, release_date_month_May &lt;int&gt;, ## # release_date_month_Jun &lt;int&gt;, release_date_month_Jul &lt;int&gt;, ## # release_date_month_Aug &lt;int&gt;, release_date_month_Sep &lt;int&gt;, ## # release_date_month_Oct &lt;int&gt;, release_date_month_Nov &lt;int&gt;, ## # release_date_month_Dec &lt;int&gt; Keine fehlenden Werte mehr in den Pr√§diktoren. Nach fehlenden Werten k√∂nnte man z.B. auch so suchen: datawizard::describe_distribution(d_train_baked) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## --------------------------------------------------------------------------------------------------------------------- ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.84 | 22.09 | 24.00 | [0.00, 338.00] | 1.02 | 8.19 | 3000 | 0 ## budget | 12.51 | 6.44 | 14.88 | [2.30, 19.76] | -0.87 | -1.09 | 3000 | 0 ## revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] | 4.54 | 27.78 | 3000 | 0 ## release_date_year | 2004.58 | 15.48 | 17.00 | [1969.00, 2068.00] | 1.22 | 3.94 | 3000 | 0 ## release_date_month_Feb | 0.08 | 0.26 | 0.00 | [0.00, 1.00] | 3.22 | 8.37 | 3000 | 0 ## release_date_month_Mar | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.11 | 7.71 | 3000 | 0 ## release_date_month_Apr | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.06 | 7.35 | 3000 | 0 ## release_date_month_May | 0.07 | 0.26 | 0.00 | [0.00, 1.00] | 3.24 | 8.49 | 3000 | 0 ## release_date_month_Jun | 0.08 | 0.27 | 0.00 | [0.00, 1.00] | 3.12 | 7.76 | 3000 | 0 ## release_date_month_Jul | 0.07 | 0.25 | 0.00 | [0.00, 1.00] | 3.38 | 9.45 | 3000 | 0 ## release_date_month_Aug | 0.09 | 0.28 | 0.00 | [0.00, 1.00] | 2.97 | 6.83 | 3000 | 0 ## release_date_month_Sep | 0.12 | 0.33 | 0.00 | [0.00, 1.00] | 2.33 | 3.43 | 3000 | 0 ## release_date_month_Oct | 0.10 | 0.30 | 0.00 | [0.00, 1.00] | 2.63 | 4.90 | 3000 | 0 ## release_date_month_Nov | 0.07 | 0.26 | 0.00 | [0.00, 1.00] | 3.27 | 8.67 | 3000 | 0 ## release_date_month_Dec | 0.09 | 0.28 | 0.00 | [0.00, 1.00] | 2.92 | 6.52 | 3000 | 0 So bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache. Check Test-Sample Das Test-Sample backen wir auch mal. Das hat nur den Zwecke, zu pr√ºfen, ob unser Rezept auch richtig funktioniert. Das Preppen und Backen des Test-Samples wir automatisch von predict() bzw. last_fit() erledigt. Wichtig: Wir preppen den Datensatz mit dem Train-Sample, auch wenn wir das Test-Sample backen wollen. d_test_baked &lt;- bake(rec1_prepped, new_data = d_test) ## Error in bake(rec1_prepped, new_data = d_test): object &#39;rec1_prepped&#39; not found d_test_baked %&gt;% head() ## Error in head(.): object &#39;d_test_baked&#39; not found Kreuzvalidierung cv_scheme &lt;- vfold_cv(d_train, v = 5, repeats = 3) Modelle Baum mod_tree &lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), mode = &quot;regression&quot;) Random Forest doParallel::registerDoParallel() mod_rf &lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000, mode = &quot;regression&quot;) %&gt;% set_engine(&quot;ranger&quot;, num.threads = 4) XGBoost mod_boost &lt;- boost_tree(mtry = tune(), min_n = tune(), trees = tune()) %&gt;% set_engine(&quot;xgboost&quot;, nthreads = parallel::detectCores()) %&gt;% set_mode(&quot;regression&quot;) LM mod_lm &lt;- linear_reg() Workflow-Set preproc &lt;- list(rec1 = rec1) models &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm) all_workflows &lt;- workflow_set(preproc, models) Fitten und tunen Wenn man das Ergebnis-Objekt abgespeichert hat, dann kann man es einfach laden, spart Rechenzeit (der Tag ist kurz): result_obj_file &lt;- &quot;tmdb_model_set.rds&quot; (Davon ausgehend, dass die Datei im Arbeitsverzeichnis liegt.) if (file.exists(result_obj_file)) { tmdb_model_set &lt;- read_rds(result_obj_file) } else { tic() tmdb_model_set &lt;- all_workflows %&gt;% workflow_map( resamples = cv_scheme, grid = 10, # metrics = metric_set(rmse), seed = 42, # reproducibility verbose = TRUE) toc() } Um Rechenzeit zu sparen, kann man das Ergebnisobjekt abspeichern, dann muss man beim n√§chsten Mal nicht wieder von Neuem berechnen: #write_rds(tmdb_model_set, &quot;objects/tmdb_model_set.rds&quot;) Finalisieren Welcher Algorithmus schneidet am besten ab? Genauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz. tune::autoplot(tmdb_model_set) + theme(legend.position = &quot;bottom&quot;) R-Quadrat ist nicht entscheidend; rmse ist wichtiger. Die Ergebnislage ist nicht ganz klar, aber einiges spricht f√ºr das Boosting-Modell, rec1_boost1. tmdb_model_set %&gt;% collect_metrics() %&gt;% arrange(-mean) %&gt;% head(10) ## # A tibble: 10 √ó 9 ## wflow_id .config preproc model .metric .estimator mean n ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 rec1_lm1 Preproc‚Ä¶ recipe line‚Ä¶ rmse standard 1.15e8 15 ## 2 rec1_tree1 Preproc‚Ä¶ recipe deci‚Ä¶ rmse standard 1.12e8 15 ## 3 rec1_rf1 Preproc‚Ä¶ recipe rand‚Ä¶ rmse standard 1.10e8 15 ## 4 rec1_tree1 Preproc‚Ä¶ recipe deci‚Ä¶ rmse standard 9.46e7 15 ## 5 rec1_tree1 Preproc‚Ä¶ recipe deci‚Ä¶ rmse standard 9.33e7 15 ## 6 rec1_boost1 Preproc‚Ä¶ recipe boos‚Ä¶ rmse standard 9.30e7 15 ## 7 rec1_boost1 Preproc‚Ä¶ recipe boos‚Ä¶ rmse standard 9.27e7 15 ## 8 rec1_tree1 Preproc‚Ä¶ recipe deci‚Ä¶ rmse standard 9.21e7 15 ## 9 rec1_tree1 Preproc‚Ä¶ recipe deci‚Ä¶ rmse standard 9.21e7 15 ## 10 rec1_boost1 Preproc‚Ä¶ recipe boos‚Ä¶ rmse standard 9.21e7 15 ## # ‚Ä¶ with 1 more variable: std_err &lt;dbl&gt; best_model_params &lt;- extract_workflow_set_result(tmdb_model_set, &quot;rec1_boost1&quot;) %&gt;% select_best() ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. best_model_params ## # A tibble: 1 √ó 4 ## mtry trees min_n .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 6 100 4 Preprocessor1_Model04 Finalisieren best_wf &lt;- all_workflows %&gt;% extract_workflow(&quot;rec1_boost1&quot;) best_wf ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: boost_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 6 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_date() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = tune() ## trees = tune() ## min_n = tune() ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost best_wf_finalized &lt;- best_wf %&gt;% finalize_workflow(best_model_params) best_wf_finalized ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: boost_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 6 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_date() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = 6 ## trees = 100 ## min_n = 4 ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost Final Fit fit_final &lt;- best_wf_finalized %&gt;% fit(d_train) ## [00:22:34] WARNING: amalgamation/../src/learner.cc:576: ## Parameters: { &quot;nthreads&quot; } might not be used. ## ## This could be a false alarm, with some parameters getting used by language bindings but ## then being mistakenly passed down to XGBoost core, or some parameter actually being used ## but getting flagged wrongly here. Please open an issue if you find any such cases. fit_final ## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: boost_tree() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 6 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_date() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## ##### xgb.Booster ## raw: 335.2 Kb ## call: ## xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, ## colsample_bytree = 1, colsample_bynode = 0.4, min_child_weight = 4L, ## subsample = 1, objective = &quot;reg:squarederror&quot;), data = x$data, ## nrounds = 100L, watchlist = x$watchlist, verbose = 0, nthreads = 8L, ## nthread = 1) ## params (as set within xgb.train): ## eta = &quot;0.3&quot;, max_depth = &quot;6&quot;, gamma = &quot;0&quot;, colsample_bytree = &quot;1&quot;, colsample_bynode = &quot;0.4&quot;, min_child_weight = &quot;4&quot;, subsample = &quot;1&quot;, objective = &quot;reg:squarederror&quot;, nthreads = &quot;8&quot;, nthread = &quot;1&quot;, validate_parameters = &quot;TRUE&quot; ## xgb.attributes: ## niter ## callbacks: ## cb.evaluation.log() ## # of features: 15 ## niter: 100 ## nfeatures : 15 ## evaluation_log: ## iter training_rmse ## 1 121008592 ## 2 100068656 ## --- ## 99 29287630 ## 100 29151778 d_test$revenue &lt;- NA final_preds &lt;- fit_final %&gt;% predict(new_data = d_test) %&gt;% bind_cols(d_test) Submission submission_df &lt;- final_preds %&gt;% select(id, revenue = .pred) Abspeichern und einreichen: write_csv(submission_df, file = &quot;submission.csv&quot;) Kaggle Score Diese Submission erzielte einen Score von 4.79227 (RMSLE). sol &lt;- 4.79227 Aufgabe Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?, ein Kaggle-Prognosewettbewerb. Ziel ist es, genaue Vorhersagen zu machen, in diesem Fall f√ºr Filme. Die Daten k√∂nnen Sie von der Kaggle-Projektseite beziehen oder so: d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; Aufgabe Reichen Sie bei Kaggle eine Submission f√ºr die Fallstudie ein! Berichten Sie den Score! Hinweise: Sie m√ºssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym m√∂glich); alternativ k√∂nnen Sie sich mit einem Google-Konto anmelden. Halten Sie das Modell so einfach wie m√∂glich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere Schn√∂rkel. Logarithmieren Sie budget und revenue. Minimieren Sie die Vorverarbeitung (steps) so weit als m√∂glich. Verwenden Sie tidymodels. Die Zielgr√∂√üe ist revenue in Dollars; nicht in ‚ÄúLog-Dollars‚Äù. Sie m√ºssen also r√ºcktransformieren, wenn Sie revenue logarithmiert haben, bevor Sie Ihre Prognose einreichen. L√∂sung Vorbereitung library(tidyverse) library(tidymodels) d_train_raw &lt;- read_csv(d_train_path) d_test_raw &lt;- read_csv(d_test_path) # d_test$revenue &lt;- NA d_train_backup &lt;- d_train_raw Mal einen Blick werfen: glimpse(d_train_raw) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Tim‚Ä¶ ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{‚Ä¶ ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whip‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;fathe‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.1749‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;Unite‚Ä¶ ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About‚Ä¶ ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, ‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 1600000‚Ä¶ Train-Set verschlanken d_train_raw_reduced &lt;- d_train_raw %&gt;% select(id, popularity, runtime, revenue, budget) Test-Set verschlanken d_test &lt;- d_test_raw %&gt;% select(id,popularity, runtime, budget) Outcome logarithmieren Der Outcome sollte nicht im Rezept transformiert werden (vgl. Part 3, S. 30, in dieser Unterlage). d_train &lt;- d_train_raw_reduced %&gt;% mutate(revenue = if_else(revenue &lt; 10, 10, revenue)) %&gt;% mutate(revenue = log(revenue)) Pr√ºfen, ob das funktioniert hat: d_train$revenue %&gt;% is.infinite() %&gt;% any() ## [1] FALSE Keine unendlichen Werte mehr Fehlende Werte pr√ºfen Welche Spalten haben viele fehlende Werte? sum_isna &lt;- function(x) {sum(is.na(x))} d_train %&gt;% summarise(across(everything(), sum_isna)) ## # A tibble: 1 √ó 5 ## id popularity runtime revenue budget ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 2 0 0 Rezept Rezept definieren rec2 &lt;- recipe(revenue ~ ., data = d_train) %&gt;% step_mutate(budget = ifelse(budget == 0, NA, budget)) %&gt;% # log mag keine 0 step_log(budget) %&gt;% step_impute_knn(all_predictors()) %&gt;% step_dummy(all_nominal_predictors()) %&gt;% update_role(id, new_role = &quot;id&quot;) rec2 ## Recipe ## ## Inputs: ## ## role #variables ## id 1 ## outcome 1 ## predictor 3 ## ## Operations: ## ## Variable mutation for ifelse(budget == 0, NA, budget) ## Log transformation on budget ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal_predictors() Schauen Sie mal, der Log mag keine Nullen: x &lt;- c(1,2, NA, 0) log(x) ## [1] 0.0000000 0.6931472 NA -Inf Da \\(log(0) = - \\infty\\). Aus dem Grund wandeln wir 0 lieber in NA um. tidy(rec2) ## # A tibble: 4 √ó 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step mutate FALSE FALSE mutate_N4aGk ## 2 2 step log FALSE FALSE log_l64vG ## 3 3 step impute_knn FALSE FALSE impute_knn_nWdrG ## 4 4 step dummy FALSE FALSE dummy_jaFQP Check das Rezept Wir berechnen das Rezept: rec2_prepped &lt;- prep(rec2, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step impute knn [training] ## oper 4 step dummy [training] ## The retained training set is ~ 0.12 Mb in memory. rec2_prepped ## Recipe ## ## Inputs: ## ## role #variables ## id 1 ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Variable mutation for ~ifelse(budget == 0, NA, budget) [trained] ## Log transformation on budget [trained] ## K-nearest neighbor imputation for runtime, budget, popularity [trained] ## Dummy variables from &lt;none&gt; [trained] Das ist noch nicht auf einen Datensatz angewendet! Lediglich die steps wurden vorbereitet, ‚Äúpr√§pariert‚Äù: z.B. ‚ÄúDiese Dummy-Variablen impliziert das Rezept‚Äù. So sieht das dann aus, wenn man das pr√§parierte Rezept auf das Train-Sample anwendet: d_train_baked2 &lt;- rec2_prepped %&gt;% bake(new_data = NULL) head(d_train_baked2) ## # A tibble: 6 √ó 5 ## id popularity runtime budget revenue ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 6.58 93 16.5 16.3 ## 2 2 8.25 113 17.5 18.4 ## 3 3 64.3 105 15.0 16.4 ## 4 4 3.17 122 14.0 16.6 ## 5 5 1.15 118 15.8 15.2 ## 6 6 0.743 83 15.9 15.0 d_train_baked2 %&gt;% map_df(sum_isna) ## # A tibble: 1 √ó 5 ## id popularity runtime budget revenue ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 Keine fehlenden Werte mehr in den Pr√§diktoren. Nach fehlenden Werten k√∂nnte man z.B. auch so suchen: datawizard::describe_distribution(d_train_baked2) ## Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing ## ----------------------------------------------------------------------------------------------------- ## id | 1500.50 | 866.17 | 1500.50 | [1.00, 3000.00] | 0.00 | -1.20 | 3000 | 0 ## popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 ## runtime | 107.85 | 22.08 | 24.00 | [0.00, 338.00] | 1.02 | 8.20 | 3000 | 0 ## budget | 16.09 | 1.89 | 1.90 | [0.00, 19.76] | -2.93 | 18.71 | 3000 | 0 ## revenue | 15.97 | 3.04 | 3.37 | [2.30, 21.14] | -1.60 | 3.82 | 3000 | 0 So bekommt man gleich noch ein paar Infos √ºber die Verteilung der Variablen. Praktische Sache. Check Test-Sample Das Test-Sample backen wir auch mal, um zu pr√ºfen, das alles l√§uft: d_test_baked2 &lt;- bake(rec2_prepped, new_data = d_test) d_test_baked2 %&gt;% head() ## # A tibble: 6 √ó 4 ## id popularity runtime budget ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3001 3.85 90 15.8 ## 2 3002 3.56 65 11.4 ## 3 3003 8.09 100 16.4 ## 4 3004 8.60 130 15.7 ## 5 3005 3.22 92 14.5 ## 6 3006 8.68 121 16.1 Sieht soweit gut aus. Kreuzvalidierung cv_scheme &lt;- vfold_cv(d_train, v = 5, repeats = 3) Modelle LM mod_lm &lt;- linear_reg() Workflow-Set Hier nur ein sehr kleiner Workflow-Set. Das ist √ºbrigens eine gute Strategie: Erstmal mit einem kleinen Prozess anfangen, und dann sukzessive erweitern. preproc2 &lt;- list(rec1 = rec2) models2 &lt;- list(lm1 = mod_lm) all_workflows2 &lt;- workflow_set(preproc2, models2) Fitten und tunen tmdb_model_set2 &lt;- all_workflows2 %&gt;% workflow_map(resamples = cv_scheme) Finalisieren tmdb_model_set2 %&gt;% collect_metrics() %&gt;% arrange(-mean) %&gt;% head(10) ## # A tibble: 2 √ó 9 ## wflow_id .config preproc model .metric .estimator mean n ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 rec1_lm1 Preprocessor‚Ä¶ recipe line‚Ä¶ rmse standard 2.48 15 ## 2 rec1_lm1 Preprocessor‚Ä¶ recipe line‚Ä¶ rsq standard 0.340 15 ## # ‚Ä¶ with 1 more variable: std_err &lt;dbl&gt; best_model_params2 &lt;- extract_workflow_set_result(tmdb_model_set2, &quot;rec1_lm1&quot;) %&gt;% select_best() ## Warning: No value of `metric` was given; metric &#39;rmse&#39; will be used. best_model_params2 ## # A tibble: 1 √ó 1 ## .config ## &lt;chr&gt; ## 1 Preprocessor1_Model1 Finalisieren Finalisieren bedeutet: Besten Workflow identifizieren (zur Erinnerung: Workflow = Rezept + Modell) Den besten Workflow mit den optimalen Modell-Parametern ausstatten Damit dann den ganzen Train-Datensatz fitten Auf dieser Basis das Test-Sample vorhersagen best_wf2 &lt;- all_workflows2 %&gt;% extract_workflow(&quot;rec1_lm1&quot;) best_wf2 ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: linear_reg() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 4 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Linear Regression Model Specification (regression) ## ## Computational engine: lm best_wf_finalized2 &lt;- best_wf2 %&gt;% finalize_workflow(best_model_params2) best_wf_finalized2 ## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: linear_reg() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 4 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## Linear Regression Model Specification (regression) ## ## Computational engine: lm Final Fit fit_final2 &lt;- best_wf_finalized2 %&gt;% fit(d_train) fit_final2 ## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: linear_reg() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 4 Recipe Steps ## ## ‚Ä¢ step_mutate() ## ‚Ä¢ step_log() ## ‚Ä¢ step_impute_knn() ## ‚Ä¢ step_dummy() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) popularity runtime budget ## 1.26186 0.03755 0.01289 0.80752 preds &lt;- fit_final2 %&gt;% predict(new_data = d_test) head(preds) ## # A tibble: 6 √ó 1 ## .pred ## &lt;dbl&gt; ## 1 15.3 ## 2 11.4 ## 3 16.1 ## 4 16.0 ## 5 14.3 ## 6 16.1 Achtung, wenn die Outcome-Variable im Rezept ver√§ndert wurde, dann w√ºrde obiger Code nicht durchlaufen. Grund ist hier beschrieben: When predict() is used, it only has access to the predictors (mirroring how this would work with new samples). Even if the outcome column is present, it is not exposed to the recipe. This is generally a good idea so that we can avoid information leakage. One approach is the use the skip = TRUE option in step_log() so that it will avoid that step during predict() and/or bake(). However, if you are using this recipe with the tune package, there will still be an issue because the metric function(s) would get the predictions in log units and the observed outcome in the original units. The better approach is, for simple transformations like yours, to log the outcome outside of the recipe (before data analysis and the initial split). Submission df submission_df &lt;- d_test %&gt;% select(id) %&gt;% bind_cols(preds) %&gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 √ó 2 ## id revenue ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3001 15.3 ## 2 3002 11.4 ## 3 3003 16.1 ## 4 3004 16.0 ## 5 3005 14.3 ## 6 3006 16.1 Zur√ºcktransformieren submission_df &lt;- submission_df %&gt;% mutate(revenue = exp(revenue)-1) head(submission_df) ## # A tibble: 6 √ó 2 ## id revenue ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3001 4435143. ## 2 3002 91755. ## 3 3003 9782986. ## 4 3004 8573795. ## 5 3005 1598106. ## 6 3006 10061439. Hier ein Beispiel, warum \\(e^{x} - 1\\) genauer ist f√ºr kleine Zahlen als \\(e^{x}\\). Abspeichern und einreichen: write_csv(submission_df, file = &quot;submission.csv&quot;) Kaggle Score Diese Submission erzielte einen Score von Score: 2.46249 (RMSLE). sol &lt;- 2.5 Aufgabe Melden Sie sich an f√ºr die Kaggle Competition TMDB Box Office Prediction - Can you predict a movie‚Äôs worldwide box office revenue?. Sie ben√∂tigen dazu ein Konto; es ist auch m√∂glich, sich mit seinem Google-Konto anzumelden. Bei diesem Prognosewettbewerb geht es darum, vorherzusagen, wieviel Umsatz wohl einige Filme machen werden. Als Pr√§diktoren stehen einige Infos wie Budget, Genre, Titel etc. zur Verf√ºgung. Eine klassische ‚Äúpredictive Competition‚Äù also :-) Allerdings k√∂nnen immer ein paar Schwierigkeiten auftreten ;-) Aufgabe Erstellen Sie ein Random-Forest-Modell mit Tidymodels! Hinweise Verzichten Sie auf Vorverarbeitung. Tunen Sie die typischen Parameter. Reichen Sie das Modell ein und berichten Sie Ihren Score. Begrenzen Sie sich auf folgende Pr√§diktoren. Verwenden Sie (langweiligerweise) nur ein lineares Modell. preds_chosen &lt;- c(&quot;id&quot;, &quot;budget&quot;, &quot;popularity&quot;, &quot;runtime&quot;) L√∂sung Pakete starten library(tidyverse) library(tidymodels) library(tictoc) Daten importieren d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; d_train &lt;- read_csv(d_train_path) d_test &lt;- read_csv(d_test_path) Werfen wir einen Blick in die Daten: glimpse(d_train) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Tim‚Ä¶ ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{‚Ä¶ ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whip‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;fathe‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.1749‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;Unite‚Ä¶ ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About‚Ä¶ ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Prince‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, ‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 1600000‚Ä¶ glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3‚Ä¶ ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pok√©mon Coll‚Ä¶ ## $ budget &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+0‚Ä¶ ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;‚Ä¶ ## $ homepage &lt;chr&gt; &quot;http://www.pokemon.com/us/movies/mov‚Ä¶ ## $ imdb_id &lt;chr&gt; &quot;tt1226251&quot;, &quot;tt0051380&quot;, &quot;tt0118556&quot;‚Ä¶ ## $ original_language &lt;chr&gt; &quot;ja&quot;, &quot;en&quot;, &quot;en&quot;, &quot;fr&quot;, &quot;en&quot;, &quot;en&quot;, &quot;‚Ä¶ ## $ original_title &lt;chr&gt; &quot;„Éá„Ç£„Ç¢„É´„Ç¨VS„Éë„É´„Ç≠„Ç¢VS„ÉÄ„Éº„ÇØ„É©„Ç§&quot;, &quot;‚Ä¶ ## $ overview &lt;chr&gt; &quot;Ash and friends (this time accompani‚Ä¶ ## $ popularity &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.59601‚Ä¶ ## $ poster_path &lt;chr&gt; &quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg&quot;, &quot;‚Ä¶ ## $ production_companies &lt;chr&gt; NA, &quot;[{&#39;name&#39;: &#39;Woolner Brothers Pict‚Ä¶ ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;JP&#39;, &#39;name&#39;: &#39;Japan‚Ä¶ ## $ release_date &lt;chr&gt; &quot;7/14/07&quot;, &quot;5/19/58&quot;, &quot;5/23/97&quot;, &quot;9/4‚Ä¶ ## $ runtime &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 1‚Ä¶ ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;Englis‚Ä¶ ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;‚Ä¶ ## $ tagline &lt;chr&gt; &quot;Somewhere Between Time &amp; Space... A ‚Ä¶ ## $ title &lt;chr&gt; &quot;Pok√©mon: The Rise of Darkrai&quot;, &quot;Atta‚Ä¶ ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 11451, &#39;name&#39;: &#39;pok‚àö¬©mon&#39;}, ‚Ä¶ ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 3, &#39;character&#39;: &#39;Tonio&#39;‚Ä¶ ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;52fe44e7c3a368484e03‚Ä¶ preds_chosen sind alle Pr√§diktoren im Datensatz, oder nicht? Das pr√ºfen wir mal kurz: preds_chosen %in% names(d_train) %&gt;% all() ## [1] TRUE Ja, alle Elemente von preds_chosen sind Pr√§diktoren im (Train-)Datensatz. CV cv_scheme &lt;- vfold_cv(d_train) Rezept 1 rec1 &lt;- recipe(revenue ~ budget + popularity + runtime, data = d_train) %&gt;% step_impute_bag(all_predictors()) %&gt;% step_naomit(all_predictors()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Operations: ## ## Bagged tree imputation for all_predictors() ## Removing rows with NA values in all_predictors() Man beachte, dass noch 21 Pr√§diktoren angezeigt werden, da das Rezept noch nicht auf den Datensatz angewandt (‚Äúgebacken‚Äù) wurde. tidy(rec1) ## # A tibble: 2 √ó 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step impute_bag FALSE FALSE impute_bag_sXqWu ## 2 2 step naomit FALSE FALSE naomit_INEp7 Rezept checken: prep(rec1) ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 3 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Bagged tree imputation for budget, popularity, runtime [trained] ## Removing rows with NA values in budget, popularity, runtime [trained] d_train_baked &lt;- rec1 %&gt;% prep() %&gt;% bake(new_data = NULL) glimpse(d_train_baked) ## Rows: 3,000 ## Columns: 4 ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00‚Ä¶ ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807‚Ä¶ ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119‚Ä¶ ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,‚Ä¶ Fehlende Werte noch √ºbrig? library(easystats) describe_distribution(d_train_baked) %&gt;% select(Variable, n_Missing) ## Variable | n_Missing ## ---------------------- ## budget | 0 ## popularity | 0 ## runtime | 0 ## revenue | 0 Modell 1 model_lm &lt;- linear_reg() Workflow 1 wf1 &lt;- workflow() %&gt;% add_model(model_lm) %&gt;% add_recipe(rec1) Modell fitten (und tunen) doParallel::registerDoParallel(4) tic() lm_fit1 &lt;- wf1 %&gt;% tune_grid(resamples = cv_scheme) ## Warning: No tuning parameters have been detected, performance will ## be evaluated using the resamples with no tuning. Did you want to ## [tune()] parameters? toc() ## 2.579 sec elapsed lm_fit1[[&quot;.notes&quot;]][1] ## [[1]] ## # A tibble: 0 √ó 3 ## # ‚Ä¶ with 3 variables: location &lt;chr&gt;, type &lt;chr&gt;, note &lt;chr&gt; Final Fit fit1_final &lt;- wf1 %&gt;% fit(d_train) fit1_final ## ‚ïê‚ïê Workflow [trained] ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê ## Preprocessor: Recipe ## Model: linear_reg() ## ## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## 2 Recipe Steps ## ## ‚Ä¢ step_impute_bag() ## ‚Ä¢ step_naomit() ## ## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## ## Call: ## stats::lm(formula = ..y ~ ., data = data) ## ## Coefficients: ## (Intercept) budget popularity runtime ## -2.901e+07 2.482e+00 2.604e+06 1.648e+05 preds &lt;- fit1_final %&gt;% predict(d_test) Submission df submission_df &lt;- d_test %&gt;% select(id) %&gt;% bind_cols(preds) %&gt;% rename(revenue = .pred) head(submission_df) ## # A tibble: 6 √ó 2 ## id revenue ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3001 -4147693. ## 2 3002 -8808622. ## 3 3003 8523906. ## 4 3004 31675369. ## 5 3005 -504520. ## 6 3006 13531528. Abspeichern und einreichen: #write_csv(submission_df, file = &quot;submission.csv&quot;) Kaggle Score Diese Submission erzielte einen Score von Score: 6.14787 (RMSLE). sol &lt;- 6.14787 Aufgabe Ein merkw√ºrdiger Fehler bzw. eine merkw√ºrdige Fehlermeldung in Tidymodels - das untersuchen wir hier genauer und versuchen das Ph√§nomen zu erkl√§ren. Aufgabe Erl√§utern Sie die Ursachen des Fehlers! Schalten Sie den Fehler an und ab, um zu zeigen, dass Sie Ihn verstehen. Startup library(tidyverse) library(tidymodels) Data import data(&quot;mtcars&quot;) d_train &lt;- mtcars %&gt;% slice(1:20) d_test &lt;- mtcars %&gt;% slice(21:nrow(mtcars)) Recipe preds_chosen &lt;- c(&quot;hp&quot;, &quot;disp&quot;, &quot;am&quot;) rec1 &lt;- recipe( ~ ., data = d_train) %&gt;% update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% update_role(all_of(preds_chosen), new_role = &quot;predictor&quot;) %&gt;% update_role(mpg, new_role = &quot;outcome&quot;) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## id 7 ## outcome 1 ## predictor 3 d_train_baked &lt;- rec1 %&gt;% prep() %&gt;% bake(new_data = NULL) glimpse(d_train_baked) ## Rows: 20 ## Columns: 11 ## $ mpg &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, ‚Ä¶ ## $ cyl &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, ‚Ä¶ ## $ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7‚Ä¶ ## $ hp &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 18‚Ä¶ ## $ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, ‚Ä¶ ## $ wt &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190‚Ä¶ ## $ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00‚Ä¶ ## $ vs &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ‚Ä¶ ## $ am &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ‚Ä¶ ## $ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, ‚Ä¶ ## $ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, ‚Ä¶ Model 1 model_lm &lt;- linear_reg() Workflow 1 wf1 &lt;- workflow() %&gt;% add_model(model_lm) %&gt;% add_recipe(rec1) Fit lm_fit1 &lt;- wf1 %&gt;% fit(d_train) preds &lt;- lm_fit1 %&gt;% predict(d_test) head(preds) ## # A tibble: 6 √ó 1 ## .pred ## &lt;dbl&gt; ## 1 22.6 ## 2 17.2 ## 3 17.4 ## 4 12.1 ## 5 14.9 ## 6 28.2 Aus Gr√ºnden der Reproduzierbarkeit bietet es sich an, eine SessionInfo anzugeben: sessionInfo() ## R version 4.1.3 (2022-03-10) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Monterey 12.3.1 ## ## Matrix products: default ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] grid stats graphics grDevices utils datasets ## [7] methods base ## ## other attached packages: ## [1] visdat_0.5.3 VIM_6.1.1 colorspace_2.0-3 ## [4] lubridate_1.8.0 rpart_4.1.16 ranger_0.13.1 ## [7] report_0.5.1.1 see_0.7.0.1 correlation_0.8.0.1 ## [10] modelbased_0.8.0 effectsize_0.6.0.1 parameters_0.17.0.9 ## [13] performance_0.9.0.2 bayestestR_0.12.1 datawizard_0.4.0.17 ## [16] insight_0.17.0.6 easystats_0.4.3 tictoc_1.0.1 ## [19] yardstick_0.0.9 workflowsets_0.1.0 workflows_0.2.6 ## [22] tune_0.2.0.9000 rsample_0.1.1 recipes_0.2.0 ## [25] parsnip_0.2.1 modeldata_0.1.1 infer_1.0.0 ## [28] dials_0.1.1 scales_1.2.0 broom_0.8.0 ## [31] tidymodels_0.1.4 forcats_0.5.1 stringr_1.4.0 ## [34] purrr_0.3.4 readr_2.1.2 tidyr_1.2.0 ## [37] tibble_3.1.7 ggplot2_3.3.6 tidyverse_1.3.1 ## [40] exams_2.3-6 dplyr_1.0.9 colorout_1.2-2 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.4.1 primes_1.1.0 ## [4] plyr_1.8.7 sp_1.4-6 splines_4.1.3 ## [7] listenv_0.8.0 TH.data_1.1-1 digest_0.6.29 ## [10] foreach_1.5.2 htmltools_0.5.2 fansi_1.0.3 ## [13] magrittr_2.0.3 doParallel_1.0.17 openxlsx_4.2.5 ## [16] tzdb_0.1.2 globals_0.14.0 modelr_0.1.8 ## [19] gower_1.0.0 vroom_1.5.7 sandwich_3.0-1 ## [22] hardhat_0.2.0 rvest_1.0.2 haven_2.4.3 ## [25] xfun_0.30 crayon_1.5.1 jsonlite_1.8.0 ## [28] survival_3.2-13 zoo_1.8-9 iterators_1.0.14 ## [31] glue_1.6.2 gtable_0.3.0 ipred_0.9-12 ## [34] emmeans_1.7.3 car_3.0-11 future.apply_1.8.1 ## [37] DEoptimR_1.0-10 abind_1.4-5 mvtnorm_1.1-3 ## [40] DBI_1.1.2 Rcpp_1.0.8.3 laeken_0.5.2 ## [43] xtable_1.8-4 foreign_0.8-82 proxy_0.4-26 ## [46] GPfit_1.0-8 bit_4.0.4 lava_1.6.10 ## [49] prodlim_2019.11.13 vcd_1.4-9 httr_1.4.3 ## [52] ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 ## [55] nnet_7.3-17 dbplyr_2.1.1 utf8_1.2.2 ## [58] labeling_0.4.2 tidyselect_1.1.2 rlang_1.0.2 ## [61] DiceDesign_1.9 munsell_0.5.0 cellranger_1.1.0 ## [64] tools_4.1.3 xgboost_1.5.2.1 cli_3.3.0 ## [67] generics_0.1.2 evaluate_0.15 fastmap_1.1.0 ## [70] knitr_1.39 bit64_4.0.5 fs_1.5.2 ## [73] zip_2.2.0 robustbase_0.93-9 future_1.24.0 ## [76] xml2_1.3.3 compiler_4.1.3 rstudioapi_0.13 ## [79] curl_4.3.2 e1071_1.7-9 reprex_2.0.1 ## [82] lhs_1.1.5 stringi_1.7.6 highr_0.9 ## [85] lattice_0.20-45 Matrix_1.4-0 vctrs_0.4.1 ## [88] pillar_1.7.0 lifecycle_1.0.1 furrr_0.2.3 ## [91] lmtest_0.9-39 estimability_1.3 data.table_1.14.2 ## [94] R6_2.5.1 rio_0.5.29 parallelly_1.31.0 ## [97] codetools_0.2-18 boot_1.3-28 MASS_7.3-55 ## [100] assertthat_0.2.1 withr_2.5.0 multcomp_1.4-19 ## [103] parallel_4.1.3 hms_1.1.1 timeDate_3043.102 ## [106] coda_0.19-4 class_7.3-20 rmarkdown_2.14 ## [109] carData_3.0-4 pROC_1.18.0 base64enc_0.1-3 L√∂sung Definiert man das Rezept so: rec2 &lt;- recipe(mpg ~ hp + disp + am, data = d_train) Dann l√§uft predict() brav durch. Auch dieser Code funktioniert: rec3 &lt;- recipe(mpg ~ ., data = d_train) %&gt;% update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% update_role(all_of(preds_chosen), new_role = &quot;predictor&quot;) %&gt;% update_role(mpg, new_role = &quot;outcome&quot;) Das Problem von rec1 scheint darin zu legen, dass die Rollen der Variablen nicht richtig gel√∂scht werden, was predict() verwirrt: rec1 &lt;- recipe(mpg ~ ., data = d_train) %&gt;% update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% update_role(all_of(preds_chosen), new_role = &quot;predictor&quot;) %&gt;% update_role(mpg, new_role = &quot;outcome&quot;) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## id 7 ## outcome 1 ## predictor 3 Daher l√§uft das Rezept rec3 durch, wenn man zun√§chst alle Pr√§diktoren in ID-Variablen umwandelt: Damit sind alle Rollen wieder sauber. 11.12 Vertiefung Einfache Durchf√ºhrung eines Modellierung mit XGBoost Fallstudie Oregon Schools Fallstudie Churn Fallstudie Ikea Fallstudie Wasserquellen in Sierra Leone Fallstudie B√§ume in San Francisco Fallstudie Vulkanausbr√ºche Fallstudie Brettspiele mit XGBoost References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
