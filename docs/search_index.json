[["kaggle.html", "Kapitel 13 Kaggle 13.1 Vorbereitung 13.2 Was ist Kaggle? 13.3 Fallstudie TMDB 13.4 Rezept 13.5 Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing 13.6 Kreuzvalidierung 13.7 Modelle 13.8 Workflows 13.9 Fitten und tunen 13.10 Finalisieren 13.11 Submission 13.12 Aufgaben 13.13 Vertiefung", " Kapitel 13 Kaggle 13.1 Vorbereitung 13.1.1 Lernsteuerung 13.1.2 Lernziele Sie wissen, wie man einen Datensatz für einen Prognosewettbwerb bei Kaggle einreicht Sie kennen einige Beispiele von Notebooks auf Kaggle (für die Sprache R) Sie wissen, wie man ein Workflow-Set in Tidymodels berechnet Sie wissen, dass Tidymodels im Rezept keine Transformationen im Test-Sample berücksichtigt und wie man damit umgeht 13.1.3 Hinweise Machen Sie sich mit Kaggle vertraut. Als Übungs-Wettbewerb dient uns TMDB Box-office Revenue 13.1.4 R-Pakete In diesem Kapitel werden folgende R-Pakete benötigt: library(tidyverse) library(tidymodels) library(tictoc) # Rechenzeit messen library(lubridate) # Datumsangaben library(VIM) # fehlende Werte library(visdat) # Datensatz visualisieren 13.2 Was ist Kaggle? Kaggle, a subsidiary of Google LLC, is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges. Quelle Kaggle as AirBnB for Data Scientists?! 13.3 Fallstudie TMDB Wir bearbeiten hier die Fallstudie TMDB Box Office Prediction - Can you predict a movie’s worldwide box office revenue?, ein Kaggle-Prognosewettbewerb. Ziel ist es, genaue Vorhersagen zu machen, in diesem Fall für Filme. 13.3.1 Aufgabe Reichen Sie bei Kaggle eine Submission für die Fallstudie ein! Berichten Sie den Score! 13.3.2 Hinweise Sie müssen sich bei Kaggle ein Konto anlegen (kostenlos und anonym möglich); alternativ können Sie sich mit einem Google-Konto anmelden. Halten Sie das Modell so einfach wie möglich. Verwenden Sie als Algorithmus die lineare Regression ohne weitere Schnörkel. Logarithmieren Sie budget und revenue. Minimieren Sie die Vorverarbeitung (steps) so weit als möglich. Verwenden Sie tidymodels. Die Zielgröße ist revenue in Dollars; nicht in “Log-Dollars”. Sie müssen also rücktransformieren, wenn Sie revenue logarithmiert haben. 13.3.3 Daten Die Daten können Sie von der Kaggle-Projektseite beziehen oder so: d_train_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/train.csv&quot; d_test_path &lt;- &quot;https://raw.githubusercontent.com/sebastiansauer/Lehre/main/data/tmdb-box-office-prediction/test.csv&quot; d_train_raw &lt;- read_csv(d_train_path) d_test &lt;- read_csv(d_test_path) Mal einen Blick werfen: glimpse(d_train_raw) ## Rows: 3,000 ## Columns: 23 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1… ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 313576, &#39;name&#39;: &#39;Hot Tub Time Machine C… ## $ budget &lt;dbl&gt; 1.40e+07, 4.00e+07, 3.30e+06, 1.20e+06, 0.00e+00… ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 35, &#39;name&#39;: &#39;Comedy&#39;}]&quot;, &quot;[{&#39;id&#39;: 35, &#39;… ## $ homepage &lt;chr&gt; NA, NA, &quot;http://sonyclassics.com/whiplash/&quot;, &quot;ht… ## $ imdb_id &lt;chr&gt; &quot;tt2637294&quot;, &quot;tt0368933&quot;, &quot;tt2582802&quot;, &quot;tt182148… ## $ original_language &lt;chr&gt; &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, &quot;hi&quot;, &quot;ko&quot;, &quot;en&quot;, &quot;en&quot;, &quot;en&quot;, … ## $ original_title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Princess Diaries … ## $ overview &lt;chr&gt; &quot;When Lou, who has become the \\&quot;father of the In… ## $ popularity &lt;dbl&gt; 6.575393, 8.248895, 64.299990, 3.174936, 1.14807… ## $ poster_path &lt;chr&gt; &quot;/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg&quot;, &quot;/w9Z7A0GHEh… ## $ production_companies &lt;chr&gt; &quot;[{&#39;name&#39;: &#39;Paramount Pictures&#39;, &#39;id&#39;: 4}, {&#39;nam… ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;United States of… ## $ release_date &lt;chr&gt; &quot;2/20/15&quot;, &quot;8/6/04&quot;, &quot;10/10/14&quot;, &quot;3/9/12&quot;, &quot;2/5/… ## $ runtime &lt;dbl&gt; 93, 113, 105, 122, 118, 83, 92, 84, 100, 91, 119… ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;English&#39;}]&quot;, &quot;[{&#39;… ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, … ## $ tagline &lt;chr&gt; &quot;The Laws of Space and Time are About to be Viol… ## $ title &lt;chr&gt; &quot;Hot Tub Time Machine 2&quot;, &quot;The Princess Diaries … ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 4379, &#39;name&#39;: &#39;time travel&#39;}, {&#39;id&#39;: 96… ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 4, &#39;character&#39;: &#39;Lou&#39;, &#39;credit_id&#39;… ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;59ac067c92514107af02c8c8&#39;, &#39;dep… ## $ revenue &lt;dbl&gt; 12314651, 95149435, 13092000, 16000000, 3923970,… glimpse(d_test) ## Rows: 4,398 ## Columns: 22 ## $ id &lt;dbl&gt; 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, … ## $ belongs_to_collection &lt;chr&gt; &quot;[{&#39;id&#39;: 34055, &#39;name&#39;: &#39;Pokémon Collection&#39;, &#39;p… ## $ budget &lt;dbl&gt; 0.00e+00, 8.80e+04, 0.00e+00, 6.80e+06, 2.00e+06… ## $ genres &lt;chr&gt; &quot;[{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;id&#39;: 16, &#39;n… ## $ homepage &lt;chr&gt; &quot;http://www.pokemon.com/us/movies/movie-pokemon-… ## $ imdb_id &lt;chr&gt; &quot;tt1226251&quot;, &quot;tt0051380&quot;, &quot;tt0118556&quot;, &quot;tt125595… ## $ original_language &lt;chr&gt; &quot;ja&quot;, &quot;en&quot;, &quot;en&quot;, &quot;fr&quot;, &quot;en&quot;, &quot;en&quot;, &quot;de&quot;, &quot;en&quot;, … ## $ original_title &lt;chr&gt; &quot;ディアルガVSパルキアVSダークライ&quot;, &quot;Attack of t… ## $ overview &lt;chr&gt; &quot;Ash and friends (this time accompanied by newco… ## $ popularity &lt;dbl&gt; 3.851534, 3.559789, 8.085194, 8.596012, 3.217680… ## $ poster_path &lt;chr&gt; &quot;/tnftmLMemPLduW6MRyZE0ZUD19z.jpg&quot;, &quot;/9MgBNBqlH1… ## $ production_companies &lt;chr&gt; NA, &quot;[{&#39;name&#39;: &#39;Woolner Brothers Pictures Inc.&#39;,… ## $ production_countries &lt;chr&gt; &quot;[{&#39;iso_3166_1&#39;: &#39;JP&#39;, &#39;name&#39;: &#39;Japan&#39;}, {&#39;iso_3… ## $ release_date &lt;chr&gt; &quot;7/14/07&quot;, &quot;5/19/58&quot;, &quot;5/23/97&quot;, &quot;9/4/10&quot;, &quot;2/11… ## $ runtime &lt;dbl&gt; 90, 65, 100, 130, 92, 121, 119, 77, 120, 92, 88,… ## $ spoken_languages &lt;chr&gt; &quot;[{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;English&#39;}, {&#39;iso_… ## $ status &lt;chr&gt; &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, &quot;Released&quot;, … ## $ tagline &lt;chr&gt; &quot;Somewhere Between Time &amp; Space... A Legend Is B… ## $ title &lt;chr&gt; &quot;Pokémon: The Rise of Darkrai&quot;, &quot;Attack of the 5… ## $ Keywords &lt;chr&gt; &quot;[{&#39;id&#39;: 11451, &#39;name&#39;: &#39;pok√©mon&#39;}, {&#39;id&#39;: 1155… ## $ cast &lt;chr&gt; &quot;[{&#39;cast_id&#39;: 3, &#39;character&#39;: &#39;Tonio&#39;, &#39;credit_i… ## $ crew &lt;chr&gt; &quot;[{&#39;credit_id&#39;: &#39;52fe44e7c3a368484e03d683&#39;, &#39;dep… 13.3.4 Train-Set verschlanken Da wir aus Gründen der Einfachheit einige Spalten nicht berücksichtigen, entfernen wir diese Spalten, was die Größe des Datensatzes massiv reduziert. d_train &lt;- d_train_raw %&gt;% select(popularity, runtime, revenue, budget, release_date) 13.3.5 Datensatz kennenlernen library(visdat) vis_dat(d_train) 13.3.6 Fehlende Werte prüfen Welche Spalten haben viele fehlende Werte? vis_miss(d_train) Mit {VIM} kann man einen Datensatz gut auf fehlende Werte hin untersuchen: aggr(d_train) 13.4 Rezept 13.4.1 Rezept definieren rec1 &lt;- recipe(revenue ~ ., data = d_train) %&gt;% #update_role(all_predictors(), new_role = &quot;id&quot;) %&gt;% #update_role(popularity, runtime, revenue, budget, original_language) %&gt;% #update_role(revenue, new_role = &quot;outcome&quot;) %&gt;% step_mutate(budget = if_else(budget &lt; 10, 10, budget)) %&gt;% step_log(budget) %&gt;% step_mutate(release_date = mdy(release_date)) %&gt;% step_date(release_date, features = c(&quot;year&quot;, &quot;month&quot;), keep_original_cols = FALSE) %&gt;% step_impute_knn(all_predictors()) %&gt;% step_dummy(all_nominal()) rec1 ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Operations: ## ## Variable mutation for if_else(budget &lt; 10, 10, budget) ## Log transformation on budget ## Variable mutation for mdy(release_date) ## Date features from release_date ## K-nearest neighbor imputation for all_predictors() ## Dummy variables from all_nominal() tidy(rec1) ## # A tibble: 6 × 6 ## number operation type trained skip id ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 step mutate FALSE FALSE mutate_rkfzE ## 2 2 step log FALSE FALSE log_3uXxr ## 3 3 step mutate FALSE FALSE mutate_VTLOR ## 4 4 step date FALSE FALSE date_zDVcU ## 5 5 step impute_knn FALSE FALSE impute_knn_sT48O ## 6 6 step dummy FALSE FALSE dummy_KQs3c 13.4.2 Check das Rezept prep(rec1, verbose = TRUE) ## oper 1 step mutate [training] ## oper 2 step log [training] ## oper 3 step mutate [training] ## oper 4 step date [training] ## oper 5 step impute knn [training] ## oper 6 step dummy [training] ## The retained training set is ~ 0.38 Mb in memory. ## Recipe ## ## Inputs: ## ## role #variables ## outcome 1 ## predictor 4 ## ## Training data contained 3000 data points and 2 incomplete rows. ## ## Operations: ## ## Variable mutation for ~if_else(budget &lt; 10, 10, budget) [trained] ## Log transformation on budget [trained] ## Variable mutation for ~mdy(release_date) [trained] ## Date features from release_date [trained] ## K-nearest neighbor imputation for runtime, budget, release_date_year, release_da... [trained] ## Dummy variables from release_date_month [trained] prep(rec1) %&gt;% bake(new_data = NULL) ## # A tibble: 3,000 × 16 ## popularity runtime budget revenue release_date_year release_date_month_Feb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6.58 93 16.5 12314651 2015 1 ## 2 8.25 113 17.5 95149435 2004 0 ## 3 64.3 105 15.0 13092000 2014 0 ## 4 3.17 122 14.0 16000000 2012 0 ## 5 1.15 118 2.30 3923970 2009 1 ## 6 0.743 83 15.9 3261638 1987 0 ## 7 7.29 92 16.5 85446075 2012 0 ## 8 1.95 84 2.30 2586511 2004 0 ## 9 6.90 100 2.30 34327391 1996 1 ## 10 4.67 91 15.6 18750246 2003 0 ## # … with 2,990 more rows, and 10 more variables: release_date_month_Mar &lt;dbl&gt;, ## # release_date_month_Apr &lt;dbl&gt;, release_date_month_May &lt;dbl&gt;, ## # release_date_month_Jun &lt;dbl&gt;, release_date_month_Jul &lt;dbl&gt;, ## # release_date_month_Aug &lt;dbl&gt;, release_date_month_Sep &lt;dbl&gt;, ## # release_date_month_Oct &lt;dbl&gt;, release_date_month_Nov &lt;dbl&gt;, ## # release_date_month_Dec &lt;dbl&gt; Wir definieren eine Helper-Funktion: sum_isna &lt;- function(x) {sum(is.na(x))} Und wenden diese auf jede Spalte an: prep(rec1) %&gt;% bake(new_data = NULL) %&gt;% map_df(sum_isna) ## # A tibble: 1 × 16 ## popularity runtime budget revenue release_date_year release_date_month_Feb ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 0 0 0 0 0 ## # … with 10 more variables: release_date_month_Mar &lt;int&gt;, ## # release_date_month_Apr &lt;int&gt;, release_date_month_May &lt;int&gt;, ## # release_date_month_Jun &lt;int&gt;, release_date_month_Jul &lt;int&gt;, ## # release_date_month_Aug &lt;int&gt;, release_date_month_Sep &lt;int&gt;, ## # release_date_month_Oct &lt;int&gt;, release_date_month_Nov &lt;int&gt;, ## # release_date_month_Dec &lt;int&gt; Keine fehlenden Werte mehr in den Prädiktoren. Nach fehlenden Werten könnte man z.B. auch so suchen: datawizard::describe_distribution(d_train) 13.5 Variable | Mean | SD | IQR | Range | Skewness | Kurtosis | n | n_Missing popularity | 8.46 | 12.10 | 6.88 | [1.00e-06, 294.34] | 14.38 | 280.10 | 3000 | 0 runtime | 107.86 | 22.09 | 24.00 | [0.00, 338.00] | 1.02 | 8.19 | 2998 | 2 revenue | 6.67e+07 | 1.38e+08 | 6.66e+07 | [1.00, 1.52e+09] | 4.54 | 27.78 | 3000 | 0 budget | 2.25e+07 | 3.70e+07 | 2.90e+07 | [0.00, 3.80e+08] | 3.10 | 13.23 | 3000 | 0 So bekommt man gleich noch ein paar Infos über die Verteilung der Variablen. Praktische Sache. 13.5.1 Check Test-Sample Das Test-Sample backen wir auch mal. Wichtig: Wir preppen den Datensatz mit dem Train-Sample. bake(prep(rec1), new_data = d_test) %&gt;% head() ## # A tibble: 6 × 15 ## popularity runtime budget release_date_year release_date_mon… release_date_mo… ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3.85 90 2.30 2007 0 0 ## 2 3.56 65 11.4 2058 0 0 ## 3 8.09 100 2.30 1997 0 0 ## 4 8.60 130 15.7 2010 0 0 ## 5 3.22 92 14.5 2005 1 0 ## 6 8.68 121 2.30 1996 1 0 ## # … with 9 more variables: release_date_month_Apr &lt;dbl&gt;, ## # release_date_month_May &lt;dbl&gt;, release_date_month_Jun &lt;dbl&gt;, ## # release_date_month_Jul &lt;dbl&gt;, release_date_month_Aug &lt;dbl&gt;, ## # release_date_month_Sep &lt;dbl&gt;, release_date_month_Oct &lt;dbl&gt;, ## # release_date_month_Nov &lt;dbl&gt;, release_date_month_Dec &lt;dbl&gt; 13.6 Kreuzvalidierung cv_scheme &lt;- vfold_cv(d_train, v = 5, repeats = 3) 13.7 Modelle 13.7.1 Baum mod_tree &lt;- decision_tree(cost_complexity = tune(), tree_depth = tune(), mode = &quot;regression&quot;) 13.7.2 Random Forest doParallel::registerDoParallel() mod_rf &lt;- rand_forest(mtry = tune(), min_n = tune(), trees = 1000, mode = &quot;regression&quot;) %&gt;% set_engine(&quot;ranger&quot;, num.threads = 4) 13.7.3 XGBoost mod_boost &lt;- boost_tree(mtry = tune(), min_n = tune(), trees = tune()) %&gt;% set_engine(&quot;xgboost&quot;, nthreads = parallel::detectCores()) %&gt;% set_mode(&quot;regression&quot;) 13.7.4 LM mod_lm &lt;- linear_reg() 13.8 Workflows preproc &lt;- list(rec1 = rec1) models &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lm1 = mod_lm) all_workflows &lt;- workflow_set(preproc, models) 13.9 Fitten und tunen if (file.exists(&quot;objects/tmdb_model_set.rds&quot;)) { tmdb_model_set &lt;- read_rds(&quot;objects/tmdb_model_set.rds&quot;) } else { tic() tmdb_model_set &lt;- all_workflows %&gt;% workflow_map( resamples = cv_scheme, grid = 10, # metrics = metric_set(rmse), seed = 42, # reproducibility verbose = TRUE) toc() } Man kann sich das Ergebnisobjekt abspeichern, um künftig Rechenzeit zu sparen: write_rds(tmdb_model_set, &quot;objects/tmdb_model_set.rds&quot;) Professioneller ist der Ansatz mit dem R-Paket target. 13.10 Finalisieren 13.10.1 Welcher Algorithmus schneidet am besten ab? Genauer geagt, welches Modell, denn es ist ja nicht nur ein Algorithmus, sondern ein Algorithmus plus ein Rezept plus die Parameterinstatiierung plus ein spezifischer Datensatz. tune::autoplot(tmdb_model_set) + theme(legend.position = &quot;bottom&quot;) R-Quadrat ist nicht entscheidend; rmse ist wichtiger. Die Ergebnislage ist nicht ganz klar, aber einiges spricht für das Boosting-Modell, rec1_boost1. tmdb_model_set %&gt;% collect_metrics() %&gt;% arrange(-mean) %&gt;% head(10) ## # A tibble: 10 × 9 ## wflow_id .config preproc model .metric .estimator mean n std_err ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 rec1_lm1 Preprocess… recipe line… rmse standard 1.15e8 15 2.20e6 ## 2 rec1_tree1 Preprocess… recipe deci… rmse standard 1.12e8 15 2.67e6 ## 3 rec1_rf1 Preprocess… recipe rand… rmse standard 1.10e8 15 2.64e6 ## 4 rec1_tree1 Preprocess… recipe deci… rmse standard 9.46e7 15 2.30e6 ## 5 rec1_tree1 Preprocess… recipe deci… rmse standard 9.33e7 15 2.26e6 ## 6 rec1_boost1 Preprocess… recipe boos… rmse standard 9.30e7 15 1.91e6 ## 7 rec1_boost1 Preprocess… recipe boos… rmse standard 9.27e7 15 2.13e6 ## 8 rec1_tree1 Preprocess… recipe deci… rmse standard 9.21e7 15 1.91e6 ## 9 rec1_tree1 Preprocess… recipe deci… rmse standard 9.21e7 15 1.91e6 ## 10 rec1_boost1 Preprocess… recipe boos… rmse standard 9.21e7 15 1.73e6 best_model_params &lt;- extract_workflow_set_result(tmdb_model_set, &quot;rec1_boost1&quot;) %&gt;% select_best() best_model_params ## # A tibble: 1 × 4 ## mtry trees min_n .config ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 6 100 4 Preprocessor1_Model04 best_wf &lt;- all_workflows %&gt;% extract_workflow(&quot;rec1_boost1&quot;) #best_wf best_wf_finalized &lt;- best_wf %&gt;% finalize_workflow(best_model_params) best_wf_finalized ## ══ Workflow ════════════════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_mutate() ## • step_date() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## Boosted Tree Model Specification (regression) ## ## Main Arguments: ## mtry = 6 ## trees = 100 ## min_n = 4 ## ## Engine-Specific Arguments: ## nthreads = parallel::detectCores() ## ## Computational engine: xgboost 13.10.2 Final Fit fit_final &lt;- best_wf_finalized %&gt;% fit(d_train) ## [16:19:46] WARNING: amalgamation/../src/learner.cc:576: ## Parameters: { &quot;nthreads&quot; } might not be used. ## ## This could be a false alarm, with some parameters getting used by language bindings but ## then being mistakenly passed down to XGBoost core, or some parameter actually being used ## but getting flagged wrongly here. Please open an issue if you find any such cases. fit_final ## ══ Workflow [trained] ══════════════════════════════════════════════════════════ ## Preprocessor: Recipe ## Model: boost_tree() ## ## ── Preprocessor ──────────────────────────────────────────────────────────────── ## 6 Recipe Steps ## ## • step_mutate() ## • step_log() ## • step_mutate() ## • step_date() ## • step_impute_knn() ## • step_dummy() ## ## ── Model ─────────────────────────────────────────────────────────────────────── ## ##### xgb.Booster ## raw: 345.4 Kb ## call: ## xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, ## colsample_bytree = 1, colsample_bynode = 0.4, min_child_weight = 4L, ## subsample = 1, objective = &quot;reg:squarederror&quot;), data = x$data, ## nrounds = 100L, watchlist = x$watchlist, verbose = 0, nthreads = 8L, ## nthread = 1) ## params (as set within xgb.train): ## eta = &quot;0.3&quot;, max_depth = &quot;6&quot;, gamma = &quot;0&quot;, colsample_bytree = &quot;1&quot;, colsample_bynode = &quot;0.4&quot;, min_child_weight = &quot;4&quot;, subsample = &quot;1&quot;, objective = &quot;reg:squarederror&quot;, nthreads = &quot;8&quot;, nthread = &quot;1&quot;, validate_parameters = &quot;TRUE&quot; ## xgb.attributes: ## niter ## callbacks: ## cb.evaluation.log() ## # of features: 15 ## niter: 100 ## nfeatures : 15 ## evaluation_log: ## iter training_rmse ## 1 123316256 ## 2 109626432 ## --- ## 99 28311248 ## 100 28190966 d_test$revenue &lt;- NA final_preds &lt;- fit_final %&gt;% predict(new_data = d_test) %&gt;% bind_cols(d_test) 13.11 Submission 13.11.1 Submission vorbereiten submission_df &lt;- final_preds %&gt;% select(id, revenue = .pred) Abspeichern und einreichen: write_csv(submission_df, file = &quot;objects/submission.csv&quot;) Diese CSV-Datei reichen wir dann bei Kagglei ein. 13.11.2 Kaggle Score Diese Submission erzielte einen Score von 4.79227 (RMSLE). 13.12 Aufgaben Arbeiten Sie sich so gut als möglich durch diese Analyse zum Verlauf von Covid-Fällen Fallstudie zur Modellierung einer logististischen Regression mit tidymodels Fallstudie zu Vulkanausbrüchen Fallstudie Himalaya 13.13 Vertiefung Fields arranged by purity, xkcd 435 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
