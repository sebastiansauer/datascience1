<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Kapitel 4 Grundkonzepte | DataScience1</title>
<meta name="author" content="Sebastian Sauer">
<meta name="description" content="4.1 Was ist Data Science? Es gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, and Horton (2017) definieren Data Science wie folgt (S. 4): The science of...">
<meta name="generator" content="bookdown 0.24.2 with bs4_book()">
<meta property="og:title" content="Kapitel 4 Grundkonzepte | DataScience1">
<meta property="og:type" content="book">
<meta property="og:description" content="4.1 Was ist Data Science? Es gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, and Horton (2017) definieren Data Science wie folgt (S. 4): The science of...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kapitel 4 Grundkonzepte | DataScience1">
<meta name="twitter:description" content="4.1 Was ist Data Science? Es gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens. Baumer, Kaplan, and Horton (2017) definieren Data Science wie folgt (S. 4): The science of...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script><script src="libs/es6shim-0.35.6/es6shim.js"></script><script src="libs/es7shim-6.0.0/es7shim.js"></script><script src="libs/graphre-0.1.3/graphre.js"></script><script src="libs/nomnoml-1.3.1/nomnoml.js"></script><script src="libs/nomnoml-binding-0.2.3/nomnoml.js"></script><script src="libs/d3-3.3.8/d3.min.js"></script><script src="libs/dagre-0.4.0/dagre-d3.min.js"></script><link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet">
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script><script src="libs/chromatography-0.1/chromatography.js"></script><script src="libs/DiagrammeR-binding-1.0.6.1/DiagrammeR.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="style-bs4.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Grundlagen der Prognosemodellierung üîÆüß∞">DataScience1</a>:
        <small class="text-muted">Grundlagen der Prognosemodellierung üîÆüß∞</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Zu diesem Buch</a></li>
<li><a class="" href="hinweise.html"><span class="header-section-number">1</span> Hinweise</a></li>
<li><a class="" href="modul%C3%BCberblick.html"><span class="header-section-number">2</span> Modul√ºberblick</a></li>
<li><a class="" href="pr%C3%BCfung.html"><span class="header-section-number">3</span> Pr√ºfung</a></li>
<li class="book-part">Themen</li>
<li><a class="active" href="grundkonzepte-1.html"><span class="header-section-number">4</span> Grundkonzepte</a></li>
<li><a class="" href="r-zweiter-blick.html"><span class="header-section-number">5</span> R, zweiter Blick</a></li>
<li><a class="" href="tidymodels-1.html"><span class="header-section-number">6</span> tidymodels 1</a></li>
<li><a class="" href="k-n%C3%A4chste-nachbarn.html"><span class="header-section-number">7</span> K-N√§chste-Nachbarn</a></li>
<li><a class="" href="tidymodels-2.html"><span class="header-section-number">8</span> tidymodels 2</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/sebastiansauer/datascience1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="grundkonzepte-1" class="section level1" number="4">
<h1>
<span class="header-section-number">Kapitel 4</span> Grundkonzepte<a class="anchor" aria-label="anchor" href="#grundkonzepte-1"><i class="fas fa-link"></i></a>
</h1>
<div id="was-ist-data-science" class="section level2" number="4.1">
<h2>
<span class="header-section-number">4.1</span> Was ist Data Science?<a class="anchor" aria-label="anchor" href="#was-ist-data-science"><i class="fas fa-link"></i></a>
</h2>
<p>Es gibt mehrere Definitionen von <em>Data Science</em>, aber keinen kompletten Konsens.
<span class="citation">Baumer, Kaplan, and Horton (<a href="references.html#ref-baumer_modern_2017" role="doc-biblioref">2017</a>)</span> definieren Data Science wie folgt (S. 4):</p>
<div class="infobox quote">
<p>The science of extracting meaningful information from data</p>
</div>
<p>Auf der anderen Seite entgegen viele Statistiker: ‚ÄúHey, das machen wir doch schon immer!‚Äù.</p>
<p>Eine Antwort auf diesen Einwand ist, dass in Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (‚ÄúDom√§ne‚Äù), die sozusagen den Empf√§nger bzw. die Kunden oder den Rahmen stellt.
Dieser ‚ÄúDreiklang‚Äù ist in folgendem Venn-Diagramm dargestellt.</p>
<script type="module" src="https://unpkg.com/venny?module"></script><p><venn-diagram><venn-set name="A" label="Statistik"></venn-set><venn-set name="B" label="Informatik"></venn-set><venn-set name="C" label="Dom√§ne" size="5"></venn-set><venn-n sets="A B C"></venn-n></venn-diagram></p>
</div>
<div id="was-ist-machine-learning" class="section level2" number="4.2">
<h2>
<span class="header-section-number">4.2</span> Was ist Machine Learning?<a class="anchor" aria-label="anchor" href="#was-ist-machine-learning"><i class="fas fa-link"></i></a>
</h2>
<p><em>Maschinelles Lernen</em> (ML), oft auch (synonym) als <em>statistisches Lernen</em> (statistical learning) bezeichnet, ist ein Teilgebiet der <em>k√ºnstlichen Intelligenz</em> (KI; artificial intelligence, AI) <span class="citation">(<a href="references.html#ref-rhys" role="doc-biblioref">Rhys 2020</a>)</span>. ML wird auch als <em>data-based</em> bezeichnet in Abgrenzung von <em>rule-based</em>, was auch als ‚Äúklassische KI‚Äù bezeichnet wird, vgl. Abb. <a href="grundkonzepte-1.html#fig:ai-ml2">4.1</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ai-ml2"></span>
<div id="htmlwidget-bc8a2715a2a83a0dfe22" style="width:100%;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-bc8a2715a2a83a0dfe22">{"x":{"diagram":"\ndigraph D {\n\n    node [fontname=\"Arial\"];\n\n    node_A [shape=record    label=\"{KI|{rule-based|data-based}}\"];\n\n\n}\n\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.1: KI und Maschinelles Lernen
</p>
</div>
<p>In beiden F√§llen finden Algorithmen Verwendung.
Algorithmen sind nichts anderes als genaue Schritt-f√ºr-Schritt-Anleitungen, um etwas zu erledigen.
Ein Kochrezept ist ein klassisches Beispiel f√ºr einen Algorithmus.</p>
<p><a href="https://www.c-programming-simple-steps.com/images/xsum-two-numbers-h.png.pagespeed.ic.AM9WYFPgEo.webp">Hier</a> findet sich ein Beispiel f√ºr einen einfachen Additionsalgorithmus.</p>
<p>Es gibt viele ML-Algorithmen, vgl. Abb. <a href="grundkonzepte-1.html#fig:algos">4.2</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:algos"></span>
<div id="htmlwidget-6d47debbacee864fe5a2" style="width:100%;height:350px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-6d47debbacee864fe5a2">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n#direction: leftright\n[KI|\n  [ML|\n    [Regression] \n    [Neuronale Netze] \n    [...]\n  ]  \n  \n]\n","svg":false},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.2: ML-Matroschka
</p>
</div>
<div id="rule-based" class="section level3" number="4.2.1">
<h3>
<span class="header-section-number">4.2.1</span> Rule-based<a class="anchor" aria-label="anchor" href="#rule-based"><i class="fas fa-link"></i></a>
</h3>
<p>Klassische (√§ltere) KI implementiert Regeln ‚Äúhartverdrahtet‚Äù in ein Computersystem.
Nutzer f√ºttern Daten in dieses System. Das System leitet dann daraus Antworten ab.</p>
<p><em>Regeln</em> kann man prototypisch mit <em>Wenn-Dann-Abfragen</em> darstellen:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">lernzeit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">20</span><span class="op">)</span>
<span class="va">schlauer_nebensitzer</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span><span class="op">)</span>

<span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span> <span class="op">{</span>
  <span class="kw">if</span> <span class="op">(</span><span class="va">lernzeit</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">&gt;</span> <span class="fl">10</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"bestanden!"</span><span class="op">)</span>
  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
    <span class="kw">if</span> <span class="op">(</span><span class="va">schlauer_nebensitzer</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">==</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">{</span>
      <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"bestanden!"</span><span class="op">)</span>
    <span class="op">}</span> <span class="kw">else</span> <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="st">"Durchgefallen!"</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<pre><code>## [1] "Durchgefallen!"
## [1] "Durchgefallen!"
## [1] "bestanden!"
## [1] "bestanden!"</code></pre>
<p>Sicherlich k√∂nnte man das schlauer programmieren, vielleicht so:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">d</span> <span class="op">&lt;-</span> 
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>
  lernzeit <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">20</span><span class="op">)</span>,
  schlauer_nebensitzer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">FALSE</span>, <span class="cn">FALSE</span>, <span class="cn">TRUE</span>, <span class="cn">TRUE</span><span class="op">)</span>
<span class="op">)</span>

<span class="va">d</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>bestanden <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">lernzeit</span> <span class="op">&gt;</span> <span class="fl">10</span> <span class="op">|</span> <span class="va">schlauer_nebensitzer</span> <span class="op">==</span> <span class="cn">TRUE</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 4 √ó 3
##   lernzeit schlauer_nebensitzer bestanden
##      &lt;dbl&gt; &lt;lgl&gt;                &lt;lgl&gt;    
## 1        0 FALSE                FALSE    
## 2       10 FALSE                FALSE    
## 3       10 TRUE                 TRUE     
## 4       20 TRUE                 TRUE</code></pre>
</div>
<div id="data-based" class="section level3" number="4.2.2">
<h3>
<span class="header-section-number">4.2.2</span> Data-based<a class="anchor" aria-label="anchor" href="#data-based"><i class="fas fa-link"></i></a>
</h3>
<p>ML hat zum Ziel, Regeln aus den Daten zu lernen. Man f√ºttert Daten und Antworten in das System, das System gibt Regeln zur√ºck.</p>
<p><span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span> definieren ML so:
Nehmen wir an, wir haben die abh√§ngige Variable <span class="math inline">\(Y\)</span> und <span class="math inline">\(p\)</span> Pr√§diktoren, <span class="math inline">\(X_1,X_2, \ldots, X_p\)</span>.
Weiter nehmen wir an, die Beziehung zwischen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X = (X_1, X_2, \ldots, X_p)\)</span> kann durch eine Funktion <span class="math inline">\(f\)</span> beschrieben werden.
Das kann man so darstellen:</p>
<p><span class="math display">\[Y = f(X) + \epsilon\]</span></p>
<p>ML kann man auffassen als eine Menge an Verfahren, um <span class="math inline">\(f\)</span> zu sch√§tzen.</p>
<p>Ein Beispiel ist in Abb. <a href="grundkonzepte-1.html#fig:statlearning">4.3</a> gezeigt <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:statlearning"></span>
<img src="img/2-2.png" alt="Vorhersage des Einkommens durch Ausbildungsjahre" width="50%"><p class="caption">
Figure 4.3: Vorhersage des Einkommens durch Ausbildungsjahre
</p>
</div>
<p>Nat√ºrlich kann <span class="math inline">\(X\)</span> mehr als eine Variable beinhalten, vgl. Abb. <a href="grundkonzepte-1.html#fig:sl2">4.4</a> <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:sl2"></span>
<img src="img/2-3.png" alt="Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren" width="100%"><p class="caption">
Figure 4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren
</p>
</div>
<!-- ```{nomnoml, echo = FALSE} -->
<!-- #direction: leftright -->
<!-- #fontSize: 8 -->
<!-- #arrowSize: 1 -->
<!-- #bendSize: 0.3 -->
<!-- #edges: rounded -->
<!-- #stroke: #123456 -->
<!--   [rule-based| -->
<!--   [Daten] -> [Antworten] -->
<!--   [Regeln] -> [Antworten] -->
<!-- ] -->
<!--   [data-based| -->
<!--   [Daten] -> [Regeln] -->
<!--   [Antworten] -> [Regeln] -->
<!-- ] -->
<!-- ``` -->
<p>Anders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gef√ºttert und liefern Antworten.
ML-Systeme werden mit Daten und Antworten gef√ºttert und liefern Regeln zur√ºck, vgl. Abb. <a href="grundkonzepte-1.html#fig:ki-ml2">4.5</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ki-ml2"></span>
<div id="htmlwidget-0a4197c1f7e7e4d09ae0" style="width:100%;height:450px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-0a4197c1f7e7e4d09ae0">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n#direction: leftright\n  [rule-based|\n  [Daten] -> [Antworten]\n  [Regeln] -> [Antworten]\n]\n  [data-based|\n  [Daten] -> [Regeln]\n  [Antworten] -> [Regeln]\n]  \n  ","svg":false},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.5: Vergleich von klassischer KI und ML
</p>
</div>
</div>
</div>
<div id="modell-vs.-algorithmus" class="section level2" number="4.3">
<h2>
<span class="header-section-number">4.3</span> Modell vs.¬†Algorithmus<a class="anchor" aria-label="anchor" href="#modell-vs.-algorithmus"><i class="fas fa-link"></i></a>
</h2>
<div id="modell" class="section level3" number="4.3.1">
<h3>
<span class="header-section-number">4.3.1</span> Modell<a class="anchor" aria-label="anchor" href="#modell"><i class="fas fa-link"></i></a>
</h3>
<p>Ein Modell, s. Abb. <a href="grundkonzepte-1.html#fig:vw">4.6</a> <span class="citation">(<a href="references.html#ref-spurzem_vw_2017" role="doc-biblioref">Spurzem 2017</a>)</span>!</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:vw"></span>
<img src="img/vw_modell.JPG" alt="Ein Modell-Auto" width="33%"><p class="caption">
Figure 4.6: Ein Modell-Auto
</p>
</div>
<p>Wie man sieht, ist ein Modell eine vereinfachte Repr√§sentation eines Gegenstands.</p>
<p>Der Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. <a href="grundkonzepte-1.html#fig:modell">4.7</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:modell"></span>
<img src="img/Modell-crop.png" alt="Gegenstand und Modell" width="100%"><p class="caption">
Figure 4.7: Gegenstand und Modell
</p>
</div>
<p>Im maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln,
die aus den Daten gelernt wurden.</p>
</div>
<div id="beispiel-f√ºr-einen-ml-algorithmus" class="section level3" number="4.3.2">
<h3>
<span class="header-section-number">4.3.2</span> Beispiel f√ºr einen ML-Algorithmus<a class="anchor" aria-label="anchor" href="#beispiel-f%C3%BCr-einen-ml-algorithmus"><i class="fas fa-link"></i></a>
</h3>
<p>Unter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren,
anhand dessen die Beziehung zwischen <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> ‚Äúgelernt‚Äù wird. Bei <span class="citation">Rhys (<a href="references.html#ref-rhys" role="doc-biblioref">2020</a>)</span> (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa so lautet:</p>
<p><em>Beispiel eines Regressionsalgorithmus</em></p>
<ol style="list-style-type: decimal">
<li>Setze Gerade in die Daten mit <span class="math inline">\(b_0 = \hat{y}, b_1 = 0\)</span>
</li>
<li>Berechne <span class="math inline">\(MSS = \sum (y_i - \hat{y_i})^2\)</span>
</li>
<li>‚ÄúDrehe‚Äù die Gerade ein bisschen, d.h. erh√∂he <span class="math inline">\(b_1^{neu} = b_1^{alt} + 0.1\)</span>
</li>
<li>Wiederhole 2-3 solange, bis <span class="math inline">\(MSS &lt; \text{Zielwert}\)</span>
</li>
</ol>
<p>Diesen Algorithmus kann man ‚Äúvon Hand‚Äù z.B. mit <a href="https://shinyapps.org/showapp.php?app=https://shiny.psy.lmu.de/felix/lmfit&amp;by=Felix%20Sch%C3%B6nbrodt&amp;title=Find-a-fit!&amp;shorttitle=Find-a-fit!">dieser App</a> durchspielen.</p>
</div>
</div>
<div id="taxonomie" class="section level2" number="4.4">
<h2>
<span class="header-section-number">4.4</span> Taxonomie<a class="anchor" aria-label="anchor" href="#taxonomie"><i class="fas fa-link"></i></a>
</h2>
<p>Methoden des maschinellen Lernens lassen sich verschiedentlich gliedern.
Eine typische Gliederung unterscheidet in <em>supervidierte</em> (geleitete) und <em>nicht-supervidierte</em> (ungeleitete) Algorithmen, s. Abb. <a href="grundkonzepte-1.html#fig:taxonomie">4.8</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:taxonomie"></span>
<div id="htmlwidget-949208c271c836204832" style="width:100%;height:250px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-949208c271c836204832">{"x":{"diagram":"\ngraph LR\n  ML[Maschinelles Lernen]\n  SL[Supervidiertes Lernen]\n  NSL[Nicht-supervidiertes Lernen]\n  Re[Regression]\n  Class[Klassifikation]\n  DimRed[Dimensionsreduktion]\n  Clust[Clustering]\n  ML --> SL\n  ML --> NSL\n  SL --> Re\n  SL --> Class\n  NSL --> DimRed\n  NSL --> Clust\n"},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.8: Taxonomie der Arten des maschinellen Lernens
</p>
</div>
<div id="geleitetes-lernen" class="section level3" number="4.4.1">
<h3>
<span class="header-section-number">4.4.1</span> Geleitetes Lernen<a class="anchor" aria-label="anchor" href="#geleitetes-lernen"><i class="fas fa-link"></i></a>
</h3>
<p>Die zwei Phasen des geleiteten Lernens sind in Abb. <a href="grundkonzepte-1.html#fig:supervid">4.9</a> dargestellt.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:supervid"></span>
<div id="htmlwidget-7d243b95a968d916c292" style="width:100%;height:550px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-7d243b95a968d916c292">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n\n\n[Lernphase|\n[Daten mit Antwort] -> [Geleiteter Algorithmus]\n[Geleiteter Algorithmus] -> [Modell]\n]\n\n[Vorhersagephase|\n[Neue Daten, ohne Antwort] -> [Modell]\n[Modell] -> [Antworten]\n]\n\n","svg":false},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.9: Geleitetes Lernen geschieht in zwei Phasen
</p>
</div>
<div id="regression-numerische-vorhersage" class="section level4" number="4.4.1.1">
<h4>
<span class="header-section-number">4.4.1.1</span> Regression: Numerische Vorhersage<a class="anchor" aria-label="anchor" href="#regression-numerische-vorhersage"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="chunk-img/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Die Modellg√ºte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden <em>G√ºtekoeffizienten</em> gemessen:</p>
<ul>
<li>Mean Squared Error (Mittlerer Quadratfehler):</li>
</ul>
<p><span class="math display">\[MSE := \frac{1}{n} \sum (y_i - \hat{y}_i)^2\]</span></p>
<ul>
<li>Mean Absolute Error (Mittlerer Absolutfehler):</li>
</ul>
<p><span class="math display">\[MAE :=  \frac{1}{n} \sum |(y_i - \hat{y}_i)|\]</span></p>
<div class="infobox caution">
<p>Wir sind nicht adaran interessiert die Vorhersagegenauigkeit in den bekannten Daten einzusch√§tzen, sondern im Hinblick auf neue Daten, die in der Lernphase dem Modell nicht bekannt waren.</p>
</div>
</div>
<div id="klassifikation-nominale-vorhersage" class="section level4" number="4.4.1.2">
<h4>
<span class="header-section-number">4.4.1.2</span> Klassifikation: Nominale Vorhersage<a class="anchor" aria-label="anchor" href="#klassifikation-nominale-vorhersage"><i class="fas fa-link"></i></a>
</h4>
<div class="inline-figure"><img src="img/aktien-plot-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Die Modellg√ºte eines numerischen Vorhersagemodells wird oft mit folgendem <em>G√ºtekoeffizienten</em> gemessen:</p>
<ul>
<li>Mittlerer Klassifikationfehler <span class="math inline">\(e\)</span>:</li>
</ul>
<p><span class="math display">\[e := \frac{1}{n} I(y_i \ne \hat{y}_i) \]</span></p>
<p>Dabei ist <span class="math inline">\(I\)</span> eine Indikatorfunktion, die <code>1</code> zur√ºckliefert,
wenn tats√§chlicher Wert und vorhergesagter Wert identisch sind.</p>
</div>
</div>
<div id="ungeleitetes-lernen" class="section level3" number="4.4.2">
<h3>
<span class="header-section-number">4.4.2</span> Ungeleitetes Lernen<a class="anchor" aria-label="anchor" href="#ungeleitetes-lernen"><i class="fas fa-link"></i></a>
</h3>
<p>Die zwei Phasen des ungeleiteten Lernens sind in Abb. <a href="grundkonzepte-1.html#fig:unsuper">4.10</a> dargestellt.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unsuper"></span>
<div id="htmlwidget-5b86251d50e2af3eb439" style="width:100%;height:450px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-5b86251d50e2af3eb439">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n\n\n[Lernphase|\n[Daten ohne Antwort] -> [Ungeleiteter Algorithmus]\n[Ungeleiteter Algorithmus] -> [Modell]\n]\n\n[Vorhersagephase|\n[Neue Daten, ohne Antwort] -> [Modell]\n[Modell] -> [Zuordnung zu den Regeln des Modells]\n]\n\n","svg":false},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.10: Die zwei Phasen des ungeleiteten Lernens
</p>
</div>
<p>Ungeleitetes Lernen kann man wiederum in zwei Arten unterteilen, vgl. Abb. <a href="grundkonzepte-1.html#fig:ungel">4.11</a>:</p>
<ol style="list-style-type: decimal">
<li>Fallreduzierendes Modellieren (Clustering)</li>
<li>Dimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)</li>
</ol>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ungel"></span>
<img src="img/ungeleitetes_Modellieren_crop.png" alt="Zwei Arten von ungeleitetem Modellieren" width="100%"><p class="caption">
Figure 4.11: Zwei Arten von ungeleitetem Modellieren
</p>
</div>
</div>
</div>
<div id="ziele-des-ml" class="section level2" number="4.5">
<h2>
<span class="header-section-number">4.5</span> Ziele des ML<a class="anchor" aria-label="anchor" href="#ziele-des-ml"><i class="fas fa-link"></i></a>
</h2>
<p>Man kann vier Ziele des ML unterscheiden, s. Abb. <a href="grundkonzepte-1.html#fig:ziele">4.12</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ziele"></span>
<div id="htmlwidget-49fb558c38ddac9b5e29" style="width:100%;height:350px;" class="DiagrammeR html-widget"></div>
<script type="application/json" data-for="htmlwidget-49fb558c38ddac9b5e29">{"x":{"diagram":"\ngraph TD\n  ML[Maschinelles Lernen]\n  V[Vorhersage]\n  E[Erkl√§rung/kausal]\n  B[Beschreibung]\n  DimRed[Dimensionsreduktion]\n  ML --> V\n  ML --> E\n  ML --> B\n  ML --> DimRed\n"},"evals":[],"jsHooks":[]}</script><p class="caption">
Figure 4.12: Ziele des maschinellen Lernens
</p>
</div>
<p><em>Vorhersage</em> bezieht sich auf die Sch√§tzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit).
<em>Erkl√§rung</em> meint die kausale Analyse von Zusammenh√§ngen.
<em>Beschreibung</em> ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken.
<em>Dimensionsreduktion</em> ist ein Oberbegriff f√ºr Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.s</p>
<p>Wie ‚Äúgut‚Äù ein Modell ist, quantifiziert man in verschiedenen Kennzahlen; man spricht von Modellg√ºte oder <em>model fit</em>.
Je schlechter die Modellg√ºte, desto h√∂her der <em>Modellfehler</em>, vgl. Abb. <a href="grundkonzepte-1.html#fig:resid">4.13</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:resid"></span>
<img src="img/resids-plot-1.png" alt="Wenig (links) vs. viel (rechts) Vorhersagefehler" width="100%"><p class="caption">
Figure 4.13: Wenig (links) vs.¬†viel (rechts) Vorhersagefehler
</p>
</div>
<p>Die Modellg√ºte eines Modells ist nur relevant f√ºr <em>neue Beobachtungen</em>,
an denen das Modell nicht trainiert wurde.</p>
</div>
<div id="√ºber--vs.-unteranpassung" class="section level2" number="4.6">
<h2>
<span class="header-section-number">4.6</span> √úber- vs.¬†Unteranpassung<a class="anchor" aria-label="anchor" href="#%C3%BCber--vs.-unteranpassung"><i class="fas fa-link"></i></a>
</h2>
<p><em>Overfitting</em>: Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als ‚Äúbare M√ºnze‚Äù, also f√§lschlich als Signal. Solche Modelle haben zu viel <em>Varianz</em> in ihren Vorhersagen.</p>
<p><em>Underfitting</em>: Ein Modell ist zu simpel (ungenau, grobk√∂rnig) - es unterschl√§gt Nuancen des tats√§chlichen Musters. Solche Modelle haben zu viel <em>Verzerrung</em> (Bias) in ihren Vorhersagen.</p>
<p>Welches der folgenden Modelle (B,C,D) passt am besten zu den Daten (A), s. Abb. <a href="grundkonzepte-1.html#fig:overunder">4.14</a>, vgl. <span class="citation">(<a href="references.html#ref-modar" role="doc-biblioref">Sauer 2019</a>)</span>, Kap. 15.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:overunder"></span>
<img src="img/overfitting-4-plots-1.png" alt="Over- vs. Underfitting" width="100%"><p class="caption">
Figure 4.14: Over- vs.¬†Underfitting
</p>
</div>
<p>Welches Modell wird wohl neue Daten am besten vorhersagen? Was meinen Sie?</p>
<p>Modell D zeigt sehr gute Beschreibung (‚ÄúRetrodiktion‚Äù) der Werte, anhand derer das Modell trainiert wurde (‚ÄúTrainingsstichprobe‚Äù).
Wird es aber ‚Äúehrlich‚Äù getestet, d.h. anhand neuer Daten (‚ÄúTest-Stichprobe‚Äù),
wird es vermutlich <em>nicht</em> so gut abschneiden.</p>
<p>Es gilt, ein Modell mit ‚Äúmittlerer‚Äù Komplexit√§t zu finden, um √úber- und Unteranpassung in Grenzen zu halten.
Leider ist es nicht m√∂glich, vorab zu sagen, was der richtige, ‚Äúmittlere‚Äù Wert an Komplexit√§t eines Modells ist, vgl. Abb. <a href="grundkonzepte-1.html#fig:overfitting">4.15</a> aus <span class="citation">(<a href="references.html#ref-modar" role="doc-biblioref">Sauer 2019</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:overfitting"></span>
<img src="img/overfitting-crop.png" alt="Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte" width="100%"><p class="caption">
Figure 4.15: Mittlere Modellkomplexit√§t f√ºhrt zur besten Vorhersageg√ºte
</p>
</div>
</div>
<div id="no-free-lunch" class="section level2" number="4.7">
<h2>
<span class="header-section-number">4.7</span> No free lunch<a class="anchor" aria-label="anchor" href="#no-free-lunch"><i class="fas fa-link"></i></a>
</h2>
<a href="https://imgflip.com/i/687izk"><img src="https://i.imgflip.com/687izk.jpg" height="400" title="made at imgflip.com"></a>
<div>
<a href="https://imgflip.com/memegenerator">from Imgflip Meme Generator</a>
</div>
<p>Wenn <span class="math inline">\(f\)</span> (die Beziehung zwischen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span>, auch <em>datengenerierender Prozess</em> genannt) linear oder fast linear ist,
dann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. <a href="grundkonzepte-1.html#fig:2-10">4.16</a> aus <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span>, dort zeigt die schwarze Linie den ‚Äúwahren Zusammenhang‚Äù, also <span class="math inline">\(f\)</span> an. In orange sieht man ein lineares Modell, in gr√ºn ein hoch komplexes Modell,
das sich in einer ‚Äúwackligen‚Äù Funktion - also mit hoher Varianz -
niederschl√§gt. Das gr√ºne Modell k√∂nnte z.B. ein Polynom-Modell hohen Grades sein, z. B.
<span class="math inline">\(y = b_0 + b_1 x^{10} + b_2 x^9 + \ldots + b_11 x^1 + \epsilon\)</span>.
Das lineare Modell hat hingegen wenig Varianz und in diesem Fall wenig Bias.
Daher ist es f√ºr dieses <span class="math inline">\(f\)</span> gut passend.
Die gr√ºne Funktion zeigt dagegen √úberanpassung (overfitting),
also viel Modellfehler (f√ºr eine Test-Stichprobe).</p>
<div class="infobox caution">
<p>Die gr√ºne Funktion in Abb. <a href="grundkonzepte-1.html#fig:2-10">4.16</a> wird neue, beim Modelltraining unbekannte Beobachtungen (<span class="math inline">\(y_0\)</span>) vergleichsweise schlecht vorhersagen. In Abb. <a href="grundkonzepte-1.html#fig:2-11">4.17</a> ist es umgekehrt.</p>
</div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:2-10"></span>
<img src="img/2-10.png" alt="Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren." width="100%"><p class="caption">
Figure 4.16: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird in einem h√∂heren Vorhersagefehler (bei neuen Daten!) resultieren.
</p>
</div>
<p>Betrachten wir im Gegensatz dazu Abb. <a href="grundkonzepte-1.html#fig:2-11">4.17</a> aus <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span>, die (in schwarz) eine hochgradig <em>nichtlineare</em> Funktion <span class="math inline">\(f\)</span> zeigt.
Entsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel.
Ein lineares Modell wird der Komplexit√§t von <span class="math inline">\(f\)</span> nicht gerecht,
Unteranpassung (underfitting) liegt vor.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:2-11"></span>
<img src="img/2-11.png" alt="Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung." width="100%"><p class="caption">
Figure 4.17: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung.
</p>
</div>
</div>
<div id="bias-varianz-abw√§gung" class="section level2" number="4.8">
<h2>
<span class="header-section-number">4.8</span> Bias-Varianz-Abw√§gung<a class="anchor" aria-label="anchor" href="#bias-varianz-abw%C3%A4gung"><i class="fas fa-link"></i></a>
</h2>
<p>Der Gesamtfehler <span class="math inline">\(E\)</span> des Modells ist die Summe dreier Terme:</p>
<p><span class="math display">\[E = (y - \hat{y}) = \text{Bias} + \text{Varianz} + \epsilon\]</span></p>
<p>Dabei meint <span class="math inline">\(\epsilon\)</span> den <em>nicht reduzierbaren Fehler</em>, z.B. weil dem Modell Informationen fehlen. So kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).</p>
<p>Bias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. Abb. <a href="grundkonzepte-1.html#fig:bias-var">4.18</a> aus <span class="citation">Sauer (<a href="references.html#ref-modar" role="doc-biblioref">2019</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bias-var"></span>
<img src="img/plot-bias-variance-1.png" alt="Abw√§ngung von Bias vs. Varianz" width="100%"><p class="caption">
Figure 4.18: Abw√§ngung von Bias vs.¬†Varianz
</p>
</div>
<!-- ## Aufgaben -->
</div>
<div id="aufgaben-5" class="section level2" number="4.9">
<h2>
<span class="header-section-number">4.9</span> Aufgaben<a class="anchor" aria-label="anchor" href="#aufgaben-5"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://www.kaggle.com/">Machen Sie sich mit ‚ÄòKaggle‚Äô vertraut</a></li>
<li><a href="https://www.kaggle.com/code/headsortails/tidy-titarnic/report">Bearbeiten Sie die Fallstudie ‚ÄòTitaRnic‚Äô auf Kaggle</a></li>
</ul>
<!-- ## Vertiefung -->
</div>
<div id="vertiefung-5" class="section level2" number="4.10">
<h2>
<span class="header-section-number">4.10</span> Vertiefung<a class="anchor" aria-label="anchor" href="#vertiefung-5"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://www.zeit.de/arbeit/2020-10/data-scientist-gehalt-geldanlage-programmieren-kontoauszug">Verdienst einer deutschen Data Scientistin</a></li>
<li><a href="https://www.kaggle.com/micahshull/r-bike-sharing-linear-regression">Weitere Fallstudie zum Thema Regression auf Kaggle</a></li>
<li><a href="https://www.coursera.org/learn/data-science-course">Crashkurs Data Science (Coursera, Johns Hopkins University) mit ‚ÄòStar-Dozenten‚Äô</a></li>
<li><a href="https://www.kaggle.com/pranjalpandey12/performing-simple-linear-regression-in-r">Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle auf</a></li>
<li><a href="https://www.kaggle.com/lazaro97/data-preprocessing-and-linear-regression-with-r">Werfen Sie einen Blick in diese Fallstudie auf Kaggle zum Thema Hauspreise</a></li>
<li><a href="https://data-se.netlify.app/2021/03/10/fallstudie-modellierung-von-flugversp%C3%A4tungen/">Wiederholen Sie unser Vorgehen in der Fallstudie zu den Flugversp√§tungen</a></li>
</ul>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="pr%C3%BCfung.html"><span class="header-section-number">3</span> Pr√ºfung</a></div>
<div class="next"><a href="r-zweiter-blick.html"><span class="header-section-number">5</span> R, zweiter Blick</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#grundkonzepte-1"><span class="header-section-number">4</span> Grundkonzepte</a></li>
<li><a class="nav-link" href="#was-ist-data-science"><span class="header-section-number">4.1</span> Was ist Data Science?</a></li>
<li>
<a class="nav-link" href="#was-ist-machine-learning"><span class="header-section-number">4.2</span> Was ist Machine Learning?</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#rule-based"><span class="header-section-number">4.2.1</span> Rule-based</a></li>
<li><a class="nav-link" href="#data-based"><span class="header-section-number">4.2.2</span> Data-based</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#modell-vs.-algorithmus"><span class="header-section-number">4.3</span> Modell vs.¬†Algorithmus</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#modell"><span class="header-section-number">4.3.1</span> Modell</a></li>
<li><a class="nav-link" href="#beispiel-f%C3%BCr-einen-ml-algorithmus"><span class="header-section-number">4.3.2</span> Beispiel f√ºr einen ML-Algorithmus</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#taxonomie"><span class="header-section-number">4.4</span> Taxonomie</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#geleitetes-lernen"><span class="header-section-number">4.4.1</span> Geleitetes Lernen</a></li>
<li><a class="nav-link" href="#ungeleitetes-lernen"><span class="header-section-number">4.4.2</span> Ungeleitetes Lernen</a></li>
</ul>
</li>
<li><a class="nav-link" href="#ziele-des-ml"><span class="header-section-number">4.5</span> Ziele des ML</a></li>
<li><a class="nav-link" href="#%C3%BCber--vs.-unteranpassung"><span class="header-section-number">4.6</span> √úber- vs.¬†Unteranpassung</a></li>
<li><a class="nav-link" href="#no-free-lunch"><span class="header-section-number">4.7</span> No free lunch</a></li>
<li><a class="nav-link" href="#bias-varianz-abw%C3%A4gung"><span class="header-section-number">4.8</span> Bias-Varianz-Abw√§gung</a></li>
<li><a class="nav-link" href="#aufgaben-5"><span class="header-section-number">4.9</span> Aufgaben</a></li>
<li><a class="nav-link" href="#vertiefung-5"><span class="header-section-number">4.10</span> Vertiefung</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/sebastiansauer/datascience1/blob/master/040-Grundkonzepte.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/sebastiansauer/datascience1/edit/master/040-Grundkonzepte.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>DataScience1</strong>: Grundlagen der Prognosemodellierung üîÆüß∞" was written by Sebastian Sauer. It was last built on 2022-04-11 20:40:29.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
