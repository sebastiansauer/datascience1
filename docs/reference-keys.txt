fig:ai-ml2
fig:algos
fig:statlearning
fig:sl2
fig:ki-ml2
fig:vw
fig:modell
fig:taxonomie
fig:supervid
fig:unsuper
fig:ungel
fig:ziele
fig:resid
fig:overunder
fig:overfitting
fig:2-10
fig:2-11
fig:bias-var
fig:obs
fig:objtypes
fig:vektorenimzentrum
fig:langbreit
fig:funs
fig:map1
fig:tidymodels-def
fig:tidymodels-workflow
fig:slang
fig:cancer1
fig:cancer2
fig:cancer3
fig:cancer4
fig:cancer5
fig:pyth1
fig:pyth2
tab:class-stats
fig:process1
fig:resampling
fig:cvmodar
fig:cvrep
fig:repcvred
fig:initialsplit
fig:lln
fig:overfitting-4-plots
fig:nnoverfit
fig:tuning1
fig:logist-regr
tab:prof-logist
fig:m83-plot
fig:odds1
fig:odds2
fig:logit2
fig:rec-part2
fig:tree1
fig:recursive-part
fig:tree3
fig:tree-metr
fig:rechteck
fig:lunch
fig:zmz
fig:bag
fig:rf1
fig:comp-trees
fig:mtry
fig:stump
fig:ada
fig:boost
fig:ols
fig:l2-shrink
fig:lasso-l1
fig:l1l2
fig:l2-penalty
fig:l1-penalty
fig:bigpic
was-sie-hier-lernen-und-wozu-das-gut-ist
zitation
download-des-buches
technische-details
hinweise
lernziele
voraussetzungen
lernhilfen
software
videos
online-zusammenarbeit
modulzeitplan
literatur
faq
prüfung
prüfungleistung
tldr-zusammenfassung
vorhersage
hauptziel-genaue-prognose
zum-aufbau-ihrer-prognosedatei-im-csv-format
einzureichende-dateien
gliederung-ihrer-analyse
abschnitt-forschungsfrage-und-hintergrund
vorbereitung
explorative-datenanalyse
modellierung
vorhersagen
tipps
tipps-für-eine-gute-prognose
tipps-zur-datenverarbeitung
tipps-zum-aufbau-des-analyseskripts
sonstiges
bewertung
kriterien
kennzahl-der-modellgüte
notenstufen
bewertungsprozess
hinweise-1
formalia
ich-brauche-hilfe
wo-finde-ich-beispiele-und-vorlagen
materialsammlung
videos-1
plagiatskontrolle
statistisches-lernen
lernsteuerung
vorbereitung-1
lernziele-1
literatur-1
hinweise-2
was-ist-data-science
was-ist-machine-learning
rule-based
data-based
modell-vs.-algorithmus
modell
beispiel-für-einen-ml-algorithmus
taxonomie
geleitetes-lernen
regression-numerische-vorhersage
klassifikation-nominale-vorhersage
ungeleitetes-lernen
ziele-des-ml
über--vs.-unteranpassung
no-free-lunch
bias-varianz-abwägung
aufgaben
vertiefung
r-zweiter-blick
lernsteuerung-1
vorbereitung-2
lernziele-2
literatur-2
objekttypen-in-r
überblick
taxonomie-1
vektoren
faktoren
listen
tibbles
indizieren
reine-vektoren
listen-1
tibbles-1
weiterführende-hinweise
indizieren-mit-dem-tidyverse
datensätze-von-lang-nach-breit-umformatieren
funktionen
wiederholungen-programmieren
across
map
weiterführende-hinweise-1
listenspalten
wozu-listenspalten
beispiele-für-listenspalten
tidymodel
kurs-datascience1
programmieren-mit-dem-tidyverse
r-ist-schwierig
aufgaben-1
vertiefung-1
tidymodels
lernsteuerung-2
vorbereitung-3
lernziele-3
literatur-3
daten
train--vs-test-datensatz-aufteilen
grundlagen-der-modellierung-mit-tidymodels
modelle-spezifizieren
modelle-berechnen
vorhersagen-1
vorhersagen-im-train-datensatz
modellkoeffizienten-im-train-datensatz
parsnip-rstudio-add-in
workflows
konzept-des-workflows-in-tidymodels
einfaches-beispiel
vorhersage-mit-einem-workflow
modellgüte
vorhersage-von-hand
rezepte-zur-vorverarbeitung
was-ist-rezept-und-wozu-ist-es-gut
workflows-mit-rezepten
spaltenrollen
fazit
aufgaben-2
knn
lernsteuerung-3
lernziele-4
literatur-4
überblick-1
intuitive-erklärung
krebsdiagnostik
berechnung-der-nähe
knn-mit-tidymodels
analog-zu-timbers-et-al.
rezept-definieren
modell-definieren
workflow-definieren
vorhersagen-2
mit-train-test-aufteilung
rezept-definieren-1
modell-definieren-1
workflow-definieren-1
vorhersagen-3
modellgüte-1
visualisierung
kennzahlen-der-klassifikation
krebstest-beispiel
aufgaben-3
resampling-und-tuning
lernsteuerung-4
vorbereitung-4
lernziele-5
literatur-5
überblick-2
tidymodels-1
datensatz-aufteilen
rezept-modell-und-workflow-definieren
resampling
illustration-des-resampling
einfache-v-fache-kreuzvalidierung
wiederholte-kreuzvalidierung
resampling-passiert-im-train-sample
andere-illustrationen
gesetz-der-großen-zahl
über--und-unteranpassung-an-einem-beispiel
cv-in-tidymodels
cv-definieren
resamples-fitten
tuning
tuning-auszeichnen
grid-search-vs.-iterative-search
tuning-mit-tidymodels
tuningparameter-betrachten
datenabhängige-tuningparameter
modelle-mit-tuning-berechnen
vorhersage-im-test-sample
aufgaben-4
vertiefung-2
logistische-regression
lernsteuerung-5
vorbereitung-5
lernziele-6
literatur-6
intuitive-erklärung-1
profil
warum-nicht-die-lineare-regression-verwenden
lineare-modelle-running-wild
wir-müssen-die-regressionsgerade-umbiegen
verallgemeinerte-lineare-modelle-zur-rettung
der-logit-link
aber-warum
tidymodels-m83
lm83-glm
m83-tidymodels
wahrscheinlichkeit-in-odds
von-odds-zu-log-odds
inverser-logit
vom-logit-zur-klasse
grenzwert-wechseln
logit-und-inverser-logit
logit
inv-logit
logistische-regression-im-überblick
die-koeffizienten-sind-schwer-zu-interpretieren
logits-vs.-wahrscheinlichkeiten
aufgaben-5
vertiefung-3
entscheidungsbäume
vorbereitung-6
lernsteuerung-6
anatomie-eines-baumes
bäume-als-regelmaschinen-rekursiver-partionierung
klassifikation
gini-als-optimierungskriterium
metrische-prädiktoren
regressionbäume
baum-beschneiden
das-rechteck-schlägt-zurück
tidymodels-2
initiale-datenaufteilung
kreuzvalidierung-definieren
rezept-definieren-2
modell-definieren-2
workflow-definieren-2
modell-tunen-und-berechnen
modellgüte-evaluieren
bestes-modell-auswählen
final-fit
nur-zum-spaß-vergleich-mit-linearem-modell
ensemble-lerner
lernsteuerung-7
lernziele-7
literatur-7
hinweise-3
vorbereitung-7
hinweise-zur-literatur
wir-brauchen-einen-wald
was-ist-ein-ensemble-lerner
bagging
bootstrapping
bagging-algorithmus
variablenrelevanz
out-of-bag-vorhersagen
random-forests
boosting
adaboost
xgboost
tidymodels-3
datensatz-churn
data-splitting-und-cv
feature-engineering
modelle
workflows-1
modelle-berechnen-mit-tuning-einzeln
baum
rf
xgboost-1
workflow-set-tunen
ergebnisse-im-train-sest
bestes-modell
finalisisieren
last-fit
variablenrelevanz-1
roc-curve
aufgaben-6
aufgaben-7
vertiefung-4
regularisierte-modelle
lernsteuerung-8
lernziele-8
literatur-8
hinweise-4
vorbereitung-8
regularisierung
was-ist-regularisierung
ähnliche-verfahren
normale-regression-ols
ridge-regression-l2
strafterm
standardisierung
lasso-l1
strafterm-1
variablenselektion
l1-vs.-l2
wer-ist-stärker
elastic-net-als-kompromiss
aufgaben-8
kaggle
vorbereitung-9
lernsteuerung-9
lernziele-9
hinweise-5
r-pakete
was-ist-kaggle
fallstudie-tmdb
aufgabe
hinweise-6
daten-1
train-set-verschlanken
datensatz-kennenlernen
fehlende-werte-prüfen
rezept
rezept-definieren-3
check-das-rezept
check-test-sample
kreuzvalidierung
modelle-1
baum-1
random-forest
xgboost-2
lm
workflows-2
fitten-und-tunen
finalisieren
welcher-algorithmus-schneidet-am-besten-ab
final-fit-1
submission
submission-vorbereiten
kaggle-score
aufgaben-9
vertiefung-5
der-rote-faden
lernziele-10
literatur-9
aussichtspunkt-1-blick-vom-hohen-berg
aussichtspunkt-2-blick-in-den-hof-der-handwerker
ein-maximale-einfaches-werkstück-mit-tidymodels
ein-immer-noch-recht-einfaches-werkstück-mit-tidymodels
aussichtspunkt-3-der-nebelberg-quiz
aussichtspunkt-4-der-exerzitien-park
aussichtspunkt-5-in-der-bibliothek
krafttraining
aufgaben-10
vertiefung-6
fallstudien
lernziele-11
literatur-10
fallstudien-zur-explorativen-datenanalyse
fallstudien-zu-linearen-modellen
fallstudien-zum-maschinellen-lernen-mit-tidymodels
aufgaben-11
vertiefung-7
staunen-mit-e
lernsteuerung-10
lernziele-12
literatur-11
vorbereitung-10
staunen
exponenzielles-wachstum
sofortiges-wachstum
andere-wachstumsraten
wachstum-mit-basis-e
logarithmus
regel-der-72
