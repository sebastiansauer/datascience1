[{"path":"index.html","id":"zu-diesem-buch","chapter":"Zu diesem Buch","heading":"Zu diesem Buch","text":"Die URL zu diesem Buch lautet https://sebastiansauer.github.io/datascience1/ und ist bei GitHub Pages gehostet.Die URL zu diesem Buch lautet https://sebastiansauer.github.io/datascience1/ und ist bei GitHub Pages gehostet.Lesen Sie sich die folgenden Informationen bitte gut durch: HinweiseLesen Sie sich die folgenden Informationen bitte gut durch: HinweiseDen Quellcode finden Sie diesem Github-Repo.Den Quellcode finden Sie diesem Github-Repo.Sie haben Feedback, Fehlerhinweise oder Wünsche zur Weiterentwicklung? besten stellen Sie hier einen Issue ein.Sie haben Feedback, Fehlerhinweise oder Wünsche zur Weiterentwicklung? besten stellen Sie hier einen Issue ein.Dieses Projekt steht unter der MIT-Lizenz.Dieses Projekt steht unter der MIT-Lizenz.Dieses Buch wurde RStudio mit Hilfe von bookdown geschrieben.Dieses Buch wurde RStudio mit Hilfe von bookdown geschrieben.Diese Version des Buches wurd mit der R-Version R version 4.1.3 (2022-03-10) und den folgenden Paketen erstellt:Diese Version des Buches wurd mit der R-Version R version 4.1.3 (2022-03-10) und den folgenden Paketen erstellt:","code":""},{"path":"hinweise.html","id":"hinweise","chapter":"Kapitel 1 Hinweise","heading":"Kapitel 1 Hinweise","text":"","code":""},{"path":"hinweise.html","id":"was-sie-hier-lernen-und-wozu-das-gut-ist","chapter":"Kapitel 1 Hinweise","heading":"1.1 Was Sie hier lernen und wozu das gut ist","text":"Alle Welt spricht von Big Data, aber ohne die Analyse sind die großen Daten nur großes Rauschen. letztlich interessiert, sind die Erkenntnisse, die Einblicke, nicht die Daten sich.\nDabei ist es egal, ob die Daten groß oder klein sind.\nNatürlich erlauben die heutigen Datenmengen im Verbund mit leistungsfähigen Rechnern und neuen Analysemethoden ein Verständnis,\ndas vor Kurzem noch nicht möglich war.\nUnd wir stehen erst Anfang dieser Entwicklung.\nVielleicht handelt es sich bei diesem Feld um eines der dynamischsten Fachgebiete der heutigen Zeit.\nSie sind dabei: Sie lernen einiges Handwerkszeugs des “Datenwissenschaftlers”.\nWir konzentrieren uns auf das vielleicht bekannteste Teilgebiet:\nEreignisse vorhersagen auf Basis von hoch strukturierten Daten\nund geeigneter Algorithmen und Verfahren.\nNach diesem Kurs sollten Sie der Lage sein,\ntypisches Gebabbel des Fachgebiet mit Lässigkeit mitzumachen.\nAch ja, und mit einigem Erfolg Vorhersagemodelle entwickeln.","code":""},{"path":"hinweise.html","id":"lernziele","chapter":"Kapitel 1 Hinweise","heading":"1.2 Lernziele","text":"Nach diesem Kurs sollten Siegrundlegende Konzepte des statistischen Lernens verstehen und mit R anwenden könnengängige Prognose-Algorithmen kennen, Grundzügen verstehen und mit R anwenden könnendie Güte und Grenze von Prognosemodellen einschätzen können","code":""},{"path":"hinweise.html","id":"voraussetzungen","chapter":"Kapitel 1 Hinweise","heading":"1.3 Voraussetzungen","text":"Um von diesem Kurs besten zu profitieren,\nsollten Sie folgendes Wissen mitbringen:grundlegende Kenntnisse im Umgang mit R, möglichst auch mit dem tidyversegrundlegende Kenntnisse der deskriptiven Statistikgrundlegende Kenntnis der Regressionsanalyse","code":""},{"path":"hinweise.html","id":"lernhilfen","chapter":"Kapitel 1 Hinweise","heading":"1.4 Lernhilfen","text":"","code":""},{"path":"hinweise.html","id":"software","chapter":"Kapitel 1 Hinweise","heading":"1.4.1 Software","text":"Installieren Sie R und seine Freunde.Installieren Sie die folgende R-Pakete:\ntidyverse\ntidymodels\nweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)\ntidyversetidymodelsweitere Pakete werden im Unterricht bekannt gegeben (es schadet aber nichts, jetzt schon Pakete nach eigenem Ermessen zu installieren)R Syntax aus dem Unterricht findet sich im Github-Repo bzw. Ordner zum jeweiligen Semester.","code":""},{"path":"hinweise.html","id":"videos","chapter":"Kapitel 1 Hinweise","heading":"1.4.2 Videos","text":"Playlist zu den ThemenAuf dem YouTube-Kanal des Autors finden sich eine Reihe von Videos mit Bezug zum Inhalt dieses Buches.","code":""},{"path":"hinweise.html","id":"online-zusammenarbeit","chapter":"Kapitel 1 Hinweise","heading":"1.4.3 Online-Zusammenarbeit","text":"Hier finden Sie einige Werkzeuge,\ndie das Online-Zusammenarbeiten vereinfachen:Frag-Jetzt-Raum zum anonymen Fragen stellen während des Unterrichts. Der Keycode wird Ihnen vom Dozenten bereitgestellt.Padlet zum einfachen (und anonymen) Hochladen von Arbeitsergebnissen der Studentis im Unterricht. Wir nutzen es als eine Art Pinwand zum Sammeln von Arbeitsbeiträgen. Die Zugangsdaten stellt Ihnen der Dozent bereit.","code":""},{"path":"hinweise.html","id":"modulzeitplan","chapter":"Kapitel 1 Hinweise","heading":"1.5 Modulzeitplan","text":"","code":""},{"path":"hinweise.html","id":"literatur","chapter":"Kapitel 1 Hinweise","heading":"1.6 Literatur","text":"Zentrale Kursliteratur für die theoretischen Konzepte ist Rhys (2020).\nBitte prüfen Sie, ob das Buch einer Bibliothek verfügbar ist.\nDie praktische Umsetzung R basiert auf Silge Kuhn (2022) (dem “Tidymodels-Konzept”);\ndas Buch ist frei online verfügbar.\nEine theoretische Konzepte sind James et al. (2021) entnommen;\ndieser Text ist frei online verfügbar.\nJames et al. (2021) haben ein weithin renommiertes und sehr bekanntes Buch verfasst.\nEs ist allerdings etwas anspruchsvoller aus Rhys (2020),\ndaher steht es nicht im Fokus dieses Kurses,\naber einige Schwenker zu Inhalten von James et al. (2021) gibt es. Schauen Sie mal rein,\ndas Buch ist gut!einigen Punkten ist weiterhin Sauer (2019) hilfreich;\ndas Buch ist über SpringerLink Ihrer Hochschul-Bibliothek verfügbar. Eine gute Ergänzung ist das “Lab-Buch” von Hvitfeldt (2022).\ndem Buch wird das Lehrbuch James et al. (2021) Tidymodels-Konzepte übersetzt; durchaus nett!","code":""},{"path":"hinweise.html","id":"faq","chapter":"Kapitel 1 Hinweise","heading":"1.7 FAQ","text":"Folien\nFrage: Gibt es ein Folienskript?\nAntwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zugängliche Literatur gibt, dort gibt es ein Skript.\nFrage: Gibt es ein Folienskript?Antwort: Wo es einfache, gute Literatur gibt, gibt es kein Skript. Wo es keine gute oder keine einfach zugängliche Literatur gibt, dort gibt es ein Skript.Englisch\nIst die Literatur auf Englisch?\nJa. Allerdings ist die Literatur gut zugänglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca Wissenschaft und Wirtschaft. Ein solides Verständnis englischer (geschriebener) Sprache ist für eine gute Ausbildung unerlässlich. Zu dem sollte die Kursliteratur fachlich passende und gute Bücher umfassen; oft sind das englische Titel.\nIst die Literatur auf Englisch?Ja. Allerdings ist die Literatur gut zugänglich. Das Englisch ist nicht schwer. Bedenken Sie: Englisch ist die lingua franca Wissenschaft und Wirtschaft. Ein solides Verständnis englischer (geschriebener) Sprache ist für eine gute Ausbildung unerlässlich. Zu dem sollte die Kursliteratur fachlich passende und gute Bücher umfassen; oft sind das englische Titel.Anstrengend\nIst der Kurs sehr anstrengend, aufwändig?\nDer Kurs hat ein mittleres Anspruchsniveau.\nIst der Kurs sehr anstrengend, aufwändig?Der Kurs hat ein mittleres Anspruchsniveau.Mathe\nMuss man ein Mathe-Crack sein, um eine gute Note zu erreichen?\nNein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur , sie werden wenig Mathe darin finden.\nMuss man ein Mathe-Crack sein, um eine gute Note zu erreichen?Nein. Mathe steht nicht im Vordergrund. Schauen Sie sich die Literatur , sie werden wenig Mathe darin finden.Prüfungsliteratur\nWelche Literatur ist prüfungsrelevant?\nDie Prüfung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, der reines Wissen abgefragt wird.\nWelche Literatur ist prüfungsrelevant?Die Prüfung ist angewandt, z.B. ein Prognosewettbewerb. Es wird keine Klausur geben, der reines Wissen abgefragt wird.Nur R?\nWird nur R dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig.\nder Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit eingeräumt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen.\nWird nur R dem Kurs gelehrt? Andere Programmiersprachen sind doch auch wichtig.der Datenanalyse gibt es zwei zentrale Programmiersprachen, R und Python. Beide sind gut und beide werden viel verwendet. einer Grundausbildung sollte man sich auf eine Sprache begrenzen, da sonst den Sprachen zu viel Zeit eingeräumt werden muss. Wichtiger als eine zweite Programmiersprache zu lernen, mit der man nicht viel mehr kann als mit der ersten, ist es, die Inhalte des Fachs zu lernen.","code":""},{"path":"modulüberblick.html","id":"modulüberblick","chapter":"Kapitel 2 Modulüberblick","heading":"Kapitel 2 Modulüberblick","text":"","code":""},{"path":"modulüberblick.html","id":"modulzeitplan-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.1 Modulzeitplan","text":"","code":""},{"path":"modulüberblick.html","id":"beschreibung-der-themen","chapter":"Kapitel 2 Modulüberblick","heading":"2.2 Beschreibung der Themen","text":"","code":""},{"path":"modulüberblick.html","id":"grundkonzepte","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1 Grundkonzepte","text":"","code":""},{"path":"modulüberblick.html","id":"vorbereitung","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.1 Vorbereitung","text":"Lesen Sie die Hinweise zum Modul.Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.Lesen Sie die Literatur.","code":""},{"path":"modulüberblick.html","id":"lernziele-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.2 Lernziele","text":"Sie können erläutern, man unter statistischem Lernen versteht.Sie wissen, war Overfitting ist, wie es entsteht, und wie es vermieden werden kann.Sie kennen verschiedenen Arten von statistischem Lernen und können Algorithmen zu diesen Arten zuordnen.","code":""},{"path":"modulüberblick.html","id":"literatur-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.3 Literatur","text":"Rhys, Kap. 1evtl. Sauer, Kap. 15","code":""},{"path":"modulüberblick.html","id":"hinweise-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.4 Hinweise","text":"Bitte beachten Sie die Hinweise zum Präsenzunterricht und der Streamingoption.Bitte stellen Sie sicher, dass Sie einen einsatzbereiten Computer haben und dass die angegebene Software (aktueller Version) läuft.","code":""},{"path":"modulüberblick.html","id":"vertiefung","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.5 Vertiefung","text":"Verdienst einer deutschen Data ScientistinWeitere Fallstudie zum Thema Regression auf KaggleCrashkurs Data Science (Coursera, Johns Hopkins University) mit ‘Star-Dozenten’Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle aufWerfen Sie einen Blick diese Fallstudie auf Kaggle zum Thema HauspreiseWiederholen Sie unser Vorgehen der Fallstudie zu den Flugverspätungen","code":""},{"path":"modulüberblick.html","id":"aufgaben","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.1.6 Aufgaben","text":"Machen Sie sich mit ‘Kaggle’ vertrautBearbeiten Sie die Fallstudie ‘TitaRnic’ auf Kaggle","code":""},{"path":"modulüberblick.html","id":"r-2.-blick","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.2 R, 2. Blick","text":"","code":""},{"path":"modulüberblick.html","id":"vorbereitung-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.2.1 Vorbereitung","text":"Lesen Sie die Literatur.","code":""},{"path":"modulüberblick.html","id":"lernziele-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.2.2 Lernziele","text":"Sie können Funktionen, R schreiben.Sie können Datensätze vom Lang- und Breit-Format wechseln.Sie können Wiederholungsstrukturen wie Mapping-Funktionen anwenden.Sie können eine dplyr-Funktion auf mehrere Spalten gleichzeitig anwenden.","code":""},{"path":"modulüberblick.html","id":"literatur-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.2.3 Literatur","text":"Rhys, Kap. 2","code":""},{"path":"modulüberblick.html","id":"aufgaben-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.2.4 Aufgaben","text":"AufgabenLernen Sie Wiederholungsstrukturen mit ggplot","code":""},{"path":"modulüberblick.html","id":"r-2.-blick---fortsetzung","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.3 R, 2. Blick - Fortsetzung","text":"","code":""},{"path":"modulüberblick.html","id":"hinweise-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.3.1 Hinweise","text":"Fortsetzung der Inhalte des vorherigen Themas","code":""},{"path":"modulüberblick.html","id":"aufgaben-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.3.2 Aufgaben","text":"Fallstudie Flugverspätungen","code":""},{"path":"modulüberblick.html","id":"tidymodels-1.-blick","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.4 tidymodels, 1. Blick","text":"","code":""},{"path":"modulüberblick.html","id":"vorbereitung-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.4.1 Vorbereitung","text":"Lesen Sie TMWR, Kapitel 1Lesen Sie übrige Literatur zu diesem Thema","code":""},{"path":"modulüberblick.html","id":"lernziele-3","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.4.2 Lernziele","text":"Sie sind der Lage, Regressionsmodelle mit dem tidymodels-Ansatz zu spezifizieren","code":""},{"path":"modulüberblick.html","id":"literatur-3","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.4.3 Literatur","text":"TMWR, Kap. 1, 5, 6, 7","code":""},{"path":"modulüberblick.html","id":"aufgaben-3","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.4.4 Aufgaben","text":"Fallstudie Seegurken","code":""},{"path":"modulüberblick.html","id":"knn","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.5 kNN","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-4","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.5.1 Literatur","text":"Rhys, Kap. 3","code":""},{"path":"modulüberblick.html","id":"statistisches-lernen","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.6 Statistisches Lernen","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-5","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.6.1 Literatur","text":"Rhys, Kap. 3","code":""},{"path":"modulüberblick.html","id":"hinweise-3","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.6.2 Hinweise","text":"dieser Woche fällt die Übung aus (Ostern).","code":""},{"path":"modulüberblick.html","id":"vertiefung-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.6.3 Vertiefung","text":"Fields arranged purity, xkcd 435","code":""},{"path":"modulüberblick.html","id":"wiederholung","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.7 Wiederholung","text":"","code":""},{"path":"modulüberblick.html","id":"hinweise-4","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.7.1 Hinweise","text":"dieser Woche fällt die Vorlesung aus (Ostern).","code":""},{"path":"modulüberblick.html","id":"logistische-regression","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.8 Logistische Regression","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-6","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.8.1 Literatur","text":"Rhys, Kap. 4","code":""},{"path":"modulüberblick.html","id":"naive-bayes","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.9 Naive Bayes","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-7","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.9.1 Literatur","text":"Rhys, Kap. 6","code":""},{"path":"modulüberblick.html","id":"entscheidungsbäume","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.10 Entscheidungsbäume","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-8","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.10.1 Literatur","text":"Rhys, Kap. 7","code":""},{"path":"modulüberblick.html","id":"zufallswälder","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.11 Zufallswälder","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-9","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.11.1 Literatur","text":"Rhys, Kap. 8","code":""},{"path":"modulüberblick.html","id":"fallstudie","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.12 Fallstudie","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-10","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.12.1 Literatur","text":"Rhys, Kap.9","code":""},{"path":"modulüberblick.html","id":"hinweise-5","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.12.2 Hinweise","text":"Nächste Woche ist Blockwoche; es findet kein regulärer Unterricht statt.Diese Woche fällt die Übung aus.","code":""},{"path":"modulüberblick.html","id":"wiederholung-1","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.13 Wiederholung","text":"","code":""},{"path":"modulüberblick.html","id":"hinweise-6","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.13.1 Hinweise","text":"dieser Woche fällt die Vorlesung aus (Pfingsten).","code":""},{"path":"modulüberblick.html","id":"gam","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.14 GAM","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-11","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.14.1 Literatur","text":"Rhys, Kap. 10","code":""},{"path":"modulüberblick.html","id":"lasso-und-co","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.15 Lasso und Co","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-12","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.15.1 Literatur","text":"Rhys, Kap. 11","code":""},{"path":"modulüberblick.html","id":"vertiefung-2","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.16 Vertiefung","text":"","code":""},{"path":"modulüberblick.html","id":"literatur-13","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.16.1 Literatur","text":"Rhys, Kap. 12","code":""},{"path":"modulüberblick.html","id":"hinweise-7","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.16.2 Hinweise","text":"Nach dieser Woche endet der Unterricht.","code":""},{"path":"modulüberblick.html","id":"vertiefung-3","chapter":"Kapitel 2 Modulüberblick","heading":"2.2.16.3 Vertiefung","text":"Wie man eine Data-Science-Projekt strukturiert","code":""},{"path":"prüfung.html","id":"prüfung","chapter":"Kapitel 3 Prüfung","heading":"Kapitel 3 Prüfung","text":"","code":""},{"path":"prüfung.html","id":"prüfungleistung","chapter":"Kapitel 3 Prüfung","heading":"3.1 Prüfungleistung","text":"Die Prüfungsleistung besteht aus einem Prognosewettbewerb.","code":""},{"path":"prüfung.html","id":"tldr-zusammenfassung","chapter":"Kapitel 3 Prüfung","heading":"3.2 tl;dr: Zusammenfassung","text":"Vorhersagen sind eine praktische Sache, zumindest wenn Sie stimmen.\nWenn Sie den DAX-Stand von morgen genau vorhersagen können,\nrufen Sie mich bitte sofort . Genau das ist Ihre Aufgabe dieser Prüfungsleistung:\nSie sollen Werte vorhersagen.Etwas konkreter: Stellen Sie sich ein paar Studentis vor.\nVon allen wissen Sie, wie lange die Person für die Statistikklausur gelernt hat.\nAußerdem wissen Sie die Motivation jeder Person und vielleicht noch ein paar noten-relevante Infos.\nUnd Sie wissen die Note jeder Person der Statistikklausur.\nAuf dieser Basis fragt sie ein Student (Alois), der im kommenden Semester die Prüfung Statistik schreiben muss :\n“Sag mal, wenn ich 100 Stunden lerne und mittel motiviert bin (bestenfalls), welche Note kann ich dann erwarten?”.\nMit Hilfe Ihrer Analyse können Sie diese Frage (und andere) beantworten.\nNatürlich könnten Sie es sich leicht machen und antworten:\n“Mei, der Notendurchschnitt war beim letzten Mal 2.7.\nAlso ist 2.7 kein ganz doofer Tipp für deine Note.”\nJa, das ist keine doofe Antwort, aber man genauere Prognose machen,\nwenn man es geschickt anstellt.\nDa hilft Ihnen die Statistik (doch, wirklich).Kurz gesagt gehen Sie vor:\nImportieren Sie die Daten R, starten Sie die nötigen R-Pakete und\nschauen Sie sich die Daten unter verschiedenen Blickwinkeln .\nDann nehmen Sie die vielversprechendsten Prädiktoren ein Regressionsmodell und schauen sich ,\nwie gut die Vorhersage ist.\nWiederholen Sie das ein paar Mal, bis Sie ein Modell haben, das Sie brauchbar finden.\nMit diesem Modell sagen Sie dann die Noten der neuen Studis (Alois und Co.) vorher.\nJe genauer Ihre Vorhersage, desto besser ist Ihr Prüfungsergebnis.","code":""},{"path":"prüfung.html","id":"vorhersage","chapter":"Kapitel 3 Prüfung","heading":"3.3 Vorhersage","text":"Neben der erklärenden, rückwärtsgerichteten Modellierung spielt insbesondere der Praxis die vorhersageorientierte Modellierung eine wichtige Rolle:\nZiel ist es, bei gegebenen, neuen Beobachtungen die noch unbekannten Werte der Zielvariablen \\(y\\) vorherzusagen, z.B. für neue Kunden auf Basis von soziodemographischen Daten den Kundenwert – möglichst genau – zu prognostizieren.\nDies geschieht auf Basis der vorhandenen Daten der Bestandskunden,\nd.h. inklusive des für diese Kunden bekannten Kundenwertes.Ihnen werden zwei Teildatenmengen zur Verfügung gestellt:\nZum einen gibt es die Trainingsdaten (auch Lerndaten genannt) und zum anderen gibt es Anwendungsdaten (auch Testdaten genannt), auf die man das Modell anwendet.Bei den Trainingsdaten (Train-Sample) liegen sowohl die erklärenden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor.\nAuf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) geschätzt. Es ist also die Variable \\(y\\) vorherszusagen.Bei den Trainingsdaten (Train-Sample) liegen sowohl die erklärenden Variablen \\({\\bf{x}} = (x_1, x_2, \\ldots, x_n)\\) als auch die Zielvariable \\(y\\) vor.\nAuf diesen Trainingsdaten wird das Modell \\(y=f({x})+\\epsilon = f(x_1, x_2, \\ldots, x_n)+\\epsilon\\) gebildet und durch \\(\\hat{f}(\\cdot)\\) geschätzt. Es ist also die Variable \\(y\\) vorherszusagen.Dieses geschätzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(\\bf{x}_0\\), für die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) berechnet.\nDer unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.Dieses geschätzte Modell (\\(\\hat{f}(\\cdot)\\)) wird auf die Anwendungsdaten \\(\\bf{x}_0\\), für die (Ihnen) die Werte der Zielvariable \\(y\\) unbekannt sind, angewendet, d.h., es wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) berechnet.\nDer unbekannte Wert \\(y_0\\) der Zielvariable \\(y\\) wird durch \\(\\hat{y}_0\\) prognostiziert.Liegt zu einem noch späteren Zeitpunkt der eingetroffene Wert \\(y_0\\) der Zielvariable \\(y\\) vor, kann die eigene Vorhersage \\(\\hat{y}_0\\) evaluiert werden,\nd.h. z.B. kann der Fehler \\(e=y_0-\\hat{y}_0\\) zwischen prognostiziertem Wert \\(\\hat{y}_0\\) und wahrem Wert \\(y_0\\) analysiert werden.der praktischen Anwendung können zeitlich drei aufeinanderfolgende Schritte unterschieden werden (vergleiche oben):die Trainingsphase, d.h., die Phase für die sowohl erklärende (\\({\\bf{x}}\\)) als auch die erklärte Variable (\\(y\\)) bekannt sind. Hier wird das Modell geschätzt (gelernt): \\(\\hat{f}(\\bf{x})\\). Dafür wird der Trainingsdatensatz genutzt.die Trainingsphase, d.h., die Phase für die sowohl erklärende (\\({\\bf{x}}\\)) als auch die erklärte Variable (\\(y\\)) bekannt sind. Hier wird das Modell geschätzt (gelernt): \\(\\hat{f}(\\bf{x})\\). Dafür wird der Trainingsdatensatz genutzt.der folgenden Anwendungsphase sind nur die erklärenden Variablen (\\({\\bf{x_0}}\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.der folgenden Anwendungsphase sind nur die erklärenden Variablen (\\({\\bf{x_0}}\\)) bekannt, nicht \\(y_0\\). Auf Basis der Ergebnisses aus dem 1. Schritt wird \\(\\hat{y}_0 :=\\hat{f}({\\bf{x}}_0)\\) prognostiziert.Evt. gibt es später noch die Evaluierungsphase, für die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, dass die Vorhersagegüte des Modells überprüft werden kann.Evt. gibt es später noch die Evaluierungsphase, für die dann auch die Zielvariable (\\(y_0\\)) bekannt ist, dass die Vorhersagegüte des Modells überprüft werden kann.Im Computer kann man dieses Anwendungsszenario simulieren:\nman teilt die Datenmenge zufällig eine Lern- bzw. Trainingsstichprobe (Trainingsdaten; \\((\\bf{x},y)\\)) und eine Teststichprobe (Anwendungsdaten, \\((\\bf{x_0})\\)) auf:\nDie Modellierung erfolgt auf den Trainingsdaten.\nDas Modell wird angewendet auf die Testdaten (Anwendungsdaten).\nDa man hier aber auch die Zielvariable (\\(y_0\\)) kennt, kann damit das Modell evaluiert werden.","code":""},{"path":"prüfung.html","id":"hauptziel-genaue-prognose","chapter":"Kapitel 3 Prüfung","heading":"3.4 Hauptziel: Genaue Prognose","text":"Ihre Aufgabe ist: Spielen Sie den Data-Scientist!\nKonstruieren Sie ein Modell auf Basis der Trainingsdaten \\((\\bf{x},y\\))\nund sagen Sie für die Anwendungsdaten (\\(\\bf{x_0}\\)) die Zielvariable möglichst genau voraus (\\(\\hat{y}_0\\)).Ihr(e) Dozent*kennt den Wert der Zielvariable (\\(y_0\\)).Von zwei Prognosemodellen zum gleichen Datensatz ist dasjenige Modell besser,\ndas weniger Vorhersagefehler aufweist, also genauer vorhersagt.\nKurz gesagt: Genauer ist besser.","code":""},{"path":"prüfung.html","id":"zum-aufbau-ihrer-prognosedatei-im-csv-format","chapter":"Kapitel 3 Prüfung","heading":"3.5 Zum Aufbau Ihrer Prognosedatei im CSV-Format","text":"Die CSV-Datei muss aus genau zwei Spalten mit (exakt) folgenden Spaltennamen bestehen:id: Den ID-Wert jedes vorhergesagten Wertespred: Der vorhergesagte Wert.Umlaute sind zu ersetzen (also Süß wird Suess etc.).Umlaute sind zu ersetzen (also Süß wird Suess etc.).Die CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).Die CSV-Datei muss als Spaltentrennzeichen ein Komma verwenden und als Dezimaltrennzeichen einen Punkt (d.h. also die Standardformatierung einer CSV-Datei; nicht die deutsche Formatierung).Die CSV-Datei muss genau die Anzahl Zeilen aufweisen, die der Zeilenlänge im Test-Datensatz entspricht.Die CSV-Datei muss genau die Anzahl Zeilen aufweisen, die der Zeilenlänge im Test-Datensatz entspricht.Prüfen Sie, dass Ihre CSV-Datei sich problemlos lesen lässt.\nFalls keine (funktionstüchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Prüfung nicht bestanden.\nTipp: Öffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich , ob alles vernünftig aussieht.\nAchtung: Öffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat,\nder CSV-Dateien verfälschen kann auch ohne dass man die Datei speichert.Prüfen Sie, dass Ihre CSV-Datei sich problemlos lesen lässt.\nFalls keine (funktionstüchtige) CSV-Datei eingereicht (hochgeladen) wurde, ist die Prüfung nicht bestanden.\nTipp: Öffnen Sie die CSV-Datei mit einem Texteditor und schauen Sie sich , ob alles vernünftig aussieht.\nAchtung: Öffnen Sie die CSV-Datei besser nicht mit Excel, da Excel einen Bug hat,\nder CSV-Dateien verfälschen kann auch ohne dass man die Datei speichert.","code":""},{"path":"prüfung.html","id":"einzureichende-dateien","chapter":"Kapitel 3 Prüfung","heading":"3.6 Einzureichende Dateien","text":"Folgende* Dateiarten* sind einzureichen:\nPrognose: Ihre Prognose-Datei (CSV-Datei)\nAnalyse: Ihr Analyseskript (R-, Rmd- oder Rmd-Notebook-Datei)\nFolgende* Dateiarten* sind einzureichen:Prognose: Ihre Prognose-Datei (CSV-Datei)Analyse: Ihr Analyseskript (R-, Rmd- oder Rmd-Notebook-Datei)Weitere Dateien sind nicht einzureichen.Weitere Dateien sind nicht einzureichen.Komprimieren Sie die Dateien nicht (z.B. via zip).Komprimieren Sie die Dateien nicht (z.B. via zip).Der Name jeder eingereichnte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd.Der Name jeder eingereichnte Datei muss wie folgt lauten: Nachname_Vorname_Matrikelnummer_Dateiart.Endung. Beispiel: Sauer_Sebastian_0123456_Prognose.csv bzw. Sauer_Sebastian_0123456_Analyse.Rmd.","code":""},{"path":"prüfung.html","id":"tipps","chapter":"Kapitel 3 Prüfung","heading":"3.7 Tipps","text":"","code":""},{"path":"prüfung.html","id":"tipps-für-eine-gute-prognose","chapter":"Kapitel 3 Prüfung","heading":"3.7.1 Tipps für eine gute Prognose","text":"Schauen Sie die Literatur.Schauen Sie die Literatur.Evtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausreißern) helfen.Evtl. kann eine Datenvorverarbeitung (Variablentransformation, z.B. \\(\\log()\\) oder die Elimination von Ausreißern) helfen.Überlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierfür gibt es Algorithmen und R-Funktionen.Überlegen Sie sich Kriterien zur Modell- und/ oder Variablenauswahl. Auch hierfür gibt es Algorithmen und R-Funktionen.Vermeiden Sie Über-Anpassung (Overfitting).Vermeiden Sie Über-Anpassung (Overfitting).Vermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgefüllt.Vermeiden Sie viele fehlende Werte bei Ihrer Prognose. Fehlende Werte werden bei der Benotung mit dem Mittelwert (der vorhandenen Prognosewerte Ihrer Einreichung) aufgefüllt.","code":""},{"path":"prüfung.html","id":"tipps-zur-datenverarbeitung","chapter":"Kapitel 3 Prüfung","heading":"3.7.2 Tipps zur Datenverarbeitung","text":"Ein “deutsches” Excel kann Standard-CSV-Dateien nicht ohne Weiteres lesen. Online-Dienste wie Google Sheets können dies allerdings.","code":""},{"path":"prüfung.html","id":"tipps-zum-aufbau-des-analyseskripts","chapter":"Kapitel 3 Prüfung","heading":"3.7.3 Tipps zum Aufbau des Analyseskripts","text":"Zu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.Zu Beginn des Skripts sollten alle verwendeten R-Pakete mittels library() gestartet werden.Zu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (nicht von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Prüfer, nicht lauffähig ist).Zu Beginn des Skripts sollten die Daten von der vom Dozenten bereitgestellten URL importiert werden (nicht von der eigenen Festplatte, da das Skript sonst bei Dritten, wie Ihrem Prüfer, nicht lauffähig ist).","code":""},{"path":"prüfung.html","id":"sonstiges","chapter":"Kapitel 3 Prüfung","heading":"3.7.4 Sonstiges","text":"Legen Sie regelmäßig Sicherheitskopien Ihrer Arbeit (ggf. auf einem anderen Datenträger).Legen Sie regelmäßig Sicherheitskopien Ihrer Arbeit (ggf. auf einem anderen Datenträger).Achten Sie darauf, dass Sie nicht durcheinander kommen, welcher Datei der aktuelle Stand Ihrer Arbeit liegt.Achten Sie darauf, dass Sie nicht durcheinander kommen, welcher Datei der aktuelle Stand Ihrer Arbeit liegt.","code":""},{"path":"prüfung.html","id":"bewertung","chapter":"Kapitel 3 Prüfung","heading":"3.8 Bewertung","text":"","code":""},{"path":"prüfung.html","id":"kriterien","chapter":"Kapitel 3 Prüfung","heading":"3.8.1 Kriterien","text":"Es gibt drei Bewertungskriterien:\nFormalia: u.. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Übersichtlichkeit der Analyse.\nMethode: u.. methodischer Anspruch und Korrektheit der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.\nInhalt: Vorhersagegüte.\nEs gibt drei Bewertungskriterien:Formalia: u.. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Übersichtlichkeit der Analyse.Formalia: u.. Reproduzierbarkeit der Analyse, Lesbarkeit der Syntax, Übersichtlichkeit der Analyse.Methode: u.. methodischer Anspruch und Korrektheit der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.Methode: u.. methodischer Anspruch und Korrektheit der Explorativen Datenanalyse, Datenvorverarbeitung, Variablenauswahl und Modellierungsmethode.Inhalt: Vorhersagegüte.Inhalt: Vorhersagegüte.Das zentrale Bewertungskriterium ist Inhalt; die übrigen beiden Kriterien fließen nur bei besonders guter oder schlechter Leistung die Gesamtnote ein.Das zentrale Bewertungskriterium ist Inhalt; die übrigen beiden Kriterien fließen nur bei besonders guter oder schlechter Leistung die Gesamtnote ein.Die quantitative Datenanalyse Durchführung und Interpretation ist der Schwerpunkt dieser Arbeit. Zufälliges identisches Vorgehen, z.B. im R Code, ist sehr unwahrscheinlich und kann als Plagiat bewertet werden.Die quantitative Datenanalyse Durchführung und Interpretation ist der Schwerpunkt dieser Arbeit. Zufälliges identisches Vorgehen, z.B. im R Code, ist sehr unwahrscheinlich und kann als Plagiat bewertet werden.Die Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.Die Gesamtnote muss sich nicht als arithmetischer Mittelwert der Teilnoten ergeben.Es werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.Es werden keine Teilnoten vergeben, sondern nur eine Gesamtnote wird vergeben.","code":""},{"path":"prüfung.html","id":"kennzahl-der-modellgüte","chapter":"Kapitel 3 Prüfung","heading":"3.8.2 Kennzahl der Modellgüte","text":"Die Güte der Vorhersage wird anhand des mittleren Absolutfehlers (mae) bemessen:\\[\\text{mae} = \\frac{1}{n} \\sum_{=1}^n|(y_i - \\hat{y}_i)|\\]","code":""},{"path":"prüfung.html","id":"notenstufen","chapter":"Kapitel 3 Prüfung","heading":"3.8.3 Notenstufen","text":"Zur Vorhersagegüte: Die Vorhersagegüte eines einfachen Minimalmodells entspricht einer \\(4,0\\), die eines Referenzmodells des Dozenten einer \\(2,0\\).Ihre Bewertung erfolgt entsprechend Ihrer Vorhersagegüte, d.h., sind Sie besser als das Referenzmodell erhalten Sie hier diesem Teilaspekt eine bessere Note als \\(2,0\\)!","code":""},{"path":"prüfung.html","id":"bewertungsprozess","chapter":"Kapitel 3 Prüfung","heading":"3.8.4 Bewertungsprozess","text":"Der Gutachter legt im Nachgang der Prüfung alle Teilnehmis ihre jeweilige Wert der Kennzahl der Modellgüte offen.\nAußerdem werden die vorherzusagenden Daten veröffentlicht\nsowie die Grenzwerte für jede Notenstufe.\nAuf dieser Basis ist es allen Teilnehmis möglich,\ndie Korrektheit Ihrer Note zu überprüfen.","code":""},{"path":"prüfung.html","id":"hinweise-8","chapter":"Kapitel 3 Prüfung","heading":"3.9 Hinweise","text":"Sie haben freie Methodenwahl bei der Modellierung und Vorverarbeitung. Nutzen Sie den Stoff wie im Unterricht gelernt; Sie können aber auch auf weitere Inhalte, die nicht im Unterricht behandelt wurden, zugreifen.Eine Einführung verschiedene Methoden gibt es z.B. bei Sebastian Sauer (2019): Moderne Datenanalyse mit R1 aber auch bei Max Kuhn und Julia Silge (2021): Tidy Modeling R.2. Die Bücher beinhalten jeweils Beispiele und Anwendung mit R.Auch ist es Ihnen überlassen, welche Variablen Sie zur Modellierung heranziehen – und ob Sie diese eventuell vorverarbeiten, d.h., transformieren, zusammenfassen, Ausreißer bereinigen o.Ä.. Denken Sie nur daran, die Datentransformation, die Sie auf den Trainingsdaten durchführen, auch auf den Testdaten (Anwendungsdaten) durchzuführen.Hinweise zur Modellwahl usw. gibt es auch erwähnter Literatur, aber auch vielen Büchern zum Thema Data-Science.Alles, Sie tun, Datenvorverarbeitung, Modellierung und Anwenden, muss transparent und reproduzierbar sein. Im Übrigen lautet die Aufgabe:\nFinden Sie ein Modell, von dem Sie glauben, dass es die Testdaten gut vorhersagt. \\(\\hat{y}=42\\) ist zwar eine schöne Antwort,\ntrifft die Wirklichkeit aber leider nicht immer.\nEine gute Modellierung auf den Trainingsdaten (z.B. hohes \\(R^2\\)) bedeutet nicht zwangsläufig eine gute Vorhersage (Test-Set).","code":""},{"path":"prüfung.html","id":"formalia","chapter":"Kapitel 3 Prüfung","heading":"3.10 Formalia","text":"Es sind nur Einzelarbeiten zulässig.Es sind nur Einzelarbeiten zulässig.der Analyse muss als Ausgangspunkt der vom/von der Dozenten/bereitgestellten Datensatz genutzt werden.der Analyse muss als Ausgangspunkt der vom/von der Dozenten/bereitgestellten Datensatz genutzt werden.Alle Analyseschritte bzw. alle Veränderungen den Daten müssen im (eingereichten) Analyseskript nachvollziehbar (transparent und reproduzierbar) aufgeführt sein. Das Analyseskript ist als R-Skript, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie können die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).Alle Analyseschritte bzw. alle Veränderungen den Daten müssen im (eingereichten) Analyseskript nachvollziehbar (transparent und reproduzierbar) aufgeführt sein. Das Analyseskript ist als R-Skript, Rmd-Datei oder Rmd-Notebook-Datei abzugeben. Sie können die bereitgestellte Vorlage als Analyseskript nutzen (Template-Dokumentation-Vorhersagemodellierung.Rmd).Das Analyseskript muss funktionstüchtig für den Prüfer sein: Alle Befehle müssen ohne Fehlermeldung durchlaufen (abgesehen von etwaiger Installation fehlender Pakete).Das Analyseskript muss funktionstüchtig für den Prüfer sein: Alle Befehle müssen ohne Fehlermeldung durchlaufen (abgesehen von etwaiger Installation fehlender Pakete).Es dürfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzulässig.Es dürfen keine weiteren Informationen (Daten) als die vom Dozenten ausgegebenen verwendet werden. Sonstige Hilfe (z.B. von Dritten) ist ebenfalls unzulässig.Nichtbeachtung der für dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug führen.Nichtbeachtung der für dieses Modul formulierten Regeln kann zu Nichtbestehen oder Punkteabzug führen.Der Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.Der Schwerpunkt dieser Hausarbeit liegt auf der quantitativen Modellierung, der formale Anspruch liegt daher unter dem von anderen Hausarbeiten.Es muss keine Literatur zitiert werden.Es muss keine Literatur zitiert werden.Ein ausgedrucktes Exemplar muss nicht abgegeben werden.Ein ausgedrucktes Exemplar muss nicht abgegeben werden.Während der Prüfungsphase werden keine inhaltlichen Fragen (“wie macht man nochmal eine Log-Transformation?”) und keine technischen Fragen (“wie installiert man nochmal ein R-Paket?”) beantwortet.Während der Prüfungsphase werden keine inhaltlichen Fragen (“wie macht man nochmal eine Log-Transformation?”) und keine technischen Fragen (“wie installiert man nochmal ein R-Paket?”) beantwortet.","code":""},{"path":"prüfung.html","id":"wo-finde-ich-beispiele","chapter":"Kapitel 3 Prüfung","heading":"3.11 Wo finde ich Beispiele?","text":"Eine Beispiel-Modellierung finden Sie der Datei Beispielanalyse-Prognose-Wettbewerb.Rmd.\nEine beispielhafte Vorlage (Template), die Sie als Richtschnur nutzen können, ist mit der Datei Template-Vorhersagemodellierung.Rmd hier bereitgestellt.\nIm Internet finden sich viele Fallstudien, von denen Sie sich inspirieren lassen können.","code":""},{"path":"prüfung.html","id":"plagiatskontrolle","chapter":"Kapitel 3 Prüfung","heading":"3.12 Plagiatskontrolle","text":"Die eingereichten Arbeiten können automatisiert auf Plagiate überprüft werden. Gibt es substanzielle Überschneidungen zwischen zwei (oder mehr) Arbeiten, werden alle betreffenden Arbeiten mit ungenügend bewertet oder es folgt eine Abwertung der Note.","code":""},{"path":"grundkonzepte-1.html","id":"grundkonzepte-1","chapter":"Kapitel 4 Grundkonzepte","heading":"Kapitel 4 Grundkonzepte","text":"","code":""},{"path":"grundkonzepte-1.html","id":"was-ist-data-science","chapter":"Kapitel 4 Grundkonzepte","heading":"4.1 Was ist Data Science?","text":"Es gibt mehrere Definitionen von Data Science, aber keinen kompletten Konsens.\nBaumer, Kaplan, Horton (2017) definieren Data Science wie folgt (S. 4):science extracting meaningful information dataAuf der anderen Seite entgegen viele Statistiker: “Hey, das machen wir doch schon immer!”.Eine Antwort auf diesen Einwand ist, dass Data Science nicht nur die Statistik eine Rolle spielt, sondern auch die Informatik sowie - zu einem geringen Teil - die Fachwissenschafte (“Domäne”), die sozusagen den Empfänger bzw. die Kunden oder den Rahmen stellt.\nDieser “Dreiklang” ist folgendem Venn-Diagramm dargestellt.","code":""},{"path":"grundkonzepte-1.html","id":"was-ist-machine-learning","chapter":"Kapitel 4 Grundkonzepte","heading":"4.2 Was ist Machine Learning?","text":"Maschinelles Lernen (ML), oft auch (synonym) als statistisches Lernen (statistical learning) bezeichnet, ist ein Teilgebiet der künstlichen Intelligenz (KI; artificial intelligence, AI) (Rhys 2020). ML wird auch als data-based bezeichnet Abgrenzung von rule-based, auch als “klassische KI” bezeichnet wird, vgl. Abb. 4.1.\nFigure 4.1: KI und Maschinelles Lernen\nbeiden Fällen finden Algorithmen Verwendung.\nAlgorithmen sind nichts anderes als genaue Schritt-für-Schritt-Anleitungen, um etwas zu erledigen.\nEin Kochrezept ist ein klassisches Beispiel für einen Algorithmus.Hier findet sich ein Beispiel für einen einfachen Additionsalgorithmus.Es gibt viele ML-Algorithmen, vgl. Abb. 4.2.\nFigure 4.2: ML-Matroschka\n","code":""},{"path":"grundkonzepte-1.html","id":"rule-based","chapter":"Kapitel 4 Grundkonzepte","heading":"4.2.1 Rule-based","text":"Klassische (ältere) KI implementiert Regeln “hartverdrahtet” ein Computersystem.\nNutzer füttern Daten dieses System. Das System leitet dann daraus Antworten ab.Regeln kann man prototypisch mit Wenn-Dann-Abfragen darstellen:Sicherlich könnte man das schlauer programmieren, vielleicht :","code":"\nlernzeit <- c(0, 10, 10, 20)\nschlauer_nebensitzer <- c(FALSE, FALSE, TRUE, TRUE)\n\nfor (i in 1:4) {\n  if (lernzeit[i] > 10) {\n    print(\"bestanden!\")\n  } else {\n    if (schlauer_nebensitzer[i] == TRUE) {\n      print(\"bestanden!\")\n    } else print(\"Durchgefallen!\")\n  }\n}## [1] \"Durchgefallen!\"\n## [1] \"Durchgefallen!\"\n## [1] \"bestanden!\"\n## [1] \"bestanden!\"\nd <- \n  tibble(\n  lernzeit = c(0, 10, 10, 20),\n  schlauer_nebensitzer = c(FALSE, FALSE, TRUE, TRUE)\n)\n\nd %>% \n  mutate(bestanden = ifelse(lernzeit > 10 | schlauer_nebensitzer == TRUE, TRUE, FALSE))## # A tibble: 4 × 3\n##   lernzeit schlauer_nebensitzer bestanden\n##      <dbl> <lgl>                <lgl>    \n## 1        0 FALSE                FALSE    \n## 2       10 FALSE                FALSE    \n## 3       10 TRUE                 TRUE     \n## 4       20 TRUE                 TRUE"},{"path":"grundkonzepte-1.html","id":"data-based","chapter":"Kapitel 4 Grundkonzepte","heading":"4.2.2 Data-based","text":"ML hat zum Ziel, Regeln aus den Daten zu lernen. Man füttert Daten und Antworten das System, das System gibt Regeln zurück.James et al. (2021) definieren ML :\nNehmen wir , wir haben die abhängige Variable \\(Y\\) und \\(p\\) Prädiktoren, \\(X_1,X_2, \\ldots, X_p\\).\nWeiter nehmen wir , die Beziehung zwischen \\(Y\\) und \\(X = (X_1, X_2, \\ldots, X_p)\\) kann durch eine Funktion \\(f\\) beschrieben werden.\nDas kann man darstellen:\\[Y = f(X) + \\epsilon\\]ML kann man auffassen als eine Menge Verfahren, um \\(f\\) zu schätzen.Ein Beispiel ist Abb. 4.3 gezeigt (James et al. 2021).\nFigure 4.3: Vorhersage des Einkommens durch Ausbildungsjahre\nNatürlich kann \\(X\\) mehr als eine Variable beinhalten, vgl. Abb. 4.4 (James et al. 2021).\nFigure 4.4: Vorhersage des Einkommens als Funktion von Ausbildungsjahren und Dienstjahren\nAnders gesagt: traditionelle KI-Systeme werden mit Daten und Regeln gefüttert und liefern Antworten.\nML-Systeme werden mit Daten und Antworten gefüttert und liefern Regeln zurück, vgl. Abb. 4.5.\nFigure 4.5: Vergleich von klassischer KI und ML\n","code":""},{"path":"grundkonzepte-1.html","id":"modell-vs.-algorithmus","chapter":"Kapitel 4 Grundkonzepte","heading":"4.3 Modell vs. Algorithmus","text":"","code":""},{"path":"grundkonzepte-1.html","id":"modell","chapter":"Kapitel 4 Grundkonzepte","heading":"4.3.1 Modell","text":"Ein Modell, s. Abb. 4.6 (Spurzem 2017)!\nFigure 4.6: Ein Modell-Auto\nWie man sieht, ist ein Modell eine vereinfachte Repräsentation eines Gegenstands.Der Gegenstand definiert (gestaltet) das Modell. Das Modell ist eine Vereinfachung des Gegenstands, vgl. Abb. 4.7.\nFigure 4.7: Gegenstand und Modell\nIm maschinellen Lernen meint ein Modell, praktisch gesehen, die Regeln,\ndie aus den Daten gelernt wurden.","code":""},{"path":"grundkonzepte-1.html","id":"beispiel-für-einen-ml-algorithmus","chapter":"Kapitel 4 Grundkonzepte","heading":"4.3.2 Beispiel für einen ML-Algorithmus","text":"Unter einem ML-Algorithmus versteht man das (mathematische oder statistische) Verfahren,\nanhand dessen die Beziehung zwischen \\(X\\) und \\(Y\\) “gelernt” wird. Bei Rhys (2020) (S. 9) findet sich dazu ein Beispiel, das kurz zusammengefasst etwa lautet:Beispiel eines RegressionsalgorithmusSetze Gerade die Daten mit \\(b_0 = \\hat{y}, b_1 = 0\\)Berechne \\(MSS = \\sum (y_i - \\hat{y_i})^2\\)“Drehe” die Gerade ein bisschen, d.h. erhöhe \\(b_1^{neu} = b_1^{alt} + 0.1\\)Wiederhole 2-3 solange, bis \\(MSS < \\text{Zielwert}\\)Diesen Algorithmus kann man “von Hand” z.B. mit dieser App durchspielen.","code":""},{"path":"grundkonzepte-1.html","id":"taxonomie","chapter":"Kapitel 4 Grundkonzepte","heading":"4.4 Taxonomie","text":"Methoden des maschinellen Lernens lassen sich verschiedentlich gliedern.\nEine typische Gliederung unterscheidet supervidierte (geleitete) und nicht-supervidierte (ungeleitete) Algorithmen, s. Abb. 4.8.\nFigure 4.8: Taxonomie der Arten des maschinellen Lernens\n","code":""},{"path":"grundkonzepte-1.html","id":"geleitetes-lernen","chapter":"Kapitel 4 Grundkonzepte","heading":"4.4.1 Geleitetes Lernen","text":"Die zwei Phasen des geleiteten Lernens sind Abb. 4.9 dargestellt.\nFigure 4.9: Geleitetes Lernen geschieht zwei Phasen\n","code":""},{"path":"grundkonzepte-1.html","id":"regression-numerische-vorhersage","chapter":"Kapitel 4 Grundkonzepte","heading":"4.4.1.1 Regression: Numerische Vorhersage","text":"Die Modellgüte eines numerischen Vorhersagemodells wird oft mit (einem der) folgenden Gütekoeffizienten gemessen:Mean Squared Error (Mittlerer Quadratfehler):\\[MSE := \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\\]Mean Absolute Error (Mittlerer Absolutfehler):\\[MAE :=  \\frac{1}{n} \\sum |(y_i - \\hat{y}_i)|\\]Wir sind nicht adaran interessiert die Vorhersagegenauigkeit den bekannten Daten einzuschätzen, sondern im Hinblick auf neue Daten, die der Lernphase dem Modell nicht bekannt waren.","code":""},{"path":"grundkonzepte-1.html","id":"klassifikation-nominale-vorhersage","chapter":"Kapitel 4 Grundkonzepte","heading":"4.4.1.2 Klassifikation: Nominale Vorhersage","text":"Die Modellgüte eines numerischen Vorhersagemodells wird oft mit folgendem Gütekoeffizienten gemessen:Mittlerer Klassifikationfehler \\(e\\):\\[e := \\frac{1}{n} (y_i \\ne \\hat{y}_i) \\]Dabei ist \\(\\) eine Indikatorfunktion, die 1 zurückliefert,\nwenn tatsächlicher Wert und vorhergesagter Wert identisch sind.","code":""},{"path":"grundkonzepte-1.html","id":"ungeleitetes-lernen","chapter":"Kapitel 4 Grundkonzepte","heading":"4.4.2 Ungeleitetes Lernen","text":"Die zwei Phasen des ungeleiteten Lernens sind Abb. 4.10 dargestellt.\nFigure 4.10: Die zwei Phasen des ungeleiteten Lernens\nUngeleitetes Lernen kann man wiederum zwei Arten unterteilen, vgl. Abb. 4.11:Fallreduzierendes Modellieren (Clustering)Dimensionsreduzierendes Modellieren (z.B. Faktorenanalyse)\nFigure 4.11: Zwei Arten von ungeleitetem Modellieren\n","code":""},{"path":"grundkonzepte-1.html","id":"ziele-des-ml","chapter":"Kapitel 4 Grundkonzepte","heading":"4.5 Ziele des ML","text":"Man kann vier Ziele des ML unterscheiden, s. Abb. 4.12.\nFigure 4.12: Ziele des maschinellen Lernens\nVorhersage bezieht sich auf die Schätzung der Werte von Zielvariablen (sowie die damit verbundene Unsicherheit).\nErklärung meint die kausale Analyse von Zusammenhängen.\nBeschreibung ist praktisch gleichzusetzen mit der Verwendung von deskriptiven Statistiken.\nDimensionsreduktion ist ein Oberbegriff für Verfahren, die die Anzahl der Variablen (Spalten) oder der Beobachtungen (Zeilen) verringert.sWie “gut” ein Modell ist, quantifiziert man verschiedenen Kennzahlen; man spricht von Modellgüte oder model fit.\nJe schlechter die Modellgüte, desto höher der Modellfehler, vgl. Abb. 4.13.\nFigure 4.13: Wenig (links) vs. viel (rechts) Vorhersagefehler\nDie Modellgüte eines Modells ist nur relevant für neue Beobachtungen,\ndenen das Modell nicht trainiert wurde.","code":""},{"path":"grundkonzepte-1.html","id":"über--vs.-unteranpassung","chapter":"Kapitel 4 Grundkonzepte","heading":"4.6 Über- vs. Unteranpassung","text":"Overfitting: Ein Modell sagt die Trainingsdaten zu genau vorher - es nimmt Rauschen als “bare Münze”, also fälschlich als Signal. Solche Modelle haben zu viel Varianz ihren Vorhersagen.Underfitting: Ein Modell ist zu simpel (ungenau, grobkörnig) - es unterschlägt Nuancen des tatsächlichen Musters. Solche Modelle haben zu viel Verzerrung (Bias) ihren Vorhersagen.Welches der folgenden Modelle (B,C,D) passt besten zu den Daten (), s. Abb. 4.14, vgl. (Sauer 2019), Kap. 15.\nFigure 4.14: - vs. Underfitting\nWelches Modell wird wohl neue Daten besten vorhersagen? meinen Sie?Modell D zeigt sehr gute Beschreibung (“Retrodiktion”) der Werte, anhand derer das Modell trainiert wurde (“Trainingsstichprobe”).\nWird es aber “ehrlich” getestet, d.h. anhand neuer Daten (“Test-Stichprobe”),\nwird es vermutlich nicht gut abschneiden.Es gilt, ein Modell mit “mittlerer” Komplexität zu finden, um Über- und Unteranpassung Grenzen zu halten.\nLeider ist es nicht möglich, vorab zu sagen, der richtige, “mittlere” Wert Komplexität eines Modells ist, vgl. Abb. 4.15 aus (Sauer 2019).\nFigure 4.15: Mittlere Modellkomplexität führt zur besten Vorhersagegüte\n","code":""},{"path":"grundkonzepte-1.html","id":"no-free-lunch","chapter":"Kapitel 4 Grundkonzepte","heading":"4.7 No free lunch","text":"Wenn \\(f\\) (die Beziehung zwischen \\(Y\\) und \\(X\\), auch datengenerierender Prozess genannt) linear oder fast linear ist,\ndann wird ein lineare Modell gute Vorhersagen liefern, vgl. Abb. 4.16 aus James et al. (2021), dort zeigt die schwarze Linie den “wahren Zusammenhang”, also \\(f\\) . orange sieht man ein lineares Modell, grün ein hoch komplexes Modell,\ndas sich einer “wackligen” Funktion - also mit hoher Varianz -\nniederschlägt. Das grüne Modell könnte z.B. ein Polynom-Modell hohen Grades sein, z. B.\n\\(y = b_0 + b_1 x^{10} + b_2 x^9 + \\ldots + b_11 x^1 + \\epsilon\\).\nDas lineare Modell hat hingegen wenig Varianz und diesem Fall wenig Bias.\nDaher ist es für dieses \\(f\\) gut passend.\nDie grüne Funktion zeigt dagegen Überanpassung (overfitting),\nalso viel Modellfehler (für eine Test-Stichprobe).Die grüne Funktion Abb. 4.16 wird neue, beim Modelltraining unbekannte Beobachtungen (\\(y_0\\)) vergleichsweise schlecht vorhersagen. Abb. 4.17 ist es umgekehrt.\nFigure 4.16: Ein lineare Funktion verlangt ein lineares Modell; ein nichtlineares Modell wird einem höheren Vorhersagefehler (bei neuen Daten!) resultieren.\nBetrachten wir im Gegensatz dazu Abb. 4.17 aus James et al. (2021), die (schwarz) eine hochgradig nichtlineare Funktion \\(f\\) zeigt.\nEntsprechend wird das lineare Modell (orange) nur schlechte Vorhersagen erreichen - es hat zu viel Bias, da zu simpel.\nEin lineares Modell wird der Komplexität von \\(f\\) nicht gerecht,\nUnteranpassung (underfitting) liegt vor.\nFigure 4.17: Eine nichtlineare Funktion (schwarz) verlangt eine nichtlineares Modell. Ein lineares Modell (orange) ist unterangepasst und hat eine schlechte Vorhersageleistung.\n","code":""},{"path":"grundkonzepte-1.html","id":"bias-varianz-abwägung","chapter":"Kapitel 4 Grundkonzepte","heading":"4.8 Bias-Varianz-Abwägung","text":"Der Gesamtfehler \\(E\\) des Modells ist die Summe dreier Terme:\\[E = (y - \\hat{y}) = \\text{Bias} + \\text{Varianz} + \\epsilon\\]Dabei meint \\(\\epsilon\\) den nicht reduzierbaren Fehler, z.B. weil dem Modell Informationen fehlen. kann man etwa auf der Motivation von Studentis keine perfekte Vorhersage ihrer Noten erreichen (lehrt die Erfahrung).Bias und Varianz sind Kontrahenten: Ein Modell, das wenig Bias hat, neigt tendenziell zu wenig Varianz und umgekehrt, vgl. Abb. 4.18 aus Sauer (2019).\nFigure 4.18: Abwängung von Bias vs. Varianz\n","code":""},{"path":"grundkonzepte-1.html","id":"aufgaben-4","chapter":"Kapitel 4 Grundkonzepte","heading":"4.9 Aufgaben","text":"Machen Sie sich mit ‘Kaggle’ vertrautBearbeiten Sie die Fallstudie ‘TitaRnic’ auf Kaggle","code":""},{"path":"grundkonzepte-1.html","id":"vertiefung-4","chapter":"Kapitel 4 Grundkonzepte","heading":"4.10 Vertiefung","text":"Verdienst einer deutschen Data ScientistinWeitere Fallstudie zum Thema Regression auf KaggleCrashkurs Data Science (Coursera, Johns Hopkins University) mit ‘Star-Dozenten’Arbeiten Sie diese Regressionsfallstudie (zum Thema Gehalt) auf Kaggle aufWerfen Sie einen Blick diese Fallstudie auf Kaggle zum Thema HauspreiseWiederholen Sie unser Vorgehen der Fallstudie zu den Flugverspätungen","code":""},{"path":"r-zweiter-blick.html","id":"r-zweiter-blick","chapter":"Kapitel 5 R, zweiter Blick","heading":"Kapitel 5 R, zweiter Blick","text":"","code":""},{"path":"r-zweiter-blick.html","id":"objekttypen-in-r","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1 Objekttypen in R","text":"Näheres zu Objekttypen findet sich Sauer (2019), Kap. 5.2.","code":""},{"path":"r-zweiter-blick.html","id":"überblick","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.1 Überblick","text":"R ist praktisch alles ein Objekt.\nEin Objekt meint ein im Computerspeicher repräsentiertes Ding, etwa eine Tabelle.Vektoren und Dataframes (Tibbles) sind die vielleicht gängigsten Objektarten R (vgl. Abb. 5.1, aus Sauer (2019)).\nFigure 5.1: Zentrale Objektarten R\nEs gibt R keine (Objekte für) Skalare (einzelne Zahlen).\nStattdessen nutzt R Vektoren der Länge 1.Ein nützliches Schema stammt aus Wickham Grolemund (2016), s. Abb. 5.2.\nFigure 5.2: Objektarten hierarchisch gegliedert\n","code":""},{"path":"r-zweiter-blick.html","id":"taxonomie-1","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.2 Taxonomie","text":"Unter homogenen Objektiven verstehen wir Datenstrukturen,\ndie nur eine Art von Daten (wie Text oder Ganze Zahlen) fassen.\nSonstige Objekte nennen wir heterogen.Homogene Objekte\nVektoren\nMatrizen\nVektorenMatrizenHeterogen\nListe\nDataframes (Tibbles)\nListeDataframes (Tibbles)","code":""},{"path":"r-zweiter-blick.html","id":"vektoren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.2.1 Vektoren","text":"Vektoren sind insofern zentral R,\nals dass die übrigen Datenstrukturen auf ihnen aufbauen, vgl. Abb. 5.3 aus Sauer (2019).Reine (atomare) Vektoren R sind eine geordnete Liste von Daten eines Typs.\nFigure 5.3: Vektoren stehen im Zentrum der Datenstrukturen R\nMit str() kann man sich die Struktur eines Objektsausgeben lassen:Vektoren können von folgenden Typen sein:Kommazahlen ( double) genanntGanzzahlig (integer, auch mit L für Long abgekürzt)Text (´character`, String)logische Ausdrücke (logical oder lgl) mit TRUE oder FALSEKommazahlen und Ganze Zahlen zusammen bilden den Typ numeric (numerisch) R.Den Typ eines Vektors kann man mit typeof() ausgeben lassen:","code":"\nein_vektor <- c(1, 2, 3)\nnoch_ein_vektor <- c(\"A\", \"B\", \"C\")\nlogischer_vektor <- c(TRUE, FALSE, TRUE)\nstr(ein_vektor)##  num [1:3] 1 2 3\nstr(noch_ein_vektor)##  chr [1:3] \"A\" \"B\" \"C\"\nstr(logischer_vektor)##  logi [1:3] TRUE FALSE TRUE## [1] \"double\""},{"path":"r-zweiter-blick.html","id":"faktoren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.2.2 Faktoren","text":"Interessant:Vertiefende Informationen findet sich Wickham Grolemund (2016).","code":"\nsex <- factor(c(\"Mann\", \"Frau\", \"Frau\"))\nstr(sex)##  Factor w/ 2 levels \"Frau\",\"Mann\": 2 1 1"},{"path":"r-zweiter-blick.html","id":"listen","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.2.3 Listen","text":"","code":"\neine_liste <- list(titel = \"Einführung\",\n                   woche = 1,\n                   datum = c(\"2022-03-14\", \"2202-03-21\"),\n                   lernziele = c(\"dies\", \"jenes\", \"und noch mehr\"),\n                   lehre = c(TRUE, TRUE, TRUE)\n                   )\nstr(eine_liste)## List of 5\n##  $ titel    : chr \"Einführung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE"},{"path":"r-zweiter-blick.html","id":"tibbles","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.2.4 Tibbles","text":"Für tibble() brauchen wir tidyverse:","code":"\nlibrary(tidyverse)\nstudentis <-\n  tibble(\n    name = c(\"Anna\", \"Berta\"),\n    motivation = c(10, 20),\n    noten = c(1.3, 1.7)\n  )\nstr(studentis)## tibble [2 × 3] (S3: tbl_df/tbl/data.frame)\n##  $ name      : chr [1:2] \"Anna\" \"Berta\"\n##  $ motivation: num [1:2] 10 20\n##  $ noten     : num [1:2] 1.3 1.7"},{"path":"r-zweiter-blick.html","id":"indizieren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.3 Indizieren","text":"Einen Teil eines Objekts auszulesen, bezeichnen wir als Indizieren.","code":""},{"path":"r-zweiter-blick.html","id":"reine-vektoren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.3.1 Reine Vektoren","text":"Zur Erinnerung:Aber nicht :Man darf Vektoren auch wie Listen ansprechen, also eine doppelte Eckklammer zum Indizieren verwendenDer Grund ist,\ndass Listen auch Vektoren sind, nur eben ein besonderer Fall eines Vektors:passiert, wenn man bei einem Vektor der Länge 3 das 4. Element indiziert?Ein schnödes NA ist die Antwort. Das ist interessant:\nWir bekommen keine Fehlermeldung, sondern den Hinweis,\ndas angesprochene Element sei leer bzw. nicht verfügbar.Sauer (2019), Kap. 5.3.1 findet man weitere Indizierungsmöglichkeiten für reine Vektoren.","code":"\nstr(ein_vektor)##  num [1:3] 1 2 3\nein_vektor[1]## [1] 1\nein_vektor[c(1,2)]## [1] 1 2\nein_vektor[1,2]## Error in ein_vektor[1, 2]: incorrect number of dimensions## [1] 2## [1] TRUE\nein_vektor[4]## [1] NA"},{"path":"r-zweiter-blick.html","id":"listen-1","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.3.2 Listen","text":"Listen können wie Vektoren, also mit [ ausgelesen werden.\nDann wird eine Liste zurückgegeben.Das hat den technischen Hintergrund,\ndass Listen als eine bestimmte Art von Vektoren implementiert sind.Mann kann auch die “doppelte Eckklammer”, [[ zum Auslesen verwenden;\ndann wird anstelle einer Liste die einfachere Struktur eines Vektors zurückgegeben:Man könnte sagen,\ndie “äußere Schicht” des Objekts, die Liste,\nwird abgeschält, und man bekommnt die “innere” Schicht,\nden Vektor.Mann die Elemente der Liste entweder mit ihrer Positionsnummer (1, 2, …) oder,\nsofern vorhanden, ihren Namen ansprechen:Dann gibt es noch den Dollar-Operator,\nmit dem Mann benannte Elemente von Listen ansprechen kann:Man kann auch tiefer eine Liste hinein indizieren.\nSagen wir, uns interessiert das 4. Element der Liste eine_liste -\nund davon das erste Element.Das geht dann :Eine einfachere Art des Indizierens von Listen bietet die Funktion pluck(), aus dem Paket purrr,\ndas Hilfen für den Umgang mit Listen bietet.Und jetzt aus dem 4. Element das 1. Element:Probieren Sie mal, aus einer Liste der Länge 5 das 6. Element auszulesen:Unser Versuch wird mit einer Fehlermeldung quittiert.Sprechen wir die Liste wie einen (atomaren) Vektor ,\nbekommen wir hingegen ein NA bzw. ein NULL:","code":"\neine_liste %>% str()## List of 5\n##  $ titel    : chr \"Einführung\"\n##  $ woche    : num 1\n##  $ datum    : chr [1:2] \"2022-03-14\" \"2202-03-21\"\n##  $ lernziele: chr [1:3] \"dies\" \"jenes\" \"und noch mehr\"\n##  $ lehre    : logi [1:3] TRUE TRUE TRUE\neine_liste[1]## $titel\n## [1] \"Einführung\"\neine_liste[2]## $woche\n## [1] 1\neine_liste[[1]]## [1] \"Einführung\"\neine_liste[[\"titel\"]]## [1] \"Einführung\"\neine_liste$titel## [1] \"Einführung\"\neine_liste[[4]][[1]] ## [1] \"dies\"\npluck(eine_liste, 4)## [1] \"dies\"          \"jenes\"         \"und noch mehr\"\npluck(eine_liste, 4, 1)## [1] \"dies\"\neine_liste %>% length()## [1] 5\neine_liste[[6]]## Error in eine_liste[[6]]: subscript out of bounds\neine_liste[6]## $<NA>\n## NULL"},{"path":"r-zweiter-blick.html","id":"tibbles-1","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.3.3 Tibbles","text":"Tibbles lassen sich sowohl wie ein Vektor als auch wie eine Liste indizieren.Die Indizierung eines Tibbles mit der einfachen Eckklammer liefert einen Tibble zurück.Mit doppelter Eckklammer bekommt man,\nanalog zur Liste,\neinen Vektor zurück:Beim Dollar-Operator kommt auch eine Liste zurück:","code":"\nstudentis[1]## # A tibble: 2 × 1\n##   name \n##   <chr>\n## 1 Anna \n## 2 Berta\nstudentis[\"name\"]## # A tibble: 2 × 1\n##   name \n##   <chr>\n## 1 Anna \n## 2 Berta\nstudentis[[\"name\"]]## [1] \"Anna\"  \"Berta\"\nstudentis$name## [1] \"Anna\"  \"Berta\""},{"path":"r-zweiter-blick.html","id":"weiterführende-hinweise","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.4 Weiterführende Hinweise","text":"Tutorial zum Themen Indizieren von Listen von Jenny BC.","code":""},{"path":"r-zweiter-blick.html","id":"indizieren-mit-dem-tidyverse","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.1.5 Indizieren mit dem Tidyverse","text":"Natürlich kann man auch die Tidyverse-Verben zum Indizieren verwenden.\nDas bietet sich , wenn zwei Bedingungen erfüllt sind:Wenn man einen Tibble als Input und als Output hatWenn man nicht programmieren möchte","code":""},{"path":"r-zweiter-blick.html","id":"datensätze-von-lang-nach-breit-umformatieren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.2 Datensätze von lang nach breit umformatieren","text":"Manchmal findet man Datensätze im sog. langen Format vor,\nmanchmal im breiten.der Regel müssen die Daten “tidy” sein,\nmeist dem langen Format entspricht, vgl. Abb. 5.4 aus Sauer (2019).\nFigure 5.4: Von lang nach breit und zurück\neiner neueren Version des Tidyverse werden diese beiden Befehle umbenannt bzw. erweitert:gather() -> pivot_longer()spread() -> pivot_wider()Weitere Informationen findet sich Wickham Grolemund (2016), diesem Abschnitt, 12.3.","code":""},{"path":"r-zweiter-blick.html","id":"funktionen","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.3 Funktionen","text":"Eine Funktion kann man sich als analog zu einer Variable vorstellen.\nEs ist ein Objekt, das nicht Daten, sondern Syntax beinhaltet,\nvgl. Abb. 5.5 aus Sauer (2019).\nFigure 5.5: Sinnbild einer Funktion\nWeitere Informationen finden sich Kapitel 19 Wickham Grolemund (2016). Alternativ findet sich ein Abschnitt dazu (28.1) Sauer (2019).","code":"\nmittelwert <- function(x){\n  \n  summe <- sum(x, na.rm = TRUE)\n  mw <- summe/length(x)\n  return(mw)\n  \n}\nmittelwert(c(1, 2, 3))## [1] 2"},{"path":"r-zweiter-blick.html","id":"wiederholungen-programmieren","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.4 Wiederholungen programmieren","text":"Häufig möchte man eine Operation mehrfach ausführen.\nEin Beispiel wäre die Anzahl der fehlenden Werte pro Spalte auslesen.\nNatürlich kann man die Abfrage einfach häufig tippen, nervt aber irgendwann.\nDaher braucht’s Strukturen, die Wiederholungen beschreiben.Dafür gibt es verschiedene Ansätze.","code":""},{"path":"r-zweiter-blick.html","id":"across","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.4.1 across()","text":"Handelt es sich um Spalten von Tibbles, dann bietet sich die Funktion across(.col, .fns) .\nacross wendet eine oder mehrere Funktionen (mit .fns bezeichnet) auf die Spalten .col .Das erklärt sich besten mit einem Beispiel:Natürlich hätte man diesem Fall auch anders vorgehen können:Möchte man der Funktion .fns Parameter übergeben, nutzt man diese Syntax (“Purrr-Lambda”):Hier findet sich ein guter Überblick zu across().","code":"\nmtcars %>% \n  summarise(across(.cols = everything(),\n                   .fns = mean))##        mpg    cyl     disp       hp     drat      wt     qsec     vs      am\n## 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625\n##     gear   carb\n## 1 3.6875 2.8125\nmtcars %>% \n  summarise(across(.cols = everything(),\n                   .fns = ~ mean(., na.rm = TRUE)))##        mpg    cyl     disp       hp     drat      wt     qsec     vs      am\n## 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625\n##     gear   carb\n## 1 3.6875 2.8125"},{"path":"r-zweiter-blick.html","id":"map","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.4.2 map()","text":"map() ist eine Funktion aus dem R-Paket purrr und Teil des Tidyverse.map(x, f) wenden die Funktion f auf jedes Element von x .\nIst x ein Tibble, wird f demnach auf jede Spalte von x angewendet (“zugeordnet”, daher map), vgl. Abb. 5.6 aus Sauer (2019).\nFigure 5.6: Sinnbild für map\nHier ein Beispiel-Code:Möchte man der gemappten Funktion Parameter übergeben,\nnutzt man wieder die “Kringel-Schreibweise”:","code":"\ndata(mtcars)\n\nmap(mtcars, mean)## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n## \n## $hp\n## [1] 146.6875\n## \n## $drat\n## [1] 3.596563\n## \n## $wt\n## [1] 3.21725\n## \n## $qsec\n## [1] 17.84875\n## \n## $vs\n## [1] 0.4375\n## \n## $am\n## [1] 0.40625\n## \n## $gear\n## [1] 3.6875\n## \n## $carb\n## [1] 2.8125\nmap(mtcars, ~ mean(., na.rm = TRUE))## $mpg\n## [1] 20.09062\n## \n## $cyl\n## [1] 6.1875\n## \n## $disp\n## [1] 230.7219\n## \n## $hp\n## [1] 146.6875\n## \n## $drat\n## [1] 3.596563\n## \n## $wt\n## [1] 3.21725\n## \n## $qsec\n## [1] 17.84875\n## \n## $vs\n## [1] 0.4375\n## \n## $am\n## [1] 0.40625\n## \n## $gear\n## [1] 3.6875\n## \n## $carb\n## [1] 2.8125"},{"path":"r-zweiter-blick.html","id":"weiterführende-hinweise-1","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.4.3 Weiterführende Hinweise","text":"Weiteres zu map() findet sich z.B. Wickham Grolemund (2016), Kapitel 21.5 oder Sauer (2019), Kap. 28.2.Tutorial zu map() von Jenny BC.","code":""},{"path":"r-zweiter-blick.html","id":"listenspalten","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.5 Listenspalten","text":"","code":""},{"path":"r-zweiter-blick.html","id":"wozu-listenspalten","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.5.1 Wozu Listenspalten?","text":"Listenspalten sind immer dann sinnvoll,\nwenn eine einfache Tabelle nicht komplex genug für unsere Daten ist.Zwei Fälle stechen dabei ins Auge:Unsere Datenstruktur ist nicht rechteckigIn einer Zelle der Tabelle soll mehr als ein einzelner Wert stehen: vielleicht ein Vektor, eine Liste oder eine TabelleDer erstere Fall (nicht reckeckig) ließe sich noch einfach lösen,\ndem man mit NA auffüllt.Der zweite Fall verlangt schlichtweg nach komplexeren Datenstrukturen.Kap. 25.3 aus Wickham Grolemund (2016) bietet einen guten Einstieg das Konzept von Listenspalten (list-columns) R.","code":""},{"path":"r-zweiter-blick.html","id":"beispiele-für-listenspalten","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.5.2 Beispiele für Listenspalten","text":"","code":""},{"path":"r-zweiter-blick.html","id":"tidymodel","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.5.2.1 tidymodel","text":"Wenn wir mit tidymodels arbeiten,\nwerden wir mit Listenspalten zu tun haben.\nDaher ist es praktisch, sich schon mal damit zu beschäftigen.Hier ein Beispiel für eine \\(v=3\\)-fache Kreuzvalidierung:Betrachten wir das Objekt mtcars_cv näher.\nDie Musik spielt der 1. Spalte.Lesen wir den Inhalt der 1. Spalte, 1 Zeile aus (nennen wir das mal “Position 1,1”):dieser Zelle findet sich eine Aufteilung des Komplettdatensatzes den Analyseteil (Analysis sample) und den Assessmentteil (Assessment Sample).Schauen wir jetzt dieses Objekt näher .\nDas können wir mit str() tun.\nstr() zeigt uns die Strktur eines Objekts.Oh! pos11 ist eine Liste, und zwar eine durchaus komplexe.\nWir müssen erkennen,\ndass einer einzelnen Zelle dieses Dataframes viel mehr steht,\nals ein Skalar bzw. ein einzelnes, atomares Element.Damit handelt es sich bei Spalte 1 dieses Dataframes (mtcars_cv) also um eine Listenspalte.Üben wir uns noch etwas im Indizieren.Sprechen wir pos11 das erste Element (data) und davon das erste Element:Wir haben hier die doppelten Eckklammern benutzt,\num den “eigentlichen” oder “inneren” Vektor zu bekommen,\nnicht die “außen” herumgewickelte Liste.\nZur Erinnerung:\nEin Dataframe ist ein Spezialfall einer Liste,\nalso auch eine Liste, nur eine mit bestimmten Eigenschaften.Zum Vergleich indizieren wir mal mit einer einfachen Eckklammer:Mit pluck() bekommen wir das gleiche Ergebnis,\nnur etwas komfortabler,\nda wir keine Eckklammern tippen müssen:Wie man sieht, können wir beliebig tief das Objekt hineinindizieren.","code":"\nlibrary(tidymodels)\nmtcars_cv <-\n  vfold_cv(mtcars, v = 3)\n\nmtcars_cv## #  3-fold cross-validation \n## # A tibble: 3 × 2\n##   splits          id   \n##   <list>          <chr>\n## 1 <split [21/11]> Fold1\n## 2 <split [21/11]> Fold2\n## 3 <split [22/10]> Fold3\npos11 <- mtcars_cv[[1]][[1]]\npos11## <Analysis/Assess/Total>\n## <21/11/32>\nstr(pos11)## List of 4\n##  $ data  :'data.frame':  32 obs. of  11 variables:\n##   ..$ mpg : num [1:32] 21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n##   ..$ cyl : num [1:32] 6 6 4 6 8 6 8 4 4 6 ...\n##   ..$ disp: num [1:32] 160 160 108 258 360 ...\n##   ..$ hp  : num [1:32] 110 110 93 110 175 105 245 62 95 123 ...\n##   ..$ drat: num [1:32] 3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n##   ..$ wt  : num [1:32] 2.62 2.88 2.32 3.21 3.44 ...\n##   ..$ qsec: num [1:32] 16.5 17 18.6 19.4 17 ...\n##   ..$ vs  : num [1:32] 0 0 1 1 0 1 0 1 1 1 ...\n##   ..$ am  : num [1:32] 1 1 1 0 0 0 0 0 0 0 ...\n##   ..$ gear: num [1:32] 4 4 4 3 3 3 3 4 4 4 ...\n##   ..$ carb: num [1:32] 4 4 1 1 2 1 4 2 2 4 ...\n##  $ in_id : int [1:21] 2 4 5 6 7 9 10 12 13 16 ...\n##  $ out_id: logi NA\n##  $ id    : tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n##   ..$ id: chr \"Fold1\"\n##  - attr(*, \"class\")= chr [1:2] \"vfold_split\" \"rsplit\"\npos11[[\"data\"]][[1]]##  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n## [31] 15.0 21.4\npos11[[\"data\"]][1] %>% \n  head()##                    mpg\n## Mazda RX4         21.0\n## Mazda RX4 Wag     21.0\n## Datsun 710        22.8\n## Hornet 4 Drive    21.4\n## Hornet Sportabout 18.7\n## Valiant           18.1\npluck(pos11, \"data\", 1, 1)## [1] 21"},{"path":"r-zweiter-blick.html","id":"kurs-datascience1","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.5.2.2 Kurs DataScience1","text":"Ein Kurs, wie dieser, kann anhand einer “Deskriptoren” wie Titel der Inhalte, Lernziele, Literatur und weiter zusammmengefasst werden.\nDiese Deskriptoren kann man wiederum jeder Kurswoche oder jedem Kursabschnitt zuordnen,\ndass eine zweidimensionale Struktur resultiert.\nEine Tabelle, einfach gesagt, etwa :Wie man sieht, entspricht jede Spalte einem Deskriptor des Kurses,\nund jede Zeile entspricht einem Thema (oder Woche oder Abschnitt) des Kurses.Jetzt ist es nur ,\ndass einzelne Zellen dieser Tabelle nicht aus nur einem Element bestehen.\nkönnte etwa “Aufgaben1” aus mehreren Aufgaben bestehen,\ndie jeweils wiederum aus mehreren (Text-)Elementen bestehen.\nOder “Literatur2” besteht vielleicht aus zwei Literaturquellen.Kurz gesagt, wir brauchen eine Tabelle,\ndie erlaubt, einer Zelle mehr als ein einzelnes Element zu packen.\nListenspalten erlauben das.Schauen wir uns die “Mastertabelle” dieses Kurses zur Illustration.Zunächst sourcen wir die nötigen Funktionen.Ihrem Environment sollten Sie jetzt die gesourcten Funktionen sehen.\nMit Klick auf den Funktionsnamen können Sie diese Funktionen auch betrachten.Die Deskriptoren des Kurses speisen sich aus zwei Textdateien, gespeichert im sog. YAML-Format, ein einfaches Textformat, und hier nicht weiter von Belang.Zum einen eine Datei mit den Datumsangaben:Zum anderen eine Datei mit den Deskriptoren,\ndie unabhängig vom Datum sind:Im Githup-Repo\ndieses Kurses können Sie die Dateien komfortabel betrachten.Die “Mastertabelle” kann man mit folgender Funktion erstellen:Betrachten Sie die Tabelle Ruhe!\nSie werden sehen, dass einige Spalten komplex sind,\nalso mehr als nur einen einzelnen Wert enthalten:Gerade haben wir aus dem Objekt mastertable, ein Dataframe,\ndie Spalte mit dem Namen Vorbereitung ausgelesen und aus dieser Spalte das erste erste Element.\nDieses erste Element ist ein Textvektor der Länge 3.Daraus könnten wir z.B. das zweite Element auslesen:würde passieren, wenn wir anstelle der doppelten Eckklammer einfache Eckklammern verwenden würden?Das macht noch keinen großen Unterschied,\naber schauen wir mal weiter.Wenn wir das erste Element der Spalte “Vorbereitung” mit doppelter Eckklammer ansprechen,\nbekommen wir einen Text-Vektor (der Länge drei) zurück.Jetzt können wir, wie oben getan,\ndiese einzelnen Elemente ansprechen.Aber: Wenn wir das erste Element der Spalte “Vorbereitung” mit einfacher Eckklammer ansprechen, bekommen wir eine Liste mit einem Element zurück.Wir können also nicht (ohne weiteres “Abschälen”)\nz.B. das zweite Element des Text-Vektors (“Installieren Sie…”) auslesen:Wenn Sie sich über pluck() wundern,\nSie hätten synonym auch schreiben können:Da die Liste nur aus einem Element besteht,\nkönnten wir z.B. nicht das zweite Element der Liste ansprechen:Haben wir aber die doppelte Eckklammer verwendet,\nbekommen wir einen Vektor der Länge drei zurück (vom Typ Text),\nund daher können wir die Elemente 1 bis 3 ansprechen:Dabei ist es egal, ob Sie einfache oder doppelte Eckklammern benutzen,\nda Listen auch Vektoren sind.","code":"\nsource(\"https://raw.githubusercontent.com/sebastiansauer/Lehre/main/R-Code/render-course-sections.R\")\ndates_file <- \"https://raw.githubusercontent.com/sebastiansauer/datascience1/main/course-dates.yaml\"\ncourse_content_file <- \"https://raw.githubusercontent.com/sebastiansauer/datascience1/main/_modul-ueberblick.yaml\"\nmastertable <- build_master_course_table(course_dates_file = dates_file,\n                                         content_file = course_content_file)\nmastertable[[\"Vorbereitung\"]][[1]]## [1] \"Lesen Sie die Hinweise zum Modul.\"                                       \n## [2] \"Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\"\n## [3] \"Lesen Sie die Literatur.\"\nmastertable[[\"Vorbereitung\"]][[1]][2]## [1] \"Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\"\nmastertable[\"Vorbereitung\"] %>% class()## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nmastertable[[\"Vorbereitung\"]] %>% class()## [1] \"list\"\nmastertable[[\"Vorbereitung\"]][[1]]## [1] \"Lesen Sie die Hinweise zum Modul.\"                                       \n## [2] \"Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\"\n## [3] \"Lesen Sie die Literatur.\"\nmastertable[[\"Vorbereitung\"]][1]## [[1]]\n## [1] \"Lesen Sie die Hinweise zum Modul.\"                                       \n## [2] \"Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\"\n## [3] \"Lesen Sie die Literatur.\"\nmastertable[[\"Vorbereitung\"]][1] %>% pluck(2)## NULL\nmastertable[[\"Vorbereitung\"]][1][2]## [[1]]\n## NULL\nmastertable[[\"Vorbereitung\"]][1][[2]]## Error in mastertable[[\"Vorbereitung\"]][1][[2]]: subscript out of bounds\nmastertable[[\"Vorbereitung\"]][[1]][2]## [1] \"Installieren (oder Updaten) Sie die für dieses Modul angegeben Software.\""},{"path":"r-zweiter-blick.html","id":"aufgaben-5","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.6 Aufgaben","text":"Aufgabe\nSchreiben Sie eine Funktion, mit folgendem Algorithmus, wobei ein\nbeliebiger Vektor als Eingabe verlangt wird.\nZähle die Anzahl verschiedener Werte.\nWenn es nur zwei verschiedene Werte gibt, gebe TRUE zurück,\nansonsten FALSE.\nHinweise:\nWählen Sie einen treffenden Namen für Ihre Funktion (nutzen Sie\nbesten ein konsistentes Namensschema).\nWichtigster Tipp: Googeln :-)\nVerschiedene Werte eines Vektors gibt die Funktion unique()\nzurück.\nVermutlich gibt es schon viele Lösungen (Implementierungen) für\ndiese Funktion. Ist nur als Übung gedacht :-)\nLösung\nhas_two_levels <- function(vec){\n\n  # input: vector type\n  # value: number unique values (double)\n\n  tmp <- length(unique(vec))\n  tmp == 2\n}\nlevels ist ein Ausdruck, der nahelegt, dass es sich um\nverschiedene Werte (“Ausprägungen” oder “Stufen”) handelt.\nAlternativ könnte man die Funktion auch schreiben:\nhas_two_values <- function(vec){\n\n  # input: vector type\n  # value: number unique values (double)\n\n  step1 <- unique(vec)\n  step2 <- length(step1)\n  step3 <- (step2 == 2) {\n    <- TRUE\n  } else {\n    <- FALSE\n  }\n\n  <- step2\n  return()\n\n}\nDas ist expliziter, aber länger.\nWenn man es genau nimmt, heißt binär, dass es nur die Werte 0\nund 1 gibt. Das ist ein strengeres Kriterium, wie dass es zwei\nbeliebigen verschiedene Werte gibt (s. unten dazu ein Vorschlag).\nTesten wir unsere Funktion, Test 1:\nx <- c(1,2, 3, 3, 3, 1)\nx2 <- c(\"\", \"B\")\n\n\nhas_two_levels(x2)\n## [1] TRUE\nhas_two_levels(x)\n## [1] FALSE\nTest 2:\ndata(mtcars)\nWir wenden unsere neue Funktion mit Tidyverse-Methoden :\nmtcars %>% \n  summarise(am_has_two_values = has_two_levels(),\n            mpg_has_two_values = has_two_levels(mpg))\n##   am_has_two_values mpg_has_two_values\n## 1              TRUE              FALSE\nBonus!\nVerwenden Sie across() (dplyr), um alle Spalten von mtcars\nmit has_two_levels() zu überprüfen.\nmtcars %>% \n  summarise(across(everything(),\n                   has_two_levels))\n##     mpg   cyl  disp    hp  drat    wt\n## 1 FALSE FALSE FALSE FALSE FALSE FALSE\n##    qsec   vs    gear  carb\n## 1 FALSE TRUE TRUE FALSE FALSE\nKann man auch schreiben:\nmtcars %>% \n  summarise(across(everything(),\n                   ~ has_two_levels(.)))\n##     mpg   cyl  disp    hp  drat    wt\n## 1 FALSE FALSE FALSE FALSE FALSE FALSE\n##    qsec   vs    gear  carb\n## 1 FALSE TRUE TRUE FALSE FALSE\nBonus-Bonus:\nkönnte man eine Funktion schreiben, die prüft, ob die\nAusprägungen eines Vektors binär sind, d.h. nur 0 oder 1:\nis_binary <- function(var){\n  return((var %% c(0,1)))\n}AufgabeSchreiben Sie eine Funktion, mit folgendem Algorithmus, wobei ein\nbeliebiger Vektor als Eingabe verlangt wird.Zähle die Anzahl verschiedener Werte.Wenn es nur zwei verschiedene Werte gibt, gebe TRUE zurück,\nansonsten FALSE.Hinweise:Wählen Sie einen treffenden Namen für Ihre Funktion (nutzen Sie\nbesten ein konsistentes Namensschema).Wichtigster Tipp: Googeln :-)Verschiedene Werte eines Vektors gibt die Funktion unique()\nzurück.Vermutlich gibt es schon viele Lösungen (Implementierungen) für\ndiese Funktion. Ist nur als Übung gedacht :-)Lösunglevels ist ein Ausdruck, der nahelegt, dass es sich um\nverschiedene Werte (“Ausprägungen” oder “Stufen”) handelt.Alternativ könnte man die Funktion auch schreiben:Das ist expliziter, aber länger.Wenn man es genau nimmt, heißt binär, dass es nur die Werte 0\nund 1 gibt. Das ist ein strengeres Kriterium, wie dass es zwei\nbeliebigen verschiedene Werte gibt (s. unten dazu ein Vorschlag).Testen wir unsere Funktion, Test 1:Test 2:Wir wenden unsere neue Funktion mit Tidyverse-Methoden :Bonus!Verwenden Sie across() (dplyr), um alle Spalten von mtcars\nmit has_two_levels() zu überprüfen.Kann man auch schreiben:Bonus-Bonus:könnte man eine Funktion schreiben, die prüft, ob die\nAusprägungen eines Vektors binär sind, d.h. nur 0 oder 1:Aufgabe\nSchreiben Sie eine Funktion zur Berechnung der Anzahl der fehlenden\nWerte einem (numerischen) Vektor!\nHinweise:\nWählen Sie einen treffenden Namen für Ihre Funktion (nutzen Sie\nbesten ein konsistentes Namensschema).\nLösung\nna_n <- function(num_vec) {\n  # input: num. vector (int double)\n  # value: count missing values (double)\n\n  (!.numeric(num_vec)) stop(\"Numeric input needed!\")\n  <- sum(.na(num_vec))\n  return()\n\n}\nTest:\nx <- c(1,2, NA, NA)\nx2 <- c(\"\", \"B\", NA)\n\nna_n(x)\n## [1] 2\nBei x2 sollte ein Fehler aufgeworfen werden:\nna_n(x2)\n## Error na_n(x2): Numeric input needed!\nGut!\nTesten wir weiter, jetzt mit dem Datensatz mtcars:\nmtcars[1, c(1,2,3,4)] <- NA  # Zeilen/Spalte\n\nmtcars %>% \n  summarise(mpg_na_n = na_n(mpg))\n##   mpg_na_n\n## 1        1\nBONUS!\nVerwenden Sie across(), um die fehlenden Werte allen Spalten\nvon mtcars zu zählen.\nWer schnell ist, der nehme gerne nycflights13::flights (aus dem\nPaket nycflights13 oder per CSV-Datei aus geeigneter Stelel aus\ndem Internet. Meistens geht es schneller, die Daten aus einem Paket\nzu laden mit data(flights) nachdem man library(nycflights13)\ngeschrieben hat).\nmtcars %>% \n  summarise(across(everything(), na_n)) \n##   mpg cyl disp hp drat wt qsec vs \n## 1   1   1    1  1    0  0    0  0  0\n##   gear carb\n## 1    0    0\nMit pivot_longer() ist es häufig übersichtlicher bzw. besser für\nweitere Bearbeitungsschritte, wie das folgende Beispiel zeigt:\nmtcars %>% \n  summarise(across(everything(), na_n)) %>% \n  pivot_longer(everything()) %>% \n  filter(value > 0)\n## # tibble: 4 × 2\n##   name  value\n##   <chr> <int>\n## 1 mpg       1\n## 2 cyl       1\n## 3 disp      1\n## 4 hp        1\nflights:\ndata(flights, package = \"nycflights13\")\n\nflights %>% \n  select((.numeric)) %>% \n  summarise(across(everything(),\n                   na_n)) %>% \n  pivot_longer(everything()) %>% \n  arrange(-value) %>%  # Sortiere absteigend nach Anzahl der fehlenden Werte\n  filter(value > 0)  # Zeige nur Variablen mit fehlenden Werten\n## # tibble: 5 × 2\n##   name      value\n##   <chr>     <int>\n## 1 arr_delay  9430\n## 2 air_time   9430\n## 3 arr_time   8713\n## 4 dep_time   8255\n## 5 dep_delay  8255AufgabeSchreiben Sie eine Funktion zur Berechnung der Anzahl der fehlenden\nWerte einem (numerischen) Vektor!Hinweise:Wählen Sie einen treffenden Namen für Ihre Funktion (nutzen Sie\nbesten ein konsistentes Namensschema).LösungTest:Bei x2 sollte ein Fehler aufgeworfen werden:Gut!Testen wir weiter, jetzt mit dem Datensatz mtcars:BONUS!Verwenden Sie across(), um die fehlenden Werte allen Spalten\nvon mtcars zu zählen.Wer schnell ist, der nehme gerne nycflights13::flights (aus dem\nPaket nycflights13 oder per CSV-Datei aus geeigneter Stelel aus\ndem Internet. Meistens geht es schneller, die Daten aus einem Paket\nzu laden mit data(flights) nachdem man library(nycflights13)\ngeschrieben hat).Mit pivot_longer() ist es häufig übersichtlicher bzw. besser für\nweitere Bearbeitungsschritte, wie das folgende Beispiel zeigt:flights:Aufgabe\nErstellen Sie für jede Variable aus mtcars ein Histogramm!\nHinweise:\nNutzen Sie eine Wiederholungsstruktur. Schreiben Sie prägnante\nSyntax.\nOptional: Lassen Sie dichotome (zweiwertige) Variablen aus.\nHier\n(und vielen anderen Stellen im Netz) finden Sie Tipps.\nLösung\nhas_two_levels <- function(vec){\n\n  # input: vector type\n  # value: number unique values (double)\n\n  tmp <- length(unique(vec))\n  tmp == 2\n}\nmtcars_hist <- function(col){\n  mtcars %>% \n    ggplot(aes(x = col)) +\n    geom_histogram()\n}\nmtcars %>% \n  select((.numeric)) %>% \n  select((negate(has_two_levels))) %>%   # `!` zum Negieren geht leider nicht\n  map(mtcars_hist)\n## $mpg\n## \n## $cyl\n## \n## $disp\n## \n## $hp\n## \n## $drat\n## \n## $wt\n## \n## $qsec\n## \n## $gear\n## \n## $carb\nAufgabeErstellen Sie für jede Variable aus mtcars ein Histogramm!Hinweise:Nutzen Sie eine Wiederholungsstruktur. Schreiben Sie prägnante\nSyntax.Optional: Lassen Sie dichotome (zweiwertige) Variablen aus.Hier\n(und vielen anderen Stellen im Netz) finden Sie Tipps.Lösung","code":"has_two_levels <- function(vec){\n\n  # input: vector of any type\n  # value: number of unique values (double)\n\n  tmp <- length(unique(vec))\n  tmp == 2\n}has_two_values <- function(vec){\n\n  # input: vector of any type\n  # value: number of unique values (double)\n\n  step1 <- unique(vec)\n  step2 <- length(step1)\n  step3 <- if(step2 == 2) {\n    out <- TRUE\n  } else {\n    out <- FALSE\n  }\n\n  out <- step2\n  return(out)\n\n}x <- c(1,2, 3, 3, 3, 1)\nx2 <- c(\"A\", \"B\")\n\n\nhas_two_levels(x2)## [1] TRUEhas_two_levels(x)## [1] FALSEdata(mtcars)mtcars %>% \n  summarise(am_has_two_values = has_two_levels(am),\n            mpg_has_two_values = has_two_levels(mpg))##   am_has_two_values mpg_has_two_values\n## 1              TRUE              FALSEmtcars %>% \n  summarise(across(everything(),\n                   has_two_levels))##     mpg   cyl  disp    hp  drat    wt\n## 1 FALSE FALSE FALSE FALSE FALSE FALSE\n##    qsec   vs   am  gear  carb\n## 1 FALSE TRUE TRUE FALSE FALSEmtcars %>% \n  summarise(across(everything(),\n                   ~ has_two_levels(.)))##     mpg   cyl  disp    hp  drat    wt\n## 1 FALSE FALSE FALSE FALSE FALSE FALSE\n##    qsec   vs   am  gear  carb\n## 1 FALSE TRUE TRUE FALSE FALSEis_binary <- function(var){\n  return(all(var %in% c(0,1)))\n}na_n <- function(num_vec) {\n  # input: num. vector (int or double)\n  # value: count of missing values (double)\n\n  if (!is.numeric(num_vec)) stop(\"Numeric input is needed!\")\n  out <- sum(is.na(num_vec))\n  return(out)\n\n}x <- c(1,2, NA, NA)\nx2 <- c(\"A\", \"B\", NA)\n\nna_n(x)## [1] 2na_n(x2)## Error in na_n(x2): Numeric input is needed!mtcars[1, c(1,2,3,4)] <- NA  # Zeilen/Spalte\n\nmtcars %>% \n  summarise(mpg_na_n = na_n(mpg))##   mpg_na_n\n## 1        1mtcars %>% \n  summarise(across(everything(), na_n)) ##   mpg cyl disp hp drat wt qsec vs am\n## 1   1   1    1  1    0  0    0  0  0\n##   gear carb\n## 1    0    0mtcars %>% \n  summarise(across(everything(), na_n)) %>% \n  pivot_longer(everything()) %>% \n  filter(value > 0)## # A tibble: 4 × 2\n##   name  value\n##   <chr> <int>\n## 1 mpg       1\n## 2 cyl       1\n## 3 disp      1\n## 4 hp        1data(flights, package = \"nycflights13\")\n\nflights %>% \n  select(where(is.numeric)) %>% \n  summarise(across(everything(),\n                   na_n)) %>% \n  pivot_longer(everything()) %>% \n  arrange(-value) %>%  # Sortiere absteigend nach Anzahl der fehlenden Werte\n  filter(value > 0)  # Zeige nur Variablen mit fehlenden Werten## # A tibble: 5 × 2\n##   name      value\n##   <chr>     <int>\n## 1 arr_delay  9430\n## 2 air_time   9430\n## 3 arr_time   8713\n## 4 dep_time   8255\n## 5 dep_delay  8255has_two_levels <- function(vec){\n\n  # input: vector of any type\n  # value: number of unique values (double)\n\n  tmp <- length(unique(vec))\n  tmp == 2\n}mtcars_hist <- function(col){\n  mtcars %>% \n    ggplot(aes(x = col)) +\n    geom_histogram()\n}mtcars %>% \n  select(where(is.numeric)) %>% \n  select(where(negate(has_two_levels))) %>%   # `!` zum Negieren geht leider nicht\n  map(mtcars_hist)## $mpg\n## \n## $cyl\n## \n## $disp\n## \n## $hp\n## \n## $drat\n## \n## $wt\n## \n## $qsec\n## \n## $gear\n## \n## $carb"},{"path":"r-zweiter-blick.html","id":"literatur-14","chapter":"Kapitel 5 R, zweiter Blick","heading":"5.7 Literatur","text":"","code":""},{"path":"tidymodels-1.html","id":"tidymodels-1","chapter":"Kapitel 6 tidymodels 1","heading":"Kapitel 6 tidymodels 1","text":"Benötigte R-Pakete für dieses Kapitel:","code":"\nlibrary(tidyverse)\nlibrary(tidymodels)"},{"path":"tidymodels-1.html","id":"daten","chapter":"Kapitel 6 tidymodels 1","heading":"6.1 Daten","text":"Dieser Abschnitt bezieht sich auf Kapitel 4 Silge Kuhn (2022).Wir benutzen den Datensatz zu Immobilienpreise aus dem Ames County Iowa, USA,\ngelegen im Zentrum des Landes.Hier wurde die AV log-transformiert.\nDas hat zwei (wichtige) Effekte:Die Verteilung ist symmetrischer, näher der Normalverteilung. Damit gibt es mehr Daten im Hauptbereich des Ranges von Sale_Price, die Vorhersagen stabiler machen dürfte.Logarithmiert man die Y-Variable, kommt dies einem multiplikativen Modell gleich, s. auch hier.","code":"\ndata(ames)  # Daten wurden über tidymodels mit geladen\names <- ames %>% mutate(Sale_Price = log10(Sale_Price))"},{"path":"tidymodels-1.html","id":"train--vs-test-datensatz-aufteilen","chapter":"Kapitel 6 tidymodels 1","heading":"6.2 Train- vs Test-Datensatz aufteilen","text":"Dieser Abschnitt bezieht sich auf Kapitel 5 Silge Kuhn (2022).Das Aufteilen Train- und Test-Datensatz ist einer der wesentlichen Grundsätze im maschinellen Lernen. Das Ziel ist, Overfitting abzuwenden.Im Train-Datensatz werden alle Modelle berechnet.\nDer Test-Datensatz wird nur einmal verwendet, und zwar zur Überprüfung der Modellgüte.QuellePraktisch funktioniert das Silge Kuhn (2022) wie folgt.Wir laden die Daten und erstellen einen Index,\nder jeder Beobachtung die Zuteilung zu Train- bzw. zum Test-Datensatz zuweist:initial_split() speichert für spätere komfortable Verwendung auch die Daten.\nAber eben auch der Index, der bestimmt, welche Beobachtung im Train-Set landet:Praktisch ist auch,\ndass die AV-Verteilung beiden Datensätzen ähnlich gehalten wird (Stratifizierung),\ndas besorgt das Argument strata.Die eigentlich Aufteilung die zwei Datensätze geht dann :","code":"\names_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_split$in_id %>% head(n = 10)##  [1]  2 27 28 31 32 33 35 79 83 87\nlength(ames_split$in_id)## [1] 2342\names_train <- training(ames_split)\names_test  <-  testing(ames_split)"},{"path":"tidymodels-1.html","id":"grundlagen-der-modellierung-mit-tidymodels","chapter":"Kapitel 6 tidymodels 1","heading":"6.3 Grundlagen der Modellierung mit tidymodels","text":"Dieser Abschnitt bezieht sich auf Kapitel 6 Silge Kuhn (2022).tidymodels ist eine Sammlung mehrerer, zusammengehöriger Pakete,\neben zum Thema statistische Modellieren.Das kann man analog zur Sammlung tidyverse verstehen,\nzu der z.B. das R-Paket dplyr gehört.Das R-Paket innerhalb von tidymodels, das zum “Fitten” von Modellen zuständig ist, heißt parsnip.Eine Liste der verfügbaren Modelltypen, Modellimplementierungen und Modellparameter, die Parsnip aktuell unterstützt werden, findet sich hier.","code":""},{"path":"tidymodels-1.html","id":"modelle-spezifizieren","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.1 Modelle spezifizieren","text":"Ein (statistisches) Modell wird Tidymodels mit drei Elementen spezifiziert, vgl. Abb. 6.1.\nFigure 6.1: Definition eines Models tidymodels\nDie Definition eines Modells tidymodels folgt diesen Ideen:Das Modell sollte unabhängig von den Daten spezifiert seinDas Modell sollte unabhängig von den Variablen (AV, UVs) spezifiziert seinDas Modell sollte unabhängig von etwaiger Vorverarbeitung (z.B. z-Transformation) spezifiziert seinDa bei einer linearen Regression nur der Modus “Regression” möglich ist,\nmuss der Modus diesem Fall nicht angegeben werden.\nTidymodels erkennt das automatisch.","code":"\nlm_model <-   \n  linear_reg() %>%   # Algorithmus, Modelltyp\n  set_engine(\"lm\")  # Implementierung\n  # Modus hier nicht nötig, da lineare Modelle immer numerisch klassifizieren"},{"path":"tidymodels-1.html","id":"modelle-berechnen","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.2 Modelle berechnen","text":"Nach Rhys (2020) ist ein Modell sogar erst ein Modell,\nwenn die Koeffizienten berechnet sind.\nTidymodels kennt diese Unterscheidung nicht.\nStattdessen spricht man Tidymodels von einem “gefitteten” Modell,\nsobald es berechnet ist.\nÄhnlich fancy könnte man von einem “instantiierten” Modell sprechen.Für das Beispiel der einfachen linearen Regression heißt das,\ndas Modell ist gefittet,\nsobald die Steigung und der Achsenabschnitt (sowie die Residualstreuung)\nberechnet sind.","code":"\nlm_form_fit <- \n  lm_model %>% \n  fit(Sale_Price ~ Longitude + Latitude, data = ames_train)"},{"path":"tidymodels-1.html","id":"vorhersagen","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.3 Vorhersagen","text":"Im maschinellen Lernen ist man primär den Vorhersagen interessiert,\nhäufig nur Punktschätzungen.\nSchauen wir uns also zunächst diese .Vorhersagen bekommt man recht einfach mit der predict() Methode:Die Syntax lautet predict(modell, daten_zum_vorhersagen).","code":"\npredict(lm_form_fit, new_data = ames_test) %>% \n  head()## # A tibble: 6 × 1\n##   .pred\n##   <dbl>\n## 1  5.28\n## 2  5.28\n## 3  5.25\n## 4  5.25\n## 5  5.24\n## 6  5.32"},{"path":"tidymodels-1.html","id":"vorhersagen-im-train-datensatz","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.4 Vorhersagen im Train-Datensatz","text":"Vorhersagen im Train-Datensatz machen keinen Sinn,\nda sie nicht gegen Overfitting geschützt sind und daher deutlich zu optimistisch sein können.Bei einer linearen Regression ist diese Gefahr nicht hoch,\naber bei anderen, flexibleren Modellen, ist diese Gefahr absurd groß.","code":""},{"path":"tidymodels-1.html","id":"modellkoeffizienten-im-train-datensatz","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.5 Modellkoeffizienten im Train-Datensatz","text":"Gibt man den Namen des Modellobjekts ein,\nwird ein Überblick relevanten Modellergebnissen Bildschirm gedruckt:Innerhalb des Ergebnisobjekts findet sich eine Liste namens fit,\nder die Koeffizienten (der “Fit”) abgelegt sind:Zum Herausholen dieser Infos kann man auch die Funktion extract_fit_engine() verwenden:Das extrahierte Objekt ist, diesem Fall,\ndas typische lm() Objekt.\nEntsprechend kann man daruaf coef() oder summary() anwenden.Schicker sind die Pendant-Befehle aus broom,\ndie jeweils einen Tibble zuückliefern:","code":"\nlm_form_fit## parsnip model object\n## \n## Fit time:  4ms \n## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -308.147       -2.061        2.863\nlm_form_fit %>% pluck(\"fit\")## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -308.147       -2.061        2.863\nlm_fit <-\n  lm_form_fit %>% \n  extract_fit_engine()\n\nlm_fit## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -308.147       -2.061        2.863\ncoef(lm_fit)## (Intercept)   Longitude    Latitude \n## -308.146695   -2.061468    2.862578\nsummary(lm_fit)## \n## Call:\n## stats::lm(formula = Sale_Price ~ Longitude + Latitude, data = data)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -1.02911 -0.09966 -0.01743  0.09762  0.57613 \n## \n## Coefficients:\n##              Estimate Std. Error t value Pr(>|t|)    \n## (Intercept) -308.1467    14.6917  -20.97   <2e-16 ***\n## Longitude     -2.0615     0.1304  -15.80   <2e-16 ***\n## Latitude       2.8626     0.1823   15.70   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.1618 on 2339 degrees of freedom\n## Multiple R-squared:  0.1691, Adjusted R-squared:  0.1684 \n## F-statistic: 238.1 on 2 and 2339 DF,  p-value: < 2.2e-16\nlibrary(broom)\ntidy(lm_fit) # Koeffizienten## # A tibble: 3 × 5\n##   term        estimate std.error statistic  p.value\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)  -308.      14.7       -21.0 1.22e-89\n## 2 Longitude      -2.06     0.130     -15.8 1.56e-53\n## 3 Latitude        2.86     0.182      15.7 6.60e-53\nglance(lm_fit) # Modellgüte## # A tibble: 1 × 12\n##   r.squared adj.r.squared sigma statistic  p.value    df logLik    AIC    BIC\n##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl>  <dbl>  <dbl>\n## 1     0.169         0.168 0.162      238. 7.65e-95     2   944. -1880. -1857.\n## # … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>"},{"path":"tidymodels-1.html","id":"parsnip-rstudio-add-in","chapter":"Kapitel 6 tidymodels 1","heading":"6.3.6 Parsnip RStudio add-in","text":"Mit dem Add-von Parsnip kann man sich eine Modellspezifikation per Klick ausgeben lassen.\nNett!","code":"\nparsnip_addin()"},{"path":"tidymodels-1.html","id":"workflows","chapter":"Kapitel 6 tidymodels 1","heading":"6.4 Workflows","text":"Dieser Abschnitt bezieht sich auf Kapitel 7 Silge Kuhn (2022).","code":""},{"path":"tidymodels-1.html","id":"konzept-des-workflows-in-tidymodels","chapter":"Kapitel 6 tidymodels 1","heading":"6.4.1 Konzept des Workflows in Tidymodels","text":"\nFigure 6.2: Definition eines Models tidymodels\n","code":""},{"path":"tidymodels-1.html","id":"einfaches-beispiel","chapter":"Kapitel 6 tidymodels 1","heading":"6.4.2 Einfaches Beispiel","text":"Wir initialisieren einen Workflow,\nverzichten auf Vorverarbeitung und fügen ein Modell hinzu:Werfen wir einen Blick das Workflow-Objekt:Wie man sieht,\ngehört die Modellformel (y ~ x) zur Vorverarbeitung\naus Sicht von Tidymodels.war nochmal im Objekt lm_model enthalten?Jetzt können wir das Modell berechnen (fitten):Natürlich kann man synonym auch schreiben:Schauen wir uns das Ergebnis :","code":"\nlm_workflow <- \n  workflow() %>%  # init\n  add_model(lm_model) %>%   # Modell hinzufügen\n  add_formula(Sale_Price ~ Longitude + Latitude)  # Modellformel hinzufügen\nlm_workflow## ══ Workflow ════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\nlm_model## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\nlm_fit <- \n  lm_workflow %>%\n  fit(ames_train)\nlm_fit <- fit(lm_wflow, ames_train)\nlm_fit## ══ Workflow [trained] ══════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ───────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##    -308.147       -2.061        2.863"},{"path":"tidymodels-1.html","id":"vorhersage-mit-einem-workflow","chapter":"Kapitel 6 tidymodels 1","heading":"6.4.3 Vorhersage mit einem Workflow","text":"Die Vorhersage mit einem Tidymodels-Workflow ist einerseits komfortabel,\nda man einfach sagen kann:“Nimm die richtigen Koeffizienten des Modells aus dem Train-Set\nund wende sie auf das Test-Sample . Berechne mir\ndie Vorhersagen und die Modellgüte.”sieht das aus:Anderseits wird auch ein recht komplexes Objekt zurückgeliefert,\ndas man erst mal durchschauen muss.Wie man sieht, gibt es mehrere Listenspalten.\nBesonders interessant erscheinen natürlich die Listenspalten .metrics und .predictions.Schauen wir uns die Vorhersagen .Es gibt auch eine Funktion, die obige Zeile vereinfacht (also synonym ist):","code":"\nfinal_lm_res <- last_fit(lm_workflow, ames_split)\nfinal_lm_res## # Resampling results\n## # Manual resampling \n## # A tibble: 1 × 6\n##   splits             id               .metrics .notes   .predictions .workflow \n##   <list>             <chr>            <list>   <list>   <list>       <list>    \n## 1 <split [2342/588]> train/test split <tibble> <tibble> <tibble>     <workflow>\nlm_preds <- final_lm_res %>% pluck(\".predictions\", 1)\nlm_preds <- collect_predictions(final_lm_res)\nlm_preds %>% slice_head(n = 5)## # A tibble: 5 × 5\n##   id               .pred  .row Sale_Price .config             \n##   <chr>            <dbl> <int>      <dbl> <chr>               \n## 1 train/test split  5.28     8       5.28 Preprocessor1_Model1\n## 2 train/test split  5.28     9       5.37 Preprocessor1_Model1\n## 3 train/test split  5.25    21       5.28 Preprocessor1_Model1\n## 4 train/test split  5.25    22       5.23 Preprocessor1_Model1\n## 5 train/test split  5.24    30       4.98 Preprocessor1_Model1"},{"path":"tidymodels-1.html","id":"modellgüte","chapter":"Kapitel 6 tidymodels 1","heading":"6.4.4 Modellgüte","text":"Dieser Abschnitt bezieht sich auf Kapitel 9 Silge Kuhn (2022).Die Vorhersagen bilden die Basis für die Modellgüte (“Metriken”),\ndie schon fertig berechnet im Objekt final_lm_res liegen und mit\ncollect_metrics herausgenommen werden können:Man kann auch angeben,\nwelche Metriken der Modellgüte man bekommen möchte:","code":"\nlm_metrics <- collect_metrics(final_lm_res)\names_metrics <- metric_set(rmse, rsq, mae)\names_metrics(data = lm_preds, \n             truth = Sale_Price, \n             estimate = .pred)## # A tibble: 3 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard       0.158\n## 2 rsq     standard       0.186\n## 3 mae     standard       0.121"},{"path":"tidymodels-1.html","id":"vorhersage-von-hand","chapter":"Kapitel 6 tidymodels 1","heading":"6.4.5 Vorhersage von Hand","text":"Man kann sich die Metriken auch von Hand ausgeben lassen,\nwenn man direktere Kontrolle haben möchte als mit last_fit und collect_metrics.Jetzt binden wir die Spalten zusammen, also die “Wahrheit” (\\(y\\)) und die Vorhersagen:Andere Koeffizienten der Modellgüte können mit rmse oder mae abgerufen werden.","code":"\names_test_small <- ames_test %>% slice(1:5)\npredict(lm_form_fit, new_data = ames_test_small)## # A tibble: 5 × 1\n##   .pred\n##   <dbl>\n## 1  5.28\n## 2  5.28\n## 3  5.25\n## 4  5.25\n## 5  5.24\names_test_small2 <- \n  ames_test_small %>% \n  select(Sale_Price) %>% \n  bind_cols(predict(lm_form_fit, ames_test_small)) %>% \n  # Add 95% prediction intervals to the results:\n  bind_cols(predict(lm_form_fit, ames_test_small, type = \"pred_int\")) \nrsq(ames_test_small2, \n   truth = Sale_Price,\n   estimate = .pred\n   )## # A tibble: 1 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rsq     standard       0.602"},{"path":"tidymodels-1.html","id":"rezepte-zur-vorverarbeitung","chapter":"Kapitel 6 tidymodels 1","heading":"6.5 Rezepte zur Vorverarbeitung","text":"Dieser Abschnitt bezieht sich auf Kapitel 8 Silge Kuhn (2022).","code":""},{"path":"tidymodels-1.html","id":"was-ist-rezept-und-wozu-ist-es-gut","chapter":"Kapitel 6 tidymodels 1","heading":"6.5.1 Was ist Rezept und wozu ist es gut?","text":"könnte ein typischer Aufruf von lm() aussehen:Neben dem Fitten des Modells besorgt die Formel-Schreibweise noch einige zusätzliche nützliche Vorarbeitung:Definition von AV und AVLog-Transformation von Gr_Liv_AreaTransformation der nominalen Variablen Dummy-VariablenDas ist schön und nütlich, hat aber auch Nachteile:Das Modell wird nicht nur spezifiziert, sondern auch gleich berechnet. Das ist unpraktisch, weil man die Modellformel vielleicht anderen Modell wiederverwenden möchte. Außerdem kann das Berechnen lange dauern.Die Schritte sind ineinander vermengt, dass man nicht einfach und übersichtlich die einzelnen Schritte bearbeiten kann.Praktischer wäre also, die Schritte der Vorverarbeitung zu ent-flechten.\nDas geht mit einem “Rezept” aus Tidmoodels:Ein Rezept berechnet kein Modell. Es macht nichts außer die Vorverarbeitung des Modells zu spezizifieren (inklusive der Modellformel).","code":"\nlm(Sale_Price ~ Neighborhood + log10(Gr_Liv_Area) + Year_Built + Bldg_Type, data = ames)\nsimple_ames <- \n  recipe(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type,\n         data = ames_train) %>%\n  step_log(Gr_Liv_Area, base = 10) %>% \n  step_dummy(all_nominal_predictors())\nsimple_ames## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##    outcome          1\n##  predictor          4\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()"},{"path":"tidymodels-1.html","id":"workflows-mit-rezepten","chapter":"Kapitel 6 tidymodels 1","heading":"6.5.2 Workflows mit Rezepten","text":"Jetzt definieren wir den Workflow nicht nur mit einer Modellformel,\nsondern mit einem Rezept:Sonst hat sich nichts geändert.Wie vorher, können wir jetzt das Modell berechnen.","code":"\nlm_workflow <-\n  workflow() %>% \n  add_model(lm_model) %>% \n  add_recipe(simple_ames)\nlm_fit <- fit(lm_workflow, ames_train)\nfinal_lm_res <- last_fit(lm_workflow, ames_split)\nfinal_lm_res## # Resampling results\n## # Manual resampling \n## # A tibble: 1 × 6\n##   splits             id               .metrics .notes   .predictions .workflow \n##   <list>             <chr>            <list>   <list>   <list>       <list>    \n## 1 <split [2342/588]> train/test split <tibble> <tibble> <tibble>     <workflow>\nlm_metrics <- collect_metrics(final_lm_res)\nlm_metrics## # A tibble: 2 × 4\n##   .metric .estimator .estimate .config             \n##   <chr>   <chr>          <dbl> <chr>               \n## 1 rmse    standard      0.0806 Preprocessor1_Model1\n## 2 rsq     standard      0.789  Preprocessor1_Model1"},{"path":"tidymodels-1.html","id":"spaltenrollen","chapter":"Kapitel 6 tidymodels 1","heading":"6.5.3 Spaltenrollen","text":"Eine praktische Funktion ist es,\nbestimmte Spalten nicht als Prädiktor,\nsondern als ID-Variable zu nutzen.\nDas kann man Tidymodels komfortabel wie folgt angeben:","code":"\names_recipe <-\n  simple_ames %>% \n  update_role(Neighborhood, new_role = \"id\")\n\names_recipe## Recipe\n## \n## Inputs:\n## \n##       role #variables\n##         id          1\n##    outcome          1\n##  predictor          3\n## \n## Operations:\n## \n## Log transformation on Gr_Liv_Area\n## Dummy variables from all_nominal_predictors()"},{"path":"tidymodels-1.html","id":"fazit","chapter":"Kapitel 6 tidymodels 1","heading":"6.5.4 Fazit","text":"Mehr zu Rezepten findet sich hier.\nEin Überblick zu allen Schritten der Vorverarbeitung findet sich hier.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
