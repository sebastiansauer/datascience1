<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Kapitel 10 Ensemble Lerner | DataScience1</title>
<meta name="author" content="Sebastian Sauer">
<meta name="description" content="10.1 Lernsteuerung  10.1.1 Lernziele Sie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest Sie wissen, anhand welche Tuningparamter man Overfitting...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Kapitel 10 Ensemble Lerner | DataScience1">
<meta property="og:type" content="book">
<meta property="og:description" content="10.1 Lernsteuerung  10.1.1 Lernziele Sie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest Sie wissen, anhand welche Tuningparamter man Overfitting...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kapitel 10 Ensemble Lerner | DataScience1">
<meta name="twitter:description" content="10.1 Lernsteuerung  10.1.1 Lernziele Sie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest Sie wissen, anhand welche Tuningparamter man Overfitting...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.9/grViz.js"></script><script src="libs/es6shim-0.35.6/es6shim.js"></script><script src="libs/es7shim-6.0.0/es7shim.js"></script><script src="libs/graphre-0.1.3/graphre.js"></script><script src="libs/nomnoml-1.4.0/nomnoml.js"></script><script src="libs/nomnoml-binding-0.2.5/nomnoml.js"></script><script src="libs/d3-3.3.8/d3.min.js"></script><script src="libs/dagre-0.4.0/dagre-d3.min.js"></script><link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet">
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script><script src="libs/chromatography-0.1/chromatography.js"></script><script src="libs/DiagrammeR-binding-1.0.9/DiagrammeR.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style-bs4.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Grundlagen der Prognosemodellierung üîÆüß∞">DataScience1</a>:
        <small class="text-muted">Grundlagen der Prognosemodellierung üîÆüß∞</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Zu diesem Buch</a></li>
<li><a class="" href="hinweise.html"><span class="header-section-number">1</span> Hinweise</a></li>
<li><a class="" href="pr%C3%BCfung.html"><span class="header-section-number">2</span> Pr√ºfung</a></li>
<li class="book-part">Themen</li>
<li><a class="" href="statistisches-lernen.html"><span class="header-section-number">3</span> Statistisches Lernen</a></li>
<li><a class="" href="r-zweiter-blick.html"><span class="header-section-number">4</span> R, zweiter Blick</a></li>
<li><a class="" href="tidymodels.html"><span class="header-section-number">5</span> tidymodels</a></li>
<li><a class="" href="knn.html"><span class="header-section-number">6</span> kNN</a></li>
<li><a class="" href="resampling-und-tuning.html"><span class="header-section-number">7</span> Resampling und Tuning</a></li>
<li><a class="" href="logistische-regression.html"><span class="header-section-number">8</span> Logistische Regression</a></li>
<li><a class="" href="entscheidungsb%C3%A4ume.html"><span class="header-section-number">9</span> Entscheidungsb√§ume</a></li>
<li><a class="active" href="ensemble-lerner.html"><span class="header-section-number">10</span> Ensemble Lerner</a></li>
<li><a class="" href="regularisierte-modelle.html"><span class="header-section-number">11</span> Regularisierte Modelle</a></li>
<li><a class="" href="kaggle.html"><span class="header-section-number">12</span> Kaggle</a></li>
<li><a class="" href="der-rote-faden.html"><span class="header-section-number">13</span> Der rote Faden</a></li>
<li><a class="" href="fallstudien.html"><span class="header-section-number">14</span> Fallstudien</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/sebastiansauer/datascience1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ensemble-lerner" class="section level1" number="10">
<h1>
<span class="header-section-number">Kapitel 10</span> Ensemble Lerner<a class="anchor" aria-label="anchor" href="#ensemble-lerner"><i class="fas fa-link"></i></a>
</h1>
<!-- ```{r global-knitr-options, include=FALSE} -->
<!--   knitr::opts_chunk$set( -->
<!--   fig.pos = 'H', -->
<!--   fig.asp = 0.618, -->
<!--   fig.align='center', -->
<!--   fig.width = 5, -->
<!--   out.width = "100%", -->
<!--   fig.cap = "",  -->
<!--   dpi = 300, -->
<!--   # tidy = TRUE, -->
<!--   echo = FALSE, -->
<!--   message = FALSE, -->
<!--   warning = FALSE, -->
<!--   cache = TRUE, -->
<!--   fig.show = "hold") -->
<!-- ``` -->
<div id="lernsteuerung-7" class="section level2" number="10.1">
<h2>
<span class="header-section-number">10.1</span> Lernsteuerung<a class="anchor" aria-label="anchor" href="#lernsteuerung-7"><i class="fas fa-link"></i></a>
</h2>
<div id="lernziele-7" class="section level3" number="10.1.1">
<h3>
<span class="header-section-number">10.1.1</span> Lernziele<a class="anchor" aria-label="anchor" href="#lernziele-7"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Sie k√∂nnen Algorithmen f√ºr Ensemble-Lernen erkl√§ren, d.i. Bagging, AdaBoost, XGBoost, Random Forest</li>
<li>Sie wissen, anhand welche Tuningparamter man Overfitting bei diesen Algorithmen begrenzen kann</li>
<li>Sie k√∂nnen diese Verfahren in R berechnen</li>
</ul>
</div>
<div id="literatur-7" class="section level3" number="10.1.2">
<h3>
<span class="header-section-number">10.1.2</span> Literatur<a class="anchor" aria-label="anchor" href="#literatur-7"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Rhys, Kap. 8</li>
</ul>
</div>
<div id="hinweise-3" class="section level3" number="10.1.3">
<h3>
<span class="header-section-number">10.1.3</span> Hinweise<a class="anchor" aria-label="anchor" href="#hinweise-3"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><a href="https://stackoverflow.com/questions/72333419/error-on-running-predict-in-tidymodels-error-in-dplyrselect-cant-su/72341769#72341769">Nutzen Sie StackOverflow als Forum f√ºr Ihre Fragen - Hier ein Beispiel zu einer Fehlermeldung, die mir Kopfzerbrechen bereitete</a></li>
</ul>
</div>
</div>
<div id="vorbereitung-7" class="section level2" number="10.2">
<h2>
<span class="header-section-number">10.2</span> Vorbereitung<a class="anchor" aria-label="anchor" href="#vorbereitung-7"><i class="fas fa-link"></i></a>
</h2>
<p>In diesem Kapitel werden folgende R-Pakete ben√∂tigt:</p>
<div class="sourceCode" id="cb406"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidymodels.tidymodels.org">tidymodels</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/collectivemedia/tictoc">tictoc</a></span><span class="op">)</span>  <span class="co"># Zeitmessung</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/koalaverse/vip/">vip</a></span><span class="op">)</span>  <span class="co"># Variable importance plot</span></code></pre></div>
</div>
<div id="hinweise-zur-literatur" class="section level2" number="10.3">
<h2>
<span class="header-section-number">10.3</span> Hinweise zur Literatur<a class="anchor" aria-label="anchor" href="#hinweise-zur-literatur"><i class="fas fa-link"></i></a>
</h2>
<p>Die folgenden Ausf√ºhrungen basieren prim√§r auf <span class="citation">Rhys (<a href="references.html#ref-rhys" role="doc-biblioref">2020</a>)</span>, aber auch auf <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span> und (weniger) <span class="citation">Kuhn and Johnson (<a href="references.html#ref-kuhn" role="doc-biblioref">2013</a>)</span>.</p>
</div>
<div id="wir-brauchen-einen-wald" class="section level2" number="10.4">
<h2>
<span class="header-section-number">10.4</span> Wir brauchen einen Wald<a class="anchor" aria-label="anchor" href="#wir-brauchen-einen-wald"><i class="fas fa-link"></i></a>
</h2>
<p>Ein Pluspunkt von Entscheidungsb√§umen ist ihre gute Interpretierbarkeit.
Man k√∂nnte behaupten, dass B√§ume eine typische Art des menschlichen Entscheidungsverhalten
nachahmen: ‚ÄúWenn A, dann tue B, ansonsten tue C‚Äù (etc.).
Allerdings: Einzelne Entscheidungsb√§ume haben oft keine so gute Prognosegenauigkeit.
Der oder zumindest ein Grund ist, dass sie (zwar wenig Bias aber) viel Varianz aufweisen.
Das sieht man z.B. daran, dass die Vorhersagegenauigkeit stark schwankt,
w√§hlt man eine andere Aufteilung von Train- vs.¬†Test-Sample.
Anders gesagt: B√§ume overfitten ziemlich schnell.
Und obwohl das No-Free-Lunch-Theorem zu den Grundfesten des maschinellen Lernens
(oder zu allem wissenschaftlichen Wissen) geh√∂rt,
kann man festhalten, dass sog. <em>Ensemble-Lernen</em> fast immer besser sind
als einzelne Baummodelle.
Kurz gesagt: Wir brauchen einen Wald: üå≥üå≥üå≥<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;√úbrigens geh√∂rt zu den weiteren Vorteilen von B√§umen, dass sie die Temperatur absenken; zu Zeiten von Hitzewellen k√∂nnte das praktisch sein. Ansonsten erzeugen sie aber nur Luft und haben auch sonst kaum erkennbaren Nutzen.&lt;/p&gt;"><sup>4</sup></a></p>
</div>
<div id="was-ist-ein-ensemble-lerner" class="section level2" number="10.5">
<h2>
<span class="header-section-number">10.5</span> Was ist ein Ensemble-Lerner?<a class="anchor" aria-label="anchor" href="#was-ist-ein-ensemble-lerner"><i class="fas fa-link"></i></a>
</h2>
<p>Ensemble-Lerner kombinieren mehrere schwache Lerner zu einem starken Lerner.
Das Paradebeispiel sind baumbasierte Modelle;
darauf wird sich die folgende Ausf√ºhrung auch begrenzen.
Aber theoretisch kann man jede Art von Lerner kombinieren.
Bei numerischer Pr√§diktion wird bei Ensemble-Lerner zumeist der Mittelwert als Optmierungskriterium
herangezogen; bei Klassifikation (nominaler Pr√§diktion) hingegen die modale Klasse (also die h√§ufigste).
Warum hilft es, mehrere Modelle (Lerner) zu einem zu aggregieren?
Die Antwort lautet, dass die Streuung der Mittelwerte sinkt,
wenn die Stichprobengr√∂√üe steigt.
Zieht man Stichproben der Gr√∂√üe 1, werden die Mittelwerte stark variieren,
aber bei gr√∂√üeren Stichproben (z.B. Gr√∂√üe 100) deutlich weniger<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;bei Fat-Tails-Variablen muss man diese Aussage einschr√§nken&lt;/p&gt;"><sup>5</sup></a>.
Die Streuung der Mittelwerte in den Stichproben nennt man bekanntlich <em>Standardefehler</em> (se).
Den se des Mittelwerts (<span class="math inline">\(se_M\)</span>) f√ºr eine normalverteilte Variable <span class="math inline">\(X \sim \mathcal{N}(\mu, \sigma)\)</span> gilt:
<span class="math inline">\(se_{M} = \sigma / \sqrt(n)\)</span>, wobei <span class="math inline">\(\sigma\)</span> die SD der Verteilung und <span class="math inline">\(\mu\)</span> den Erwartungswert (‚ÄúMittelwert‚Äù) meint,
und <span class="math inline">\(n\)</span> ist die Stichprobengr√∂√üe.</p>
<div class="infobox quote">
<p>Je gr√∂√üer die Stichprobe, desto kleiner die Varianz des Sch√§tzers (ceteris paribus).
Anders gesagt: Gr√∂√üere Stichproben sch√§tzen genauer als kleine Stichproben.</p>
</div>
<p>Aus diesem Grund bietet es sich an,
schwache Lerner mit viel Varianz zu kombinieren,
da die Varianz so verringert wird.</p>
</div>
<div id="bagging" class="section level2" number="10.6">
<h2>
<span class="header-section-number">10.6</span> Bagging<a class="anchor" aria-label="anchor" href="#bagging"><i class="fas fa-link"></i></a>
</h2>
<div id="bootstrapping" class="section level3" number="10.6.1">
<h3>
<span class="header-section-number">10.6.1</span> Bootstrapping<a class="anchor" aria-label="anchor" href="#bootstrapping"><i class="fas fa-link"></i></a>
</h3>
<p>Das erste baumbasierte Modell, was vorgestellt werden soll,
basiert auf sog. <em>Bootstrapping</em>, ein Standardverfahren in der Statistik <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>.</p>
<p>Bootstrapping ist eine Nachahmung f√ºr folgende Idee:
H√§tte man viele Stichproben aus der relevanten Verteilung,
so k√∂nnte man z.B. die Genauigkeit eines Modells <span class="math inline">\(\hat{f}_{\bar{X}}\)</span> zur Sch√§tzung des Erwartungswertes <span class="math inline">\(\mu\)</span> einfach dadurch bestimmen,
indem man <em>se</em> berechnet, also die Streuung der Mitterwerte <span class="math inline">\(\bar{X}\)</span> berechnet.
Au√üerdem gilt, dass die Pr√§zision der Sch√§tzung des Erwartungswerts steigt mit steigendem Stichprobenumfang <span class="math inline">\(n\)</span>.
Wir k√∂nnten also f√ºr jede der <span class="math inline">\(B\)</span> Stichproben, <span class="math inline">\(b=1,\ldots, B\)</span>, ein (Baum-)Modell berechnen, <span class="math inline">\(\hat{f}^b\)</span>,
und dann deren Vorhersagen aggregieren (zum Mittelwert oder Modalwert).
Das kann man formal so darstellen <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>:</p>
<p><span class="math display">\[\hat{f}_{\bar{X}} = \frac{1}{B}\sum_{b=1}^{B}\hat{f}^b\]</span></p>
<p>Mit diesem Vorgehen kann die Varianz des Modells <span class="math inline">\(\hat{f}_{\bar{X}}\)</span> verringert werden;
die Vorhersagegenauigkeit steigt.</p>
<p>Leider haben wir in der Regel nicht viele (<span class="math inline">\(B\)</span>) Datens√§tze.</p>
<p>Daher ‚Äúbauen‚Äù wir uns aus dem einzelnen Datensatz, der uns zur Verf√ºgung steht,
viele Datens√§tze.
Das h√∂rt sich nach ‚Äútoo good to be true‚Äù an<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Wenn es einen No-Free-Lunch-Satz gibt, m√ºsste es auch einen Too-Good-to-be-True-Satz geben, den wir hiermit postulieren.&lt;/p&gt;"><sup>6</sup></a>
Weil es sich unglaubw√ºrdig anh√∂rt, nennt man das entsprechende Verfahren (gleich kommt es!) auch ‚ÄúM√ºnchhausen-Methode‚Äù,
nach dem ber√ºhmten L√ºbgenbaron.
Die Amerikaner ziehen sich √ºbrigens nicht am Schopf aus dem Sumpf, sondern
mit den Stiefelschlaufen (die Cowboys wieder),
daher spricht man im Amerikanischen auch von der ‚ÄúBoostrapping-Methode‚Äù.</p>
<p>Diese ‚ÄúPseudo-Stichproben‚Äù oder ‚ÄúBootstrapping-Stichproben‚Äù sind aber recht einfach zu gewinnen..
Gegeben sei Stichprobe der Gr√∂√üe <span class="math inline">\(n\)</span>:</p>
<ol style="list-style-type: decimal">
<li>Ziehe mit Zur√ºcklegen (ZmZ) aus der Stichprobe <span class="math inline">\(n\)</span> Beobachtungen</li>
<li>Fertig ist die Bootstrapping-Stichprobe.</li>
</ol>
<p>Abb. <a href="ensemble-lerner.html#fig:zmz">10.1</a> verdeutlicht das Prinzip des ZMZ, d.h. des Bootstrappings.
Wie man sieht, sind die Bootstrap-Stichproben (rechts) vom gleichen Umfang <span class="math inline">\(n\)</span>
wie die Originalstichprobe (links).
Allerdins kommen nicht alle F√§lle (in der Regel) in den ‚ÄúBoostrap-Beutel‚Äù (in bag),
sondern einige F√§lle werden oft mehrfach gezogen, so dass
einige F√§lle nicht gezogen werden (out of bag).</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:zmz"></span>
<img src="img/zmz.png" alt="Bootstrapping: Der Topf links symbolisiert die Original-Stichprobe, aus der wir hier mehrere ZMZ-Stichproben ziehen (Rechts), dargestellt mit 'in bag'" width="70%"><p class="caption">
Abbildung 10.1: Bootstrapping: Der Topf links symbolisiert die Original-Stichprobe, aus der wir hier mehrere ZMZ-Stichproben ziehen (Rechts), dargestellt mit ‚Äòin bag‚Äô
</p>
</div>
<p>Man kann zeigen, dass ca. 2/3 der F√§lle gezogen werden,
bzw. ca. 1/3 nicht gezogen werden. Die nicht gezogenen F√§lle nennt man auch <em>out of bag</em> (OOB).</p>
<p>F√ºr die Entwicklung des Bootstrapping wurde der Autor, Bradley Efron, im Jahr 2018
mit dem internationalen Preis f√ºr Statistik <a href="https://www.amstat.org/news-listing/2021/10/08/international-prize-in-statistics-awarded-to-bradley-efron">ausgezeichnet</a>;</p>
<blockquote>
<p>‚ÄúWhile statistics offers no magic pill for quantitative scientific investigations, the bootstrap is the best statistical pain reliever ever produced,‚Äù says Xiao-Li Meng, Whipple V. N. Jones Professor of Statistics at Harvard University.‚Äú</p>
</blockquote>
</div>
</div>
<div id="bagging-algorithmus" class="section level2" number="10.7">
<h2>
<span class="header-section-number">10.7</span> Bagging-Algorithmus<a class="anchor" aria-label="anchor" href="#bagging-algorithmus"><i class="fas fa-link"></i></a>
</h2>
<p>Bagging, die Kurzform f√ºr <em>B</em>ootstrap-<em>Agg</em>regation ist wenig mehr als die Umsetzung des Boostrappings.</p>
<p>Der Algorithmus von Bagging kann so beschrieben werden:</p>
<ol style="list-style-type: decimal">
<li>W√§hle <span class="math inline">\(B\)</span>, die Anzahl der Boostrap-Stichproben und damit auch Anzahl der Submodelle (Lerner)</li>
<li>Ziehe <span class="math inline">\(B\)</span> Boostrap-Stichproben</li>
<li>Berechne das Modell <span class="math inline">\(\hat{f}^{*b}\)</span> f√ºr jede der <span class="math inline">\(B\)</span> Stichproben (typischerweise ein einfacher Baum)</li>
<li>Schicke die Test-Daten durch jedes Sub-Modell</li>
<li>Aggregiere ihre Vorhersage zu einem Wert (Modus bzw. Mittelwert) pro Fall aus dem Test-Sample, zu <span class="math inline">\(\hat{f}_{\text{bag}}\)</span>
</li>
</ol>
<p>Anders gesagt:</p>
<p><span class="math display">\[\hat{f}_{\text{bag}} = \frac{1}{B}\sum_{b=1}^{B}\hat{f}^{*b}\]</span></p>
<p>Der Bagging-Algorithmus ist in Abbildung <a href="ensemble-lerner.html#fig:bag">10.2</a> dargestellt.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bag"></span>
<div id="htmlwidget-f81ebad18c390154e66f" style="width:70%;height:350px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-f81ebad18c390154e66f">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n\n  [<database> Datensatz] ->zmz [Baum 1]\n[<database> Datensatz] ->zmz [Baum 2]\n[<database> Datensatz] ->zmz [Baum ...]\n[<database> Datensatz] ->zmz [Baum B]\n[Baum 1] -> [Modus als Vorhersagewert]\n[Baum 2] -> [Modus als Vorhersagewert]\n[Baum ...] -> [Modus als Vorhersagewert]\n[Baum B] -> [Modus als Vorhersagewert]\n  ","svg":false,"png":null},"evals":[],"jsHooks":[]}</script><p class="caption">
Abbildung 10.2: Bagging schematisch illustriert
</p>
</div>
<p>Die Anzahl der B√§ume (allgemeiner: Submodelle) <span class="math inline">\(B\)</span> ist h√§ufig im oberen drei- oder niedrigem vierstelligen
Bereich, z.B. <span class="math inline">\(B=1000\)</span>.
Eine gute Nachricht ist, dass Bagging nicht √ºberanpasst, wenn <span class="math inline">\(B\)</span> gro√ü wird.</p>
<div id="variablenrelevanz" class="section level3" number="10.7.1">
<h3>
<span class="header-section-number">10.7.1</span> Variablenrelevanz<a class="anchor" aria-label="anchor" href="#variablenrelevanz"><i class="fas fa-link"></i></a>
</h3>
<p>Man kann die Relevanz der Pr√§diktoren in einem Bagging-Modell auf mehrere Arten sch√§tzen.
Ein Weg (bei numerischer Pr√§diktion) ist, dass man die RSS-Verringerung, die durch Aufteilung anhand eines Pr√§diktors
erzeugt wird, mittelt √ºber alle beteiligten B√§ume (Modelle).
Bei Klassifikation kann man die analog die Reduktion des Gini-Wertes √ºber alle B√§ume mitteln
und als Sch√§tzwert f√ºr die Relevanz des Pr√§diktors heranziehen.</p>
</div>
<div id="out-of-bag-vorhersagen" class="section level3" number="10.7.2">
<h3>
<span class="header-section-number">10.7.2</span> Out of Bag Vorhersagen<a class="anchor" aria-label="anchor" href="#out-of-bag-vorhersagen"><i class="fas fa-link"></i></a>
</h3>
<p>Da nicht alle F√§lle der Stichprobe in das Modell einflie√üen (sondern nur ca. 2/3),
kann der Rest der F√§lle zur Vorhersage genutzt werden.
Bagging erzeugt sozusagen innerhalb der Stichprobe selbst√§ndig ein Train- und ein Test-Sample.
Man spricht von <em>Out-of-Bag-Sch√§tzung</em> (OOB-Sch√§tzung).
Der OOB-Fehler (z.B. MSE bei numerischen Modellen und Genauigkeit bei nominalen)
ist eine valide Sch√§tzung des typischen Test-Sample-Fehlers.</p>
<p>Hat man aber Tuningparameter, so wird man dennoch auf die typische Train-Test-Aufteilung
zur√ºckgreifen, um Overfitting durch das Ausprobieren der Tuning-Kandidaten zu vermeiden
(was sonst zu Zufallstreffern f√ºhren w√ºrde bei gen√ºgend vielen Modellkandidaten).</p>
</div>
</div>
<div id="random-forests" class="section level2" number="10.8">
<h2>
<span class="header-section-number">10.8</span> Random Forests<a class="anchor" aria-label="anchor" href="#random-forests"><i class="fas fa-link"></i></a>
</h2>
<p>Random Forests (‚ÄúZufallsw√§lder‚Äù) sind eine Weiterentwicklung von Bagging-Modellen.
Sie <em>sind</em> Bagging-Modelle, aber haben noch ein Ass im √Ñrmel:
Und zwar wird an jedem Slit (Astgabel, Aufteilung) <em>nur eine Zufallsauswahl an <span class="math inline">\(m\)</span> Pr√§diktoren ber√ºcksichtigt</em>.
Das h√∂rt sich verr√ºckt an: ‚ÄúWie, mit weniger Pr√§diktoren soll eine bessere Vorhersage erreicht werden?!‚Äù
Ja, genau so ist es!
Nehmen Sie an, es gibt im Datensatz einen sehr starken und ein paar mittelstarke Pr√§diktoren;
der Rest der Pr√§diktoren ist wenig relevant.
Wenn Sie jetzt viele ‚Äúgebootstrapte‚Äù<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Schlimmes Denglisch&lt;/p&gt;"><sup>7</sup></a> ziehen,
werden diese B√§ume sehr √§hnlich sein: Der st√§rkste Pr√§diktor steht vermutlich immer ob an der Wurzel,
dann kommen die mittelstarken Pr√§diktoren.
Jeder zus√§tzliche Baum tr√§gt dann wenig neue Information bei.
Anders gesagt: Die Vorhersagen der B√§ume sind dann sehr √§hnlich bzw. hoch korreliert.
Bildet man den Mittelwert von hoch korrelierten Variablen,
verringert sich leider die Varianzu nur <em>wenig</em> im Vergleich zu nicht oder gering korrelierten Variablen <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>.
Dadurch dass Random Forests nur <span class="math inline">\(m\)</span> der <span class="math inline">\(p\)</span> Pr√§diktoren pro Split zulassen,
werden die B√§ume unterschiedlicher. Wir ‚Äúdekorrelieren‚Äù die B√§ume.
Bildet man den Mittelwert von gering(er) korrelierten Variablen,
so ist die Varianzreduktion h√∂her - und die Vohersage genauer.
L√§sst man pro Split <span class="math inline">\(m=p\)</span> Pr√§diktoren zu,
so gleicht Bagging dem Random Forest.
Die Anzahl <span class="math inline">\(m\)</span> der erlaubten Pr√§diktoren werden als Zufallstichprobe aus den <span class="math inline">\(p\)</span>
Pr√§diktoren des Datensatzes gezogen (ohne Zur√ºcklegen).
<span class="math inline">\(m\)</span> ist ein Tuningparameter; <span class="math inline">\(m=\sqrt(p)\)</span> ist ein beliebter Startwert.
In den meisten Implementationen wird <span class="math inline">\(m\)</span> mit <code>mtry</code> bezeichnet (so auch in Tidymodels).</p>
<p>Der Random-Forest-Algorithmus ist in Abb. <a href="ensemble-lerner.html#fig:rf1">10.3</a> illustriert.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:rf1"></span>
<div id="htmlwidget-d4b993144e4f8e7cf5c0" style="width:100%;height:700px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-d4b993144e4f8e7cf5c0">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n\n#direction:down\n                 [<database> Datensatz] ->zmz [Baum1\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n]\n\n[<database> Datensatz] ->zmz [Baum2\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n]\n[<database> Datensatz] ->zmz [Baum ...\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n]\n[<database> Datensatz] ->zmz [Baum B\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n]\n[Baum1\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n] -> [Modus als Vorhersagewert]\n[Baum2\n[ZoZ]->[ZOZ2]\n[ZoZ]->[ZoZ3]\n] -> [Modus als Vorhersagewert]\n[Baum ...] -> [Modus als Vorhersagewert]\n[Baum B] -> [Modus als Vorhersagewert]\n                 ","svg":false,"png":null},"evals":[],"jsHooks":[]}</script><p class="caption">
Abbildung 10.3: Zufallsw√§lder durch Ziehen mit Zur√ºcklegen (zmz) und Ziehen ohne Zur√ºcklegen (ZoZ)
</p>
</div>
<p>Abb. <a href="ensemble-lerner.html#fig:comp-trees">10.4</a> vergleicht die Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen aus <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span>.
In diesem Fall ist die Vorhersageg√ºte deutlich unter der OOB-G√ºte; laut <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span> ist dies hier ‚ÄúZufall‚Äù.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:comp-trees"></span>
<img src="img/8.8.png" alt="Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen" width="70%"><p class="caption">
Abbildung 10.4: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen
</p>
</div>
<p>Den Effekt von <span class="math inline">\(m\)</span> (Anzahl der Pr√§diktoren pro Split) ist in Abb. <a href="ensemble-lerner.html#fig:mtry">10.5</a> dargestellt <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>)</span>.
Man erkennt, dass der Zusatznutzen an zus√§tzlichen B√§umen, <span class="math inline">\(B\)</span>, sich abschw√§cht.
<span class="math inline">\(m=\sqrt{p}\)</span> schneidet wie erwartet am besten ab.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:mtry"></span>
<img src="img/8.10.png" alt="Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen" width="70%"><p class="caption">
Abbildung 10.5: Test-Sample-Vorhersageg√ºte von Bagging- und Random-Forest-Algorithmen
</p>
</div>
</div>
<div id="boosting" class="section level2" number="10.9">
<h2>
<span class="header-section-number">10.9</span> Boosting<a class="anchor" aria-label="anchor" href="#boosting"><i class="fas fa-link"></i></a>
</h2>
<p>Im Unterschied zu Bagging und Random-Forest-Modellen wird beim Boosting der ‚ÄúWald‚Äù
<em>sequenziell</em> entwickelt, nicht gleichzeitig wie bei den anderen vorgestellten ‚ÄúWald-Modellen‚Äù.
Die zwei bekanntesten Implementierungen bzw. Algorithmus-Varianten sind <em>AdaBoost</em> und <em>XGBoost</em>.
Gerade XGBoost hat den Ruf, hervorragende Vorhersagen zu leisten.
Auf <a href="https://en.wikipedia.org/wiki/Kaggle">Kaggle</a> gewinnt nach <a href="https://www.kaggle.com/code/msjgriffiths/r-what-algorithms-are-most-successful-on-kaggle/report">einigen Berichten oft XGBoost</a>.
Nur neuronale Netze schneiden besser ab.
Random-Forest-Modelle kommen nach diesem Bereich auf Platz 3.
Allerdings ben√∂tigen neuronale Netzen oft riesige Stichprobengr√∂√üen
und bei spielen ihre Nuanciertheit vor allem bei komplexen Daten wie Bildern oder Sprache aus.
F√ºr ‚Äúrechteckige‚Äù Daten (also aus einfachen, normalen Tabellen) wird ein baumbasiertes Modell oft besser abschneiden.</p>
<p>Die Idee des Boosting ist es, anschaulich gesprochen,
aus Fehlern zu lernen: Fitte einen Baum, schau welche F√§lle er schlecht vorhergesagt hat,
konzentriere dich beim n√§chsten Baum auf diese F√§lle und so weiter.</p>
<p>Wie andere Ensemble-Methoden auch kann Boosting theoretisch f√ºr beliebige Algorithmen eingesetzt werden.
Es macht aber Sinn, Boosting bei ‚Äúschwachen Lernern‚Äù einzusetzen.
Typisches Beispiel ist ein einfacher Baum; ‚Äúeinfach‚Äù soll hei√üen, der Baum hat nur wenig Gabeln oder vielleicht sogar nur eine einzige.
Dann spricht man von einem <em>Stumpf</em>, was intuitiv gut passt.</p>
<div id="adaboost" class="section level3" number="10.9.1">
<h3>
<span class="header-section-number">10.9.1</span> AdaBoost<a class="anchor" aria-label="anchor" href="#adaboost"><i class="fas fa-link"></i></a>
</h3>
<p>Der AdaBoost-Algorithmus funktioniert, einfach dargestellt, wie folgt.
Zuerst hat jeder Fall <span class="math inline">\(i\)</span> im Datensatz des gleiche Gewicht.
Die erste (und alle weiteren) Stichprobe werden per Bootstrapping aus dem
Datensatz gezogen. Dabei ist die Wahrscheinlichkeit, gezogen zu werden,
proportional zum Gewicht des Falles, <span class="math inline">\(w_i\)</span>. Da im ersten Durchgang die Gewichte identisch sind,
haben zun√§chst alle F√§lle die gleiche Wahrscheinlichkeit, in das Bootstrap-Sample gezogen zu werden.
Die B√§ume bei AdaBoost sind eigentlich nur ‚ÄúSt√ºmpfe‚Äù: Sie bestehen aus einem einzelnen Split, s. Abb. <a href="ensemble-lerner.html#fig:stump">10.6</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:stump"></span>
<div id="htmlwidget-3e413b5ede4af4e9cbdd" style="width:70%;height:200px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-3e413b5ede4af4e9cbdd">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n#direction: topdown\n  [root] -> [leaf1]\n  [root] -> [leaf2]\n  ","svg":false,"png":null},"evals":[],"jsHooks":[]}</script><p class="caption">
Abbildung 10.6: Ein Baumstumpf bei AdaBoost
</p>
</div>
<p>Nach Berechnung des Baumes und der Vorhersagen werden die <em>richtig</em> klassifizierten F√§lle heruntergewichtet
und die falsch klassifizierten F√§lle hoch gewichtet, also st√§rker gewichtet (bleiben wir aus Gr√ºnden der Einfachheit zun√§chst bei der Klassifikation).
Dieses Vorgehen folgt dem Gedanken, dass man sich seine Fehler genauer anschauen muss,
die falsch klassifizierten F√§lle sozusagen mehr Aufmerksamkeit bed√ºrfen.
Das n√§chste (zweite) Modell zieht ein weiteres Bootstrap-Sample.
Jetzt sind allerdings die Gewichte schon angepasst,
so dass mehr F√§lle, die im vorherigen Modell falsch klassifiziert wurden, in den neuen (zweiten)
Baum gezogen werden.
Das neue Modell hat also bessere Chancen,
die Aspekte, die das Vorg√§nger-Modell √ºbersah zu korrigieren bzw. zu lernen.
Jetzt haben wir zwei Modelle. Die k√∂nnen wir aggregieren, genau
wie beim Bagging: Der Modus der Vorhersage √ºber alle (beide) B√§ume hinwig ist
dann die Vorhersage f√ºr einen bestimmten Fall (‚ÄúFall‚Äù und ‚ÄúBeobachtung‚Äù sind stets synonym f√ºr <span class="math inline">\(y_i\)</span> zu verstehen).
So wiederholt sich das Vorgehen f√ºr <span class="math inline">\(B\)</span> B√§ume:
Die Gewichte werden angepasst, das neue Modell wird berechnet,
alle Modelle machen ihre Vorhersagen, per Mehrheitsbeschluss - mit gewichteten Modellen - wird die Vorhersage bestimmt pro Fall.
Irgendwann erreichen wir die vorab definierte Maximalzahl an B√§umen, <span class="math inline">\(B\)</span>, und das Modell kommt zu einem Ende.</p>
<p>Da das Modell die Fehler seiner Vorg√§nger reduziert,
wird der Bias im Gesamtmodell verringert.
Da wir gleichzeitig auch Bagging vornehmen,
wird aber die Varianz auch verringert.
Klingt schon wieder (fast) nach Too-Good-to-be-True!</p>
<p>Das Gewicht <span class="math inline">\(w_i^b\)</span> des <span class="math inline">\(i\)</span>ten Falls im <span class="math inline">\(b\)</span>ten Modell von <span class="math inline">\(B\)</span> berechnet sich wie folgt <span class="citation">(<a href="references.html#ref-rhys" role="doc-biblioref">Rhys 2020</a>)</span>:</p>
<p><span class="math display">\[ w_i^b = \begin{cases}
w_i^{b-1} \cdot e^{-\text{model weight}} \qquad \text{wenn korrekt klassifiziert} \\
w_i^{b-1} \cdot e^{\text{model weight}} \qquad \text{wenn inkorrekt klassifiziert} \\
\end{cases}\]</span></p>
<p>Das <em>Modellgewicht</em> <span class="math inline">\(mw\)</span> berechnet sich dabei so <span class="citation">(<a href="references.html#ref-rhys" role="doc-biblioref">Rhys 2020</a>)</span>:</p>
<p><span class="math display">\[mw_b = 0.5 \cdot log\left( \frac{1-p(\text{inkorrect})}{p(\text{korrekt})} \right) \propto \mathcal{L(p)} \]</span></p>
<p><span class="math inline">\(p(\cdot)\)</span> ist der Anteil (Wahrscheinlichkeit) einer Vorhersage.</p>
<p>Das Modellgewicht ist ein Faktor, der schlechtere Modelle bestraft.
Das folgt dem Gedanken,
dass schlechteren Modellen weniger Geh√∂rt geschenkt werden soll,
aber schlecht klassifizierten F√§llen mehr Geh√∂r.</p>
<p>Das Vorgehen von AdaBoost ist in Abb. <a href="ensemble-lerner.html#fig:ada">10.7</a> illustriert.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:ada"></span>
<div id="htmlwidget-ea9d2c62ca09f0f1c57c" style="width:70%;height:450px;" class="nomnoml html-widget"></div>
<script type="application/json" data-for="htmlwidget-ea9d2c62ca09f0f1c57c">{"x":{"code":"\n#fill: #FEFEFF\n#lineWidth: 1\n#zoom: 4\n#direction: right\n\n\n  [m1] -> [ensemble]\n  [ensemble] -> [m2]\n  [m2] -> [ensemble]\n  [ensemble] -> [m3]\n  [m3] -> [ensemble]\n  [ensemble] -> [m4]\n  [m4] -> [ensemble]\n  [ensemble] -> [M ...]\n  [M ...] -> [ensemble]\n  [ensemble] -> [M B]\n  ","svg":false,"png":null},"evals":[],"jsHooks":[]}</script><p class="caption">
Abbildung 10.7: AdaBoost illustriert
</p>
</div>
</div>
<div id="xgboost" class="section level3" number="10.9.2">
<h3>
<span class="header-section-number">10.9.2</span> XGBoost<a class="anchor" aria-label="anchor" href="#xgboost"><i class="fas fa-link"></i></a>
</h3>
<p>XGBoost ist ein Gradientenverfahren,
eine Methode also, die die Richtung des parziellen Ableitungskoeffizienten als Optimierungskriterium heranzieht.
XGBoost ist √§hnlich zu AdaBoost,
nur dass <em>Residuen</em> modelliert werden, nicht <span class="math inline">\(y\)</span>.
Die Vorhersagefehler von <span class="math inline">\(\hat{f}^b\)</span> werden die Zielvariable von <span class="math inline">\(\hat{f}^{b+1}\)</span>.
Ein Residuum ist der Vorhersagefehler, bei metrischen Modellen etwa RMSE,
oder schlicht <span class="math inline">\(r_i = y_i - \hat{y}_i\)</span>.
Details finden sich z.B. <a href="https://arxiv.org/pdf/1603.02754.pdf">hier</a>, dem Original XGBoost-Paper <span class="citation">(<a href="references.html#ref-chen_xgboost_2016" role="doc-biblioref">Chen and Guestrin 2016</a>)</span>.</p>
<p>Die hohe Vorhersageg√ºte von Boosting-Modellen ist exemplarisch in Abb. <a href="ensemble-lerner.html#fig:boost">10.8</a> dargestellt <span class="citation">(<a href="references.html#ref-islr" role="doc-biblioref">James et al. 2021</a>, S. 358ff)</span>.
Allerdings verwenden die Autoren Friedmans <span class="citation">(<a href="references.html#ref-friedman_greedy_2001" role="doc-biblioref">2001</a>)</span> <em>Gradient Boosting Machine</em>, eine weitere Variante des Boosting .</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:boost"></span>
<img src="img/8.10.png" alt="Vorhersageg√ºte von Boosting und Random Forest" width="70%"><p class="caption">
Abbildung 10.8: Vorhersageg√ºte von Boosting und Random Forest
</p>
</div>
</div>
</div>
<div id="tidymodels-3" class="section level2" number="10.10">
<h2>
<span class="header-section-number">10.10</span> Tidymodels<a class="anchor" aria-label="anchor" href="#tidymodels-3"><i class="fas fa-link"></i></a>
</h2>
<div id="datensatz-churn" class="section level3" number="10.10.1">
<h3>
<span class="header-section-number">10.10.1</span> Datensatz Churn<a class="anchor" aria-label="anchor" href="#datensatz-churn"><i class="fas fa-link"></i></a>
</h3>
<p>Wir betrachten einen Datensatz zur Kundenabwanderung (Churn) aus <a href="https://www.gmudatamining.com/lesson-13-r-tutorial.html">dieser Quelle</a>.</p>
<div class="sourceCode" id="cb407"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">knitr</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/knitr/man/opts_chunk.html">opts_chunk</a></span><span class="op">$</span><span class="fu">set</span><span class="op">(</span>echo <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb408"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">read_rds</a></span><span class="op">(</span><span class="st">'https://gmudatamining.com/data/churn_data.rds'</span><span class="op">)</span></code></pre></div>
<p>Ein Blick in die Daten:</p>
<div class="sourceCode" id="cb409"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_df</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">gt</span><span class="fu">::</span><span class="fu"><a href="https://gt.rstudio.com/reference/gt.html">gt</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div id="gxufiivzxn" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#gxufiivzxn .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#gxufiivzxn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#gxufiivzxn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#gxufiivzxn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#gxufiivzxn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#gxufiivzxn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#gxufiivzxn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#gxufiivzxn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#gxufiivzxn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#gxufiivzxn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#gxufiivzxn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#gxufiivzxn .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#gxufiivzxn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#gxufiivzxn .gt_from_md > :first-child {
  margin-top: 0;
}

#gxufiivzxn .gt_from_md > :last-child {
  margin-bottom: 0;
}

#gxufiivzxn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#gxufiivzxn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#gxufiivzxn .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#gxufiivzxn .gt_row_group_first td {
  border-top-width: 2px;
}

#gxufiivzxn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#gxufiivzxn .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#gxufiivzxn .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#gxufiivzxn .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#gxufiivzxn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#gxufiivzxn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#gxufiivzxn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#gxufiivzxn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#gxufiivzxn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#gxufiivzxn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#gxufiivzxn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#gxufiivzxn .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#gxufiivzxn .gt_left {
  text-align: left;
}

#gxufiivzxn .gt_center {
  text-align: center;
}

#gxufiivzxn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#gxufiivzxn .gt_font_normal {
  font-weight: normal;
}

#gxufiivzxn .gt_font_bold {
  font-weight: bold;
}

#gxufiivzxn .gt_font_italic {
  font-style: italic;
}

#gxufiivzxn .gt_super {
  font-size: 65%;
}

#gxufiivzxn .gt_two_val_uncert {
  display: inline-block;
  line-height: 1em;
  text-align: right;
  font-size: 60%;
  vertical-align: -0.25em;
  margin-left: 0.1em;
}

#gxufiivzxn .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#gxufiivzxn .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#gxufiivzxn .gt_slash_mark {
  font-size: 0.7em;
  line-height: 0.7em;
  vertical-align: 0.15em;
}

#gxufiivzxn .gt_fraction_numerator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: 0.45em;
}

#gxufiivzxn .gt_fraction_denominator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: -0.05em;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">canceled_service</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">enrollment_discount</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">spouse_partner</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">dependents</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">phone_service</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">internet_service</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">online_security</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">online_backup</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">device_protection</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">tech_support</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">streaming_tv</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">streaming_movies</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">contract</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">paperless_bill</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">payment_method</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">months_with_company</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">monthly_charges</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">late_payments</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">multiple_lines</td>
<td class="gt_row gt_center">fiber_optic</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">one_year</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">credit_card</td>
<td class="gt_row gt_right">30</td>
<td class="gt_row gt_right">51.01440</td>
<td class="gt_row gt_right">3</td>
</tr>
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">multiple_lines</td>
<td class="gt_row gt_center">fiber_optic</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">two_year</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">electronic_check</td>
<td class="gt_row gt_right">39</td>
<td class="gt_row gt_right">80.42466</td>
<td class="gt_row gt_right">4</td>
</tr>
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">single_line</td>
<td class="gt_row gt_center">fiber_optic</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">month_to_month</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">mailed_check</td>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">75.88737</td>
<td class="gt_row gt_right">3</td>
</tr>
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">single_line</td>
<td class="gt_row gt_center">fiber_optic</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">two_year</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">credit_card</td>
<td class="gt_row gt_right">29</td>
<td class="gt_row gt_right">81.96467</td>
<td class="gt_row gt_right">3</td>
</tr>
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">single_line</td>
<td class="gt_row gt_center">digital</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">month_to_month</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">bank_draft</td>
<td class="gt_row gt_right">9</td>
<td class="gt_row gt_right">101.34257</td>
<td class="gt_row gt_right">5</td>
</tr>
<tr>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">single_line</td>
<td class="gt_row gt_center">fiber_optic</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">yes</td>
<td class="gt_row gt_center">month_to_month</td>
<td class="gt_row gt_center">no</td>
<td class="gt_row gt_center">mailed_check</td>
<td class="gt_row gt_right">14</td>
<td class="gt_row gt_right">72.01285</td>
<td class="gt_row gt_right">4</td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="data-splitting-und-cv" class="section level3" number="10.10.2">
<h3>
<span class="header-section-number">10.10.2</span> Data Splitting und CV<a class="anchor" aria-label="anchor" href="#data-splitting-und-cv"><i class="fas fa-link"></i></a>
</h3>
<p>Das Kreuzvalidieren (CV) fassen wir auch unter diesen Punkt.</p>
<div class="sourceCode" id="cb410"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">churn_df</span>, prop <span class="op">=</span> <span class="fl">0.75</span>, 
                             strata <span class="op">=</span> <span class="va">canceled_service</span><span class="op">)</span>

<span class="va">churn_training</span> <span class="op">&lt;-</span> <span class="va">churn_split</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">training</span><span class="op">(</span><span class="op">)</span>

<span class="va">churn_test</span> <span class="op">&lt;-</span> <span class="va">churn_split</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu">testing</span><span class="op">(</span><span class="op">)</span>

<span class="va">churn_folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">churn_training</span>, v <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></code></pre></div>
</div>
<div id="feature-engineering" class="section level3" number="10.10.3">
<h3>
<span class="header-section-number">10.10.3</span> Feature Engineering<a class="anchor" aria-label="anchor" href="#feature-engineering"><i class="fas fa-link"></i></a>
</h3>
<p>Hier definieren wir zwei Rezepte.
Gleichzeitig ver√§ndern wir die Pr√§diktoren (normalisieren, dummysieren, ‚Ä¶).
Das nennt man auch <em>Feature Engineering</em>.</p>
<div class="sourceCode" id="cb411"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_recipe1</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">canceled_service</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">churn_training</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
                       <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
                       <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="va">churn_recipe2</span> <span class="op">&lt;-</span> <span class="fu">recipe</span><span class="op">(</span><span class="va">canceled_service</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">churn_training</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
                       <span class="fu">step_YeoJohnson</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
                       <span class="fu">step_normalize</span><span class="op">(</span><span class="fu">all_numeric</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
                       <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span>, <span class="op">-</span><span class="fu">all_outcomes</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p><code>step_YeoJohnson()</code> reduziert Schiefe in der Verteilung.</p>
</div>
<div id="modelle" class="section level3" number="10.10.4">
<h3>
<span class="header-section-number">10.10.4</span> Modelle<a class="anchor" aria-label="anchor" href="#modelle"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb412"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tree_model</span> <span class="op">&lt;-</span> <span class="fu">decision_tree</span><span class="op">(</span>cost_complexity <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                            tree_depth <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                            min_n <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
              <span class="fu">set_engine</span><span class="op">(</span><span class="st">'rpart'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
              <span class="fu">set_mode</span><span class="op">(</span><span class="st">'classification'</span><span class="op">)</span>

<span class="va">rf_model</span> <span class="op">&lt;-</span> <span class="fu">rand_forest</span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                        trees <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                        min_n <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
            <span class="fu">set_engine</span><span class="op">(</span><span class="st">'ranger'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
            <span class="fu">set_mode</span><span class="op">(</span><span class="st">'classification'</span><span class="op">)</span>


<span class="va">boost_model</span> <span class="op">&lt;-</span> <span class="fu">boost_tree</span><span class="op">(</span>mtry <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                        min_n <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span>,
                        trees <span class="op">=</span> <span class="fu"><a href="https://hardhat.tidymodels.org/reference/tune.html">tune</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"xgboost"</span>, nthreads <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">set_mode</span><span class="op">(</span><span class="st">"classification"</span><span class="op">)</span>


<span class="va">glm_model</span> <span class="op">&lt;-</span> <span class="fu">logistic_reg</span><span class="op">(</span><span class="op">)</span></code></pre></div>
</div>
<div id="workflows-1" class="section level3" number="10.10.5">
<h3>
<span class="header-section-number">10.10.5</span> Workflows<a class="anchor" aria-label="anchor" href="#workflows-1"><i class="fas fa-link"></i></a>
</h3>
<p>Wir definieren ein Workflow-Set:</p>
<div class="sourceCode" id="cb413"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">preproc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>rec1 <span class="op">=</span> <span class="va">churn_recipe1</span>, rec2 <span class="op">=</span> <span class="va">churn_recipe2</span><span class="op">)</span>
<span class="va">models</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>tree1 <span class="op">=</span> <span class="va">tree_model</span>, rf1 <span class="op">=</span> <span class="va">rf_model</span>, boost1 <span class="op">=</span> <span class="va">boost_model</span>, glm1 <span class="op">=</span> <span class="va">glm_model</span><span class="op">)</span>
 
 
<span class="va">all_workflows</span> <span class="op">&lt;-</span> <span class="fu">workflow_set</span><span class="op">(</span><span class="va">preproc</span>, <span class="va">models</span><span class="op">)</span></code></pre></div>
<p>Infos zu <code>workflow_set</code> bekommt man wie gewohnt mit <code>?workflow_set</code>.</p>
<p>Im Standard werden alle Rezepte und Modelle miteinander kombiniert (<code>cross = TRUE</code>),
also <code>preproc * models</code> Modelle gefittet.</p>
</div>
<div id="modelle-berechnen-mit-tuning-einzeln" class="section level3" number="10.10.6">
<h3>
<span class="header-section-number">10.10.6</span> Modelle berechnen mit Tuning, einzeln<a class="anchor" aria-label="anchor" href="#modelle-berechnen-mit-tuning-einzeln"><i class="fas fa-link"></i></a>
</h3>
<p>Wir k√∂nnten jetzt jedes Modell einzeln tunen, wenn wir wollen.</p>
<div id="baum" class="section level4" number="10.10.6.1">
<h4>
<span class="header-section-number">10.10.6.1</span> Baum<a class="anchor" aria-label="anchor" href="#baum"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb414"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tree_wf</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">tree_model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">churn_recipe1</span><span class="op">)</span>


<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">tic</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">tree_fit</span> <span class="op">&lt;-</span>
  <span class="va">tree_wf</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/tune_grid.html">tune_grid</a></span><span class="op">(</span>
    resamples <span class="op">=</span> <span class="va">churn_folds</span>,
    metrics <span class="op">=</span>  <span class="fu">metric_set</span><span class="op">(</span><span class="va">roc_auc</span>, <span class="va">sens</span>, <span class="fu">yardstick</span><span class="fu">::</span><span class="va"><a href="https://yardstick.tidymodels.org/reference/spec.html">spec</a></span><span class="op">)</span>
    <span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">toc</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## 16.453 sec elapsed</code></pre>
<p>Im Standard werden 10 Modellkandidaten getuned.</p>
<div class="sourceCode" id="cb416"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tree_fit</span></code></pre></div>
<pre><code>## # Tuning results
## # 5-fold cross-validation 
## # A tibble: 5 √ó 4
##   splits             id    .metrics          .notes          
##   &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
## 1 &lt;split [2393/599]&gt; Fold1 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 2 &lt;split [2393/599]&gt; Fold2 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 3 &lt;split [2394/598]&gt; Fold3 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 4 &lt;split [2394/598]&gt; Fold4 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 5 &lt;split [2394/598]&gt; Fold5 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;</code></pre>
<p>Schauen wir uns das Objekt etwas n√§her an:</p>
<div class="sourceCode" id="cb418"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tree_fit</span><span class="op">$</span><span class="va">.metrics</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></code></pre></div>
<pre><code>## # A tibble: 30 √ó 7
##    cost_complexity tree_depth min_n .metric .estimator .estimate .config        
##              &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          
##  1        4.47e- 9         14    18 sens    binary         0.848 Preprocessor1_‚Ä¶
##  2        4.47e- 9         14    18 spec    binary         0.857 Preprocessor1_‚Ä¶
##  3        4.47e- 9         14    18 roc_auc binary         0.917 Preprocessor1_‚Ä¶
##  4        3.04e- 3          2    32 sens    binary         0.774 Preprocessor1_‚Ä¶
##  5        3.04e- 3          2    32 spec    binary         0.843 Preprocessor1_‚Ä¶
##  6        3.04e- 3          2    32 roc_auc binary         0.822 Preprocessor1_‚Ä¶
##  7        1.12e-10          5    36 sens    binary         0.819 Preprocessor1_‚Ä¶
##  8        1.12e-10          5    36 spec    binary         0.857 Preprocessor1_‚Ä¶
##  9        1.12e-10          5    36 roc_auc binary         0.903 Preprocessor1_‚Ä¶
## 10        9.36e- 9          4    39 sens    binary         0.856 Preprocessor1_‚Ä¶
## # ‚Ä¶ with 20 more rows</code></pre>
<p>30 Zeilen: 3 G√ºtemetriken (Sens, Spec, ROC AUC) mit je 10 Werten (Submodellen),
gibt 30 Koeffizienten.</p>
<p>F√ºr jeden der 5 Faltungen haben wir also 10 Submodelle.</p>
<p>Welches Modell ist das beste?</p>
<div class="sourceCode" id="cb420"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tune.tidymodels.org/reference/show_best.html">show_best</a></span><span class="op">(</span><span class="va">tree_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 5 √ó 9
##   cost_complexity tree_depth min_n .metric .estimator  mean     n std_err
##             &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
## 1   0.0000476             13    16 roc_auc binary     0.926     5 0.00171
## 2   0.00000638             9    22 roc_auc binary     0.926     5 0.00299
## 3   0.000213              10    26 roc_auc binary     0.925     5 0.00333
## 4   0.00000000447         14    18 roc_auc binary     0.925     5 0.00271
## 5   0.000000121            6    11 roc_auc binary     0.918     5 0.00443
## # ‚Ä¶ with 1 more variable: .config &lt;chr&gt;</code></pre>
<p>Aha, das sind die f√ºnf besten Modelle, bzw. ihre Tuningparameter,
ihre mittlere G√ºte zusammen mit dem Standardfehler.</p>
<div class="sourceCode" id="cb422"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">tree_fit</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="110-Ensemble-Lerner_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="rf" class="section level4" number="10.10.6.2">
<h4>
<span class="header-section-number">10.10.6.2</span> RF<a class="anchor" aria-label="anchor" href="#rf"><i class="fas fa-link"></i></a>
</h4>
<p>Was f√ºr Tuningparameter hat den der Algorithmus bzw. seine Implementierung?</p>
<div class="sourceCode" id="cb423"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">show_model_info</span><span class="op">(</span><span class="st">"rand_forest"</span><span class="op">)</span></code></pre></div>
<pre><code>## Information for `rand_forest`
##  modes: unknown, classification, regression, censored regression 
## 
##  engines: 
##    classification: randomForest, ranger, spark
##    regression:     randomForest, ranger, spark
## 
##  arguments: 
##    ranger:       
##       mtry  --&gt; mtry
##       trees --&gt; num.trees
##       min_n --&gt; min.node.size
##    randomForest: 
##       mtry  --&gt; mtry
##       trees --&gt; ntree
##       min_n --&gt; nodesize
##    spark:        
##       mtry  --&gt; feature_subset_strategy
##       trees --&gt; num_trees
##       min_n --&gt; min_instances_per_node
## 
##  fit modules:
##          engine           mode
##          ranger classification
##          ranger     regression
##    randomForest classification
##    randomForest     regression
##           spark classification
##           spark     regression
## 
##  prediction modules:
##              mode       engine                    methods
##    classification randomForest           class, prob, raw
##    classification       ranger class, conf_int, prob, raw
##    classification        spark                class, prob
##        regression randomForest               numeric, raw
##        regression       ranger     conf_int, numeric, raw
##        regression        spark                    numeric</code></pre>
<p>Da die Berechnung einiges an Zeit braucht,
kann man das (schon fr√ºher einmal berechnete) Ergebnisobjekt
von der Festplatte lesen (sofern es existiert).
Ansonsten berechnet man neu:</p>
<div class="sourceCode" id="cb425"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="st">"objects/rf_fit1.rds"</span><span class="op">)</span><span class="op">)</span><span class="op">{</span>
  <span class="va">rf_fit1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">read_rds</a></span><span class="op">(</span><span class="st">"objects/rf_fit1.rds"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
<span class="va">rf_wf1</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">rf_model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">churn_recipe1</span><span class="op">)</span>


<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">tic</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">rf_fit1</span> <span class="op">&lt;-</span>
  <span class="va">rf_wf1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/tune_grid.html">tune_grid</a></span><span class="op">(</span>
    resamples <span class="op">=</span> <span class="va">churn_folds</span>,
    metrics <span class="op">=</span>  <span class="fu">metric_set</span><span class="op">(</span><span class="va">roc_auc</span>, <span class="va">sens</span>, <span class="va">spec</span><span class="op">)</span>
    <span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">toc</a></span><span class="op">(</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>So
kann man das berechnete Objekt abspeichern auf Festplatte,
um k√ºnftig Zeit zu sparen:</p>
<div class="sourceCode" id="cb426"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">write_rds</a></span><span class="op">(</span><span class="va">rf_fit1</span>, file <span class="op">=</span> <span class="st">"objects/rf_fit1.rds"</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb427"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">rf_fit1</span></code></pre></div>
<pre><code>## # Tuning results
## # 5-fold cross-validation 
## # A tibble: 5 √ó 4
##   splits             id    .metrics          .notes          
##   &lt;list&gt;             &lt;chr&gt; &lt;list&gt;            &lt;list&gt;          
## 1 &lt;split [2393/599]&gt; Fold1 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 2 &lt;split [2393/599]&gt; Fold2 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 3 &lt;split [2394/598]&gt; Fold3 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 4 &lt;split [2394/598]&gt; Fold4 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;
## 5 &lt;split [2394/598]&gt; Fold5 &lt;tibble [30 √ó 7]&gt; &lt;tibble [0 √ó 3]&gt;</code></pre>
<div class="sourceCode" id="cb429"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tune.tidymodels.org/reference/show_best.html">show_best</a></span><span class="op">(</span><span class="va">rf_fit1</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 5 √ó 9
##    mtry trees min_n .metric .estimator  mean     n std_err .config              
##   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
## 1     6  1686    18 roc_auc binary     0.958     5 0.00330 Preprocessor1_Model03
## 2     5   747    34 roc_auc binary     0.958     5 0.00324 Preprocessor1_Model10
## 3    10   818    22 roc_auc binary     0.956     5 0.00378 Preprocessor1_Model01
## 4     8   342     2 roc_auc binary     0.955     5 0.00361 Preprocessor1_Model09
## 5    13  1184    25 roc_auc binary     0.954     5 0.00423 Preprocessor1_Model08</code></pre>
</div>
<div id="xgboost-1" class="section level4" number="10.10.6.3">
<h4>
<span class="header-section-number">10.10.6.3</span> XGBoost<a class="anchor" aria-label="anchor" href="#xgboost-1"><i class="fas fa-link"></i></a>
</h4>
<div class="sourceCode" id="cb431"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">boost_wf1</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">boost_model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">churn_recipe1</span><span class="op">)</span>


<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">tic</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">boost_fit1</span> <span class="op">&lt;-</span>
  <span class="va">boost_wf1</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/tune_grid.html">tune_grid</a></span><span class="op">(</span>
    resamples <span class="op">=</span> <span class="va">churn_folds</span>,
    metrics <span class="op">=</span>  <span class="fu">metric_set</span><span class="op">(</span><span class="va">roc_auc</span>, <span class="va">sens</span>, <span class="va">spec</span><span class="op">)</span>
    <span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">toc</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<p>Wieder auf Festplatte speichern:</p>
<div class="sourceCode" id="cb432"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">write_rds</a></span><span class="op">(</span><span class="va">boost_fit1</span>, file <span class="op">=</span> <span class="st">"objects/boost_fit1.rds"</span><span class="op">)</span></code></pre></div>
<p>Und so weiter.</p>
</div>
</div>
<div id="workflow-set-tunen" class="section level3" number="10.10.7">
<h3>
<span class="header-section-number">10.10.7</span> Workflow-Set tunen<a class="anchor" aria-label="anchor" href="#workflow-set-tunen"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb433"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="st">"objects/churn_model_set.rds"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
  <span class="va">churn_model_set</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">read_rds</a></span><span class="op">(</span><span class="st">"objects/churn_model_set.rds"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">tic</a></span><span class="op">(</span><span class="op">)</span>
  <span class="va">churn_model_set</span> <span class="op">&lt;-</span>
    <span class="va">all_workflows</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
    <span class="fu">workflow_map</span><span class="op">(</span>
      resamples <span class="op">=</span> <span class="va">churn_folds</span>,
      grid <span class="op">=</span> <span class="fl">20</span>,
      metrics <span class="op">=</span> <span class="fu">metric_set</span><span class="op">(</span><span class="va">roc_auc</span><span class="op">)</span>,
      seed <span class="op">=</span> <span class="fl">42</span>,  <span class="co"># reproducibility</span>
      verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/pkg/tictoc/man/tic.html">toc</a></span><span class="op">(</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Da die Berechnung schon etwas Zeit braucht,
macht es Sinn, das Modell (bzw. das Ergebnisobjekt) auf Festplatte zu speichern:</p>
<div class="sourceCode" id="cb434"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">write_rds</a></span><span class="op">(</span><span class="va">churn_model_set</span>, file <span class="op">=</span> <span class="st">"objects/churn_model_set.rds"</span><span class="op">)</span></code></pre></div>
<p><em>Achtung</em> Dieser Schritt ist <em>gef√§hrlich</em>:
Wenn Sie Ihr Rezept und Fit-Objekt √§ndenr, kriegt das Ihre Festplatte nicht unbedingt
mit. Sie k√∂nnten also unbemerkt mit dem alten Objekt von Ihrer Festplatte weiterarbeiten,
ohne durch eine Fehlermeldung gewarnt zu werden.</p>
<p>Entsprechend kann man das Modellobjekt wieder importieren, wenn einmal abgespeichert:</p>
<div class="sourceCode" id="cb435"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_model_set</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_rds.html">read_rds</a></span><span class="op">(</span>file <span class="op">=</span> <span class="st">"objects/churn_model_set.rds"</span><span class="op">)</span></code></pre></div>
</div>
<div id="ergebnisse-im-train-sest" class="section level3" number="10.10.8">
<h3>
<span class="header-section-number">10.10.8</span> Ergebnisse im Train-Sest<a class="anchor" aria-label="anchor" href="#ergebnisse-im-train-sest"><i class="fas fa-link"></i></a>
</h3>
<p>Hier ist die Rangfolge der Modelle, geordnet nach mittlerem ROC AUC:</p>
<div class="sourceCode" id="cb436"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">rank_results</span><span class="op">(</span><span class="va">churn_model_set</span>, rank_metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 122 √ó 9
##    wflow_id    .config      .metric  mean std_err     n preprocessor model  rank
##    &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;
##  1 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.963 0.00104     5 recipe       boos‚Ä¶     1
##  2 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.963 0.00104     5 recipe       boos‚Ä¶     2
##  3 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00106     5 recipe       boos‚Ä¶     3
##  4 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00106     5 recipe       boos‚Ä¶     4
##  5 rec2_glm1   Preprocesso‚Ä¶ roc_auc 0.961 0.00272     5 recipe       logi‚Ä¶     5
##  6 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00102     5 recipe       boos‚Ä¶     6
##  7 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.961 0.00102     5 recipe       boos‚Ä¶     7
##  8 rec2_boost1 Preprocesso‚Ä¶ roc_auc 0.960 0.00120     5 recipe       boos‚Ä¶     8
##  9 rec1_boost1 Preprocesso‚Ä¶ roc_auc 0.960 0.00120     5 recipe       boos‚Ä¶     9
## 10 rec1_rf1    Preprocesso‚Ä¶ roc_auc 0.960 0.00278     5 recipe       rand‚Ä¶    10
## # ‚Ä¶ with 112 more rows</code></pre>
<div class="sourceCode" id="cb438"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">churn_model_set</span>, metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="110-Ensemble-Lerner_files/figure-html/unnamed-chunk-20-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="bestes-modell" class="section level3" number="10.10.9">
<h3>
<span class="header-section-number">10.10.9</span> Bestes Modell<a class="anchor" aria-label="anchor" href="#bestes-modell"><i class="fas fa-link"></i></a>
</h3>
<p>Und hier nur der beste Kandidat pro Algorithmus:</p>
<div class="sourceCode" id="cb439"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">churn_model_set</span>, metric <span class="op">=</span> <span class="st">"roc_auc"</span>, select_best <span class="op">=</span> <span class="st">"TRUE"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">mean</span> <span class="op">-</span> <span class="fl">.01</span>, label <span class="op">=</span> <span class="va">wflow_id</span><span class="op">)</span>, angle <span class="op">=</span> <span class="fl">90</span>, hjust <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html">lims</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.85</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="110-Ensemble-Lerner_files/figure-html/unnamed-chunk-21-1.png" width="70%" style="display: block; margin: auto;"></div>
<p>Boosting hat - knapp - am besten abgeschnitten.
Allerdings sind Random Forest und die schlichte, einfache logistische Regression auch fast genau so gut.
Das w√§re ein Grund f√ºr das einfachste Modell, das GLM, zu votieren.
Zumal die Interpretierbarkeit am besten ist.
Alternativ k√∂nnte man sich f√ºr das Boosting-Modell aussprechen.</p>
<p>Man kann sich das beste Submodell auch von Tidymodels bestimmen lassen.
Das scheint aber (noch) nicht f√ºr ein Workflow-Set zu funktionieren,
sondern nur f√ºr das Ergebnisobjekt von <code>tune_grid</code>.</p>
<div class="sourceCode" id="cb440"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tune.tidymodels.org/reference/show_best.html">select_best</a></span><span class="op">(</span><span class="va">churn_model_set</span>, metric <span class="op">=</span> <span class="st">"roc_auc"</span><span class="op">)</span></code></pre></div>
<pre><code>## Error in `is_metric_maximize()`:
## ! Please check the value of `metric`.</code></pre>
<p><code>rf_fit1</code> haben wir mit <code><a href="https://tune.tidymodels.org/reference/tune_grid.html">tune_grid()</a></code> berechnet;
mit diesem Modell kann <code><a href="https://tune.tidymodels.org/reference/show_best.html">select_best()</a></code> arbeiten:</p>
<div class="sourceCode" id="cb442"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tune.tidymodels.org/reference/show_best.html">select_best</a></span><span class="op">(</span><span class="va">rf_fit1</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 √ó 4
##    mtry trees min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1     6  1686    18 Preprocessor1_Model03</code></pre>
<p>Aber wir k√∂nnen uns h√§ndisch behelfen.</p>
<p>Schauen wir uns mal die Metriken (Vorhersageg√ºte) an:</p>
<div class="sourceCode" id="cb444"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">churn_model_set</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/collect_predictions.html">collect_metrics</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="op">-</span><span class="va">mean</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 122 √ó 9
##    wflow_id    .config      preproc model .metric .estimator  mean     n std_err
##    &lt;chr&gt;       &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
##  1 rec1_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.963     5 0.00104
##  2 rec2_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.963     5 0.00104
##  3 rec1_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.961     5 0.00106
##  4 rec2_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.961     5 0.00106
##  5 rec2_glm1   Preprocesso‚Ä¶ recipe  logi‚Ä¶ roc_auc binary     0.961     5 0.00272
##  6 rec1_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.961     5 0.00102
##  7 rec2_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.961     5 0.00102
##  8 rec1_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.960     5 0.00120
##  9 rec2_boost1 Preprocesso‚Ä¶ recipe  boos‚Ä¶ roc_auc binary     0.960     5 0.00120
## 10 rec1_rf1    Preprocesso‚Ä¶ recipe  rand‚Ä¶ roc_auc binary     0.960     5 0.00278
## # ‚Ä¶ with 112 more rows</code></pre>
<p><code>rec1_boost1</code> scheint das beste Modell zu sein.</p>
<div class="sourceCode" id="cb446"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_model_params</span> <span class="op">&lt;-</span>
<span class="fu">extract_workflow_set_result</span><span class="op">(</span><span class="va">churn_model_set</span>, <span class="st">"rec1_boost1"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/show_best.html">select_best</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">best_model_params</span></code></pre></div>
<pre><code>## # A tibble: 1 √ó 4
##    mtry trees min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1     6    80    21 Preprocessor1_Model05</code></pre>
</div>
<div id="finalisisieren" class="section level3" number="10.10.10">
<h3>
<span class="header-section-number">10.10.10</span> Finalisisieren<a class="anchor" aria-label="anchor" href="#finalisisieren"><i class="fas fa-link"></i></a>
</h3>
<p>Wir entscheiden uns mal f√ºr das Boosting-Modell, <code>rec1_boost1</code>.
Diesen Workflow, in finalisierter Form,
brauchen wir f√ºr den ‚Äúfinal Fit‚Äù.
Finalisierte Form hei√üt:</p>
<ul>
<li>Schritt 1: Nimm den passenden Workflow, hier <code>rec1</code> und <code>boost1</code>; das hatte uns oben <code>rank_results()</code> verraten.</li>
<li>Schritt 2: Update (Finalisiere) ihn mit den besten Tuningparameter-Werten</li>
</ul>
<div class="sourceCode" id="cb448"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Schritt 1:</span>
<span class="va">best_wf</span> <span class="op">&lt;-</span> 
<span class="va">all_workflows</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://hardhat.tidymodels.org/reference/hardhat-extract.html">extract_workflow</a></span><span class="op">(</span><span class="st">"rec1_boost1"</span><span class="op">)</span>

<span class="va">best_wf</span></code></pre></div>
<pre><code>## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 2 Recipe Steps
## 
## ‚Ä¢ step_normalize()
## ‚Ä¢ step_dummy()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = tune()
##   min_n = tune()
## 
## Engine-Specific Arguments:
##   nthreads = parallel::detectCores()
## 
## Computational engine: xgboost</code></pre>
<p>Jetzt finalisieren wir den Workflow,
d.h. wir setzen die Parameterwerte des besten Submodells ein:</p>
<div class="sourceCode" id="cb450"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Schritt 2:</span>
<span class="va">best_wf_finalized</span> <span class="op">&lt;-</span> 
  <span class="va">best_wf</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/finalize_model.html">finalize_workflow</a></span><span class="op">(</span><span class="va">best_model_params</span><span class="op">)</span>

<span class="va">best_wf_finalized</span></code></pre></div>
<pre><code>## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 2 Recipe Steps
## 
## ‚Ä¢ step_normalize()
## ‚Ä¢ step_dummy()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = 6
##   trees = 80
##   min_n = 21
## 
## Engine-Specific Arguments:
##   nthreads = parallel::detectCores()
## 
## Computational engine: xgboost</code></pre>
</div>
<div id="last-fit" class="section level3" number="10.10.11">
<h3>
<span class="header-section-number">10.10.11</span> Last Fit<a class="anchor" aria-label="anchor" href="#last-fit"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb452"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_final</span> <span class="op">&lt;-</span>
  <span class="va">best_wf_finalized</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/last_fit.html">last_fit</a></span><span class="op">(</span><span class="va">churn_split</span><span class="op">)</span>

<span class="va">fit_final</span></code></pre></div>
<pre><code>## # Resampling results
## # Manual resampling 
## # A tibble: 1 √ó 6
##   splits             id               .metrics .notes   .predictions .workflow 
##   &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    
## 1 &lt;split [2992/998]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;</code></pre>
<div class="sourceCode" id="cb454"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tune.tidymodels.org/reference/collect_predictions.html">collect_metrics</a></span><span class="op">(</span><span class="va">fit_final</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 √ó 4
##   .metric  .estimator .estimate .config             
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary         0.890 Preprocessor1_Model1
## 2 roc_auc  binary         0.954 Preprocessor1_Model1</code></pre>
</div>
<div id="variablenrelevanz-1" class="section level3" number="10.10.12">
<h3>
<span class="header-section-number">10.10.12</span> Variablenrelevanz<a class="anchor" aria-label="anchor" href="#variablenrelevanz-1"><i class="fas fa-link"></i></a>
</h3>
<p>Um die Variablenrelevanz zu plotten,
m√ºssen wir aus dem Tidymodels-Ergebnisobjekt
das eigentliche Ergebnisobjekt herausziehen, von der R-Funktion, die die eigentliche
Berechnung durchf√ºhrt,
das w√§re <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> bei einer logistischen Regression oder <code><a href="https://rdrr.io/pkg/xgboost/man/xgb.train.html">xgboost::xgb.train()</a></code> bei
XGBoost:</p>
<div class="sourceCode" id="cb456"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_final</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://hardhat.tidymodels.org/reference/hardhat-extract.html">extract_fit_parsnip</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## parsnip model object
## 
## ##### xgb.Booster
## raw: 100.3 Kb 
## call:
##   xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, 
##     colsample_bytree = 1, colsample_bynode = 0.285714285714286, 
##     min_child_weight = 21L, subsample = 1, objective = "binary:logistic"), 
##     data = x$data, nrounds = 80L, watchlist = x$watchlist, verbose = 0, 
##     nthreads = 8L, nthread = 1)
## params (as set within xgb.train):
##   eta = "0.3", max_depth = "6", gamma = "0", colsample_bytree = "1", colsample_bynode = "0.285714285714286", min_child_weight = "21", subsample = "1", objective = "binary:logistic", nthreads = "8", nthread = "1", validate_parameters = "TRUE"
## xgb.attributes:
##   niter
## callbacks:
##   cb.evaluation.log()
## # of features: 21 
## niter: 80
## nfeatures : 21 
## evaluation_log:
##     iter training_logloss
##        1        0.5694834
##        2        0.4810064
## ---                      
##       79        0.1854236
##       80        0.1851494</code></pre>
<p><em>Dieses</em> Objekt √ºbergeben wir dann an <a href="https://github.com/koalaverse/vip/">vip</a>:</p>
<div class="sourceCode" id="cb458"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_final</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://hardhat.tidymodels.org/reference/hardhat-extract.html">extract_fit_parsnip</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://rdrr.io/pkg/vip/man/vip.html">vip</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="110-Ensemble-Lerner_files/figure-html/unnamed-chunk-28-1.png" width="70%" style="display: block; margin: auto;"></div>
</div>
<div id="roc-curve" class="section level3" number="10.10.13">
<h3>
<span class="header-section-number">10.10.13</span> ROC-Curve<a class="anchor" aria-label="anchor" href="#roc-curve"><i class="fas fa-link"></i></a>
</h3>
<p>Eine ROC-Kurve berechnet Sensitivit√§t und Spezifit√§t aus den Vorhersagen,
bzw. aus dem Vergleich von Vorhersagen und wahrem Wert (d.h. der beobachtete Wert).</p>
<p>Ziehen wir also zuerst die Vorhersagen heraus:</p>
<div class="sourceCode" id="cb459"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_final</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/collect_predictions.html">collect_predictions</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 998 √ó 7
##    id              .pred_yes .pred_no  .row .pred_class canceled_service .config
##    &lt;chr&gt;               &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;fct&gt;            &lt;chr&gt;  
##  1 train/test spl‚Ä¶     0.792  0.208       2 yes         yes              Prepro‚Ä¶
##  2 train/test spl‚Ä¶     0.773  0.227       6 yes         yes              Prepro‚Ä¶
##  3 train/test spl‚Ä¶     0.496  0.504      13 no          yes              Prepro‚Ä¶
##  4 train/test spl‚Ä¶     0.919  0.0809     15 yes         yes              Prepro‚Ä¶
##  5 train/test spl‚Ä¶     0.989  0.0111     18 yes         yes              Prepro‚Ä¶
##  6 train/test spl‚Ä¶     0.973  0.0267     21 yes         yes              Prepro‚Ä¶
##  7 train/test spl‚Ä¶     0.989  0.0111     23 yes         yes              Prepro‚Ä¶
##  8 train/test spl‚Ä¶     0.998  0.00154    26 yes         yes              Prepro‚Ä¶
##  9 train/test spl‚Ä¶     0.996  0.00388    27 yes         yes              Prepro‚Ä¶
## 10 train/test spl‚Ä¶     0.994  0.00642    41 yes         yes              Prepro‚Ä¶
## # ‚Ä¶ with 988 more rows</code></pre>
<p>Praktischerweise werden die ‚Äúwahren Werte‚Äù (also die beobachtaten Werte), <code>canceled_service</code>,
ausch angegeben.</p>
<p>Dann berechnen wir die <code>roc_curve</code> und <code>autoplot</code>ten sie.</p>
<div class="sourceCode" id="cb461"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">fit_final</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://tune.tidymodels.org/reference/collect_predictions.html">collect_predictions</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">roc_curve</span><span class="op">(</span><span class="va">canceled_service</span>, <span class="va">.pred_yes</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="110-Ensemble-Lerner_files/figure-html/unnamed-chunk-30-1.png" width="70%" style="display: block; margin: auto;"></div>
<!-- ## Aufgaben und Vertiefung -->
</div>
</div>
<div id="aufgaben-6" class="section level2" number="10.11">
<h2>
<span class="header-section-number">10.11</span> Aufgaben<a class="anchor" aria-label="anchor" href="#aufgaben-6"><i class="fas fa-link"></i></a>
</h2>
</div>
<div id="aufgaben-7" class="section level2" number="10.12">
<h2>
<span class="header-section-number">10.12</span> Aufgaben<a class="anchor" aria-label="anchor" href="#aufgaben-7"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://github.com/sebastiansauer/datascience1/blob/main/Aufgaben/Thema11-Loesungen1.pdf">Aufgaben zu Tidymodels, PDF</a></li>
<li><a href="https://github.com/sebastiansauer/datascience1/blob/main/Aufgaben/Thema11-Loesungen1.html">Aufgaben zu Tidymodels, HTML</a></li>
</ul>
</div>
<div id="vertiefung-4" class="section level2" number="10.13">
<h2>
<span class="header-section-number">10.13</span> Vertiefung<a class="anchor" aria-label="anchor" href="#vertiefung-4"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://data-se.netlify.app/2020/12/14/titanic-tidymodels-boost/">Einfache Durchf√ºhrung eines Modellierung mit XGBoost</a></li>
<li><a href="https://bcullen.rbind.io/post/2020-06-02-tidymodels-decision-tree-learning-in-r/">Fallstudie Oregon Schools</a></li>
<li><a href="https://www.gmudatamining.com/lesson-13-r-tutorial.html">Fallstudie Churn</a></li>
<li><a href="https://juliasilge.com/blog/ikea-prices/">Fallstudie Ikea</a></li>
<li><a href="https://juliasilge.com/blog/water-sources/">Fallstudie Wasserquellen in Sierra Leone</a></li>
<li><a href="https://dev.to/juliasilge/tuning-random-forest-hyperparameters-in-r-with-tidytuesday-trees-data-4ilh">Fallstudie B√§ume in San Francisco</a></li>
<li><a href="https://juliasilge.com/blog/multinomial-volcano-eruptions/">Fallstudie Vulkanausbr√ºche</a></li>
<li><a href="https://juliasilge.com/blog/board-games/">Fallstudie Brettspiele mit XGBoost</a></li>
</ul>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="entscheidungsb%C3%A4ume.html"><span class="header-section-number">9</span> Entscheidungsb√§ume</a></div>
<div class="next"><a href="regularisierte-modelle.html"><span class="header-section-number">11</span> Regularisierte Modelle</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ensemble-lerner"><span class="header-section-number">10</span> Ensemble Lerner</a></li>
<li>
<a class="nav-link" href="#lernsteuerung-7"><span class="header-section-number">10.1</span> Lernsteuerung</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#lernziele-7"><span class="header-section-number">10.1.1</span> Lernziele</a></li>
<li><a class="nav-link" href="#literatur-7"><span class="header-section-number">10.1.2</span> Literatur</a></li>
<li><a class="nav-link" href="#hinweise-3"><span class="header-section-number">10.1.3</span> Hinweise</a></li>
</ul>
</li>
<li><a class="nav-link" href="#vorbereitung-7"><span class="header-section-number">10.2</span> Vorbereitung</a></li>
<li><a class="nav-link" href="#hinweise-zur-literatur"><span class="header-section-number">10.3</span> Hinweise zur Literatur</a></li>
<li><a class="nav-link" href="#wir-brauchen-einen-wald"><span class="header-section-number">10.4</span> Wir brauchen einen Wald</a></li>
<li><a class="nav-link" href="#was-ist-ein-ensemble-lerner"><span class="header-section-number">10.5</span> Was ist ein Ensemble-Lerner?</a></li>
<li>
<a class="nav-link" href="#bagging"><span class="header-section-number">10.6</span> Bagging</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#bootstrapping"><span class="header-section-number">10.6.1</span> Bootstrapping</a></li></ul>
</li>
<li>
<a class="nav-link" href="#bagging-algorithmus"><span class="header-section-number">10.7</span> Bagging-Algorithmus</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#variablenrelevanz"><span class="header-section-number">10.7.1</span> Variablenrelevanz</a></li>
<li><a class="nav-link" href="#out-of-bag-vorhersagen"><span class="header-section-number">10.7.2</span> Out of Bag Vorhersagen</a></li>
</ul>
</li>
<li><a class="nav-link" href="#random-forests"><span class="header-section-number">10.8</span> Random Forests</a></li>
<li>
<a class="nav-link" href="#boosting"><span class="header-section-number">10.9</span> Boosting</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#adaboost"><span class="header-section-number">10.9.1</span> AdaBoost</a></li>
<li><a class="nav-link" href="#xgboost"><span class="header-section-number">10.9.2</span> XGBoost</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tidymodels-3"><span class="header-section-number">10.10</span> Tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#datensatz-churn"><span class="header-section-number">10.10.1</span> Datensatz Churn</a></li>
<li><a class="nav-link" href="#data-splitting-und-cv"><span class="header-section-number">10.10.2</span> Data Splitting und CV</a></li>
<li><a class="nav-link" href="#feature-engineering"><span class="header-section-number">10.10.3</span> Feature Engineering</a></li>
<li><a class="nav-link" href="#modelle"><span class="header-section-number">10.10.4</span> Modelle</a></li>
<li><a class="nav-link" href="#workflows-1"><span class="header-section-number">10.10.5</span> Workflows</a></li>
<li><a class="nav-link" href="#modelle-berechnen-mit-tuning-einzeln"><span class="header-section-number">10.10.6</span> Modelle berechnen mit Tuning, einzeln</a></li>
<li><a class="nav-link" href="#workflow-set-tunen"><span class="header-section-number">10.10.7</span> Workflow-Set tunen</a></li>
<li><a class="nav-link" href="#ergebnisse-im-train-sest"><span class="header-section-number">10.10.8</span> Ergebnisse im Train-Sest</a></li>
<li><a class="nav-link" href="#bestes-modell"><span class="header-section-number">10.10.9</span> Bestes Modell</a></li>
<li><a class="nav-link" href="#finalisisieren"><span class="header-section-number">10.10.10</span> Finalisisieren</a></li>
<li><a class="nav-link" href="#last-fit"><span class="header-section-number">10.10.11</span> Last Fit</a></li>
<li><a class="nav-link" href="#variablenrelevanz-1"><span class="header-section-number">10.10.12</span> Variablenrelevanz</a></li>
<li><a class="nav-link" href="#roc-curve"><span class="header-section-number">10.10.13</span> ROC-Curve</a></li>
</ul>
</li>
<li><a class="nav-link" href="#aufgaben-6"><span class="header-section-number">10.11</span> Aufgaben</a></li>
<li><a class="nav-link" href="#aufgaben-7"><span class="header-section-number">10.12</span> Aufgaben</a></li>
<li><a class="nav-link" href="#vertiefung-4"><span class="header-section-number">10.13</span> Vertiefung</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/sebastiansauer/datascience1/blob/master/110-Ensemble-Lerner.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/sebastiansauer/datascience1/edit/master/110-Ensemble-Lerner.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>DataScience1</strong>: Grundlagen der Prognosemodellierung üîÆüß∞" was written by Sebastian Sauer. It was last built on 2022-06-18 18:30:22.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
