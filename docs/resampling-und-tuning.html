<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Kapitel 7 Resampling und Tuning | DataScience1</title>
<meta name="author" content="Sebastian Sauer">
<meta name="description" content="Ben√∂tigte R-Pakete f√ºr dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<meta name="generator" content="bookdown 0.26.2 with bs4_book()">
<meta property="og:title" content="Kapitel 7 Resampling und Tuning | DataScience1">
<meta property="og:type" content="book">
<meta property="og:description" content="Ben√∂tigte R-Pakete f√ºr dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kapitel 7 Resampling und Tuning | DataScience1">
<meta name="twitter:description" content="Ben√∂tigte R-Pakete f√ºr dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script><script src="libs/es6shim-0.35.6/es6shim.js"></script><script src="libs/es7shim-6.0.0/es7shim.js"></script><script src="libs/graphre-0.1.3/graphre.js"></script><script src="libs/nomnoml-1.3.1/nomnoml.js"></script><script src="libs/nomnoml-binding-0.2.3/nomnoml.js"></script><script src="libs/d3-3.3.8/d3.min.js"></script><script src="libs/dagre-0.4.0/dagre-d3.min.js"></script><link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet">
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script><script src="libs/chromatography-0.1/chromatography.js"></script><script src="libs/DiagrammeR-binding-1.0.6.1/DiagrammeR.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style-bs4.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Grundlagen der Prognosemodellierung üîÆüß∞">DataScience1</a>:
        <small class="text-muted">Grundlagen der Prognosemodellierung üîÆüß∞</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Zu diesem Buch</a></li>
<li><a class="" href="hinweise.html"><span class="header-section-number">1</span> Hinweise</a></li>
<li><a class="" href="pr%C3%BCfung.html"><span class="header-section-number">2</span> Pr√ºfung</a></li>
<li class="book-part">Themen</li>
<li><a class="" href="statistisches-lernen.html"><span class="header-section-number">3</span> Statistisches Lernen</a></li>
<li><a class="" href="r-zweiter-blick.html"><span class="header-section-number">4</span> R, zweiter Blick</a></li>
<li><a class="" href="tidymodels.html"><span class="header-section-number">5</span> tidymodels</a></li>
<li><a class="" href="knn.html"><span class="header-section-number">6</span> kNN</a></li>
<li><a class="active" href="resampling-und-tuning.html"><span class="header-section-number">7</span> Resampling und Tuning</a></li>
<li><a class="" href="logistische-regression.html"><span class="header-section-number">8</span> Logistische Regression</a></li>
<li><a class="" href="entscheidungsb%C3%A4ume.html"><span class="header-section-number">9</span> Entscheidungsb√§ume</a></li>
<li><a class="" href="ensemble-lerner.html"><span class="header-section-number">10</span> Ensemble Lerner</a></li>
<li><a class="" href="regularisierte-modelle.html"><span class="header-section-number">11</span> Regularisierte Modelle</a></li>
<li><a class="" href="kaggle.html"><span class="header-section-number">12</span> Kaggle</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/sebastiansauer/datascience1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="resampling-und-tuning" class="section level1" number="7">
<h1>
<span class="header-section-number">Kapitel 7</span> Resampling und Tuning<a class="anchor" aria-label="anchor" href="#resampling-und-tuning"><i class="fas fa-link"></i></a>
</h1>
<p>Ben√∂tigte R-Pakete f√ºr dieses Kapitel:</p>
<div id="lernsteuerung-4" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Lernsteuerung<a class="anchor" aria-label="anchor" href="#lernsteuerung-4"><i class="fas fa-link"></i></a>
</h2>
<!-- Chapter Start sections: Lernziele, Literatur, Hinweise, ... -->
<div id="vorbereitung-3" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> Vorbereitung<a class="anchor" aria-label="anchor" href="#vorbereitung-3"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Lesen Sie die Literatur.</li>
</ul>
</div>
<div id="lernziele-5" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> Lernziele<a class="anchor" aria-label="anchor" href="#lernziele-5"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.</li>
<li>Sie k√∂nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.</li>
</ul>
</div>
<div id="literatur-5" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> Literatur<a class="anchor" aria-label="anchor" href="#literatur-5"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Rhys, Kap. 3</li>
<li>TMWR, Kap. 10, 12</li>
</ul>
<!-- Das Paket `tune` auf CRAN hat einen Bug^[https://community.rstudio.com/t/trouble-using-extract-parameter-set-dials-in-tidy-models-with-r/131178], --><!-- daher empfiehlt der Autor, Max Kuhn, die Version des Pakets von Github zu installieren: --><!-- ```{r eval = FALSE, echo = TRUE} --><!-- devtools::install_github("tidymodels/tune") --><!-- ``` -->
</div>
</div>
<div id="√ºberblick-2" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> √úberblick<a class="anchor" aria-label="anchor" href="#%C3%BCberblick-2"><i class="fas fa-link"></i></a>
</h2>
<p>Der Standardablauf des maschinellen Lernens ist in Abb. <a href="resampling-und-tuning.html#fig:process1">7.1</a> dargestellt.
Eine alternative, hilfreich Abbildung findet sich <a href="https://www.tmwr.org/resampling.html">hier</a> in Kap. 10.2 in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:process1"></span>
<img src="https://nomnoml.com/image.svg?source=%23direction%3A%20right%0A%5B%3Cdatabase%3E%20Gesamtdatensatz%5D%20-%3E%20%20%5BSplitte%20in%20Train-%20und%20Test-Sample%5D%0A%5BSplitte%20in%20Train-%20und%20Test-Sample%5D%20-%3E%20%5BF%C3%BCr%20jeden%20Modell-Kandidaten%20i%3D1%2C2%2C..%2Cn%20%7C%0A%20%20%5BTrain-Test%20Modellkandidat%20i%7C%0A%20%20%20%20%5BFitte%20in%20Train-Sample%5D%20-%3E%20%5BTeste%20im%20Assessment-Sample%5D%5D%0A%20%20%5D%20%0A%20%20%5BF%C3%BCr%20jeden%20Modell-Kandidaten%20i%3D1%2C2%2C..%2Cn%20%7C%0A%20%20%5BTrain-Test%20Modellkandidat%20i%7C%0A%20%20%20%20%5BFitte%20in%20Train-Sample%5D%20-%3E%20%5BTeste%20im%20Assessment-Sample%5D%5D%0A%20%20%5D%20-%3E%20%5BBestimme%20besten%20Modell-Kandidaten%5D%0A%20%20%5BBestimme%20besten%20Modell-Kandidaten%5D%20-%3E%20%5BFitte%20Modell%20im%20Train-Datensatz%5D%0A%20%20%5BFitte%20Modell%20im%20Train-Datensatz%5D%20-%3E%20%5BTest%20im%20Test-Datensatz%5D%0A%20%20%5BTest%20im%20Test-Datensatz%5D%20-%3E%20%5B%3Cend%3E%20Ende%5D" alt="Standardablauf des maschinellen Lernens mit Tuning und Resampling" width="100%"><p class="caption">
Figure 7.1: Standardablauf des maschinellen Lernens mit Tuning und Resampling
</p>
</div>
</div>
<div id="tidymodels-1" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> tidymodels<a class="anchor" aria-label="anchor" href="#tidymodels-1"><i class="fas fa-link"></i></a>
</h2>
<div id="datensatz-aufteilen" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Datensatz aufteilen<a class="anchor" aria-label="anchor" href="#datensatz-aufteilen"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">ames</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4595</span><span class="op">)</span>
<span class="va">data_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">ames</span>, strata <span class="op">=</span> <span class="st">"Sale_Price"</span><span class="op">)</span>

<span class="va">ames_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">data_split</span><span class="op">)</span>
<span class="va">ames_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">data_split</span><span class="op">)</span></code></pre></div>
</div>
<div id="rezept-modell-und-workflow-definieren" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> Rezept, Modell und Workflow definieren<a class="anchor" aria-label="anchor" href="#rezept-modell-und-workflow-definieren"><i class="fas fa-link"></i></a>
</h3>
<p>In gewohnter Weise definieren wir den Workflow
mit einem kNN-Modell.</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_rec</span> <span class="op">&lt;-</span>
  <span class="fu">recipe</span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">ames_train</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_log</span><span class="op">(</span><span class="va">Sale_Price</span>, base <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_other</span><span class="op">(</span><span class="va">Neighborhood</span>, threshold <span class="op">=</span> <span class="fl">.1</span><span class="op">)</span>  <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> 

<span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span>

<span class="va">ames_wflow</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">ames_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<p>Das kNN-Modell ist noch <em>nicht</em> <em>berechnet</em>,
es ist nur ein ‚ÄúRezept‚Äù erstellt:</p>
<div class="sourceCode" id="cb248"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span></code></pre></div>
<pre><code>## K-Nearest Neighbor Model Specification (regression)
## 
## Computational engine: kknn</code></pre>
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span></code></pre></div>
<pre><code>## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 4 Recipe Steps
## 
## ‚Ä¢ step_log()
## ‚Ä¢ step_other()
## ‚Ä¢ step_dummy()
## ‚Ä¢ step_zv()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## K-Nearest Neighbor Model Specification (regression)
## 
## Computational engine: kknn</code></pre>
</div>
</div>
<div id="resampling" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Resampling<a class="anchor" aria-label="anchor" href="#resampling"><i class="fas fa-link"></i></a>
</h2>
<p>Vergleichen Sie die drei F√§lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:</p>
<ol style="list-style-type: decimal">
<li>Wir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe ‚Äúvorher‚Äù. Wir finden eine Gesamtgenauigkeit von 80%.</li>
<li>Wir fitten ein Klassifikationsmodell in einem Teil der urspr√ºnglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der urspr√ºnglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.</li>
<li>Wir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der F√§lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.</li>
</ol>
<p>Welchen der drei F√§lle finden Sie am sinnvollsten? Warum?</p>
</div>
<div id="illustration-des-resampling" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> Illustration des Resampling<a class="anchor" aria-label="anchor" href="#illustration-des-resampling"><i class="fas fa-link"></i></a>
</h2>
<p><em>Resampling</em> stellt einen Oberbegriff dar; <em>Kreuzvalidierung</em> ist ein Unterbegriff dazu.
Es gibt noch andere Arten des Resampling, etwa <em>Bootstrapping</em> oder <em>Leave-One-Out-Cross-Validation</em> (LOOCV).</p>
<p>Im Folgenden ist nur die Kreuzvalidierung dargestellt,
da es eines der wichtigsten und vielleicht das Wichtigste ist.
In vielen Quellen finden sich Erl√§uterungen anderer Verfahren dargestellt,
etwa in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>, <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span> oder <span class="citation">Rhys (<a href="references.html#ref-rhys" role="doc-biblioref">2020</a>)</span>.</p>
<div id="einfache-v-fache-kreuzvalidierung" class="section level3" number="7.5.1">
<h3>
<span class="header-section-number">7.5.1</span> Einfache v-fache Kreuzvalidierung<a class="anchor" aria-label="anchor" href="#einfache-v-fache-kreuzvalidierung"><i class="fas fa-link"></i></a>
</h3>
<p>Abb. <a href="resampling-und-tuning.html#fig:resampling">7.2</a> illustriert die zuf√§llige Aufteilung von <span class="math inline">\(n=10\)</span> F√§llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe.
Man spricht von <em>Kreuzvalidierung</em> (cross validation, CV).</p>
<p>In diesem Fall wurden 70% der (<span class="math inline">\(n=10\)</span>) F√§lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe);
ein willk√ºrlicher, aber nicht un√ºblicher Anteil.
Diese Aufteilung wurde <span class="math inline">\(v=3\)</span> Mal vorgenommen,
es resultieren drei ‚ÄúResampling-Stichproben‚Äù, die
manchmal auch als ‚ÄúFaltungen‚Äù bezeichnet werden.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:resampling"></span>
<img src="080-Resampling-Tuning_files/figure-html/resampling-1.png" alt="Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt" width="100%"><p class="caption">
Figure 7.2: Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt
</p>
</div>
<p><span class="citation">Sauer (<a href="references.html#ref-modar" role="doc-biblioref">2019</a>)</span> stellt das Resampling so dar (S. 259), s. Abb. <a href="resampling-und-tuning.html#fig:cvmodar">7.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cvmodar"></span>
<img src="img/crossval.png" alt="Kreuzvalidierung, Aufteilung in Train- vs. Testsample" width="100%"><p class="caption">
Figure 7.3: Kreuzvalidierung, Aufteilung in Train- vs.¬†Testsample
</p>
</div>
<p>Der Gesamtfehler der Vorhersage wird als Mittelwerte der Vorhersagefehler in den einzelnen Faltungen berechnet.</p>
<p>Warum ist die Vorhersage besser,
wenn man mehrere Faltungen, mehrere Sch√§tzungen f√ºr <span class="math inline">\(y\)</span> also, vornimmt?</p>
<p>Der Grund ist das Gesetz der gro√üen Zahl,
nachdem sich eine Sch√§tzung in Mittelwert und Variabilit√§t stabilisiert mit steigendem
Stichprobenumfang,
dem wahren Mittelwert also pr√§ziser sch√§tzt.
Bei Normalverteilungen klappt das gut,
bei randlastigen Verteilungen leider nicht mehr <span class="citation">(<a href="references.html#ref-fattails" role="doc-biblioref">Taleb 2019</a>)</span>.</p>
<p>H√§ufig werden <span class="math inline">\(v=10\)</span> Faltungen verwendet,
was sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.</p>
</div>
<div id="wiederholte-kreuzvalidierung" class="section level3" number="7.5.2">
<h3>
<span class="header-section-number">7.5.2</span> Wiederholte Kreuzvalidierung<a class="anchor" aria-label="anchor" href="#wiederholte-kreuzvalidierung"><i class="fas fa-link"></i></a>
</h3>
<p>Die <span class="math inline">\(r\)</span>-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (n√§mlich <span class="math inline">\(r=4\)</span> mal),
<span class="citation">Sauer (<a href="references.html#ref-modar" role="doc-biblioref">2019</a>)</span> stellt das Resampling so dar (S. 259), s. Abb. <a href="resampling-und-tuning.html#fig:cvrep">7.4</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cvrep"></span>
<img src="img/crossval_repeated.png" alt="Wiederholte Kreuzvalidierung" width="100%"><p class="caption">
Figure 7.4: Wiederholte Kreuzvalidierung
</p>
</div>
<p>Die wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.</p>
<p><span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> zeigen die Verringerung des Sch√§tzfehlers als Funktion der <span class="math inline">\(r\)</span> Wiederholungen dar,
s. Abb. <a href="resampling-und-tuning.html#fig:repcvred">7.5</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:repcvred"></span>
<img src="https://www.tmwr.org/figures/variance-reduction-1.png" alt="Reduktion des Sch√§tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung" width="100%"><p class="caption">
Figure 7.5: Reduktion des Sch√§tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung
</p>
</div>
<p>Warum ist die Wiederholung der Kreuzvalidierung n√ºtzlich?</p>
<p>Die Kreuvalidierung liefert einen Sch√§tzwert der Modellparameter,
die wahren Modellparameter werden also anhand einer Stichprobe von <span class="math inline">\(n=1\)</span> gesch√§tzt.
Mit h√∂herem Stichprobenumfang kann diese Sch√§tzung nat√ºrlich pr√§zisiert werden.</p>
<p>Da jede Stichprobenverteilung bei <span class="math inline">\(n \rightarrow \infty\)</span> normalverteilt ist -
ein zentrales Theorem der Statistik, der <em>Zentrale Grenzwertsatz</em> (Central Limit Theorem) -
kann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem <span class="math inline">\(n\)</span> ebenfalls ann√§hernd
normalverteilt<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Das klappt bei randlastigen Verteilungen nicht&lt;/p&gt;"><sup>3</sup></a>.
Dann sind die Quantile bekannt und man kann die Streuung der Sch√§tzers,
<span class="math inline">\({\sigma }_{\bar {x}}\)</span>, z.B. f√ºr den Mittelwert,
einfach sch√§tzen:</p>
<p><span class="math display">\[{\displaystyle {\sigma }_{\bar {x}}\ ={\frac {\sigma }{\sqrt {n}}}}\]</span></p>
</div>
<div id="resampling-passiert-im-train-sample" class="section level3" number="7.5.3">
<h3>
<span class="header-section-number">7.5.3</span> Resampling passiert im Train-Sample<a class="anchor" aria-label="anchor" href="#resampling-passiert-im-train-sample"><i class="fas fa-link"></i></a>
</h3>
<p>Wichtig zu beachten ist, dass
die Resampling nur im Train-Sample stattfindet.
Das Test-Sample bleibt unanger√ºhrt.
Dieser Sachverhalt ist in Abb. <a href="resampling-und-tuning.html#fig:initialsplit">7.6</a>, aus <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>, illustriert.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:initialsplit"></span>
<img src="https://www.tmwr.org/premade/resampling.svg" alt="Resampling im Train-, nicht im Test-Sample" width="100%"><p class="caption">
Figure 7.6: Resampling im Train-, nicht im Test-Sample
</p>
</div>
<p>Wie in Abb. <a href="resampling-und-tuning.html#fig:initialsplit">7.6</a> dargestellt,
wird das Modell im <em>Analyse-Sample</em> berechnet (gefittet),
und im <em>Assessment-Sample</em> auf Modellg√ºte hin √ºberpr√ºft.</p>
<p>Die letztliche Modellg√ºte ist dann die Zusammenfassung (Mittelwert) der einzelnen Resamples.</p>
</div>
<div id="andere-illustrationen" class="section level3" number="7.5.4">
<h3>
<span class="header-section-number">7.5.4</span> Andere Illustrationen<a class="anchor" aria-label="anchor" href="#andere-illustrationen"><i class="fas fa-link"></i></a>
</h3>
<p>Es gibt eine Reihe vergleichbarer Illustrationen in anderen B√ºchern:</p>
<ul>
<li><a href="https://datasciencebook.ca/img/cv.png">Timbers, Campbell &amp; Lee, 2022, Kap. 6</a></li>
<li><a href="https://datasciencebook.ca/img/cv.png">Silge &amp; Kuhn, 2022, Abb. 10.1</a></li>
<li><a href="https://www.tmwr.org/premade/three-CV.svg">Silge &amp; Kuhn, 2022, Abb. 10.2</a></li>
<li><a href="https://www.tmwr.org/premade/three-CV-iter.svg">Silge &amp; Kuhn, 2022, Abb. 10.3</a></li>
<li>James, Witten, hastie &amp; Tishirani, 2021, Abb. 5.3</li>
</ul>
</div>
</div>
<div id="gesetz-der-gro√üen-zahl" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> Gesetz der gro√üen Zahl<a class="anchor" aria-label="anchor" href="#gesetz-der-gro%C3%9Fen-zahl"><i class="fas fa-link"></i></a>
</h2>
<p>Nach dem <em>Gesetz der gro√üen Zahl</em> (Law of Large Numbers) sollte sich der Mittelwert einer gro√üen Stichprobe
dem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess)
sehr nahe kommen.</p>
<p><span class="math display">\[\displaystyle \lim _{n\to \infty }\sum _{i=1}^{n}{\frac {X_{i}}{n}}={\overline {X}}\]</span></p>
<p>David Salazar visualisiert das folgenderma√üen in <a href="https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/">diesem Post</a> seines lesenswerten <a href="https://david-salazar.github.io/">Blogs</a>, s. Abb. <a href="resampling-und-tuning.html#fig:lln">7.7</a>.</p>
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># source: https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/</span>
<span class="va">samples</span> <span class="op">&lt;-</span> <span class="fl">1000</span>

<span class="va">thin</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">samples</span>, sd <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>

<span class="va">cumulative_mean</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span><span class="op">)</span>
    <span class="va">cum_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumsum</a></span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span><span class="op">/</span><span class="va">x</span> 
    <span class="va">cum_mean</span>
<span class="op">}</span>

<span class="va">thin_cum_mean</span> <span class="op">&lt;-</span> <span class="fu">cumulative_mean</span><span class="op">(</span><span class="va">thin</span><span class="op">)</span>

<span class="va">thin_cum_mean</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>running_mean <span class="op">=</span> <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/add_rownames.html">add_rownames</a></span><span class="op">(</span>var <span class="op">=</span> <span class="st">'number_samples'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>number_samples <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="va">number_samples</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">number_samples</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">number_samples</span>, y <span class="op">=</span> <span class="va">running_mean</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">'dodgerblue4'</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, linetype <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">hrbrthemes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/hrbrthemes/man/theme_ipsum_rc.html">theme_ipsum_rc</a></span><span class="op">(</span>grid <span class="op">=</span> <span class="st">'Y'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Stichprobengr√∂√üe"</span>,
       title <span class="op">=</span> <span class="st">"Gesetz der gro√üen Zahl"</span>, 
       subtitle <span class="op">=</span> <span class="st">"Kumulierter Mittelwert aus einer Normalverteilung mit sd=20"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lln"></span>
<img src="080-Resampling-Tuning_files/figure-html/lln-1.png" alt="Gesetz der gro√üen Zahl" width="100%"><p class="caption">
Figure 7.7: Gesetz der gro√üen Zahl
</p>
</div>
<p>Wie man sieht, n√§hert sich der empirische Mittelwert (also in der Stichprobe)
immer mehr dem theoretischen Mittelwert, 0, an.</p>
<p>Achtung: Bei randlastigen Verteilungen darf man dieses sch√∂ne, wohlerzogene Verhalten nicht erwarten <span class="citation">(<a href="references.html#ref-fattails" role="doc-biblioref">Taleb 2019</a>)</span>.</p>
</div>
<div id="√ºber--und-unteranpassung-an-einem-beispiel" class="section level2" number="7.7">
<h2>
<span class="header-section-number">7.7</span> √úber- und Unteranpassung an einem Beispiel<a class="anchor" aria-label="anchor" href="#%C3%BCber--und-unteranpassung-an-einem-beispiel"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:overfitting-4-plots"></span>
<img src="080-Resampling-Tuning_files/figure-html/overfitting-4-plots-1.png" alt="Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die 'wahre Funktion', der datengenerierende Prozess ist im Teil A dargestellt" width="100%"><p class="caption">
Figure 7.8: Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die ‚Äòwahre Funktion‚Äô, der datengenerierende Prozess ist im Teil A dargestellt
</p>
</div>
<p>Abb. <a href="resampling-und-tuning.html#fig:overfitting-4-plots">7.8</a> zeigt:</p>
<ul>
<li>Teil <em>A</em>: Die ‚Äòwahre Funktion‚Äô, <span class="math inline">\(f\)</span>, die die Daten erzeugt. Man spricht auch von der ‚Äúdatengenerierenden Funktion‚Äù. Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das hei√üt nicht, dass die wahre Funktion die Daten perfekt erkl√§rt, schlie√ülich kann die Funktion zwar wahr, aber unvollst√§ndig sein oder unsere Messinstrumente sind nicht perfekt pr√§zise.</li>
<li>Teil <em>B:</em> Die Daten, erzeugt aus A plus etwas zuf√§lliges Fehler (Rauschen).</li>
<li>Teil <em>C</em>: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.</li>
<li>Teil <em>D</em>: Ein zu komplexes Modell: √úberanpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.</li>
<li>Teil <em>E</em>: Ein Modell mittlerer Komplexit√§t. Keine √úberanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.</li>
</ul>
</div>
<div id="cv-in-tidymodels" class="section level2" number="7.8">
<h2>
<span class="header-section-number">7.8</span> CV in tidymodels<a class="anchor" aria-label="anchor" href="#cv-in-tidymodels"><i class="fas fa-link"></i></a>
</h2>
<div id="cv-definieren" class="section level3" number="7.8.1">
<h3>
<span class="header-section-number">7.8.1</span> CV definieren<a class="anchor" aria-label="anchor" href="#cv-definieren"><i class="fas fa-link"></i></a>
</h3>
<p>So kann man eine <em>einfache</em> v-fache Kreuzvalidierung in Tidymodels auszeichnen:</p>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2453</span><span class="op">)</span>
<span class="va">ames_folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">ames_train</span>, strata <span class="op">=</span> <span class="st">"Sale_Price"</span><span class="op">)</span>
<span class="va">ames_folds</span></code></pre></div>
<pre><code>## #  10-fold cross-validation using stratification 
## # A tibble: 10 √ó 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [1976/221]&gt; Fold01
##  2 &lt;split [1976/221]&gt; Fold02
##  3 &lt;split [1976/221]&gt; Fold03
##  4 &lt;split [1976/221]&gt; Fold04
##  5 &lt;split [1977/220]&gt; Fold05
##  6 &lt;split [1977/220]&gt; Fold06
##  7 &lt;split [1978/219]&gt; Fold07
##  8 &lt;split [1978/219]&gt; Fold08
##  9 &lt;split [1979/218]&gt; Fold09
## 10 &lt;split [1980/217]&gt; Fold10</code></pre>
<p>Werfen wir einen Blick in die Spalte <code>splits</code>, erste Zeile:</p>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_folds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span></code></pre></div>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;1976/221/2197&gt;</code></pre>
<p>M√∂chte man die Defaults vpn <code>vfold_cv</code> wissen, schaut man in der Hilfe nach: <code>?vfold_cv</code>:</p>
<p><code>vfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)</code></p>
<p>Probieren wir <span class="math inline">\(v=5\)</span> und <span class="math inline">\(r=2\)</span>:</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_folds_rep</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">ames_train</span>, 
                           strata <span class="op">=</span> <span class="st">"Sale_Price"</span>, 
                           v <span class="op">=</span> <span class="fl">5</span>,
                           repeats <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">ames_folds_rep</span></code></pre></div>
<pre><code>## #  5-fold cross-validation repeated 2 times using stratification 
## # A tibble: 10 √ó 3
##    splits             id      id2  
##    &lt;list&gt;             &lt;chr&gt;   &lt;chr&gt;
##  1 &lt;split [1756/441]&gt; Repeat1 Fold1
##  2 &lt;split [1757/440]&gt; Repeat1 Fold2
##  3 &lt;split [1757/440]&gt; Repeat1 Fold3
##  4 &lt;split [1758/439]&gt; Repeat1 Fold4
##  5 &lt;split [1760/437]&gt; Repeat1 Fold5
##  6 &lt;split [1756/441]&gt; Repeat2 Fold1
##  7 &lt;split [1757/440]&gt; Repeat2 Fold2
##  8 &lt;split [1757/440]&gt; Repeat2 Fold3
##  9 &lt;split [1758/439]&gt; Repeat2 Fold4
## 10 &lt;split [1760/437]&gt; Repeat2 Fold5</code></pre>
</div>
<div id="resamples-fitten" class="section level3" number="7.8.2">
<h3>
<span class="header-section-number">7.8.2</span> Resamples fitten<a class="anchor" aria-label="anchor" href="#resamples-fitten"><i class="fas fa-link"></i></a>
</h3>
<p>Hat unser Computer mehrere Rechenkerne, dann k√∂nnen wir diese nutzen und die Berechnungen beschleunigen.
Im Standard wird sonst nur ein Kern verwendet.</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mycores</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span>logical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">mycores</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Auf Unix/MacOC-Systemen kann man dann die Anzahl der parallen Kerne so einstellen:</p>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">doMC</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/doMC/man/registerDoMC.html">registerDoMC</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="va">mycores</span><span class="op">)</span></code></pre></div>
<p>So, und jetzt fitten wir die Resamples und trachten die Modellg√ºte in den Resamples:</p>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_resamples_fit</span> <span class="op">&lt;-</span> 
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">fit_resamples</span><span class="op">(</span><span class="va">ames_folds</span><span class="op">)</span>

 <span class="va">ames_resamples_fit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 √ó 6
##   .metric .estimator   mean     n std_err .config             
##   &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard   0.0928    10 0.00187 Preprocessor1_Model1
## 2 rsq     standard   0.722     10 0.00864 Preprocessor1_Model1</code></pre>
<p>Nat√ºrlich interessiert uns prim√§r die Modellg√ºte im Test-Sample:</p>
<div class="sourceCode" id="cb264"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames</span> <span class="op">&lt;-</span>
  <span class="fu">last_fit</span><span class="op">(</span><span class="va">ames_wflow</span>, <span class="va">data_split</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 √ó 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard       0.103 Preprocessor1_Model1
## 2 rsq     standard       0.678 Preprocessor1_Model1</code></pre>
</div>
</div>
<div id="tuning" class="section level2" number="7.9">
<h2>
<span class="header-section-number">7.9</span> Tuning<a class="anchor" aria-label="anchor" href="#tuning"><i class="fas fa-link"></i></a>
</h2>
<div id="tuning-auszeichnen" class="section level3" number="7.9.1">
<h3>
<span class="header-section-number">7.9.1</span> Tuning auszeichnen<a class="anchor" aria-label="anchor" href="#tuning-auszeichnen"><i class="fas fa-link"></i></a>
</h3>
<p>In der Modellspezifikation des Modells k√∂nnen wir mit <code>tune()</code> auszeichnen,
welche Parameter wir tunen m√∂chten.
Wir k√∂nenn</p>
<div class="sourceCode" id="cb267"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
    neighbors <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span></code></pre></div>
<p>Wir k√∂nnen dem Tuningparameter auch einen Namen (ID/Laben) geben, z.B. ‚ÄúK‚Äù:</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
    neighbors <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="st">"K"</span><span class="op">)</span>
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span></code></pre></div>
</div>
<div id="grid-search-vs.-iterative-search" class="section level3" number="7.9.2">
<h3>
<span class="header-section-number">7.9.2</span> Grid Search vs.¬†Iterative Search<a class="anchor" aria-label="anchor" href="#grid-search-vs.-iterative-search"><i class="fas fa-link"></i></a>
</h3>
<p>Im K-N√§chste-Nachbarn-Modell ist der vorhergesagt Wert, <span class="math inline">\(\hat{y}\)</span> f√ºr eine neue Beobachtung <span class="math inline">\(x_0\)</span> wie folgt definiert:</p>
<p><span class="math display">\[
\hat y = \frac{1}{K}\sum_{\ell = 1}^K x_\ell^*,
\]</span></p>
<p>wobei <span class="math inline">\(K\)</span> die Anzahl der zu ber√ºcksichtigen n√§chsten Nachbarn darstellt und <span class="math inline">\(x_\ell^*\)</span> die Werte dieser ber√ºcksichtiggten Nachbarn.</p>
<p>Die Wahl von <span class="math inline">\(K\)</span> hat einen gewaltigen Einfluss auf die Vorhersagen und damit auf die Vorhersageg√ºte.
Allerdings wird <span class="math inline">\(K\)</span> nicht vom Modell gesch√§tzt.
Es liegt an den Nutzi,
diesen Wert zu w√§hlen.</p>
<p>Parameter dieser Art (die von den Nutzi zu bestimmen sind, nicht vom Algorithmus),
nennt man <em>Tuningparameter</em>.</p>
<p>Abbildung <a href="resampling-und-tuning.html#fig:nnoverfit">7.9</a> aus <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> stellt exemplarisch dar,
welchen gro√üen Einfluss die Wahl des Werts eines Tuningparameters auf die
Vorhersagen eines Modells haben.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:nnoverfit"></span>
<img src="https://www.tmwr.org/figures/two-class-boundaries-1.png" alt="Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter" width="100%"><p class="caption">
Figure 7.9: Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter
</p>
</div>
<p>Aber wie w√§hlt man ‚Äúgute‚Äù Werte der Tuningparater?
Zwei Ans√§tze, grob gesprochen, bieten sich an.</p>
<ol style="list-style-type: decimal">
<li><p><em>Grid Search:</em> Probiere viele Werte aus und schaue, welcher der beste ist. Dabei musst du hoffen, dass du die Werte erwischt, die nicht nur im Train-, sondern auch im Test-Sample gut funktionieren werden.</p></li>
<li><p><em>Iterative Search:</em> Wenn du einen Wert eines Tuningparameters hast, nutze diesen, um intelligenter einen neuen Wert eines Tuningparameters zu finden.</p></li>
</ol>
<p>Der Unterschied beider Ans√§tze ist in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> wie in Abb. <a href="resampling-und-tuning.html#fig:tuning1">7.10</a> dargestellt.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:tuning1"></span>
<img src="https://www.tmwr.org/figures/tuning-strategies-1.png" alt="Links: Grid Search. Rechts: Iterative Search2" width="100%"><p class="caption">
Figure 7.10: Links: Grid Search. Rechts: Iterative Search2
</p>
</div>
<p>In <code>tidymodels</code> kann man mit <code>tune()</code> angeben, dass man einen bestimmten Parameter tunen m√∂chte.
<code>tidymodels</code> f√ºhrt das dann ohne weiteres Federlesens f√ºr uns durch.</p>
</div>
</div>
<div id="tuning-mit-tidymodels" class="section level2" number="7.10">
<h2>
<span class="header-section-number">7.10</span> Tuning mit Tidymodels<a class="anchor" aria-label="anchor" href="#tuning-mit-tidymodels"><i class="fas fa-link"></i></a>
</h2>
<div id="tuningparameter-betrachten" class="section level4" number="7.10.0.1">
<h4>
<span class="header-section-number">7.10.0.1</span> Tuningparameter betrachten<a class="anchor" aria-label="anchor" href="#tuningparameter-betrachten"><i class="fas fa-link"></i></a>
</h4>
<p>M√∂chte man wissen,
welche und wie viele Tuningparameter tidymodels in einem Modell ber√ºcksichtigt,
kann man <code>extract_parameter_set_dials()</code> aufrufen:</p>
<div class="sourceCode" id="cb269"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<pre><code>## Collection of 1 parameters for tuning
## 
##  identifier      type    object
##           K neighbors nparam[+]</code></pre>
<p>Die Ausgabe informiert uns,
dass es nur einen Tuningparameter gibt in diesem Modell und
dass der Name (Label, ID) des Tuningparameters ‚ÄúK‚Äù ist.
Au√üerdem sollen die Anzahl der Nachbarn getunt werden.
Der Tuningparameter ist numerisch; das sieht man an <code>nparam[+]</code>.</p>
<p>Schauen wir uns mal an,
auf welchen Wertebereich <code>tidymodels</code> den Parameter <span class="math inline">\(K\)</span> begrenzt hat:</p>
<div class="sourceCode" id="cb271"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">extract_parameter_dials</span><span class="op">(</span><span class="st">"K"</span><span class="op">)</span></code></pre></div>
<pre><code>## # Nearest Neighbors (quantitative)
## Range: [1, 15]</code></pre>
<p>Aktualisieren wir mal unseren Workflow entsprechend:</p>
<div class="sourceCode" id="cb273"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span> <span class="op">&lt;-</span>
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">update_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<p>Wir k√∂nnen auch Einfluss nehmen und angeben,
dass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll
(f√ºr den Tuningparameter <code>neighbors</code>):</p>
<div class="sourceCode" id="cb274"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_set</span> <span class="op">&lt;-</span>
  <span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="va">ames_wflow</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span>K <span class="op">=</span> <span class="fu">neighbors</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">ames_set</span></code></pre></div>
<pre><code>## Collection of 1 parameters for tuning
## 
##  identifier      type    object
##           K neighbors nparam[+]</code></pre>
</div>
<div id="datenabh√§ngige-tuningparameter" class="section level3" number="7.10.1">
<h3>
<span class="header-section-number">7.10.1</span> Datenabh√§ngige Tuningparameter<a class="anchor" aria-label="anchor" href="#datenabh%C3%A4ngige-tuningparameter"><i class="fas fa-link"></i></a>
</h3>
<p>Manche Tuningparameter kann man nur bestimmen,
wenn man den Datensatz kennt.
So ist die Anzahl der Pr√§diktoren, <code>mtry</code> in einem Random-Forest-Modell
sinnvollerweise als Funktion der Pr√§diktorenzahl zu w√§hlen.
Der Workflow kennt aber den Datensatz nicht.
Daher muss der Workflow noch ‚Äúfinalisiert‚Äù oder ‚Äúaktualisiert‚Äù werden,
um den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen.</p>
<p>Wenn wir im Rezept aber z.B. die Anzahl der Pr√§diktoren ver√§ndert haben,
m√∂chten wir die Grenzen des Wertebereichs f√ºr <code>mtry</code> (oder andere Tuningparameter) vielleicht nicht h√§ndisch, ‚Äúhartverdrahtet‚Äù selber bestimmen,
sondern lieber den Computer anweisen, und sinngem√§√ü sagen:
‚ÄúWarte mal mit der Bestimmung der Werte der Tuningparameter,
bis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir,
dass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch √§ndern musst. Und tu das dann auch.‚Äù Dazu sp√§ter mehr.</p>
<div class="sourceCode" id="cb276"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_set</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">ames_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">finalize</span><span class="op">(</span><span class="va">ames_train</span><span class="op">)</span></code></pre></div>
</div>
<div id="modelle-mit-tuning-berechnen" class="section level3" number="7.10.2">
<h3>
<span class="header-section-number">7.10.2</span> Modelle mit Tuning berechnen<a class="anchor" aria-label="anchor" href="#modelle-mit-tuning-berechnen"><i class="fas fa-link"></i></a>
</h3>
<p>Nachdem wir die Tuningwerte bestimmt haben,
k√∂nnen wir jetzt das Modell berechnen:
F√ºr jeden Wert des Tuningparameters wird ein Modell berechnet:</p>
<div class="sourceCode" id="cb277"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_grid_search</span> <span class="op">&lt;-</span>
  <span class="fu">tune_grid</span><span class="op">(</span>
    <span class="va">ames_wflow</span>,
    resamples <span class="op">=</span> <span class="va">ames_folds</span>
  <span class="op">)</span>
<span class="va">ames_grid_search</span></code></pre></div>
<pre><code>## # Tuning results
## # 10-fold cross-validation using stratification 
## # A tibble: 10 √ó 4
##    splits             id     .metrics          .notes          
##    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [1976/221]&gt; Fold01 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  2 &lt;split [1976/221]&gt; Fold02 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  3 &lt;split [1976/221]&gt; Fold03 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  4 &lt;split [1976/221]&gt; Fold04 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  5 &lt;split [1977/220]&gt; Fold05 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  6 &lt;split [1977/220]&gt; Fold06 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  7 &lt;split [1978/219]&gt; Fold07 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  8 &lt;split [1978/219]&gt; Fold08 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
##  9 &lt;split [1979/218]&gt; Fold09 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;
## 10 &lt;split [1980/217]&gt; Fold10 &lt;tibble [16 √ó 5]&gt; &lt;tibble [0 √ó 3]&gt;</code></pre>
<p>Im Default berechnet <code>tiymodels</code> 10 Kandidatenmodelle.</p>
<p>Die Spalte <code>.metrics</code> beinhaltet die Modellg√ºte f√ºr jedes Kandidatenmodell.</p>
<div class="sourceCode" id="cb279"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_grid_search</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 16 √ó 7
##        K .metric .estimator   mean     n std_err .config             
##    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
##  1     2 rmse    standard   0.103     10 0.00213 Preprocessor1_Model1
##  2     2 rsq     standard   0.662     10 0.0112  Preprocessor1_Model1
##  3     4 rmse    standard   0.0950    10 0.00188 Preprocessor1_Model2
##  4     4 rsq     standard   0.708     10 0.00916 Preprocessor1_Model2
##  5     6 rmse    standard   0.0912    10 0.00189 Preprocessor1_Model3
##  6     6 rsq     standard   0.732     10 0.00842 Preprocessor1_Model3
##  7     7 rmse    standard   0.0900    10 0.00192 Preprocessor1_Model4
##  8     7 rsq     standard   0.740     10 0.00829 Preprocessor1_Model4
##  9     9 rmse    standard   0.0883    10 0.00201 Preprocessor1_Model5
## 10     9 rsq     standard   0.752     10 0.00827 Preprocessor1_Model5
## 11    11 rmse    standard   0.0872    10 0.00211 Preprocessor1_Model6
## 12    11 rsq     standard   0.761     10 0.00845 Preprocessor1_Model6
## 13    13 rmse    standard   0.0865    10 0.00217 Preprocessor1_Model7
## 14    13 rsq     standard   0.767     10 0.00848 Preprocessor1_Model7
## 15    15 rmse    standard   0.0861    10 0.00221 Preprocessor1_Model8
## 16    15 rsq     standard   0.772     10 0.00850 Preprocessor1_Model8</code></pre>
<p>Das k√∂nnen wir uns einfach visualisieren lassen:</p>
<div class="sourceCode" id="cb281"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="080-Resampling-Tuning_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Auf Basis dieser Ergebnisse k√∂nnte es Sinn machen,
noch gr√∂√üere Werte f√ºr <span class="math inline">\(K\)</span> zu √ºberpr√ºfen.</p>
</div>
<div id="vorhersage-im-test-sample" class="section level3" number="7.10.3">
<h3>
<span class="header-section-number">7.10.3</span> Vorhersage im Test-Sample<a class="anchor" aria-label="anchor" href="#vorhersage-im-test-sample"><i class="fas fa-link"></i></a>
</h3>
<p>Welches Modellkandidat war jetzt am besten?</p>
<div class="sourceCode" id="cb282"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">show_best</span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 5 √ó 7
##       K .metric .estimator   mean     n std_err .config             
##   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1    15 rmse    standard   0.0861    10 0.00221 Preprocessor1_Model8
## 2    13 rmse    standard   0.0865    10 0.00217 Preprocessor1_Model7
## 3    11 rmse    standard   0.0872    10 0.00211 Preprocessor1_Model6
## 4     9 rmse    standard   0.0883    10 0.00201 Preprocessor1_Model5
## 5     7 rmse    standard   0.0900    10 0.00192 Preprocessor1_Model4</code></pre>
<p>W√§hlen wir jetzt mal das beste Modell aus (im Sinne des Optimierungskriteriusms):</p>
<div class="sourceCode" id="cb284"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">select_best</span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 √ó 2
##       K .config             
##   &lt;int&gt; &lt;chr&gt;               
## 1    15 Preprocessor1_Model8</code></pre>
<p>Ok,
notieren wir uns die Kombination der Tuningparameterwerte
im besten Kandiatenmodell.
In diesem Fall hat das Modull nur einen Tuningparameter:</p>
<div class="sourceCode" id="cb286"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_knn_best_params</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>K <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></code></pre></div>
<p>Unser Workflow wei√ü noch nicht,
welche Tuningparameterwerte am besten sind:</p>
<div class="sourceCode" id="cb287"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span></code></pre></div>
<pre><code>## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 4 Recipe Steps
## 
## ‚Ä¢ step_log()
## ‚Ä¢ step_other()
## ‚Ä¢ step_dummy()
## ‚Ä¢ step_zv()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## K-Nearest Neighbor Model Specification (regression)
## 
## Main Arguments:
##   neighbors = tune("K")
## 
## Computational engine: kknn</code></pre>
<p><code>neighbors = tune("K")</code> sagt uns,
dass er diesen Parameter tunen will.
Das haben wir jetzt ja erledigt.
Wir wollen f√ºr das Test-Sample nur noch einen Wert,
eben aus dem besten Kandidatenmodell,
verwenden:</p>
<div class="sourceCode" id="cb289"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_final_wflow</span> <span class="op">&lt;-</span>
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">ames_knn_best_params</span><span class="op">)</span>

<span class="va">ames_final_wflow</span></code></pre></div>
<pre><code>## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## 4 Recipe Steps
## 
## ‚Ä¢ step_log()
## ‚Ä¢ step_other()
## ‚Ä¢ step_dummy()
## ‚Ä¢ step_zv()
## 
## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
## K-Nearest Neighbor Model Specification (regression)
## 
## Main Arguments:
##   neighbors = 15
## 
## Computational engine: kknn</code></pre>
<p>Wie man sieht,
steht im Workflow nichts mehr von Tuningparameter.</p>
<p>Wir k√∂nnen jetzt das <em>ganze Train-Sample</em> fitten,
also das Modell auf das ganze Train-Sample anwenden -
nicht nur auf ein Analysis-Sample.
Und mit den dann resultierenden Modellkoeffizienten sagen
wir das TestSample vorher:</p>
<div class="sourceCode" id="cb291"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames_knn_fit</span> <span class="op">&lt;-</span>
  <span class="fu">last_fit</span><span class="op">(</span><span class="va">ames_final_wflow</span>, <span class="va">data_split</span><span class="op">)</span>

<span class="va">final_ames_knn_fit</span></code></pre></div>
<pre><code>## # Resampling results
## # Manual resampling 
## # A tibble: 1 √ó 6
##   splits             id               .metrics .notes   .predictions .workflow 
##   &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    
## 1 &lt;split [2197/733]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;</code></pre>
<p>Holen wir uns die Modellg√ºte:</p>
<div class="sourceCode" id="cb293"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">final_ames_knn_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 √ó 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard      0.0951 Preprocessor1_Model1
## 2 rsq     standard      0.736  Preprocessor1_Model1</code></pre>
<!-- ### Vorhersage von Hand -->
<!-- Nat√ºrlich k√∂nnten wir auch "von Hand" vorhersagen: -->
<!-- ```{r ames-fit-von-hand} -->
<!-- final_ames_knn_fit <- -->
<!--   ames_final_wflow %>%  -->
<!--   fit(ames_train) -->
<!-- ``` -->
<!-- Man beachte, -->
<!-- dass die Vorhersageg√ºte f√ºr das Train-Sample √ºberoptimistisch ist. -->
<!-- Und jetzt sagen wir auf dieser Basis das Test-Sample vorher: -->
<!-- ```{r error = TRUE} -->
<!-- ames_pred <- -->
<!--   predict(final_ames_knn_fit, new_data = ames_test) -->
<!-- ``` -->
<!-- Oh Nein! Es geht nicht, woran liegt das wohl? -->
<!-- Wir m√ºssen noch die Transformationen des Rezept auf das Test-Sample anwenden.  -->
<!-- Puh, ganz sch√∂n unkomfortabel. -->
<!-- Es ist nicht empfehlenswert, den folgenden Weg einzuschlagen, -->
<!-- viel einfacher ist es, mit `last_fit()` seine Ergebnisse zu bekommen. -->
<!-- Aber sei's drum, jetzt ziehen wir das halt mal durch. -->
<!-- Zuerst berechnen wir die Werte des *Rezepts*, z.B. -->
<!-- die MW- und SD-Werte f√ºr z-Transformationen oder die Anzahl -->
<!-- der Pr√§diktoren im Datensatz. -->
<!-- ```{r ames-prep} -->
<!-- ames_prep <- -->
<!--   prep(ames_rec, training = ames_train) -->
<!-- ames_prep -->
<!-- ``` -->
<!-- Mit `prep()` haben wir *nur* das Rezept berechnet, -->
<!-- noch kein Modell auf einen Datensatz gefittet! -->
<!-- Alternativ k√∂nnten wir uns das trainierte Rezept auch so holen: -->
<!-- ```{r} -->
<!-- extract_recipe(final_ames_knn_fit) -->
<!-- ``` -->
<!-- Jetzt wenden wir das Rezept auf den Test-Datensatz an: -->
<!-- ```{r ames-bake} -->
<!-- ames_test_baked <-  -->
<!--   bake(ames_prep, new_data = ames_test) -->
<!-- ``` -->
<!-- Das Ergebnis ist jetzt der "gebackene" Datensatz `ames_test_baked`, -->
<!-- in dem jetzt die Transformationen des Test-Samples angewendet sind. -->
<!-- Damit k√∂nnen wir jetzt die Vorhersagen im Test-Sample durchf√ºhren. -->
<!-- ```{r ames-pred-final-von-hand, error = TRUE} -->
<!-- ames_pred <- -->
<!--   predict(final_ames_knn_fit, new_data = ames_test) -->
<!-- ``` -->
<!-- Und damit haben wir unsere Modellg√ºte f√ºr das Test-Sample. -->
<!-- ## Aufgaben und Vertiefung -->
</div>
</div>
<div id="aufgaben-4" class="section level2" number="7.11">
<h2>
<span class="header-section-number">7.11</span> Aufgaben<a class="anchor" aria-label="anchor" href="#aufgaben-4"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Arbeiten Sie sich so gut als m√∂glich durch <a href="https://github.com/sebastiansauer/covid-icu">diese Analyse zum Verlauf von Covid-F√§llen</a>
</li>
<li><a href="https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/">Fallstudie zur Modellierung einer logististischen Regression mit tidymodels</a></li>
<li><a href="https://juliasilge.com/blog/multinomial-volcano-eruptions/">Fallstudie zu Vulkanausbr√ºchen</a></li>
<li><a href="https://juliasilge.com/blog/himalayan-climbing/">Fallstudie Himalaya</a></li>
</ul>
</div>
<div id="vertiefung-2" class="section level2" number="7.12">
<h2>
<span class="header-section-number">7.12</span> Vertiefung<a class="anchor" aria-label="anchor" href="#vertiefung-2"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://xkcd.com/435/">Fields arranged by purity, xkcd 435</a></li>
</ul>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="knn.html"><span class="header-section-number">6</span> kNN</a></div>
<div class="next"><a href="logistische-regression.html"><span class="header-section-number">8</span> Logistische Regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#resampling-und-tuning"><span class="header-section-number">7</span> Resampling und Tuning</a></li>
<li>
<a class="nav-link" href="#lernsteuerung-4"><span class="header-section-number">7.1</span> Lernsteuerung</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#vorbereitung-3"><span class="header-section-number">7.1.1</span> Vorbereitung</a></li>
<li><a class="nav-link" href="#lernziele-5"><span class="header-section-number">7.1.2</span> Lernziele</a></li>
<li><a class="nav-link" href="#literatur-5"><span class="header-section-number">7.1.3</span> Literatur</a></li>
</ul>
</li>
<li><a class="nav-link" href="#%C3%BCberblick-2"><span class="header-section-number">7.2</span> √úberblick</a></li>
<li>
<a class="nav-link" href="#tidymodels-1"><span class="header-section-number">7.3</span> tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#datensatz-aufteilen"><span class="header-section-number">7.3.1</span> Datensatz aufteilen</a></li>
<li><a class="nav-link" href="#rezept-modell-und-workflow-definieren"><span class="header-section-number">7.3.2</span> Rezept, Modell und Workflow definieren</a></li>
</ul>
</li>
<li><a class="nav-link" href="#resampling"><span class="header-section-number">7.4</span> Resampling</a></li>
<li>
<a class="nav-link" href="#illustration-des-resampling"><span class="header-section-number">7.5</span> Illustration des Resampling</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#einfache-v-fache-kreuzvalidierung"><span class="header-section-number">7.5.1</span> Einfache v-fache Kreuzvalidierung</a></li>
<li><a class="nav-link" href="#wiederholte-kreuzvalidierung"><span class="header-section-number">7.5.2</span> Wiederholte Kreuzvalidierung</a></li>
<li><a class="nav-link" href="#resampling-passiert-im-train-sample"><span class="header-section-number">7.5.3</span> Resampling passiert im Train-Sample</a></li>
<li><a class="nav-link" href="#andere-illustrationen"><span class="header-section-number">7.5.4</span> Andere Illustrationen</a></li>
</ul>
</li>
<li><a class="nav-link" href="#gesetz-der-gro%C3%9Fen-zahl"><span class="header-section-number">7.6</span> Gesetz der gro√üen Zahl</a></li>
<li><a class="nav-link" href="#%C3%BCber--und-unteranpassung-an-einem-beispiel"><span class="header-section-number">7.7</span> √úber- und Unteranpassung an einem Beispiel</a></li>
<li>
<a class="nav-link" href="#cv-in-tidymodels"><span class="header-section-number">7.8</span> CV in tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cv-definieren"><span class="header-section-number">7.8.1</span> CV definieren</a></li>
<li><a class="nav-link" href="#resamples-fitten"><span class="header-section-number">7.8.2</span> Resamples fitten</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tuning"><span class="header-section-number">7.9</span> Tuning</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tuning-auszeichnen"><span class="header-section-number">7.9.1</span> Tuning auszeichnen</a></li>
<li><a class="nav-link" href="#grid-search-vs.-iterative-search"><span class="header-section-number">7.9.2</span> Grid Search vs.¬†Iterative Search</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tuning-mit-tidymodels"><span class="header-section-number">7.10</span> Tuning mit Tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#datenabh%C3%A4ngige-tuningparameter"><span class="header-section-number">7.10.1</span> Datenabh√§ngige Tuningparameter</a></li>
<li><a class="nav-link" href="#modelle-mit-tuning-berechnen"><span class="header-section-number">7.10.2</span> Modelle mit Tuning berechnen</a></li>
<li><a class="nav-link" href="#vorhersage-im-test-sample"><span class="header-section-number">7.10.3</span> Vorhersage im Test-Sample</a></li>
</ul>
</li>
<li><a class="nav-link" href="#aufgaben-4"><span class="header-section-number">7.11</span> Aufgaben</a></li>
<li><a class="nav-link" href="#vertiefung-2"><span class="header-section-number">7.12</span> Vertiefung</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/sebastiansauer/datascience1/blob/master/080-Resampling-Tuning.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/sebastiansauer/datascience1/edit/master/080-Resampling-Tuning.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>DataScience1</strong>: Grundlagen der Prognosemodellierung üîÆüß∞" was written by Sebastian Sauer. It was last built on 2022-05-22 00:46:40.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
