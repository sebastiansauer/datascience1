<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Kapitel 7 Resampling und Tuning | DataScience1</title>
<meta name="author" content="Sebastian Sauer">
<meta name="description" content="BenÃ¶tigte R-Pakete fÃ¼r dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<meta name="generator" content="bookdown 0.26.2 with bs4_book()">
<meta property="og:title" content="Kapitel 7 Resampling und Tuning | DataScience1">
<meta property="og:type" content="book">
<meta property="og:description" content="BenÃ¶tigte R-Pakete fÃ¼r dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kapitel 7 Resampling und Tuning | DataScience1">
<meta name="twitter:description" content="BenÃ¶tigte R-Pakete fÃ¼r dieses Kapitel:  7.1 Lernsteuerung   7.1.1 Vorbereitung Lesen Sie die Literatur.  7.1.2 Lernziele Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen....">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/viz-1.8.2/viz.js"></script><link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script><script src="libs/es6shim-0.35.6/es6shim.js"></script><script src="libs/es7shim-6.0.0/es7shim.js"></script><script src="libs/graphre-0.1.3/graphre.js"></script><script src="libs/nomnoml-1.3.1/nomnoml.js"></script><script src="libs/nomnoml-binding-0.2.3/nomnoml.js"></script><script src="libs/d3-3.3.8/d3.min.js"></script><script src="libs/dagre-0.4.0/dagre-d3.min.js"></script><link href="libs/mermaid-0.3.0/dist/mermaid.css" rel="stylesheet">
<script src="libs/mermaid-0.3.0/dist/mermaid.slim.min.js"></script><script src="libs/chromatography-0.1/chromatography.js"></script><script src="libs/DiagrammeR-binding-1.0.6.1/DiagrammeR.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style-bs4.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°">DataScience1</a>:
        <small class="text-muted">Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Zu diesem Buch</a></li>
<li><a class="" href="hinweise.html"><span class="header-section-number">1</span> Hinweise</a></li>
<li><a class="" href="pr%C3%BCfung.html"><span class="header-section-number">2</span> PrÃ¼fung</a></li>
<li class="book-part">Themen</li>
<li><a class="" href="statistisches-lernen.html"><span class="header-section-number">3</span> Statistisches Lernen</a></li>
<li><a class="" href="r-zweiter-blick.html"><span class="header-section-number">4</span> R, zweiter Blick</a></li>
<li><a class="" href="tidymodels.html"><span class="header-section-number">5</span> tidymodels</a></li>
<li><a class="" href="knn.html"><span class="header-section-number">6</span> kNN</a></li>
<li><a class="active" href="resampling-und-tuning.html"><span class="header-section-number">7</span> Resampling und Tuning</a></li>
<li><a class="" href="logistische-regression.html"><span class="header-section-number">8</span> Logistische Regression</a></li>
<li><a class="" href="entscheidungsb%C3%A4ume.html"><span class="header-section-number">9</span> EntscheidungsbÃ¤ume</a></li>
<li><a class="" href="ensemble-lerner.html"><span class="header-section-number">10</span> Ensemble Lerner</a></li>
<li><a class="" href="regularisierte-modelle.html"><span class="header-section-number">11</span> Regularisierte Modelle</a></li>
<li><a class="" href="kaggle.html"><span class="header-section-number">12</span> Kaggle</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/sebastiansauer/datascience1">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="resampling-und-tuning" class="section level1" number="7">
<h1>
<span class="header-section-number">Kapitel 7</span> Resampling und Tuning<a class="anchor" aria-label="anchor" href="#resampling-und-tuning"><i class="fas fa-link"></i></a>
</h1>
<p>BenÃ¶tigte R-Pakete fÃ¼r dieses Kapitel:</p>
<div id="lernsteuerung-4" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Lernsteuerung<a class="anchor" aria-label="anchor" href="#lernsteuerung-4"><i class="fas fa-link"></i></a>
</h2>
<!-- Chapter Start sections: Lernziele, Literatur, Hinweise, ... -->
<div id="vorbereitung-3" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> Vorbereitung<a class="anchor" aria-label="anchor" href="#vorbereitung-3"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Lesen Sie die Literatur.</li>
</ul>
</div>
<div id="lernziele-5" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> Lernziele<a class="anchor" aria-label="anchor" href="#lernziele-5"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Sie verstehen den Nutzen von Resampling und Tuning im maschinellen Nutzen.</li>
<li>Sie kÃ¶nnen Methoden des Resampling und Tunings mit Hilfe von Tidymodels anwenden.</li>
</ul>
</div>
<div id="literatur-5" class="section level3" number="7.1.3">
<h3>
<span class="header-section-number">7.1.3</span> Literatur<a class="anchor" aria-label="anchor" href="#literatur-5"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>Rhys, Kap. 3</li>
<li>TMWR, Kap. 10, 12</li>
</ul>
<!-- Das Paket `tune` auf CRAN hat einen Bug^[https://community.rstudio.com/t/trouble-using-extract-parameter-set-dials-in-tidy-models-with-r/131178], --><!-- daher empfiehlt der Autor, Max Kuhn, die Version des Pakets von Github zu installieren: --><!-- ```{r eval = FALSE, echo = TRUE} --><!-- devtools::install_github("tidymodels/tune") --><!-- ``` -->
</div>
</div>
<div id="Ã¼berblick-2" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Ãœberblick<a class="anchor" aria-label="anchor" href="#%C3%BCberblick-2"><i class="fas fa-link"></i></a>
</h2>
<p>Der Standardablauf des maschinellen Lernens ist in Abb. <a href="resampling-und-tuning.html#fig:process1">7.1</a> dargestellt.
Eine alternative, hilfreich Abbildung findet sich <a href="https://www.tmwr.org/resampling.html">hier</a> in Kap. 10.2 in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:process1"></span>
<img src="https://nomnoml.com/image.svg?source=%23direction%3A%20right%0A%5B%3Cdatabase%3E%20Gesamtdatensatz%5D%20-%3E%20%20%5BSplitte%20in%20Train-%20und%20Test-Sample%5D%0A%5BSplitte%20in%20Train-%20und%20Test-Sample%5D%20-%3E%20%5BF%C3%BCr%20jeden%20Modell-Kandidaten%20i%3D1%2C2%2C..%2Cn%20%7C%0A%20%20%5BTrain-Test%20Modellkandidat%20i%7C%0A%20%20%20%20%5BFitte%20in%20Train-Sample%5D%20-%3E%20%5BTeste%20im%20Assessment-Sample%5D%5D%0A%20%20%5D%20%0A%20%20%5BF%C3%BCr%20jeden%20Modell-Kandidaten%20i%3D1%2C2%2C..%2Cn%20%7C%0A%20%20%5BTrain-Test%20Modellkandidat%20i%7C%0A%20%20%20%20%5BFitte%20in%20Train-Sample%5D%20-%3E%20%5BTeste%20im%20Assessment-Sample%5D%5D%0A%20%20%5D%20-%3E%20%5BBestimme%20besten%20Modell-Kandidaten%5D%0A%20%20%5BBestimme%20besten%20Modell-Kandidaten%5D%20-%3E%20%5BFitte%20Modell%20im%20Train-Datensatz%5D%0A%20%20%5BFitte%20Modell%20im%20Train-Datensatz%5D%20-%3E%20%5BTest%20im%20Test-Datensatz%5D%0A%20%20%5BTest%20im%20Test-Datensatz%5D%20-%3E%20%5B%3Cend%3E%20Ende%5D" alt="Standardablauf des maschinellen Lernens mit Tuning und Resampling" width="100%"><p class="caption">
Figure 7.1: Standardablauf des maschinellen Lernens mit Tuning und Resampling
</p>
</div>
</div>
<div id="tidymodels-1" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> tidymodels<a class="anchor" aria-label="anchor" href="#tidymodels-1"><i class="fas fa-link"></i></a>
</h2>
<div id="datensatz-aufteilen" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Datensatz aufteilen<a class="anchor" aria-label="anchor" href="#datensatz-aufteilen"><i class="fas fa-link"></i></a>
</h3>
<div class="sourceCode" id="cb246"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">ames</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">4595</span><span class="op">)</span>
<span class="va">data_split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">ames</span>, strata <span class="op">=</span> <span class="st">"Sale_Price"</span><span class="op">)</span>

<span class="va">ames_train</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">data_split</span><span class="op">)</span>
<span class="va">ames_test</span> <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">data_split</span><span class="op">)</span></code></pre></div>
</div>
<div id="rezept-modell-und-workflow-definieren" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> Rezept, Modell und Workflow definieren<a class="anchor" aria-label="anchor" href="#rezept-modell-und-workflow-definieren"><i class="fas fa-link"></i></a>
</h3>
<p>In gewohnter Weise definieren wir den Workflow
mit einem kNN-Modell.</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_rec</span> <span class="op">&lt;-</span>
  <span class="fu">recipe</span><span class="op">(</span><span class="va">Sale_Price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">ames_train</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_log</span><span class="op">(</span><span class="va">Sale_Price</span>, base <span class="op">=</span> <span class="fl">10</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_other</span><span class="op">(</span><span class="va">Neighborhood</span>, threshold <span class="op">=</span> <span class="fl">.1</span><span class="op">)</span>  <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_dummy</span><span class="op">(</span><span class="fu">all_nominal</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">step_zv</span><span class="op">(</span><span class="fu">all_predictors</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> 

<span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span>

<span class="va">ames_wflow</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">ames_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">add_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<p>Das kNN-Modell ist noch <em>nicht</em> <em>berechnet</em>,
es ist nur ein â€œRezeptâ€ erstellt:</p>
<div class="sourceCode" id="cb248"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span></code></pre></div>
<pre><code>## K-Nearest Neighbor Model Specification (regression)
## 
## Computational engine: kknn</code></pre>
<div class="sourceCode" id="cb250"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span></code></pre></div>
<pre><code>## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 4 Recipe Steps
## 
## â€¢ step_log()
## â€¢ step_other()
## â€¢ step_dummy()
## â€¢ step_zv()
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## K-Nearest Neighbor Model Specification (regression)
## 
## Computational engine: kknn</code></pre>
</div>
</div>
<div id="resampling" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Resampling<a class="anchor" aria-label="anchor" href="#resampling"><i class="fas fa-link"></i></a>
</h2>
<p>Vergleichen Sie die drei FÃ¤lle, die sich in der Nutzung von Train- und Test-Sample unterscheiden:</p>
<ol style="list-style-type: decimal">
<li>Wir fitten ein Klassifikationsmodell in einer Stichprobe, sagen die Y-Werte dieser Stichprobe â€œvorherâ€. Wir finden eine Gesamtgenauigkeit von 80%.</li>
<li>Wir fitten ein Klassifikationsmodell in einem Teil der ursprÃ¼nglichen Stichprobe (Train-Sample) und sagen Y-die Werte im verbleibenden Teil der ursprÃ¼nglichen Stichprobe vorher (Test-Sample). Wir finden eine Gesamtgenauigkeit von 70%.</li>
<li>Wir wiederholen Fall 2 noch drei Mal mit jeweils anderer Zuweisung der FÃ¤lle zum Train- bzw. zum Test-Sample. Wir finden insgesamt folgende Werte an Gesamtgenauigkeit: 70%, 70%, 65%, 75%.</li>
</ol>
<p>Welchen der drei FÃ¤lle finden Sie am sinnvollsten? Warum?</p>
</div>
<div id="illustration-des-resampling" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> Illustration des Resampling<a class="anchor" aria-label="anchor" href="#illustration-des-resampling"><i class="fas fa-link"></i></a>
</h2>
<p><em>Resampling</em> stellt einen Oberbegriff dar; <em>Kreuzvalidierung</em> ist ein Unterbegriff dazu.
Es gibt noch andere Arten des Resampling, etwa <em>Bootstrapping</em> oder <em>Leave-One-Out-Cross-Validation</em> (LOOCV).</p>
<p>Im Folgenden ist nur die Kreuzvalidierung dargestellt,
da es eines der wichtigsten und vielleicht das Wichtigste ist.
In vielen Quellen finden sich ErlÃ¤uterungen anderer Verfahren dargestellt,
etwa in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>, <span class="citation">James et al. (<a href="references.html#ref-islr" role="doc-biblioref">2021</a>)</span> oder <span class="citation">Rhys (<a href="references.html#ref-rhys" role="doc-biblioref">2020</a>)</span>.</p>
<div id="einfache-v-fache-kreuzvalidierung" class="section level3" number="7.5.1">
<h3>
<span class="header-section-number">7.5.1</span> Einfache v-fache Kreuzvalidierung<a class="anchor" aria-label="anchor" href="#einfache-v-fache-kreuzvalidierung"><i class="fas fa-link"></i></a>
</h3>
<p>Abb. <a href="resampling-und-tuning.html#fig:resampling">7.2</a> illustriert die zufÃ¤llige Aufteilung von <span class="math inline">\(n=10\)</span> FÃ¤llen der Originalstrichprobe auf eine Train- bzw. Test-Stichpobe.
Man spricht von <em>Kreuzvalidierung</em> (cross validation, CV).</p>
<p>In diesem Fall wurden 70% der (<span class="math inline">\(n=10\)</span>) FÃ¤lle der Train-Stichprobe zugewiesen (der Rest der Test-Stichprobe);
ein willkÃ¼rlicher, aber nicht unÃ¼blicher Anteil.
Diese Aufteilung wurde <span class="math inline">\(v=3\)</span> Mal vorgenommen,
es resultieren drei â€œResampling-Stichprobenâ€, die
manchmal auch als â€œFaltungenâ€ bezeichnet werden.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:resampling"></span>
<img src="080-Resampling-Tuning_files/figure-html/resampling-1.png" alt="Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt" width="100%"><p class="caption">
Figure 7.2: Resampling: Eine Stichprobe wird mehrfach (hier 3 Mal) zu 70% in ein Train- und zu 30% in die Test-Stichprobe aufgeteilt
</p>
</div>
<p><span class="citation">Sauer (<a href="references.html#ref-modar" role="doc-biblioref">2019</a>)</span> stellt das Resampling so dar (S. 259), s. Abb. <a href="resampling-und-tuning.html#fig:cvmodar">7.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cvmodar"></span>
<img src="img/crossval.png" alt="Kreuzvalidierung, Aufteilung in Train- vs. Testsample" width="100%"><p class="caption">
Figure 7.3: Kreuzvalidierung, Aufteilung in Train- vs.Â Testsample
</p>
</div>
<p>Der Gesamtfehler der Vorhersage wird als Mittelwerte der Vorhersagefehler in den einzelnen Faltungen berechnet.</p>
<p>Warum ist die Vorhersage besser,
wenn man mehrere Faltungen, mehrere SchÃ¤tzungen fÃ¼r <span class="math inline">\(y\)</span> also, vornimmt?</p>
<p>Der Grund ist das Gesetz der groÃŸen Zahl,
nachdem sich eine SchÃ¤tzung in Mittelwert und VariabilitÃ¤t stabilisiert mit steigendem
Stichprobenumfang,
dem wahren Mittelwert also prÃ¤ziser schÃ¤tzt.
Bei Normalverteilungen klappt das gut,
bei randlastigen Verteilungen leider nicht mehr <span class="citation">(<a href="references.html#ref-fattails" role="doc-biblioref">Taleb 2019</a>)</span>.</p>
<p>HÃ¤ufig werden <span class="math inline">\(v=10\)</span> Faltungen verwendet,
was sich empirisch als guter Kompromiss von Rechenaufwand und Fehlerreduktion herausgestellt hat.</p>
</div>
<div id="wiederholte-kreuzvalidierung" class="section level3" number="7.5.2">
<h3>
<span class="header-section-number">7.5.2</span> Wiederholte Kreuzvalidierung<a class="anchor" aria-label="anchor" href="#wiederholte-kreuzvalidierung"><i class="fas fa-link"></i></a>
</h3>
<p>Die <span class="math inline">\(r\)</span>-fach wiederholte Kreuzvalidierung wiederholte die einfache Kreuzvalidierung mehrfach (nÃ¤mlich <span class="math inline">\(r=4\)</span> mal),
<span class="citation">Sauer (<a href="references.html#ref-modar" role="doc-biblioref">2019</a>)</span> stellt das Resampling so dar (S. 259), s. Abb. <a href="resampling-und-tuning.html#fig:cvrep">7.4</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cvrep"></span>
<img src="img/crossval_repeated.png" alt="Wiederholte Kreuzvalidierung" width="100%"><p class="caption">
Figure 7.4: Wiederholte Kreuzvalidierung
</p>
</div>
<p>Die wiederholte Kreuzvalidierung reduziert den Standardfehler der Vorhersagen.</p>
<p><span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> zeigen die Verringerung des SchÃ¤tzfehlers als Funktion der <span class="math inline">\(r\)</span> Wiederholungen dar,
s. Abb. <a href="resampling-und-tuning.html#fig:repcvred">7.5</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:repcvred"></span>
<img src="https://www.tmwr.org/figures/variance-reduction-1.png" alt="Reduktion des SchÃ¤tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung" width="100%"><p class="caption">
Figure 7.5: Reduktion des SchÃ¤tzfehlers als Funktion der r Wiederhoulugen der Kreuzvalidierung
</p>
</div>
<p>Warum ist die Wiederholung der Kreuzvalidierung nÃ¼tzlich?</p>
<p>Die Kreuvalidierung liefert einen SchÃ¤tzwert der Modellparameter,
die wahren Modellparameter werden also anhand einer Stichprobe von <span class="math inline">\(n=1\)</span> geschÃ¤tzt.
Mit hÃ¶herem Stichprobenumfang kann diese SchÃ¤tzung natÃ¼rlich prÃ¤zisiert werden.</p>
<p>Da jede Stichprobenverteilung bei <span class="math inline">\(n \rightarrow \infty\)</span> normalverteilt ist -
ein zentrales Theorem der Statistik, der <em>Zentrale Grenzwertsatz</em> (Central Limit Theorem) -
kann man hoffen, dass sich eine bestimmte Stichprobenverteilung bei kleinerem <span class="math inline">\(n\)</span> ebenfalls annÃ¤hernd
normalverteilt<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Das klappt bei randlastigen Verteilungen nicht&lt;/p&gt;"><sup>3</sup></a>.
Dann sind die Quantile bekannt und man kann die Streuung der SchÃ¤tzers,
<span class="math inline">\({\sigma }_{\bar {x}}\)</span>, z.B. fÃ¼r den Mittelwert,
einfach schÃ¤tzen:</p>
<p><span class="math display">\[{\displaystyle {\sigma }_{\bar {x}}\ ={\frac {\sigma }{\sqrt {n}}}}\]</span></p>
</div>
<div id="resampling-passiert-im-train-sample" class="section level3" number="7.5.3">
<h3>
<span class="header-section-number">7.5.3</span> Resampling passiert im Train-Sample<a class="anchor" aria-label="anchor" href="#resampling-passiert-im-train-sample"><i class="fas fa-link"></i></a>
</h3>
<p>Wichtig zu beachten ist, dass
die Resampling nur im Train-Sample stattfindet.
Das Test-Sample bleibt unangerÃ¼hrt.
Dieser Sachverhalt ist in Abb. <a href="resampling-und-tuning.html#fig:initialsplit">7.6</a>, aus <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span>, illustriert.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:initialsplit"></span>
<img src="https://www.tmwr.org/premade/resampling.svg" alt="Resampling im Train-, nicht im Test-Sample" width="100%"><p class="caption">
Figure 7.6: Resampling im Train-, nicht im Test-Sample
</p>
</div>
<p>Wie in Abb. <a href="resampling-und-tuning.html#fig:initialsplit">7.6</a> dargestellt,
wird das Modell im <em>Analyse-Sample</em> berechnet (gefittet),
und im <em>Assessment-Sample</em> auf ModellgÃ¼te hin Ã¼berprÃ¼ft.</p>
<p>Die letztliche ModellgÃ¼te ist dann die Zusammenfassung (Mittelwert) der einzelnen Resamples.</p>
</div>
<div id="andere-illustrationen" class="section level3" number="7.5.4">
<h3>
<span class="header-section-number">7.5.4</span> Andere Illustrationen<a class="anchor" aria-label="anchor" href="#andere-illustrationen"><i class="fas fa-link"></i></a>
</h3>
<p>Es gibt eine Reihe vergleichbarer Illustrationen in anderen BÃ¼chern:</p>
<ul>
<li><a href="https://datasciencebook.ca/img/cv.png">Timbers, Campbell &amp; Lee, 2022, Kap. 6</a></li>
<li><a href="https://datasciencebook.ca/img/cv.png">Silge &amp; Kuhn, 2022, Abb. 10.1</a></li>
<li><a href="https://www.tmwr.org/premade/three-CV.svg">Silge &amp; Kuhn, 2022, Abb. 10.2</a></li>
<li><a href="https://www.tmwr.org/premade/three-CV-iter.svg">Silge &amp; Kuhn, 2022, Abb. 10.3</a></li>
<li>James, Witten, hastie &amp; Tishirani, 2021, Abb. 5.3</li>
</ul>
</div>
</div>
<div id="gesetz-der-groÃŸen-zahl" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> Gesetz der groÃŸen Zahl<a class="anchor" aria-label="anchor" href="#gesetz-der-gro%C3%9Fen-zahl"><i class="fas fa-link"></i></a>
</h2>
<p>Nach dem <em>Gesetz der groÃŸen Zahl</em> (Law of Large Numbers) sollte sich der Mittelwert einer groÃŸen Stichprobe
dem theoretischen Mittelwert der zugrundeliegenden Verteilung (Population, datengeneriender Prozess)
sehr nahe kommen.</p>
<p><span class="math display">\[\displaystyle \lim _{n\to \infty }\sum _{i=1}^{n}{\frac {X_{i}}{n}}={\overline {X}}\]</span></p>
<p>David Salazar visualisiert das folgendermaÃŸen in <a href="https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/">diesem Post</a> seines lesenswerten <a href="https://david-salazar.github.io/">Blogs</a>, s. Abb. <a href="resampling-und-tuning.html#fig:lln">7.7</a>.</p>
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># source: https://david-salazar.github.io/2020/04/17/fat-vs-thin-does-lln-work/</span>
<span class="va">samples</span> <span class="op">&lt;-</span> <span class="fl">1000</span>

<span class="va">thin</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">samples</span>, sd <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>

<span class="va">cumulative_mean</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span><span class="op">)</span>
    <span class="va">cum_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cumsum.html">cumsum</a></span><span class="op">(</span><span class="va">numbers</span><span class="op">)</span><span class="op">/</span><span class="va">x</span> 
    <span class="va">cum_mean</span>
<span class="op">}</span>

<span class="va">thin_cum_mean</span> <span class="op">&lt;-</span> <span class="fu">cumulative_mean</span><span class="op">(</span><span class="va">thin</span><span class="op">)</span>

<span class="va">thin_cum_mean</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>running_mean <span class="op">=</span> <span class="va">.</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/add_rownames.html">add_rownames</a></span><span class="op">(</span>var <span class="op">=</span> <span class="st">'number_samples'</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>number_samples <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/double.html">as.double</a></span><span class="op">(</span><span class="va">number_samples</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">number_samples</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">number_samples</span>, y <span class="op">=</span> <span class="va">running_mean</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">'dodgerblue4'</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="fl">0</span>, linetype <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">'red'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu">hrbrthemes</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/hrbrthemes/man/theme_ipsum_rc.html">theme_ipsum_rc</a></span><span class="op">(</span>grid <span class="op">=</span> <span class="st">'Y'</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="va"><a href="https://scales.r-lib.org/reference/comma.html">comma</a></span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"StichprobengrÃ¶ÃŸe"</span>,
       title <span class="op">=</span> <span class="st">"Gesetz der groÃŸen Zahl"</span>, 
       subtitle <span class="op">=</span> <span class="st">"Kumulierter Mittelwert aus einer Normalverteilung mit sd=20"</span><span class="op">)</span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lln"></span>
<img src="080-Resampling-Tuning_files/figure-html/lln-1.png" alt="Gesetz der groÃŸen Zahl" width="100%"><p class="caption">
Figure 7.7: Gesetz der groÃŸen Zahl
</p>
</div>
<p>Wie man sieht, nÃ¤hert sich der empirische Mittelwert (also in der Stichprobe)
immer mehr dem theoretischen Mittelwert, 0, an.</p>
<p>Achtung: Bei randlastigen Verteilungen darf man dieses schÃ¶ne, wohlerzogene Verhalten nicht erwarten <span class="citation">(<a href="references.html#ref-fattails" role="doc-biblioref">Taleb 2019</a>)</span>.</p>
</div>
<div id="Ã¼ber--und-unteranpassung-an-einem-beispiel" class="section level2" number="7.7">
<h2>
<span class="header-section-number">7.7</span> Ãœber- und Unteranpassung an einem Beispiel<a class="anchor" aria-label="anchor" href="#%C3%BCber--und-unteranpassung-an-einem-beispiel"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:overfitting-4-plots"></span>
<img src="080-Resampling-Tuning_files/figure-html/overfitting-4-plots-1.png" alt="Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die 'wahre Funktion', der datengenerierende Prozess ist im Teil A dargestellt" width="100%"><p class="caption">
Figure 7.8: Welches Modell (Teile C-E) passt am besten zu den Daten (Teil B)? Die â€˜wahre Funktionâ€™, der datengenerierende Prozess ist im Teil A dargestellt
</p>
</div>
<p>Abb. <a href="resampling-und-tuning.html#fig:overfitting-4-plots">7.8</a> zeigt:</p>
<ul>
<li>Teil <em>A</em>: Die â€˜wahre Funktionâ€™, <span class="math inline">\(f\)</span>, die die Daten erzeugt. Man spricht auch von der â€œdatengenerierenden Funktionâ€. Wir gehen gemeinhin davon aus, dass es eine wahre Funktion gibt. Das heiÃŸt nicht, dass die wahre Funktion die Daten perfekt erklÃ¤rt, schlieÃŸlich kann die Funktion zwar wahr, aber unvollstÃ¤ndig sein oder unsere Messinstrumente sind nicht perfekt prÃ¤zise.</li>
<li>Teil <em>B:</em> Die Daten, erzeugt aus A plus etwas zufÃ¤lliges Fehler (Rauschen).</li>
<li>Teil <em>C</em>: Ein zu einfaches Modell: Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.</li>
<li>Teil <em>D</em>: Ein zu komplexes Modell: Ãœberanpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden nicht so gut sein.</li>
<li>Teil <em>E</em>: Ein Modell mittlerer KomplexitÃ¤t. Keine Ãœberanpassung, keine Unteranpassung. Vorhersagen in einer neuen Stichprobe (basierend auf dem datengenerierenden Prozess aus A) werden gut sein.</li>
</ul>
</div>
<div id="cv-in-tidymodels" class="section level2" number="7.8">
<h2>
<span class="header-section-number">7.8</span> CV in tidymodels<a class="anchor" aria-label="anchor" href="#cv-in-tidymodels"><i class="fas fa-link"></i></a>
</h2>
<div id="cv-definieren" class="section level3" number="7.8.1">
<h3>
<span class="header-section-number">7.8.1</span> CV definieren<a class="anchor" aria-label="anchor" href="#cv-definieren"><i class="fas fa-link"></i></a>
</h3>
<p>So kann man eine <em>einfache</em> v-fache Kreuzvalidierung in Tidymodels auszeichnen:</p>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2453</span><span class="op">)</span>
<span class="va">ames_folds</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">ames_train</span>, strata <span class="op">=</span> <span class="st">"Sale_Price"</span><span class="op">)</span>
<span class="va">ames_folds</span></code></pre></div>
<pre><code>## #  10-fold cross-validation using stratification 
## # A tibble: 10 Ã— 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [1976/221]&gt; Fold01
##  2 &lt;split [1976/221]&gt; Fold02
##  3 &lt;split [1976/221]&gt; Fold03
##  4 &lt;split [1976/221]&gt; Fold04
##  5 &lt;split [1977/220]&gt; Fold05
##  6 &lt;split [1977/220]&gt; Fold06
##  7 &lt;split [1978/219]&gt; Fold07
##  8 &lt;split [1978/219]&gt; Fold08
##  9 &lt;split [1979/218]&gt; Fold09
## 10 &lt;split [1980/217]&gt; Fold10</code></pre>
<p>Werfen wir einen Blick in die Spalte <code>splits</code>, erste Zeile:</p>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_folds</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/pluck.html">pluck</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span></code></pre></div>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;1976/221/2197&gt;</code></pre>
<p>MÃ¶chte man die Defaults vpn <code>vfold_cv</code> wissen, schaut man in der Hilfe nach: <code>?vfold_cv</code>:</p>
<p><code>vfold_cv(data, v = 10, repeats = 1, strata = NULL, breaks = 4, pool = 0.1, ...)</code></p>
<p>Probieren wir <span class="math inline">\(v=5\)</span> und <span class="math inline">\(r=2\)</span>:</p>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_folds_rep</span> <span class="op">&lt;-</span> <span class="fu">vfold_cv</span><span class="op">(</span><span class="va">ames_train</span>, 
                           strata <span class="op">=</span> <span class="st">"Sale_Price"</span>, 
                           v <span class="op">=</span> <span class="fl">5</span>,
                           repeats <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">ames_folds_rep</span></code></pre></div>
<pre><code>## #  5-fold cross-validation repeated 2 times using stratification 
## # A tibble: 10 Ã— 3
##    splits             id      id2  
##    &lt;list&gt;             &lt;chr&gt;   &lt;chr&gt;
##  1 &lt;split [1756/441]&gt; Repeat1 Fold1
##  2 &lt;split [1757/440]&gt; Repeat1 Fold2
##  3 &lt;split [1757/440]&gt; Repeat1 Fold3
##  4 &lt;split [1758/439]&gt; Repeat1 Fold4
##  5 &lt;split [1760/437]&gt; Repeat1 Fold5
##  6 &lt;split [1756/441]&gt; Repeat2 Fold1
##  7 &lt;split [1757/440]&gt; Repeat2 Fold2
##  8 &lt;split [1757/440]&gt; Repeat2 Fold3
##  9 &lt;split [1758/439]&gt; Repeat2 Fold4
## 10 &lt;split [1760/437]&gt; Repeat2 Fold5</code></pre>
</div>
<div id="resamples-fitten" class="section level3" number="7.8.2">
<h3>
<span class="header-section-number">7.8.2</span> Resamples fitten<a class="anchor" aria-label="anchor" href="#resamples-fitten"><i class="fas fa-link"></i></a>
</h3>
<p>Hat unser Computer mehrere Rechenkerne, dann kÃ¶nnen wir diese nutzen und die Berechnungen beschleunigen.
Im Standard wird sonst nur ein Kern verwendet.</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">mycores</span> <span class="op">&lt;-</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html">detectCores</a></span><span class="op">(</span>logical <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="va">mycores</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>Auf Unix/MacOC-Systemen kann man dann die Anzahl der parallen Kerne so einstellen:</p>
<div class="sourceCode" id="cb261"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">doMC</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/pkg/doMC/man/registerDoMC.html">registerDoMC</a></span><span class="op">(</span>cores <span class="op">=</span> <span class="va">mycores</span><span class="op">)</span></code></pre></div>
<p>So, und jetzt fitten wir die Resamples und trachten die ModellgÃ¼te in den Resamples:</p>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_resamples_fit</span> <span class="op">&lt;-</span> 
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">fit_resamples</span><span class="op">(</span><span class="va">ames_folds</span><span class="op">)</span>

 <span class="va">ames_resamples_fit</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 Ã— 6
##   .metric .estimator   mean     n std_err .config             
##   &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard   0.0928    10 0.00187 Preprocessor1_Model1
## 2 rsq     standard   0.722     10 0.00864 Preprocessor1_Model1</code></pre>
<p>NatÃ¼rlich interessiert uns primÃ¤r die ModellgÃ¼te im Test-Sample:</p>
<div class="sourceCode" id="cb264"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames</span> <span class="op">&lt;-</span>
  <span class="fu">last_fit</span><span class="op">(</span><span class="va">ames_wflow</span>, <span class="va">data_split</span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb265"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 Ã— 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard       0.103 Preprocessor1_Model1
## 2 rsq     standard       0.678 Preprocessor1_Model1</code></pre>
</div>
</div>
<div id="tuning" class="section level2" number="7.9">
<h2>
<span class="header-section-number">7.9</span> Tuning<a class="anchor" aria-label="anchor" href="#tuning"><i class="fas fa-link"></i></a>
</h2>
<div id="tuning-auszeichnen" class="section level3" number="7.9.1">
<h3>
<span class="header-section-number">7.9.1</span> Tuning auszeichnen<a class="anchor" aria-label="anchor" href="#tuning-auszeichnen"><i class="fas fa-link"></i></a>
</h3>
<p>In der Modellspezifikation des Modells kÃ¶nnen wir mit <code>tune()</code> auszeichnen,
welche Parameter wir tunen mÃ¶chten.
Wir kÃ¶nenn</p>
<div class="sourceCode" id="cb267"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
    neighbors <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="op">)</span>
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span></code></pre></div>
<p>Wir kÃ¶nnen dem Tuningparameter auch einen Namen (ID/Laben) geben, z.B. â€œKâ€:</p>
<div class="sourceCode" id="cb268"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op">&lt;-</span>
  <span class="fu">nearest_neighbor</span><span class="op">(</span>
    mode <span class="op">=</span> <span class="st">"regression"</span>,
    neighbors <span class="op">=</span> <span class="fu">tune</span><span class="op">(</span><span class="st">"K"</span><span class="op">)</span>
  <span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu">set_engine</span><span class="op">(</span><span class="st">"kknn"</span><span class="op">)</span></code></pre></div>
</div>
<div id="grid-search-vs.-iterative-search" class="section level3" number="7.9.2">
<h3>
<span class="header-section-number">7.9.2</span> Grid Search vs.Â Iterative Search<a class="anchor" aria-label="anchor" href="#grid-search-vs.-iterative-search"><i class="fas fa-link"></i></a>
</h3>
<p>Im K-NÃ¤chste-Nachbarn-Modell ist der vorhergesagt Wert, <span class="math inline">\(\hat{y}\)</span> fÃ¼r eine neue Beobachtung <span class="math inline">\(x_0\)</span> wie folgt definiert:</p>
<p><span class="math display">\[
\hat y = \frac{1}{K}\sum_{\ell = 1}^K x_\ell^*,
\]</span></p>
<p>wobei <span class="math inline">\(K\)</span> die Anzahl der zu berÃ¼cksichtigen nÃ¤chsten Nachbarn darstellt und <span class="math inline">\(x_\ell^*\)</span> die Werte dieser berÃ¼cksichtiggten Nachbarn.</p>
<p>Die Wahl von <span class="math inline">\(K\)</span> hat einen gewaltigen Einfluss auf die Vorhersagen und damit auf die VorhersagegÃ¼te.
Allerdings wird <span class="math inline">\(K\)</span> nicht vom Modell geschÃ¤tzt.
Es liegt an den Nutzi,
diesen Wert zu wÃ¤hlen.</p>
<p>Parameter dieser Art (die von den Nutzi zu bestimmen sind, nicht vom Algorithmus),
nennt man <em>Tuningparameter</em>.</p>
<p>Abbildung <a href="resampling-und-tuning.html#fig:nnoverfit">7.9</a> aus <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> stellt exemplarisch dar,
welchen groÃŸen Einfluss die Wahl des Werts eines Tuningparameters auf die
Vorhersagen eines Modells haben.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:nnoverfit"></span>
<img src="https://www.tmwr.org/figures/two-class-boundaries-1.png" alt="Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter" width="100%"><p class="caption">
Figure 7.9: Overfitting als Funktion der Modellparameter und insofern als Problem de Wahl der Tuningparameter
</p>
</div>
<p>Aber wie wÃ¤hlt man â€œguteâ€ Werte der Tuningparater?
Zwei AnsÃ¤tze, grob gesprochen, bieten sich an.</p>
<ol style="list-style-type: decimal">
<li><p><em>Grid Search:</em> Probiere viele Werte aus und schaue, welcher der beste ist. Dabei musst du hoffen, dass du die Werte erwischt, die nicht nur im Train-, sondern auch im Test-Sample gut funktionieren werden.</p></li>
<li><p><em>Iterative Search:</em> Wenn du einen Wert eines Tuningparameters hast, nutze diesen, um intelligenter einen neuen Wert eines Tuningparameters zu finden.</p></li>
</ol>
<p>Der Unterschied beider AnsÃ¤tze ist in <span class="citation">Silge and Kuhn (<a href="references.html#ref-silge_tidy_2022" role="doc-biblioref">2022</a>)</span> wie in Abb. <a href="resampling-und-tuning.html#fig:tuning1">7.10</a> dargestellt.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:tuning1"></span>
<img src="https://www.tmwr.org/figures/tuning-strategies-1.png" alt="Links: Grid Search. Rechts: Iterative Search2" width="100%"><p class="caption">
Figure 7.10: Links: Grid Search. Rechts: Iterative Search2
</p>
</div>
<p>In <code>tidymodels</code> kann man mit <code>tune()</code> angeben, dass man einen bestimmten Parameter tunen mÃ¶chte.
<code>tidymodels</code> fÃ¼hrt das dann ohne weiteres Federlesens fÃ¼r uns durch.</p>
</div>
</div>
<div id="tuning-mit-tidymodels" class="section level2" number="7.10">
<h2>
<span class="header-section-number">7.10</span> Tuning mit Tidymodels<a class="anchor" aria-label="anchor" href="#tuning-mit-tidymodels"><i class="fas fa-link"></i></a>
</h2>
<div id="tuningparameter-betrachten" class="section level4" number="7.10.0.1">
<h4>
<span class="header-section-number">7.10.0.1</span> Tuningparameter betrachten<a class="anchor" aria-label="anchor" href="#tuningparameter-betrachten"><i class="fas fa-link"></i></a>
</h4>
<p>MÃ¶chte man wissen,
welche und wie viele Tuningparameter tidymodels in einem Modell berÃ¼cksichtigt,
kann man <code>extract_parameter_set_dials()</code> aufrufen:</p>
<div class="sourceCode" id="cb269"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<pre><code>## Collection of 1 parameters for tuning
## 
##  identifier      type    object
##           K neighbors nparam[+]</code></pre>
<p>Die Ausgabe informiert uns,
dass es nur einen Tuningparameter gibt in diesem Modell und
dass der Name (Label, ID) des Tuningparameters â€œKâ€ ist.
AuÃŸerdem sollen die Anzahl der Nachbarn getunt werden.
Der Tuningparameter ist numerisch; das sieht man an <code>nparam[+]</code>.</p>
<p>Schauen wir uns mal an,
auf welchen Wertebereich <code>tidymodels</code> den Parameter <span class="math inline">\(K\)</span> begrenzt hat:</p>
<div class="sourceCode" id="cb271"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">knn_model</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">extract_parameter_dials</span><span class="op">(</span><span class="st">"K"</span><span class="op">)</span></code></pre></div>
<pre><code>## # Nearest Neighbors (quantitative)
## Range: [1, 15]</code></pre>
<p>Aktualisieren wir mal unseren Workflow entsprechend:</p>
<div class="sourceCode" id="cb273"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span> <span class="op">&lt;-</span>
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">update_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span></code></pre></div>
<p>Wir kÃ¶nnen auch Einfluss nehmen und angeben,
dass die Grenzen des Wertebereichs zwischen 1 und 50 liegen soll
(fÃ¼r den Tuningparameter <code>neighbors</code>):</p>
<div class="sourceCode" id="cb274"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_set</span> <span class="op">&lt;-</span>
  <span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="va">ames_wflow</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span>K <span class="op">=</span> <span class="fu">neighbors</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">50</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">ames_set</span></code></pre></div>
<pre><code>## Collection of 1 parameters for tuning
## 
##  identifier      type    object
##           K neighbors nparam[+]</code></pre>
</div>
<div id="datenabhÃ¤ngige-tuningparameter" class="section level3" number="7.10.1">
<h3>
<span class="header-section-number">7.10.1</span> DatenabhÃ¤ngige Tuningparameter<a class="anchor" aria-label="anchor" href="#datenabh%C3%A4ngige-tuningparameter"><i class="fas fa-link"></i></a>
</h3>
<p>Manche Tuningparameter kann man nur bestimmen,
wenn man den Datensatz kennt.
So ist die Anzahl der PrÃ¤diktoren, <code>mtry</code> in einem Random-Forest-Modell
sinnvollerweise als Funktion der PrÃ¤diktorenzahl zu wÃ¤hlen.
Der Workflow kennt aber den Datensatz nicht.
Daher muss der Workflow noch â€œfinalisiertâ€ oder â€œaktualisiertâ€ werden,
um den Wertebereich (Unter- und Obergrenze) eines Tuningparameters zu bestimmen.</p>
<p>Wenn wir im Rezept aber z.B. die Anzahl der PrÃ¤diktoren verÃ¤ndert haben,
mÃ¶chten wir die Grenzen des Wertebereichs fÃ¼r <code>mtry</code> (oder andere Tuningparameter) vielleicht nicht hÃ¤ndisch, â€œhartverdrahtetâ€ selber bestimmen,
sondern lieber den Computer anweisen, und sinngemÃ¤ÃŸ sagen:
â€œWarte mal mit der Bestimmung der Werte der Tuningparameter,
bis du den Datensatz bzw. dessen Dimensionen kennst. Merk dir,
dass du, wenn du den Datensatz kennst, die Werte des Tuningparameter noch Ã¤ndern musst. Und tu das dann auch.â€ Dazu spÃ¤ter mehr.</p>
<div class="sourceCode" id="cb276"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_set</span> <span class="op">&lt;-</span>
  <span class="fu">workflow</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_model</span><span class="op">(</span><span class="va">knn_model</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">add_recipe</span><span class="op">(</span><span class="va">ames_rec</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">extract_parameter_set_dials</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">finalize</span><span class="op">(</span><span class="va">ames_train</span><span class="op">)</span></code></pre></div>
</div>
<div id="modelle-mit-tuning-berechnen" class="section level3" number="7.10.2">
<h3>
<span class="header-section-number">7.10.2</span> Modelle mit Tuning berechnen<a class="anchor" aria-label="anchor" href="#modelle-mit-tuning-berechnen"><i class="fas fa-link"></i></a>
</h3>
<p>Nachdem wir die Tuningwerte bestimmt haben,
kÃ¶nnen wir jetzt das Modell berechnen:
FÃ¼r jeden Wert des Tuningparameters wird ein Modell berechnet:</p>
<div class="sourceCode" id="cb277"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_grid_search</span> <span class="op">&lt;-</span>
  <span class="fu">tune_grid</span><span class="op">(</span>
    <span class="va">ames_wflow</span>,
    resamples <span class="op">=</span> <span class="va">ames_folds</span>
  <span class="op">)</span>
<span class="va">ames_grid_search</span></code></pre></div>
<pre><code>## # Tuning results
## # 10-fold cross-validation using stratification 
## # A tibble: 10 Ã— 4
##    splits             id     .metrics          .notes          
##    &lt;list&gt;             &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          
##  1 &lt;split [1976/221]&gt; Fold01 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  2 &lt;split [1976/221]&gt; Fold02 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  3 &lt;split [1976/221]&gt; Fold03 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  4 &lt;split [1976/221]&gt; Fold04 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  5 &lt;split [1977/220]&gt; Fold05 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  6 &lt;split [1977/220]&gt; Fold06 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  7 &lt;split [1978/219]&gt; Fold07 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  8 &lt;split [1978/219]&gt; Fold08 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
##  9 &lt;split [1979/218]&gt; Fold09 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;
## 10 &lt;split [1980/217]&gt; Fold10 &lt;tibble [16 Ã— 5]&gt; &lt;tibble [0 Ã— 3]&gt;</code></pre>
<p>Im Default berechnet <code>tiymodels</code> 10 Kandidatenmodelle.</p>
<p>Die Spalte <code>.metrics</code> beinhaltet die ModellgÃ¼te fÃ¼r jedes Kandidatenmodell.</p>
<div class="sourceCode" id="cb279"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_grid_search</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">collect_metrics</span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 16 Ã— 7
##        K .metric .estimator   mean     n std_err .config             
##    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
##  1     2 rmse    standard   0.103     10 0.00213 Preprocessor1_Model1
##  2     2 rsq     standard   0.662     10 0.0112  Preprocessor1_Model1
##  3     4 rmse    standard   0.0950    10 0.00188 Preprocessor1_Model2
##  4     4 rsq     standard   0.708     10 0.00916 Preprocessor1_Model2
##  5     6 rmse    standard   0.0912    10 0.00189 Preprocessor1_Model3
##  6     6 rsq     standard   0.732     10 0.00842 Preprocessor1_Model3
##  7     7 rmse    standard   0.0900    10 0.00192 Preprocessor1_Model4
##  8     7 rsq     standard   0.740     10 0.00829 Preprocessor1_Model4
##  9     9 rmse    standard   0.0883    10 0.00201 Preprocessor1_Model5
## 10     9 rsq     standard   0.752     10 0.00827 Preprocessor1_Model5
## 11    11 rmse    standard   0.0872    10 0.00211 Preprocessor1_Model6
## 12    11 rsq     standard   0.761     10 0.00845 Preprocessor1_Model6
## 13    13 rmse    standard   0.0865    10 0.00217 Preprocessor1_Model7
## 14    13 rsq     standard   0.767     10 0.00848 Preprocessor1_Model7
## 15    15 rmse    standard   0.0861    10 0.00221 Preprocessor1_Model8
## 16    15 rsq     standard   0.772     10 0.00850 Preprocessor1_Model8</code></pre>
<p>Das kÃ¶nnen wir uns einfach visualisieren lassen:</p>
<div class="sourceCode" id="cb281"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/autoplot.html">autoplot</a></span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="080-Resampling-Tuning_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;"></div>
<p>Auf Basis dieser Ergebnisse kÃ¶nnte es Sinn machen,
noch grÃ¶ÃŸere Werte fÃ¼r <span class="math inline">\(K\)</span> zu Ã¼berprÃ¼fen.</p>
</div>
<div id="vorhersage-im-test-sample" class="section level3" number="7.10.3">
<h3>
<span class="header-section-number">7.10.3</span> Vorhersage im Test-Sample<a class="anchor" aria-label="anchor" href="#vorhersage-im-test-sample"><i class="fas fa-link"></i></a>
</h3>
<p>Welches Modellkandidat war jetzt am besten?</p>
<div class="sourceCode" id="cb282"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">show_best</span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 5 Ã— 7
##       K .metric .estimator   mean     n std_err .config             
##   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1    15 rmse    standard   0.0861    10 0.00221 Preprocessor1_Model8
## 2    13 rmse    standard   0.0865    10 0.00217 Preprocessor1_Model7
## 3    11 rmse    standard   0.0872    10 0.00211 Preprocessor1_Model6
## 4     9 rmse    standard   0.0883    10 0.00201 Preprocessor1_Model5
## 5     7 rmse    standard   0.0900    10 0.00192 Preprocessor1_Model4</code></pre>
<p>WÃ¤hlen wir jetzt mal das beste Modell aus (im Sinne des Optimierungskriteriusms):</p>
<div class="sourceCode" id="cb284"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">select_best</span><span class="op">(</span><span class="va">ames_grid_search</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 Ã— 2
##       K .config             
##   &lt;int&gt; &lt;chr&gt;               
## 1    15 Preprocessor1_Model8</code></pre>
<p>Ok,
notieren wir uns die Kombination der Tuningparameterwerte
im besten Kandiatenmodell.
In diesem Fall hat das Modull nur einen Tuningparameter:</p>
<div class="sourceCode" id="cb286"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_knn_best_params</span> <span class="op">&lt;-</span>
  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>K <span class="op">=</span> <span class="fl">15</span><span class="op">)</span></code></pre></div>
<p>Unser Workflow weiÃŸ noch nicht,
welche Tuningparameterwerte am besten sind:</p>
<div class="sourceCode" id="cb287"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_wflow</span></code></pre></div>
<pre><code>## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 4 Recipe Steps
## 
## â€¢ step_log()
## â€¢ step_other()
## â€¢ step_dummy()
## â€¢ step_zv()
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## K-Nearest Neighbor Model Specification (regression)
## 
## Main Arguments:
##   neighbors = tune("K")
## 
## Computational engine: kknn</code></pre>
<p><code>neighbors = tune("K")</code> sagt uns,
dass er diesen Parameter tunen will.
Das haben wir jetzt ja erledigt.
Wir wollen fÃ¼r das Test-Sample nur noch einen Wert,
eben aus dem besten Kandidatenmodell,
verwenden:</p>
<div class="sourceCode" id="cb289"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ames_final_wflow</span> <span class="op">&lt;-</span>
  <span class="va">ames_wflow</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> 
  <span class="fu">finalize_workflow</span><span class="op">(</span><span class="va">ames_knn_best_params</span><span class="op">)</span>

<span class="va">ames_final_wflow</span></code></pre></div>
<pre><code>## â•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## â”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## 4 Recipe Steps
## 
## â€¢ step_log()
## â€¢ step_other()
## â€¢ step_dummy()
## â€¢ step_zv()
## 
## â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
## K-Nearest Neighbor Model Specification (regression)
## 
## Main Arguments:
##   neighbors = 15
## 
## Computational engine: kknn</code></pre>
<p>Wie man sieht,
steht im Workflow nichts mehr von Tuningparameter.</p>
<p>Wir kÃ¶nnen jetzt das <em>ganze Train-Sample</em> fitten,
also das Modell auf das ganze Train-Sample anwenden -
nicht nur auf ein Analysis-Sample.
Und mit den dann resultierenden Modellkoeffizienten sagen
wir das TestSample vorher:</p>
<div class="sourceCode" id="cb291"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">final_ames_knn_fit</span> <span class="op">&lt;-</span>
  <span class="fu">last_fit</span><span class="op">(</span><span class="va">ames_final_wflow</span>, <span class="va">data_split</span><span class="op">)</span>

<span class="va">final_ames_knn_fit</span></code></pre></div>
<pre><code>## # Resampling results
## # Manual resampling 
## # A tibble: 1 Ã— 6
##   splits             id               .metrics .notes   .predictions .workflow 
##   &lt;list&gt;             &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    
## 1 &lt;split [2197/733]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;</code></pre>
<p>Holen wir uns die ModellgÃ¼te:</p>
<div class="sourceCode" id="cb293"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">collect_metrics</span><span class="op">(</span><span class="va">final_ames_knn_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 2 Ã— 4
##   .metric .estimator .estimate .config             
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 rmse    standard      0.0951 Preprocessor1_Model1
## 2 rsq     standard      0.736  Preprocessor1_Model1</code></pre>
<!-- ### Vorhersage von Hand -->
<!-- NatÃ¼rlich kÃ¶nnten wir auch "von Hand" vorhersagen: -->
<!-- ```{r ames-fit-von-hand} -->
<!-- final_ames_knn_fit <- -->
<!--   ames_final_wflow %>%  -->
<!--   fit(ames_train) -->
<!-- ``` -->
<!-- Man beachte, -->
<!-- dass die VorhersagegÃ¼te fÃ¼r das Train-Sample Ã¼beroptimistisch ist. -->
<!-- Und jetzt sagen wir auf dieser Basis das Test-Sample vorher: -->
<!-- ```{r error = TRUE} -->
<!-- ames_pred <- -->
<!--   predict(final_ames_knn_fit, new_data = ames_test) -->
<!-- ``` -->
<!-- Oh Nein! Es geht nicht, woran liegt das wohl? -->
<!-- Wir mÃ¼ssen noch die Transformationen des Rezept auf das Test-Sample anwenden.  -->
<!-- Puh, ganz schÃ¶n unkomfortabel. -->
<!-- Es ist nicht empfehlenswert, den folgenden Weg einzuschlagen, -->
<!-- viel einfacher ist es, mit `last_fit()` seine Ergebnisse zu bekommen. -->
<!-- Aber sei's drum, jetzt ziehen wir das halt mal durch. -->
<!-- Zuerst berechnen wir die Werte des *Rezepts*, z.B. -->
<!-- die MW- und SD-Werte fÃ¼r z-Transformationen oder die Anzahl -->
<!-- der PrÃ¤diktoren im Datensatz. -->
<!-- ```{r ames-prep} -->
<!-- ames_prep <- -->
<!--   prep(ames_rec, training = ames_train) -->
<!-- ames_prep -->
<!-- ``` -->
<!-- Mit `prep()` haben wir *nur* das Rezept berechnet, -->
<!-- noch kein Modell auf einen Datensatz gefittet! -->
<!-- Alternativ kÃ¶nnten wir uns das trainierte Rezept auch so holen: -->
<!-- ```{r} -->
<!-- extract_recipe(final_ames_knn_fit) -->
<!-- ``` -->
<!-- Jetzt wenden wir das Rezept auf den Test-Datensatz an: -->
<!-- ```{r ames-bake} -->
<!-- ames_test_baked <-  -->
<!--   bake(ames_prep, new_data = ames_test) -->
<!-- ``` -->
<!-- Das Ergebnis ist jetzt der "gebackene" Datensatz `ames_test_baked`, -->
<!-- in dem jetzt die Transformationen des Test-Samples angewendet sind. -->
<!-- Damit kÃ¶nnen wir jetzt die Vorhersagen im Test-Sample durchfÃ¼hren. -->
<!-- ```{r ames-pred-final-von-hand, error = TRUE} -->
<!-- ames_pred <- -->
<!--   predict(final_ames_knn_fit, new_data = ames_test) -->
<!-- ``` -->
<!-- Und damit haben wir unsere ModellgÃ¼te fÃ¼r das Test-Sample. -->
<!-- ## Aufgaben und Vertiefung -->
</div>
</div>
<div id="aufgaben-4" class="section level2" number="7.11">
<h2>
<span class="header-section-number">7.11</span> Aufgaben<a class="anchor" aria-label="anchor" href="#aufgaben-4"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li>Arbeiten Sie sich so gut als mÃ¶glich durch <a href="https://github.com/sebastiansauer/covid-icu">diese Analyse zum Verlauf von Covid-FÃ¤llen</a>
</li>
<li><a href="https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/">Fallstudie zur Modellierung einer logististischen Regression mit tidymodels</a></li>
<li><a href="https://juliasilge.com/blog/multinomial-volcano-eruptions/">Fallstudie zu VulkanausbrÃ¼chen</a></li>
<li><a href="https://juliasilge.com/blog/himalayan-climbing/">Fallstudie Himalaya</a></li>
</ul>
</div>
<div id="vertiefung-2" class="section level2" number="7.12">
<h2>
<span class="header-section-number">7.12</span> Vertiefung<a class="anchor" aria-label="anchor" href="#vertiefung-2"><i class="fas fa-link"></i></a>
</h2>
<ul>
<li><a href="https://xkcd.com/435/">Fields arranged by purity, xkcd 435</a></li>
</ul>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="knn.html"><span class="header-section-number">6</span> kNN</a></div>
<div class="next"><a href="logistische-regression.html"><span class="header-section-number">8</span> Logistische Regression</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#resampling-und-tuning"><span class="header-section-number">7</span> Resampling und Tuning</a></li>
<li>
<a class="nav-link" href="#lernsteuerung-4"><span class="header-section-number">7.1</span> Lernsteuerung</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#vorbereitung-3"><span class="header-section-number">7.1.1</span> Vorbereitung</a></li>
<li><a class="nav-link" href="#lernziele-5"><span class="header-section-number">7.1.2</span> Lernziele</a></li>
<li><a class="nav-link" href="#literatur-5"><span class="header-section-number">7.1.3</span> Literatur</a></li>
</ul>
</li>
<li><a class="nav-link" href="#%C3%BCberblick-2"><span class="header-section-number">7.2</span> Ãœberblick</a></li>
<li>
<a class="nav-link" href="#tidymodels-1"><span class="header-section-number">7.3</span> tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#datensatz-aufteilen"><span class="header-section-number">7.3.1</span> Datensatz aufteilen</a></li>
<li><a class="nav-link" href="#rezept-modell-und-workflow-definieren"><span class="header-section-number">7.3.2</span> Rezept, Modell und Workflow definieren</a></li>
</ul>
</li>
<li><a class="nav-link" href="#resampling"><span class="header-section-number">7.4</span> Resampling</a></li>
<li>
<a class="nav-link" href="#illustration-des-resampling"><span class="header-section-number">7.5</span> Illustration des Resampling</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#einfache-v-fache-kreuzvalidierung"><span class="header-section-number">7.5.1</span> Einfache v-fache Kreuzvalidierung</a></li>
<li><a class="nav-link" href="#wiederholte-kreuzvalidierung"><span class="header-section-number">7.5.2</span> Wiederholte Kreuzvalidierung</a></li>
<li><a class="nav-link" href="#resampling-passiert-im-train-sample"><span class="header-section-number">7.5.3</span> Resampling passiert im Train-Sample</a></li>
<li><a class="nav-link" href="#andere-illustrationen"><span class="header-section-number">7.5.4</span> Andere Illustrationen</a></li>
</ul>
</li>
<li><a class="nav-link" href="#gesetz-der-gro%C3%9Fen-zahl"><span class="header-section-number">7.6</span> Gesetz der groÃŸen Zahl</a></li>
<li><a class="nav-link" href="#%C3%BCber--und-unteranpassung-an-einem-beispiel"><span class="header-section-number">7.7</span> Ãœber- und Unteranpassung an einem Beispiel</a></li>
<li>
<a class="nav-link" href="#cv-in-tidymodels"><span class="header-section-number">7.8</span> CV in tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#cv-definieren"><span class="header-section-number">7.8.1</span> CV definieren</a></li>
<li><a class="nav-link" href="#resamples-fitten"><span class="header-section-number">7.8.2</span> Resamples fitten</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tuning"><span class="header-section-number">7.9</span> Tuning</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#tuning-auszeichnen"><span class="header-section-number">7.9.1</span> Tuning auszeichnen</a></li>
<li><a class="nav-link" href="#grid-search-vs.-iterative-search"><span class="header-section-number">7.9.2</span> Grid Search vs.Â Iterative Search</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#tuning-mit-tidymodels"><span class="header-section-number">7.10</span> Tuning mit Tidymodels</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#datenabh%C3%A4ngige-tuningparameter"><span class="header-section-number">7.10.1</span> DatenabhÃ¤ngige Tuningparameter</a></li>
<li><a class="nav-link" href="#modelle-mit-tuning-berechnen"><span class="header-section-number">7.10.2</span> Modelle mit Tuning berechnen</a></li>
<li><a class="nav-link" href="#vorhersage-im-test-sample"><span class="header-section-number">7.10.3</span> Vorhersage im Test-Sample</a></li>
</ul>
</li>
<li><a class="nav-link" href="#aufgaben-4"><span class="header-section-number">7.11</span> Aufgaben</a></li>
<li><a class="nav-link" href="#vertiefung-2"><span class="header-section-number">7.12</span> Vertiefung</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/sebastiansauer/datascience1/blob/master/080-Resampling-Tuning.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/sebastiansauer/datascience1/edit/master/080-Resampling-Tuning.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>DataScience1</strong>: Grundlagen der Prognosemodellierung ğŸ”®ğŸ§°" was written by Sebastian Sauer. It was last built on 2022-05-22 00:46:40.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
