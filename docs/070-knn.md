# kNN

## Lernsteuerung


<!-- Chapter Start sections: Lernziele, Literatur, Hinweise, ... -->


### Lernziele 

- Sie sind in der Lage, einfache Klassifikationsmodelle zu spezifizieren mit tidymodels
- Sie können den knn-Algorithmus erläutern
- Sie können den knn-Algorithmus in tidymodels anwenden
- Sie können die Gütemetriken von Klassifikationsmodellen einschätzen



### Literatur 

- Rhys, Kap. 3
- [Timbers et al., Kap. 5](https://datasciencebook.ca/classification.html#classification)


## Überblick

In diesem Kapitel geht es um das Verfahren *KNN*, *K-Nächste-Nachbarn*.




Benötigte R-Pakete für dieses Kapitel:


```r
library(tidyverse)
library(tidymodels)
```





## Intuitive Erklärung

*K-Nächste-Nachbarn* (k nearest neighbors, kNN) ist ein einfacher Algorithmus des maschinellen Lernens,
der sowohl für Klassifikation als auch für numerische Vorhersage (Regression) genutzt werden kann.
Wir werden kNN als Beispiel für eine Klassifikation betrachten.


Betrachen wir ein einführendes Beispiel von @rhys, für das es eine [Online-Quelle](https://livebook.manning.com/book/machine-learning-for-mortals-mere-and-otherwise/chapter-3/22) gibt.
Stellen Sie sich vor, wir laufen durch englische Landschaft,
vielleicht die Grafschaft Kent, und sehen ein kleines Tier durch das Gras huschen.
Eine Schlange?!
In England gibt es (laut @rhys) nur eine giftige Schlange,
die Otter (Adder). 
Eine andere Schlange, die *Grass Snake* ist nicht giftig,
und dann kommt noch der *Slow Worm* in Frage,
der gar nicht zur Familie der Schlangen gehört.
Primär interessiert uns die Frage, haben wir jetzt eine Otter gesehen?
Oder was für ein Tier war es?

Zum Glück wissen wir einiges über Schlangen bzw. schlangenähnliche Tiere Englands.
Nämlich können wir die betreffenden Tierarten in Größe und Aggressivität einschätzen,
das ist in Abbildung \@ref(fig:slang) dargestellt.

<div class="figure" style="text-align: center">
<img src="img/rhys-fig3-2.jpeg" alt="Haben wir gerade eine Otter gesehen?" width="70%" />
<p class="caption">(\#fig:slang)Haben wir gerade eine Otter gesehen?</p>
</div>

Der Algorithmus von kNN sieht einfach gesagt vor,
dass wir schauen, welcher Tierarten Tiere mit ähnlicher Aggressivität und Größe angehören.
Die Tierart die bei diesen "Nachbarn" hinsichtlich Ähnlichkeit relevanter Merkmale am häufigsten vertreten ist, ordnen wir die bisher unklassifizierte Beobachtung zu.

Etwas zugespitzt:

>   Wenn es quakt wie eine Ente, läuft wie eine Ente und aussieht wie eine Ente, dann ist es eine Ente.


Die Anzahl $k$ der nächsten Nachbarn können wir frei wählen; 
der Wert wird *nicht* vom Algorithmuss bestimmt.
Solche vom Nutzi zu bestimmenden Größen nennt man auch *Tuningparameter*.




## Krebsdiagnostik

Betrachten wir ein Beispiel von @timbers_data_2022,
das [hier](https://datasciencebook.ca/classification.html#classification-with-k-nearest-neighbors) frei eingesehen werden kann.

Die Daten sind so zu beziehen:



```r
data_url <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv"
cancer <- read_csv(data_url)
```

In diesem Beispiel versuchen wir Tumore der Brust zu klassifizieren,
ob sie einen schweren Verlauf (maligne, engl. malignant) oder einen weniger schweren Verlauf (benigne, engl. benign) erwarten lassen.
Der Datensatz ist [hier](https://datasciencebook.ca/classification.html#describing-the-variables-in-the-cancer-data-set) näher erläutert.


Wie in Abb. \@ref(fig:cancer1) ersichtlich,
steht eine Tumordiagnose (malignant vs. benign) in Abhängigkeit
von Umfang (engl. perimeter) und [Konkavität](https://de.wikipedia.org/wiki/Konvexe_und_konkave_Funktionen),
die "Gekrümmtheit nach innen".

<div class="figure" style="text-align: center">
<img src="chunk-img/tidymodelscancer1-1.png" alt="Streudiagramm zur Einschätzung von Tumordiagnosen" width="70%" />
<p class="caption">(\#fig:cancer1)Streudiagramm zur Einschätzung von Tumordiagnosen</p>
</div>

Wichtig ist, dass die Merkmale standardisiert sind, also eine identische Skalierung aufweisen,
da sonst das Merkmal mit kleinerer Skala weniger
in die Berechnung der Nähe (bzw. Abstand) eingeht.

Für einen neuen, bisher unklassifizierten Fall suchen nur nun nach einer Diagnose,
also nach der am besten passenden Diagnose (maligne oder benigne),
s. Abb. \@ref(fig:cancer2), wieder aus @timbers_data_2022.
Ihr Quellcode für dieses Diagramm (und das ganze Kapitel) findet sich [hier](https://github.com/UBC-DSCI/introduction-to-datascience/blob/master/classification1.Rmd).

<div class="figure" style="text-align: center">
<img src="chunk-img/tidymodelscancer2-1.png" alt="Ein neuer Fall, bisher unklassifiziert" width="70%" />
<p class="caption">(\#fig:cancer2)Ein neuer Fall, bisher unklassifiziert</p>
</div>

Wir können zunächst den (im euklidischen Koordinatensystem) nächst gelegenen Fall (der "nächste Nachbar") betrachten,
und vereinbaren, 
dass wir dessen Klasse als Schätzwert für den unklassiffizierten Fall übernehmen,
s. Abb. \@ref(fig:cancer3).


<div class="figure" style="text-align: center">
<img src="chunk-img/tidymodelscancer3-1.png" alt="Ein nächster Nachbar" width="70%" />
<p class="caption">(\#fig:cancer3)Ein nächster Nachbar</p>
</div>


Betrachten wir einen anderen zu klassifizierenden Fall, s. Abb \@ref(fig:cancer4).
Ob hier die Klassifikation von "benign" korrekt ist?
Womöglich nicht, denn viele andere Nachbarn, 
die etwas weiter weg gelegen sind, gehören zur anderen Diagnose, malign.


<div class="figure" style="text-align: center">
<img src="https://datasciencebook.ca/_main_files/figure-html/05-knn-4-1.png" alt="Trügt der nächste Nachbar?" width="70%" />
<p class="caption">(\#fig:cancer4)Trügt der nächste Nachbar?</p>
</div>

Um die Vorhersage zu verbessern,
können wir nicht nur den nächst gelegenen Nachbarn betrachten,
sondern die $k$ nächst gelegenen, z.B. $k=3$, s. Abb \@ref(fig:cancer5).


<div class="figure" style="text-align: center">
<img src="https://datasciencebook.ca/_main_files/figure-html/05-knn-5-1.png" alt="kNN mit k=3" width="70%" />
<p class="caption">(\#fig:cancer5)kNN mit k=3</p>
</div>


Die Entscheidungsregel ist dann einfach eine Mehrheitsentscheidung:
Wir klassifizieren den neuen Fall entsprechend der Mehrheit in den $k$ nächst gelegenen Nachbarn.


## Berechnung der Nähe


Es gibt verschiedenen Algorithmen,
um die Nähe bzw. Distanz der Nachbarn zum zu klassifizieren Fall zu berechnen.

Eine gebräuchliche Methode ist der *euklidische* Abstand,
der mit Pythagoras berechnet werden kann, s. Abb. \@ref(fig:pyth1) aus @modar.


<div class="figure" style="text-align: center">
<img src="img/distanz_crop.png" alt="Euklidischer Abstand wird mit der Regel von Pythagoras berechnet" width="70%" />
<p class="caption">(\#fig:pyth1)Euklidischer Abstand wird mit der Regel von Pythagoras berechnet</p>
</div>

Wie war das noch mal?

$$c^2 = a^2 + b^2$$

Im Beispiel oben also:

$c^2 = 3^2 + 4^2 = 5^2$

Damit gilt: $c = \sqrt{c^2} = \sqrt{5^2}=5$.


Im 2D-Raum ist das so einfach, dass man das (fat) mit bloßem Augenschein entscheiden kann.
In mehr als 2 Dimensionen wird es aber schwierig für das Auge, wie ein [Beispiel](https://datasciencebook.ca/classification.html#more-than-two-explanatory-variables) aus @timbers_data_2022 zeigt.


Allerdings kann man den guten alten Pythagoras auch auf Dreiecke mit mehr als zwei Dimensionen anwenden, s. Abb. \@ref(fig:pyth2) aus @modar, Kap. 21.1.2.


<!-- ```{r pyth2, echo = FALSE, fig.cap = "Pythagoras aufgebohrt"} -->
<!-- knitr::include_graphics("img/pythagoras_crop.png") -->
<!-- ``` -->



<div class="figure" style="text-align: center">
<img src="img/pythagoras-crop.png" alt="Pythagoras in der Ebene (links) und in 3D (rechts)" width="45%" /><img src="img/pythagoras2-crop.png" alt="Pythagoras in der Ebene (links) und in 3D (rechts)" width="45%" />
<p class="caption">(\#fig:pyth2)Pythagoras in der Ebene (links) und in 3D (rechts)</p>
</div>

Bleiben wir beim Beispiel von Anna und Berta und nehmen wir eine dritte Variable 
hinzu (Statistikliebe). 
Sagen wir, der Unterschied in dieser dritten Variable zwischen Anna und Berta betrage 2.

Es gilt:

$$
\begin{aligned}
e^2 &= c^2 + d^2 \\
e^2 &= 5^2 + 2^2 \\
e^2 &= 25 + 4\\
e &= \sqrt{29} \approx 5.4
\end{aligned}
$$





## kNN mit Tidymodels


### Analog zu Timbers et al.

Eine Anwendung von kNN mit Tidymodels ist in @timbers_data_2022, Kap. 5.6, [hier](https://datasciencebook.ca/classification.html#k-nearest-neighbors-with-tidymodels) beschrieben.


Die Daten aus @timbers_data_2022 finden sich [in diesem Github-Repo](https://github.com/UBC-DSCI/introduction-to-datascience/tree/master/data)-

Die (z-transformierten) Daten zur Tumorklassifikation können [hier](https://raw.githubusercontent.com/UBC-DSCI/data-science-a-first-intro-worksheets/main/worksheet_classification1/data/clean-wdbc-data.csv) bezogen werden.



```r
data_url <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/wdbc.csv"
cancer <- read_csv(data_url)
```

@timbers_data_2022 verwenden in Kap. 5 auch noch nicht standardisierte Daten, `unscales_wdbc.csv`, die [hier](https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv) als CSV-Datei heruntergeladen werden können.



```r
cancer_unscales_path <- "https://raw.githubusercontent.com/UBC-DSCI/introduction-to-datascience/master/data/unscaled_wdbc.csv"

unscaled_cancer <- read_csv(cancer_unscales_path) |>
  mutate(Class = as_factor(Class)) |>
  select(Class, Area, Smoothness)
unscaled_cancer
```

```
## # A tibble: 569 × 3
##    Class  Area Smoothness
##    <fct> <dbl>      <dbl>
##  1 M     1001      0.118 
##  2 M     1326      0.0847
##  3 M     1203      0.110 
##  4 M      386.     0.142 
##  5 M     1297      0.100 
##  6 M      477.     0.128 
##  7 M     1040      0.0946
##  8 M      578.     0.119 
##  9 M      520.     0.127 
## 10 M      476.     0.119 
## # … with 559 more rows
```

### Rezept definieren


```r
uc_recipe <- recipe(Class ~ ., data = unscaled_cancer)
print(uc_recipe)
```

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          2
```

Und jetzt die z-Transformation:



```r
uc_recipe <- 
  uc_recipe |>
  step_scale(all_predictors()) |>
  step_center(all_predictors())
```


Die Schritte `prep()` und `bake()` sparen wir uns, da `fit()` und `predict()` 
das für uns besorgen.

### Modell definieren



```r
knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = 5) |>
  set_engine("kknn") |>
  set_mode("classification")
knn_spec
```

```
## K-Nearest Neighbor Model Specification (classification)
## 
## Main Arguments:
##   neighbors = 5
##   weight_func = rectangular
## 
## Computational engine: kknn
```

### Workflow definieren


```r
knn_fit <- workflow() |>
  add_recipe(uc_recipe) |>
  add_model(knn_spec) |>
  fit(data = unscaled_cancer)

knn_fit
```

```
## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 2 Recipe Steps
## 
## • step_scale()
## • step_center()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(5,     data, 5), kernel = ~"rectangular")
## 
## Type of response variable: nominal
## Minimal misclassification: 0.1107206
## Best kernel: rectangular
## Best k: 5
```

### Vorhersagen



```r
new_observation <- tibble(Area = c(500, 1500), Smoothness = c(0.075, 0.1))
prediction <- predict(knn_fit, new_observation)

prediction
```

```
## # A tibble: 2 × 1
##   .pred_class
##   <fct>      
## 1 B          
## 2 M
```



## Mit Train-Test-Aufteilung

Im Kapitel 5 greifen @timbers_data_2022 die Aufteilung in Train- vs. Test-Sample noch nicht auf (aber in Kapitel 6).

Da in diesem Kurs diese Aufteilung aber schon besprochen wurde,
soll dies hier auch dargestellt werden.


```r
cancer_split <- initial_split(cancer, prop = 0.75, strata = Class)
cancer_train <- training(cancer_split)
cancer_test <- testing(cancer_split) 
```



### Rezept definieren


```r
cancer_recipe <- recipe(Class ~ Smoothness + Concavity, data = cancer_train) |>
  step_scale(all_predictors()) |>
  step_center(all_predictors())
```


### Modell definieren



```r
knn_spec <- nearest_neighbor(weight_func = "rectangular", neighbors = 3) |>
  set_engine("kknn") |>
  set_mode("classification")
```



### Workflow definieren



```r
knn_fit <- workflow() |>
  add_recipe(cancer_recipe) |>
  add_model(knn_spec) |>
  fit(data = cancer_train)

knn_fit
```

```
## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 2 Recipe Steps
## 
## • step_scale()
## • step_center()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(3,     data, 5), kernel = ~"rectangular")
## 
## Type of response variable: nominal
## Minimal misclassification: 0.1361502
## Best kernel: rectangular
## Best k: 3
```


### Vorhersagen

Im Gegensatz zu @timbers_data_2022 verwenden wir hier `last_fit()` und `collect_metrics()`,
da wir dies  bereits eingeführt haben und künftig darauf aufbauen werden.




```r
cancer_test_fit <- last_fit(knn_fit, cancer_split)

cancer_test_fit
```

```
## # Resampling results
## # Manual resampling 
## # A tibble: 1 × 6
##   splits            id               .metrics .notes   .predictions .workflow 
##   <list>            <chr>            <list>   <list>   <list>       <list>    
## 1 <split [426/143]> train/test split <tibble> <tibble> <tibble>     <workflow>
```


### Modellgüte


```r
cancer_test_fit %>% collect_metrics()
```

```
## # A tibble: 2 × 4
##   .metric  .estimator .estimate .config             
##   <chr>    <chr>          <dbl> <chr>               
## 1 accuracy binary         0.902 Preprocessor1_Model1
## 2 roc_auc  binary         0.935 Preprocessor1_Model1
```

Die eigentlichen Predictions stecken in der Listenspalte `.predictions` im Fit-Objekt:


```r
names(cancer_test_fit)
```

```
## [1] "splits"       "id"           ".metrics"     ".notes"       ".predictions"
## [6] ".workflow"
```

Genau genommen ist `.predictions` eine Spalte, in der in jeder Zeile (und damit Zelle) eine Tabelle (Tibble) steht. 
Wir haben nur eine Zeile und wollen das erste Element dieser Spalte herausziehen.
Da hilft `pluck()`:


```r
cancer_test_predictions <- 
cancer_test_fit %>% 
  pluck(".predictions", 1)

confusion <- cancer_test_predictions |>
             conf_mat(truth = Class, estimate = .pred_class)

confusion
```

```
##           Truth
## Prediction  B  M
##          B 82  6
##          M  8 47
```



### Visualisierung



```r
autoplot(confusion, type = "mosaic")
autoplot(confusion, type = "heatmap") +
  labs(x = "Beobachtung",
       y = "Vorhersage",
       title = "Konfusionsmatrix")
```

<img src="chunk-img/tidymodelsunnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /><img src="chunk-img/tidymodelsunnamed-chunk-18-2.png" width="70%" style="display: block; margin: auto;" />


## Kennzahlen der Klassifikation


In @modar, Kap. 19.6, findet sich einige Erklärung zu Kennzahlen der Klassifikationsgüte.

Ein Test kann vier verschiedenen Ergebnisse haben:


```{=html}
<div id="beqwxkrufh" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#beqwxkrufh .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#beqwxkrufh .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#beqwxkrufh .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#beqwxkrufh .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#beqwxkrufh .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#beqwxkrufh .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#beqwxkrufh .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#beqwxkrufh .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#beqwxkrufh .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#beqwxkrufh .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#beqwxkrufh .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#beqwxkrufh .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#beqwxkrufh .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#beqwxkrufh .gt_from_md > :first-child {
  margin-top: 0;
}

#beqwxkrufh .gt_from_md > :last-child {
  margin-bottom: 0;
}

#beqwxkrufh .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#beqwxkrufh .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#beqwxkrufh .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#beqwxkrufh .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#beqwxkrufh .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#beqwxkrufh .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#beqwxkrufh .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#beqwxkrufh .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#beqwxkrufh .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#beqwxkrufh .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#beqwxkrufh .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#beqwxkrufh .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#beqwxkrufh .gt_left {
  text-align: left;
}

#beqwxkrufh .gt_center {
  text-align: center;
}

#beqwxkrufh .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#beqwxkrufh .gt_font_normal {
  font-weight: normal;
}

#beqwxkrufh .gt_font_bold {
  font-weight: bold;
}

#beqwxkrufh .gt_font_italic {
  font-style: italic;
}

#beqwxkrufh .gt_super {
  font-size: 65%;
}

#beqwxkrufh .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  <caption>(#tab:class-stats)Vier Arten von Ergebnissen von Klassifikationen</caption>
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Wahrheit</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Als negativ (-) vorhergesagt</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Als positiv (+) vorhergesagt</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Summe</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">In Wahrheit negativ (-)</td>
<td class="gt_row gt_left">Richtig negativ (RN)</td>
<td class="gt_row gt_left">Falsch positiv (FP)</td>
<td class="gt_row gt_left">N</td></tr>
    <tr><td class="gt_row gt_left">In Wahrheit positiv (+)</td>
<td class="gt_row gt_left">Falsch negativ (FN)</td>
<td class="gt_row gt_left">Richtig positiv (RN)</td>
<td class="gt_row gt_left">P</td></tr>
    <tr><td class="gt_row gt_left">Summe</td>
<td class="gt_row gt_left">N*</td>
<td class="gt_row gt_left">P*</td>
<td class="gt_row gt_left">N+P</td></tr>
  </tbody>
  
  
</table>
</div>
```


Es gibt eine verwirrende Vielfalt von Kennzahlen,
um die Güte einer Klassifikation einzuschätzen.
Hier sind einige davon:



```{=html}
<div id="sbwbhhfcoc" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#sbwbhhfcoc .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#sbwbhhfcoc .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sbwbhhfcoc .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#sbwbhhfcoc .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#sbwbhhfcoc .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sbwbhhfcoc .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#sbwbhhfcoc .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#sbwbhhfcoc .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#sbwbhhfcoc .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#sbwbhhfcoc .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#sbwbhhfcoc .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#sbwbhhfcoc .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#sbwbhhfcoc .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#sbwbhhfcoc .gt_from_md > :first-child {
  margin-top: 0;
}

#sbwbhhfcoc .gt_from_md > :last-child {
  margin-bottom: 0;
}

#sbwbhhfcoc .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#sbwbhhfcoc .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#sbwbhhfcoc .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbwbhhfcoc .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#sbwbhhfcoc .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#sbwbhhfcoc .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#sbwbhhfcoc .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#sbwbhhfcoc .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#sbwbhhfcoc .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sbwbhhfcoc .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#sbwbhhfcoc .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#sbwbhhfcoc .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#sbwbhhfcoc .gt_left {
  text-align: left;
}

#sbwbhhfcoc .gt_center {
  text-align: center;
}

#sbwbhhfcoc .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#sbwbhhfcoc .gt_font_normal {
  font-weight: normal;
}

#sbwbhhfcoc .gt_font_bold {
  font-weight: bold;
}

#sbwbhhfcoc .gt_font_italic {
  font-style: italic;
}

#sbwbhhfcoc .gt_super {
  font-size: 65%;
}

#sbwbhhfcoc .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 65%;
}
</style>
<table class="gt_table">
  <thead class="gt_header">
    <tr>
      <th colspan="3" class="gt_heading gt_title gt_font_normal" style>Geläufige Kennwerte der Klassifikation.</th>
    </tr>
    <tr>
      <th colspan="3" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>F: Falsch. R: Richtig. P: Positiv. N: Negativ</th>
    </tr>
  </thead>
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Name</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Definition</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Synonyme</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">FP-Rate</td>
<td class="gt_row gt_left">FP/N</td>
<td class="gt_row gt_left">Alphafehler, Typ-1-Fehler, 1-Spezifität, Fehlalarm</td></tr>
    <tr><td class="gt_row gt_left">RP-Rate</td>
<td class="gt_row gt_left">RP/N</td>
<td class="gt_row gt_left">Power, Sensitivität, 1-Betafehler, Recall</td></tr>
    <tr><td class="gt_row gt_left">FN-Rate</td>
<td class="gt_row gt_left">FN/N</td>
<td class="gt_row gt_left">Fehlender Alarm, Befafehler</td></tr>
    <tr><td class="gt_row gt_left">RN-Rate</td>
<td class="gt_row gt_left">RN/N</td>
<td class="gt_row gt_left">Spezifität, 1-Alphafehler</td></tr>
    <tr><td class="gt_row gt_left">Pos. Vorhersagewert</td>
<td class="gt_row gt_left">RP/P*</td>
<td class="gt_row gt_left">Präzision, Relevanz</td></tr>
    <tr><td class="gt_row gt_left">Neg. Vorhersagewert</td>
<td class="gt_row gt_left">RN/N*</td>
<td class="gt_row gt_left">Segreganz</td></tr>
    <tr><td class="gt_row gt_left">Richtigkeit</td>
<td class="gt_row gt_left">(RP+RN)/(N+P)</td>
<td class="gt_row gt_left">Korrektklassifikationsrate, Gesamtgenauigkeit</td></tr>
  </tbody>
  
  
</table>
</div>
```



## Krebstest-Beispiel

Betrachten wir Daten eines fiktiven Krebstest, aber realistischen
Daten.


```
## # A tibble: 1 × 7
##   format width height colorspace matte filesize density
##   <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  
## 1 PNG      500    429 sRGB       TRUE     40643 72x72
```

<img src="chunk-img/tidymodelsunnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;" />

Wie gut ist dieser Test?
Berechnen wir einige Kennzahlen.

Da die Funktionen zur Klassifikation stets einen Faktor wollen,
wandeln wir die relevanten Spalten zuerst in einen Faktor um (aktuell sind es numerische Spalten).



```r
krebstest <-
  krebstest  %>% 
  mutate(Krebs = factor(Krebs),
         Test = factor(Test))
```

Gesamtgenauigkeit:



```r
accuracy(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   <chr>    <chr>          <dbl>
## 1 accuracy binary          0.87
```



Sensitivität:


```r
sens(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 sens    binary         0.884
```

Spezifität:


```r
spec(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 spec    binary           0.6
```

Kappa:


```r
kap(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 kap     binary         0.261
```

Positiver Vorhersagewert:


```r
ppv(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 ppv     binary         0.977
```

Negativer Vorhersagewert:


```r
npv(krebstest, truth = Krebs, estimate = Test)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   <chr>   <chr>          <dbl>
## 1 npv     binary         0.214
```

Während Sensitivität und Spezitivität sehr hoch sind,
ist die der negative Vorhersagewert sehr gering:

Wenn man einen positiven Test erhält, ist die 
Wahrscheinlichkeit, in Wahrheit krank zu sein gering, zum Glück!









<!-- ## Aufgaben und Vertiefung -->




## Aufgaben 

- Arbeiten Sie sich so gut als möglich durch [diese Analyse zum Verlauf von Covid-Fällen](https://github.com/sebastiansauer/covid-icu)
- [Fallstudie zur Modellierung einer logististischen Regression mit tidymodels](https://onezero.blog/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1/)
- [Fallstudie zu Vulkanausbrüchen](https://juliasilge.com/blog/multinomial-volcano-eruptions/)
- [Fallstudie Himalaya](https://juliasilge.com/blog/himalayan-climbing/)




